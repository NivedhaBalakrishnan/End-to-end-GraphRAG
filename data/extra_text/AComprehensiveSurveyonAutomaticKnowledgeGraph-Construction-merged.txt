                                         A Comprehensive Survey on Automatic Knowledge Graph
                                         Construction
                                         LINGFENG ZHONG, Macquarie University, Australia
                                         JIA WU, Macquarie University, Australia
                                                                                                                                                                           66
arXiv:2302.05019v1 [cs.IR] 10 Feb 2023




                                         QIAN LI, Beihang University, China
                                         HAO PENG, Beihang University, China
                                         XINDONG WU, Hefei University of Technology, China
                                         Automatic knowledge graph construction aims to manufacture structured human knowledge. To this end,
                                         much effort has historically been spent extracting informative fact patterns from different data sources.
                                         However, more recently, research interest has shifted to acquiring conceptualized structured knowledge
                                         beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated
                                         construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms
                                         to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively
                                         survey more than 300 methods to summarize the latest developments in knowledge graph construction.
                                         A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge
                                         evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-
                                         grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity
                                         relationships in complex scenarios. The survey covers models for knowledge refinement, including knowledge
                                         graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically
                                         presented, including condition knowledge acquisition, condition knowledge graph completion, and knowledge
                                         dynamic. We present the paradigms to compare the distinction among these methods along the axis of the
                                         data environment, motivation, and architecture. Additionally, we also provide briefs on accessible resources
                                         that can help readers to develop practical knowledge graph systems. The survey concludes with discussions
                                         on the challenges and possible directions for future exploration.

                                         Additional Key Words and Phrases: knowledge graph, deep learning, information extraction, knowledge graph
                                         completion, knowledge fusion, logic reasoning
                                         ACM Reference Format:
                                         Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. 2022. A Comprehensive Survey on Automatic
                                         Knowledge Graph Construction. ACM Comput. Surv. 36, 4, Article 66 (July 2022), 50 pages. https://doi.org/
                                         0000001.0000001

                                         1    INTRODUCTION
                                         Knowledge graphs (KGs) provide well-organized human knowledge for applications like search
                                         engines [1], recommendation systems [2], and question answering [3].

                                         Authors‚Äô addresses: Lingfeng Zhong, Macquarie University, Sydney, NSW, Australia, dmiczlf@gmail.com; Jia Wu, Macquarie
                                         University, Sydney, NSW, Australia, jia.wu@mq.edu.au; Qian Li, Beihang University, Haidian, Beijing, China, liqian@
                                         act.buaa.edu.cn; Hao Peng, Beihang University, Haidian, Beijing, China, penghao@act.buaa.edu.cn; Xindong Wu, Hefei
                                         University of Technology, Hefei, China, uvmxwu@gmail.com.

                                         Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
                                         provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
                                         the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
                                         Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
                                         prior specific permission and/or a fee. Request permissions from permissions@acm.org.
                                         ¬© 2022 Association for Computing Machinery.
                                         0360-0300/2022/7-ART66 $15.00
                                         https://doi.org/0000001.0000001


                                                                                          ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:2                                                                                           Lingfeng Zhong, et al.


                            Knowledge Dynamics                                           ùë°1           ùë°2
                                                                                                                ‚Ä¶
                       Condition Knowledge Acquisition
                                                                                        KGs/Condition-KGs Group
                          Condition KG Completion               Knowledge Evolution     with Dynamic Information

                                    Knowledge Fusion
                       complete
 Existing KGs                         KG Completion            Knowledge Refinement
                                                                                              Refined KG
   Entity Linking                   Relation Extraction

       Entity Typing              Coreference Resolution
                                                               Knowledge Acquisition
                                     Entity Discovery                                         Raw KGs
       Named Entity
        Recognition
                                                                </XML>                     John is from
                                                                                           London.         ‚Ä¶
                                                  Table         Web pages      images          text

Fig. 1. The general process of constructing a knowledge graph. In this diagram, semi-structured or unstruc-
tured input data is manufactured into a raw knowledge graph by acquiring knowledge. Then the knowledge
will be refined to complete the knowledge graph or enrich it with other existing knowledge graphs. If the
input is only an existing knowledge graph, it will be directly handled by the knowledge refinement process.
Last, the knowledge evolution process will try to obtain a group of knowledge graphs/conditional knowledge
graphs that contains dynamic information about the graph‚Äôs evolution.

   Many of the well-known large KG systems have been constructed through crowd-sourcing,
like Freebase [4] and Wikidata [5]. Hence, a systematic solution that can automatically build a
knowledge graph from unstructured or semi-structured data offers a massive boost to what is a
very arduous manual process for practical purposes.
   A knowledge graph is a semantic graph consisting of edges and nodes that depicts knowledge of
real-world objects. Within these structures, a knowledge tuple is the minimum knowledge-carrying
group. The tuples comprise two nodes representing concepts connected by an edge representing a
relationship. Thus, constructing a knowledge graph is the task of discovering the elements that
constitute a knowledge graph in a domain-specific or open-domain area. Early in the study of this
discipline, researchers were mostly focused on scratching out factual tuples from semi-structured
or unstructured textual data as patterned knowledge mentions. Information extraction systems
like TextRunner [6] and Knowitall [7] are the milestones for early knowledge graph construction,
driven by designated rules or clustering. Unfortunately, these designs are not sufficiently equipped
with background knowledge, and thus suffer from two major defects: 1) insubstantial, traditional in-
formation extraction systems do not create or distinguish entities from different expressions, which
prevents knowledge aggregation; 2) uninformative, traditional information extraction systems
only extract information from syntactic structures without capturing the semantic denotations in
the given expressions. Furthermore, conventional rule-based information extraction systems also
require heavy feature engineering and extra expert knowledge. Wu et al. [8] point out that if a KG
system does not organize nodes and edges with background knowledge about concepts, it is merely
a data graph.
   Regarding this issue, researchers then recourse to well-partitioned acquisition sub-tasks for
arranging semantic knowledge structures. The most classic paradigm is the pipeline that first
discovers and links conceptual entities, resolves coreference mentions, then extracts relationships
among entities. The general procedure of knowledge graph construction is displayed in Fig. 1.
   More recently, deep learning methods have given rise to tremendous breakthroughs in natural
language processing (NLP), and these breakthroughs have fed applications for knowledge graph

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                                           66:3


                                                                                                              <<occupation>>        Biden
                                                                                              John is          senator    VP            president
                                               </XML>                                         from                                                                          ‚Ä¶
Heterogenous                                                                                  London.
                                                                                                                1973      2009              2021

                      Table                   Web pages               images                   text                 Temporal Data                           Existing KGs


                                                                                              ‚Ä¶          User-personalized Data
Autonomous
                                                                                                         from Autonomous Communities

                                      ...‚Ä¶.
                                      ‚ÄúHe was with me in                  <<president-of>>
                                      River Avon during this
                                                                                          ‚úî              ‚Ä¶     ‚Ä¶
                John was visiting     trip.‚Äù, ‚Ä¶‚Ä¶
                                                                         Trump   U.S.A                                                                  ?
                England with his                                         Boris   France   X
                friend.
                ...‚Ä¶.                 ‚Ä¶‚Ä¶.                                  CONTEXT
                                                                                                                          Data
                                                                                                                                              Model
                                                                                                                                                             ?
Complex                               , said Leo in the previous           MISSING
                                                                                          ?
                                                                                                                                                                            ‚Ä¶
                                      record.
                    Long-term Context                                    Noisy Data               Low-resource Data                  Interpretability

                                Statement                          Statement                      Statement                    ùë°1                  ùë°2            ùë°3
              Condition        Fact           Condition              Fact    Condition              Fact
Evolving                                                                                                                                                          ?         ‚Ä¶
                <<ùëü1 >>    <<ùëü2 >>               <<ùëü3 >>       <<ùëü1 >>           <<ùëü4 >>       <<ùëü5 >>

                                              Conditional Facts                                                           Temporal Dynamics


Fig. 2. An illustration of the challenges framed by the HACE environments. In terms of heterogeneous data,
knowledge graph construction with semi-structured and unstructured data in outlined in Section 4. Methods
of refining existing knowledge graphs are detailed in Section 5. Methods of obtaining temporal data are
described in 6.1. Section 8.2 presents a discussion on multi-modal knowledge graphs. In terms of complex
data, long-term contexts and their involvement with multiple KG construction tasks are discussed in Sections
4.1.2, 4.2, 4.3.6. Methods for tackling noisy data are mainly presented in Section 4.3.3. Model interpretability is
covered in Section 5.1.3. In terms of evolving data, recent work in knowledge evolution is presented in Section
6, and research on autonomous data is discussed in Section 8.5.

construction in a range of respects. Numerous deep learning models have delivered good perfor-
mances with tasks like named entity recognition [9][10], entity typing [11][12], entity linking
[13][14], coreference resolution [15], relation extraction [16][17]. Additionally, deep knowledge
representation models have also been developed that can refine knowledge graphs. The refinements
include completing corrupt tuples, discovering new tuples in a built knowledge graph via its inner
graph structure, and merging graphs from different sources to construct new knowledge graphs.
At present, many knowledge bases1 , such as TransOMCS [18], ASER [19] and huapu [20] have put
automatic KG construction methods into practice.
   Further, with advances in the pre-training of deep learning models, such as the pre-trained
BERT model [21] and some of the massive-scale graph convolution network (GCN) models, KG
construction tasks are being applied to more complicated scenarios in the big data environment.
Beyond systems that deal with heterogeneous data, like web pages and table forms, more attention
is being paid to effective methods of tackling complex data ‚Äì for example, jointly unifying multiple
acquisition sub-tasks or solutions that harvest knowledge graphs from long-term contexts [22],
noisy data [23], or low-resource data [24].
   In terms of knowledge graph refinement tasks, interpretable reasoning has become a prevalent
trend. Researchers are seeking solutions that merge cross-lingual knowledge and derive new rela-
tionships between nodes through logic and reasoning. Researchers are also focusing on knowledge
graphs for conditional knowledge, such as temporal knowledge graphs [25] and the generic condi-
tion knowledge graphs [26]. Active learning [27], which asks human users about unknown valuable
1 Knowledge   base (KB) and knowledge graph (KG) are identical terms in this paper.


                                                                     ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:4                                                                                                                             Lingfeng Zhong, et al.


                     Table 1. A Comparison between Existing Survey on Knowledge Graph Construction.

                                                                                             KA           KGR               Target Data       Resource
 Survey               Year                          Topic
                                                                                    Ent   Rel CO Cond KGC TKGC   KF   Web    Tab Sent Doc   Tool Dataset
 Our Survey           2022 Overall Process of KG Construction in HACE environment   ‚Ä¢     ‚Ä¢   ‚Ä¢   ‚Ä¢   ‚Ä¢    ‚Ä¢     ‚Ä¢     ‚Ä¢     ‚Ä¢      ‚Ä¢   ‚Ä¢    ‚Ä¢      ‚Ä¢
 Paulheim [30]        2017                       KG Refinement                      ‚Ä¢     ‚Ä¢   -   -   ‚Ä¢    -     -     ‚Ä¢     ‚Ä¢      ‚Ä¢   -    -      ‚Ä¢
 Yan et al. [32]      2018                KG Application, Construction              ‚Ä¢     ‚Ä¢   ‚Ä¢   -   ‚Ä¢    -     -     ‚Ä¢     ‚Ä¢      ‚Ä¢   ‚Ä¢    ‚Ä¢      ‚Ä¢
 Wu et al. [31]       2019                    Raw KG Construction                   ‚Ä¢     ‚Ä¢   ‚Ä¢   -   -    -     -     ‚Ä¢     -      ‚Ä¢   -    ‚Ä¢      ‚Ä¢
 Ji et al. [35]       2020        KG Application, Representation, Acquisition       ‚Ä¢     ‚Ä¢   -   -   ‚Ä¢    ‚Ä¢     ‚Ä¢     -     -      ‚Ä¢   -    ‚Ä¢      ‚Ä¢
 Arora [36]           2020                       KG Completion                      -     -   -   -   ‚Ä¢    -     -     -     -      -   -    -      ‚Ä¢
 Nayak et al. [33]    2021                 Relation Triples Extraction              ‚Ä¢     ‚Ä¢   -   -   -    -     -     ‚Ä¢     -      ‚Ä¢   ‚Ä¢    ‚Ä¢      ‚Ä¢
 Pawar et al. [34]    2021          Joint Extraction of Entities and Relations      ‚Ä¢     ‚Ä¢   -   -   -    -     -     -     -      ‚Ä¢   -    -      ‚Ä¢
 Hogan et al. [29]    2021                       Overview of KG                     ‚Ä¢     ‚Ä¢   -   -   ‚Ä¢    ‚Ä¢     -     ‚Ä¢     ‚Ä¢      ‚Ä¢   -    ‚Ä¢      ‚Ä¢
 Cai et al. [37]      2022                        Temporal KG                       -     -   -   -   ‚Ä¢    ‚Ä¢     -     -     -      -   -    -      ‚Ä¢

*-:Not covered, ‚Ä¢:1-5 references covered, ‚Ä¢:6-14 references covered, ‚Ä¢: 15+ references covered.
*Ent: Entity, Rel: Relationship, CO: Coreference, Cond: Condition (timestamp or prerequisite).
*Web: Web page, Tab: Table forms, Sent: Sentence, Doc: Textual document.
*KA: Knowledge Acquisition, KGR: Knowledge Graph Refinement, KF: Knowledge Fusion.
*KGC: Knowledge Graph Completion, TKGC: Temporal Knowledge Graph Completion.

data for collection, is another significant direction for handling knowledge from autonomous
communities. Wu et al. [28] summarize the challenges facing knowledge discovery in big data
environments with the HACE theorem, which is shown in Fig. 2.

1.1       Major Differences and Contributions
Many surveys have provided an overview of knowledge graphs and their applications. For example,
Hogan et al. [29] provided an encyclopedic survey for the knowledge graph, while Paulheim [30]
looks into methods that refine and fill knowledge graphs. Other surveys summarize methods for
acquiring knowledge from unstructured or semi-structured data. Wu et al. [31] review competitive
tools and models for KG construction sub-task over texts including relation extraction, named
entity recognition, and coreference resolution, while Yan et. al [32] browse methods for different
data types like web pages, table forms, etc. Deep learning approaches for jointly extracting entities
with their relationships are reviewed in [33], [34]. Some surveys also focus on acquiring knowledge
from existing knowledge graphs. Prior work such as [35] and [36] also covers the methods for
knowledge representation learning and knowledge graph completion, while Cai et al. [37] dive
into temporal knowledge graphs. Table 1 compares previous work with this survey.
   Unlike other surveys, we go deeper into the paradigms of the recent models for knowledge
graph construction, arranging our work according to different stages and aspects of the HACE
environments. We also present practical resources and discuss future challenges and directions
with data, models, and architectures. Hence, our contributions are summarized as follows:
    ‚Ä¢ We introduce the process of knowledge graph construction and various knowledge graphs by
       giving formal definitions and classifications. We also summarize necessary information on
       KG-related resources, including practical knowledge graph projects and construction tools,
       covering published years, citations, and access links for readers to compare.
    ‚Ä¢ We comprehensively analyze models for knowledge graph construction in different scenarios
      ‚Äì from knowledge acquisition to knowledge graph refinement ‚Äì according to their task
       backgrounds and challenges. We summarize the motivations and designs of classical and
       novel models, then primarily delineate the pragmatics in terms of their architectures and
       improvements.
    ‚Ä¢ We discuss knowledge graph construction in HACE big data environments, including noisy,
       document-level data and low-resource data. Then we review achievements for acquiring
       model interpretability and evolutionary condition knowledge. Finally, we summarize the
       major challenges and directions that impact KG construction tasks.

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                                             66:5


                                              Table 2. The information of practical KG projects.

 Categorization          Project                     KG Inclusion                                           Year   URL
                         YAGO                        2B+ facts, 64M+ entities                                    2007 https://yago-knowledge.org
                         Freebase                    360M+ fact triples                                          2007 https://freebase-easy.cs.uni-freiburg.de/dump/
                         DBpedia                     320 classes with 1, 650 different properties, 247M+ triples 2007 https://github.com/DBpedia/
 Encyclopedia KG         CN-DBpedia                  9M+ entities, 67M+ triples                                  2015 http://kw.fudan.edu.cn/cnDBpedia/download/
                         Probase                     5.4M+ concepts                                              2010 https://concept.research.microsoft.com/
                         Wikidata                    96M+items                                                   2012 https://www.wikidata.org/wiki
                         CN-Probase                  17M+ entities, 33M+ ‚Äúis-a‚Äù relations                        2017 http://kw.fudan.edu.cn/apis/cnprobase/
                         WordNet                     117 000 synsets                                             1985 https://wordnet.princeton.edu/
                         ConceptNet                  34M+ items                                                  1999 https://www.conceptnet.io/
 Linguistic KG           HowNet                      35, 202 concepts, 2, 196 sememes                            1999 https://openhownet.thunlp.org/download
                         Babelnet                    13M nodes                                                   2010 http://babelnet.org/rdf/page/
                         THUOCL                      157K+ word nodes in 7.3B+ documents                         2016 http://thuocl.thunlp.org/
                         OpenCyc                     2M+ fact triples                                            1984 https://sourceforge.net/projects/opencyc/
 Commonsense KG          ASER                        438M+ nodes, 648M+ edges                                    2020 https://github.com/HKUST-KnowComp/ASER
                         TransOMCS                   18M+ +                                                      2020 https://github.com/HKUST-KnowComp/TransOMCS
                         Google Knowledge Graph      500B+ facts on 5B+ entities                                 2012 https://developers.google.com/knowledge-graph
 Enterprise support KG
                         Facebook Graph Search       dynamic social network of users, User-generated contents 2013 https://developers.facebook.com/docs/graph-api/
                         Pubmed                      5B+triples                                                  2000 http://pubmed.bio2rdf.org/sparql
                         Drugbank                    14K+ drug entities                                          2006 https://go.drugbank.com/releases/latest
                         AMiner ASN                  2M+ paper nodes, 8M+ citation relations                     2007 https://www.aminer.cn/aminernetwork
                         Huapu                       17M+ person nodes                                           2017 https://www.zhonghuapu.com/
 Domain-specific KG
                         OAG                         369M+ authors, 380M+ papers 92M+ linking relations          2017 https://www.aminer.cn/data/?nav=openData#Open-Academic-Graph
                         TransOMCS                   18M+ +                                                      2020 https://github.com/HKUST-KnowComp/TransOMCS
                         COVID-19 Concepts           4784 entities, 35172 relation links                         2020 http://openkg.cn/dataset/covid-19-concept
                         Aminer COVID-19 Open Data   reports, news, research and other achieves of COVID-19      2020 https://www.aminer.cn/data-covid19/
                         GEDMatch                    1.2M+ DNA profiles                                          2010 https://www.gedmatch.com/
 Federated KG
                         OpenKG.cn                   200+ datasets from 94 organizations                         2015 http://www.openkg.cn




1.2       Organization of the Survey
We organize our survey as follows. Section 2 gives the background for knowledge graph construction,
including definitions and resources of KG projects. Section 3 delivers methods to pre-process semi-
structured data, including content extraction and structure interpretation. Section 4 introduces
the methods for handling tasks that obtain entities and relationships from various data types
and environments. Section 5 reviews the methods for refining knowledge graphs with external
structured data. We portray recent achievements and trends in evolutionary knowledge graphs,
including conditional knowledge graphs and temporal knowledge graphs in Section 6. Section 7
delivers solutions that store knowledge graphs effectively. Finally, we envisage future directions
and development in Section 8 while concluding the article in Section 9.

2     BACKGROUND
2.1 Definitions
Many contributions have been made to formally define knowledge graphs. Wang et al. [38] modeled
a knowledge graph as a multi-relation graph, where the nodes are entities and the edges represent
different types of relationships. However, the previous definition does not consider the semantic
structures in a knowledge graph. Ehrlinger and Wo√ü [39] further emphasize that a knowledge
graph arranges information into an ontology and then enlightens novel knowledge discovery
with ‚Äúa reasoner‚Äù. To specifically protrude the essence component supporting knowledge-level
information, Wu et al. [31] define a knowledge graph as a semantic graph where the nodes represent
concepts (entities/attributes/facts), and the edges represent relationships that connect the nodes
while drawing on background knowledge about the concepts and relations.
    Definition 1 (Knowledge Graph). A knowledge graph G is defined as G = {E, R, T , Fùëò },
where E and R represent sets of concepts and relations, respectively. In this paper, concepts can
be regarded as entities/attributes. T is the set of factual triples, where a standard binary fact is a
triple (‚Ñé, ùë°, ùëü ) ‚àà T , ‚Ñé, ùë° ‚àà E, ùëü ‚àà R. An n-ary relation triple will be formed as (ùëí 1, ..., ùëíùëõ , ùëü ), where
ùëí 1, ..., ùëíùëõ ‚àà E. Fùëò is a set function representing the background knowledge that constrains potential
facts to be knowledge-level informative, and we have T ‚äÇ Fùëò ({E, R}). In practice, background
knowledge can be seen as a rule set, schema, or set of implicit math principles.

                                                                     ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:6                                                                             Lingfeng Zhong, et al.


  Definition 2 (Knowledge Graph Construction). Knowledge graph construction ùëì is a proce-
dure that maps a data source into a knowledge graph: ùëì : ùê∑ √ó ùëìùëò (ùê∑) ‚Üí G, where D is the set of
data sources, and ùëìùëò (ùê∑) is background knowledge of the data target, which can be domain knowl-
edge. Notably, knowledge graph construction is usually unable to continue without background
knowledge that is provided by pre-designed rules or a language model of representations.

2.2 Practical Knowledge Graph Projects
In this section, we review the representative practical projects (datasets) of knowledge graphs,
including encyclopedia knowledge graphs, linguistic knowledge graphs, commonsense knowledge
graphs, enterprise support knowledge graphs, domain-specific knowledge graphs, and federated
knowledge graphs. The details are presented in Table 2.
2.2.1 Encyclopedia KGs.
   Encyclopedia knowledge graphs systematically cover factual or event knowledge from different
domains. Many researchers have developed knowledge graph structures from manually-built online
encyclopedias. For example, DBpedia [40] (developed from Wikipedia) is a fundamental encyclope-
dia knowledge graph, while Freebase [4] incorporates automatic extraction tools to obtain more
content. Probase [41] (supported by Microsoft Concept Graph), as an event encyclopedia knowledge
graph, creatively depicts knowledge of uncertain events containing conflicting information in the
form of probabilistic models. XLore [42] (a sub-project of THUKC), as a multi-lingual encyclopedia
knowledge graph, establishes entity links across multi-lingual content via deep learning approaches.
After an early attempt by the DBpedia project to incorporate automatic extraction tools, more
knowledge graph projects decided to do the same, including Wikidata [5] and CN-DBpedia [43].
The Max Planck Institution developed YAGO [44], which integrates temporal and geographical
structures in Wikipedia with a WordNet ontology. Minz et al. [45] applied distance supervision to
Freebase for automatically annotating entity relationships. The research community has also been
concerned with knowledge graphs of eventualities. For example, CN-Probase [46] extends Probase
with concepts in Chinese to understand general modes of textual data that involve uncertain
occurrences.
2.2.2 Linguistic KGs.
   Linguistic knowledge graphs deliver knowledge of the human language to provide basic semantics
as ontologies or external features. WordNet [47] is a classical widely-used knowledge graph
dictionary for linguistic study, providing synonymy or hyponymy relationships among words. With
these tools, developers create high-performance word embeddings based on well-built linguistic
knowledge graphs for downstream applications. Beyond WordNet , BabelNet [48] extends WordNet
with cross-lingual attributes and relations of words from encyclopedias. ConceptNet [49], as a part
of Link Open Data, gathers conceptual knowledge based on crown sourcing, while HowNet [50]
manually collects sememe information (minimum indivisible semantic units) about word concepts
and attributes. THUOCL [51] records the document frequency of words from a well-filtered web
corpus. Developers have also created high-performance word embeddings based on well-built
linguistic knowledge graphs for downstream applications.
2.2.3 Enterprise support KGs.
   Knowledge graphs and their related systems have been effectively supporting the business of
enterprise activities. Google Knowledge Graph (GKG) [53], served as a core function since 2012,
delivers knowledge support for user queries and enriches the results with more semantically-related
content. Facebook Graph Search 2 is the powerful semantic search engine of Facebook, providing
2 https://developers.facebook.com/docs/graph-api/



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                    66:7


                        Table 3. The infomation of off-the-shelf knowledge graph tools.

         Task                    Tool                 Year   URL
                               WebCollector           2016   https://github.com/CrawlScript/WebCollector
         Data Pre-processing
                               Web Scraper (v0.4.0)   2019   https://webscraper.io/
                               NLTK                   2002   https://www.nltk.org/
                               StanfordNLP            2002   https://stanfordnlp.github.io/stanfordnlp/
                               KnowItAll              2005   https://github.com/knowitall
                               TextRunner             2007   https://www.cs.washington.edu/research/textrunner/
                               OpenCalais             2008   http://www.opencalais.com
                               ReVerb                 2011   https://github.com/knowitall/reverb
         Knowledge Acquisition OLLIE                  2012   https://knowitall.github.io/ollie/
                               spaCy                  2017   https://spacy.io/
                               TableMiner+            2017   https://github.com/ziqizhang/sti
                               MantisTable            2019   http://mantistable.disco.unimib.it/
                               OpenNRE                2019   https://github.com/thunlp/OpenNRE
                               gBuilder               2021   http://gbuilder.gstore.cn/
                               Falcon-AO              2008   http://ws.nju.edu.cn/falcon-ao/
                               OpenKE                 2018   https://github.com/thunlp/OpenKE
         Knowledge Acquisition
                               OpenNE                 2019   https://github.com/thunlp/OpenNE
                               OpenEA                 2020   https://github.com/nju-websoft/OpenEA


user-specific answers through the dynamic knowledge base in the Facebook social system. Similar to
GKG, Facebook Graph Search delivers the powerful semantic search engine of Facebook, providing
user-specific answers through the dynamic Facebook social knowledge base.
2.2.4 Commonsense KGs.
   Commonsense knowledge graphs depict widely-accepted knowledge of common understandings.
OpenCyc [52] is one of the earliest of these attempts, which encodes knowledge concepts, rules,
and common sense ideas in the form of CycL. Besides OpenCyc, ASER [19] provides a weighted
knowledge graph that describes commonsense by modeling entities of actions, states, events, and
relationships among these objects, which acquire its nodes via dependency patterns selection
and conceptualized by Probase. TransOMCS [18] develops an auto-generated dataset covering 20
commonsense relations obtained from linguistic graphs.
2.2.5 Domain-specific KGs.
   Researchers also assemble specific knowledge to serve multiple professional research fields. As
for the biomedical field, Pubmed [54] provides an open biomedical literature database released by
the Pubmed center, while Durgbank [55] provides an insight into pharmacology with protein and
drug information. Many KG collection efforts are also contributed to fighting against the COVID-19
pandemic, such as the COVID-19 Concept dataset 3 and Aminer COVID-19 Open Data 4 . As for
academic activities, the Academic Social Network (ASN) of AMiner [56] discloses the scholars and
their academic activities with the network containing paper and citation relationships. Similarly,
Open Academic Graph (OAG) [57] delivers integrated academic social networks with paper data.
Creatively, Huapu [20] builds a high-quality Chinese family book semantic network from digitized
thousands of ancestral genealogy books, while providing relationship links between the same
people in the different family trees established by fusing multiple Web sources.
2.2.6 Federated KGs.
   Privacy protection plays a critical role for knowledge bases with massive user data from differ-
ent providers, while knowledge communities collecting multi-source KG data possess abundant
3 http://openkg.cn/dataset/covid-19-concept
4 https://www.aminer.cn/data-covid19/



                                              ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:8                                                                               Lingfeng Zhong, et al.


features, which can be unified to build integrated knowledge models. Federated learning is pro-
posed to combine sub-KG features from different data providers with protection to prevent data
exchange. Federation strategies have been applied to KG systems with sensitive data. GEDmatch5
is a genealogy KGs collecting user-provided information for enquiring DNA while distributing a
federated knowledge model to probe data tracking. Federation strategies have been applied to many
knowledge graph systems with sensitive data. These have helped to build integrated knowledge
models while preventing data exchange. Researchers have also focused on federated knowledge
graph platforms. OpenKG.cn [58] is a crowd-sourcing community that provides a knowledge-
sharing platform to develop knowledge applications with federated learning while supporting the
decentralization of knowledge blockchains.

2.3    Knowledge Graph Construction Tools
In this section, we review some of the tools commonly used for knowledge graph construction.
These tools mainly support construction sub-tasks, such as pre-processing, knowledge acquisition,
and knowledge refinement. The details of these tools are displayed in Table 3.
2.3.1 Data Preprocessing.
   Data pre-processing tasks remove noise like advertisements. For instance, WebCollector [59] is
a representative data pre-processing toolkit that automatically filters non-content noise, such as
advertisements and layout information, while retaining the page content via integrated algorithms.
Many web crawlers also support data preprocessing tasks that extract informative structures or
content. Beyond WebCollector, Web Scraper 6 is a user-friendly manual extraction tool for collecting
multiple web pages. It provides a user interface to preserve focused web structures and a cloud
server for extracting massive amounts of content.
2.3.2 Knowledge Acquisition.
   The early toolkits for knowledge acquisition directly extract fact triples through rules, patterns,
and statistical features. These are also known as information extraction toolkits. Beyond KnowItAll
[7], other toolkits, such as TextRunner [6], ReVerb [60], leverage semi-supervised designs for
collecting relational information. These tools produce refined verbal triples via syntactic and lexical
information. In addition, there is OLLIE [61] which supports the discover of non-verbal triples.
   Many NLP applications can directly perform knowledge acquisition sub-tasks, including named
entity recognition, relation extraction, and coreference resolution tasks, or they can provide lin-
guistic features for related applications. NLTK [62] and StanfordNLP [63] are powerful toolkits
for knowledge acquisition based on statistical algorithms like conditional random field and MEM.
These tools can also provide background features such as POS tags and NP chunks. Meanwhile,
TableMiner+ [64] and MantisTable [65] extract knowledge from semi-structured table forms.
   Recently, developers have been drawn into deep learning-based toolkits. For example, spaCy [66]
is a comprehensive practical NLP toolkit that integrates NeuralCoref for coreference resolution
tasks and also provides a trainable deep learning module for specialized relation extraction (in spaCy
v3). OpenNRE [67] provides various extensible neural network models such as CNN and LSTM to
perform supervised relation extraction. Deep learning toolkits provide high-performance techniques
for users. For industrial applications, users can customize their knowledge acquisition solution by
OpenCalais 7 . Further, gBuilder 8 is a milestone end-to-end solution based on user-selected neural

5 https://www.gedmatch.com/
6 https://webscraper.io/
7 http://www.opencalais.com
8 http://gbuilder.gstore.cn/



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                               66:9


architectures that also supports an active learning interface for performance optimization. gBuilder
can directly output a raw knowledge graph from inputted unstructured data.

2.3.3 Knowledge Refinement.
   Knowledge refinement tools refine an existing raw knowledge graph by completing it or merging
it with other knowledge graphs. Tools based on deep learning are popular solutions. For example,
OpenKE [68] provides multiple knowledge representation models for knowledge graph completion,
while OpenEA [69] leverages similar methods for merging structures in knowledge graphs. Beyond
the integrated deep learning toolkits, OpenKE and OpenEA, OpenNE9 integrates embedding models
such as Node2VEC [70] and LINE [71] to generate global representations from a complete knowledge
graph. In terms of knowledge fusion (merging) tasks, Falcon-AO [72] uses multiple algorithms to
measure semantic similarity so as to align concepts in different notations.

3     SEMI-STRUCTURED DATA PRE-PROCESSING
Real-world raw data sources include multi-structure contents with irrelevant parts impairing the
effect of knowledge extraction. Data preprocessing is necessary for handling a messy data environ-
ment. Preprocessing sub-tasks mainly include Content Extraction and Structure Interpretation.

3.1    Content Extraction
Many web pages contain non-content noises such as advertisements. Content extraction tasks aim
to erase these irrelevant elements while reserving knowledge content. Users can manually select the
main part of a web page, e.g., contents enveloped by ‚Äú<table>‚Äù, to achieve this goal by web crawlers
such as JSoup, BeautifulSoup, and Web Scraper that retrieve and interpret elements in Document
Object Model (DOM) structures, then users can select the main part of a web page. However, when
the data volume is high, manual work will fail to handle them. Mainstream automatic content
extraction methods mainly include wrapper-based methods and statistic-based methods.
   Wrapper-based methods are the earliest attempts to detect main contents, leveraging matching
rules to capture informative content. Off-the-shelf wrapper tools automatically generating rules
from semi-structured pages include IEPAD [73], SoftMealy [74]. Bootstrapping methods iteratively
enhance extraction templates with seed examples, such as [75] and [76]. Some toolkits providing
user interfaces to optimize extraction templates, such as NoDoSE [77] and DEByE [78]. Template-
based wrappers are easy to understand and achieve feasible results where the page structures are
well-formed, but fail to grasp the inner contents covered by intricate novel elements or structures.
   Users can also utilize methods based on statistical features of web pages to obtain informative
content. Finn et.al [79] propose an empirical assumption that an informative sub-sequence in a web
page contains sufficient enough words with minimal tags. Many models consider statistical features
of web contents for extracting informative content, such as CETR [80] (the ratio of text length to
tag number), CETD [81] (text density in each sub-tree structure of a DOM tree) and CEPR [82] (path
ratio of Web links). Users can utilize WebCollector [59] that integrates the statistic-based models
for content extraction. Another heuristic research direction is visual-features-based methods. For
example, VIPS [83] utilizes the visual appearances (such as fonts and color types) of a page to build
a content structure tree for content extraction.
   When content extraction has been performed on a semi-structured page, users will acquire a
renewed noise-free semi-structured or unstructured document.


9 https://github.com/thunlp/OpenNE



                                         ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:10                                                                                       Lingfeng Zhong, et al.


                                                            Entity Linking
         PERSON                 LOCATION
         Trump is a leader from New York.                   Entity Typing

         Trump is a leader from New York.             Named Entity Recognition     Trump is a leader from
         PERSON             LOCATION                                               New York.

      President Businessman     City            Trump is a leader from New York.

                                        Fig. 3. The entity discovery process.

3.2     Structure Interpretation
Many table forms in the web pages function as navigators or style-formatted containers for contents
(handled by content extractors), comprising no relational structures. Models shall filter these
decorative non-relational web table structures before obtaining relational information.
    Relational table interpretation is a binary classification task that determines whether a table is
informative. Methods analyze semantic features of table structures for classification. Wang and
Hu [84] design a table classifier integrated with support vector machines (SVM) and decision trees
based on the layout and content type features. Similarly, WebTables [85] develops a rule-based
classifier based on the table size (number of rows and columns) and tags. Eberius et al. [86] develop
a classification system DWTC via the feature of the table matrixes. Many web tables also contain
data noises. OCTOPUS [87] further incorporates data cleansing with table classification tasks to
filter informative tables.
    Developing a table interpretation model includes two steps: first select features in the table forms,
then integrate learning models to analyze relational semantics in the data. We recommend readers
to refer to [88] for more table syntax features and high-performance model ensembles.

4     KNOWLEDGE ACQUISITION
Knowledge acquisition is the general process of collecting elements from multi-structured data
to build a knowledge graph. It includes entity recognition, coreference resolution, and relation
extraction. Entity recognition tasks discover entity mentions within data. Co-reference resolution
tasks then locate referred mention pairs, followed by relation extraction tasks, which link entities
with their semantic relationships.

4.1     Entity Discovery
Entity discovery acquires a subset of concepts from semi-structured or structured data that can
constitute the nodes of a knowledge graph. The general procedure of entity discovery includes
named entity recognition, entity typing, and entity linking tasks. Named entity recognition tasks
discover strings that refer to semantic entities and then classify them to the general types (e.g.,
person, location, country, company). Entity typing tasks categorize the found entities into specific
types (e.g., actor, artist, brand). Entity linking associates a discovered entity with a possible node in
the knowledge graph. If there are no available nodes for linking, a corresponding entity node will
be created to represent the newly found entity. Fig. 3 depicts an overview of the general process.
4.1.1 Named Entity Recognition from semi-structured data vs unstructured data.
   Named entity recognition tasks tag named entities in semi-structured or unstructured data with
their positions and classifications. Semi-structured data are enveloped by semantic hints related to
property-attribute structures, while unstructured data only contains texts.
   Rule-based approaches [89] are the general solutions for NER. As for semi-structured web data,
Wrapper inductions generate rule wrappers to interpret semi-structures such as DOM tree nodes

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                              66:11

                                   B-P I-P   O O B-L I-L
        Tag decoder (CRF)
         Label embeddings
                                               + Attention
           Context encoder
               Word                                                     N     e      w
            embeddings                                                            LSTM
                                                                                          Character
         Pre-trained vectors       Word Feature Extractor                                embeddings
               BERT
               ELMO
                ‚Ä¶‚Ä¶             Donald Trump is from New York           N e w CNN


Fig. 4. Illustration of the standard architecture for deep-learning-based named entity recognition. When a
sentence is input, such NER model will output tagged entity words with positional information and rough
entity classifications.
and tags for harvesting entities from pages. Some rule-based solutions are unsupervised, which
requires no human annotations, such as Omini [90]. As for entities in table forms, many approaches
are proposed based on property-attribute layouts of Wikipedia, such as rule-based tools [40][44]
for DBpedia, and YAGO. For unstructured data, classic NER systems [91] also rely on manually-
constructed rule sets for pattern matching. Semi-supervised approaches are developed to improve
rule-based NER by iteratively generating refined new patterns via pattern seeds and scoring, such
as Bootstrapping-based NER [92].
   Statistic-based approaches treat named entity recognition as a sequential classification tagging
task that tags entities according to the BIES scheme (beginning, intermedia, ending, single) and
their types. For unstructured named entity recognition, the key hypothesis is that a tag for each
word only depends on the previous words. Hence, applications built on hidden Markov models
[93] and conditional random fields (CRF) models [94], which capture neighborhood-dependencies,
are popular NER designs. With semi-structured table data, researchers often use CRF variants to
tackle the two-dimensional features of the attributes that relate to the entities, such as 2D-CRF [95].
Thus, they extract multiple attributes of each entity in a 2D structure. Dynamic conditional random
field (DCRF) [96] infers potential attribute-entity interaction via the dynamic Bayesian network,
and hierarchical CRF [97] models semi-structured data into a hierarchical tree for joint extraction.
Further, Finn and Kushmerick [98] developed a model to locate the boundaries of entities in texts
which is based on SVM.
   Deep learning is also becoming a popular trend in named entity recognition, especially for text
named entity recognition. These deep learning approaches typically treat named entity recognition
as a seq2seq model (words sequences to label sequences). These models aggregate contextual
embeddings according to the input, and context encoders then output word type tags through tag
decoders such as a CRF structure or a softmax structure [99].
   CNN structures mainly focus on local features for capturing entities. Colloabert et al. [100] was
the first to employ a CNN with a CRF output layer as a unified solution for entity detection. IDCNN
et al. [101] improved upon the CNN with dilated convolutions that enlarge the perception field by
omitting some of the input to enhance generalization.
   RNN structures can better digest global contextual features in long sentences, such as the uni-
directional RNN for biomedical entity recognition presented in [102]. However, RNNs may suffer
from context bias with later upcoming words [9]. Hence, many models consider bi-directional RNNs,
such as the Bi-LSTM-CRF-based in [9] and the GRU-based NER model in [103]. Combinations of
character and word encoders are also widely-applied structures, such as a structure comprising a
CNN for character embedding and an LSTM for word embedding [10]. The standard architecture
of deep learning-based NER models is pictured in Fig. 4.

                                         ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:12                                                                                                                  Lingfeng Zhong, et al.


                              Fine-grained type [/president,/businessman]

             Type     ùíïùüè                                    Adaptive Thresholds
                      ùíïùüê
           embeddings ùíïùüë ‚Ä¶                            Logistic Regression
                                          Feature embedding
                                                 Aggregator
                                                                                                                 Attention
                        Document-level                                Entity                                   Sentence-level
                        Context Encoder                              Encoder                                      Encoder

                                 ‚Ä¶ , ùë§1ùë†1 , ùë§2ùë†1 , ùëí1ùë†1 , ùëí2ùë†1 , ùë§5ùë†1 , ùë§1ùë†2 , ùë§2ùë†2 , ùëí1ùë†2 , ùëí2ùë†2 , ùë§5ùë†2 , ‚Ä¶

Fig. 5. Illustration of deep learning-based entity typing via multi-scale feature extraction (based on [111]).

   Another direction that projects salient interactions for global contexts is the attention mechanism.
Luo et al. [104] introduce word-level soft attention to enhance named entity recognition. Gregoric
et al. [105] employ word-word self-attention for named entity recognition.
   Graph convolution networks are often used to handle context in linguistic graph structures for
named entity recognition. For example, Cetoli et al. [106] proposed a GCN framework that encodes
the LSTM-proceed features via GCN structures with a syntactic dependency tree. Pre-trained
language models that provide representations as background knowledge for training with named
entity recognition tasks have also achieved breakthroughs in named entity recognition. Models
include Elmo [107], Ltp [108], and LUKE [109].
4.1.2 Entity Typing.
   Entity typing (ET) tasks provide fine-grained and ultra-grained type information for entities such
as scientists, clubs, and hotels. Information loss occurs if ET tasks are not performed, e.g., Donald
Trump is a politician and a businessman. Semi-structured tables provide hints for fine-grained
types in the captions. For example, ‚Äúsoccer players in England‚Äù suggests soccer players as the entity.
However, tagging proper fine-grained entity types in different contexts for unstructured data can
be intricate.
   Deep learning approaches tackle two main challenges for entity typing: 1) infrequent fine-grain
types; and 2) overly-specific typing. Some specific types can be imbalanced or infrequent. For this
reason, Shimaoka et al. [110] proposed an LSTM-based attentive neural network for infrequent
entity typing that relies on hierarchical label encoding integrated with mention and context
representations to exploit fine-grained contextual features. Overly-specific type annotations derive
correct types but do not fit the current data context. Xu et al. [11] applied an out-of-context loss
function to the entities with multiple labels for filtering overly-specific data noise which assumed
that the type label which scored the highest probability during training was correctly tagged. To
further explore context scenarios, Zhang et al. [111] introduced document-level representations
to provide a global context for discovering entities. Sentence-level contextual representations are
then used to align the same entity representations appearing in different sentences. An adaptive
probability threshold then generates labels of the entity types in different contexts. Fig. 5 presents
a typical deep learning-based ET model.
   Novel embedding-based models avail of combing global graph structure features and background
knowledge for predicting potential types of entities via representations. Researchers reported
that the classical TransE model acts poorly while directly applied to ET tasks. Moon et al. [112]
propose the TransE-ET model adjusting the TransE model by optimizing the euclidean distance
between entities and their types representations, limited by insufficient entities types and triples

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                        66:13


                                                                     Entity-type-feature
                                                                        Embedding

                                                                                                                            Fine-grained type
                                                                                                                            Donald Trump
                                      Graph                                  Graph                        Type                  politician
   Data-labeling
                                    &onstruction                           Embedding                    Inference
                                                                                                                              businessman
             Type-type correlation graph                                                   Entity-type graph (from KB)
                       singer           artist                                                       businessman     politician

                       0.2                       author
                                        0.5                                              J.K.            Woody           Donald
                        actor                          director                         Rowling          Allen           Trump
    businessman                         person            athlete
                      0.03 0.1
                                                                             person         author           actor        director
              politician
                   Hierarchical type tree                                             Entity-feature (context) graph (from KB)
                            Root                                                                       Donald
                                                                                                       Trump
           product        person            location        organization
                                                                                        CONTEXT_                CONTEXT_
            politician             artist           athlete                                                     campaign
                                                                                        republican
                                                          ‚Ä¶
       ‚Ä¶      singer            actor         director                                                  ‚Ä¶‚Ä¶


           Fig. 6. Illustration of embedding-based ET via heterogeneous graph structures (PTE [12]).

features. New solutions aim at constructing various graphs to share diversified features of entity-
related objects for learning embeddings with entity-type features. PTE [12] reduces data noise via
a partial-label embedding, which constructs a bipartisan graph between entities and all their types
while connecting entities nodes to their related extracted text features. Finally, PTE utilizes the
background KG by building a type hierarchy tree with the derived correlation weights. JOIE [113]
embeds entity nodes in the ontology-view graph and instance graphs, gathering entity types by
top-k ranking between entity and type candidates. Likewise, ConnectE [114] maps entities onto
their types and learning knowledge triples embeddings. Practical models improving embeddings
on heterogeneous graphs for ET tasks (in Xlore project [42]) also include [115], [116], [117]. We
present graph structures for embedding model-based ET in Fig. 6.
4.1.3 Entity Linking from semi-structured data vs unstructured data.
   Entity linking (EL) tasks, also called entity disambiguation, link entity mentions to their corre-
sponding objects in a knowledge graph. A textual mention can have different references, e.g., the
text ‚ÄúTesla‚Äù may refer to the car, the corporation, or the scientist. Entity linking connects mentions
in different data backgrounds with the contextual information of their respective nodes. With
semi-structured data, entity linking identifies entities using semantic hints from column heads,
type labels, cell texts of tables, and hyperlinks. With unstructured text, entity linking models focus
on the contextual representations of entity mentions.
   Statistical approaches, especially those approaches based on probabilistic graphs and SVM models,
are the general solutions for semi-structured and unstructured data. Models based on probabilistic
graphs construct a probabilistic graph of mentions in tables, then link entities by calculating the
semantic factors of nodes. Limaye et al. [118], for instance, constructed a factor graph for collective
entity linking based on the TF-IDF algorithm that calculates the term frequency of entity labels
with cell-text pairs and type labels with column-head pairs. Some models incorporate external
knowledge bases to improve entity linking tasks. For example, TabEL [119] improves its factor graph
by leveraging the hyperlinks in Wikipedia to estimate semantic relatedness features before collective
classification for disambiguation. Wu et al. [120] propose an approach for enhancing entity linking

                                                              ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:14                                                                                                 Lingfeng Zhong, et al.


   John and Mary decided to visit London.
   He and she cannot wait to see this historical city.
                                        Antecedent Discovery        Coreference
 John and Mary decided to visit London.
                                                                         John and Mary decided to visit London.
 He and she cannot wait to see this historical city.
                                         Mention Discovery               He and she cannot wait to see this historical city.
  John and Mary decided to visit London.
  He and she cannot wait to see this historical city.


Fig. 7. The coreference resolution process. First, mentions are detected. Then the antecedents of the mentions
are selected and matches to co-referred pairs. Noticeably, coreference resolution tasks can be performed on
documents with multiple sentences, while handling identical mentions in a compound sentence.
with the ‚Äúsame-as‚Äù edges in multiple knowledge bases. Efthymiou et al. [121] systematically exploit
semantic features for entity linking. Their approach integrates vector representations of an entity‚Äôs
context, minimal entity context, and schematic structures shared between knowledge bases and
tables. SVM models treat entity linking as a classification task. Here, Mulwad et al. [122] develop
a model based on SVMRanker that determines which potential nodes can link to a target entity.
Similarly, Guo et al. [123] propose a probabilistic model for unstructured data, that leverages the
prior probability of an entity, context, and name when performing linking tasks with unstructured
data. Han et al. [124] employed a reference graph of entities, assuming that entities co-occurring in
the same documents should be semantically related.
   Embedding-based models are also critical solutions for entity linking via entity embeddings.
LIEGE [125] derives distribution context representations to links entities for web pages. Early
researchers [126] leverage Bag-of-word (BoW) for contextual embeddings of entity mentions,
then performed clustering to gather linked entity pairs. Later, Lasek et al. [127] extend the BoW
model with linguistic embeddings for EL tasks. Researchers also focus on Deep representations
for high-performance linking. DSRM [128] employs a deep neural network to exploit semantic
relatedness, combining entity descriptions and relationships with types features to obtain deep
entity features for linking. EDKate [129] jointly learns low-dimensional embedding of entities and
words in the knowledge base and textual data, capturing intrinsic entity-mention features beyond
the BoW model. Furthermore, Ganea and Hofmann [13] introduce an attention mechanism for joint
embedding and passed semantic interaction for disambiguation. Le and Titov [14] model the latent
relations between mentions in the context for embedding, utilizing mention-wise and relation-wise
normalization to score pair-wise coherence score function.
4.1.4 Other Advances.
   Few/Zero-shot entity typing is an intricate challenging issue. Ma et al. [139] develops Proto-HLE
that models the prototype of entity label embeddings for zero-shot fine-grain ET tasks, combining
prototypical features with hierarchical type labels for inferring essential features of a new type.
Zhang et al. [140] further propose MZET that exploits contextual features and word embeddings
with a Memory Network to provide semantic side information for few-shot entity typing.
   Joint extraction models incorporating NER with EL tasks reduce error propagation of the pipeline-
based entity recognition tasks. NEREL [141] couples NER and EL tasks by ranking extracted
mention-entity pairs to exploit the interaction features between entity mentions and their links.
Graphic models are also effective designs to combine NEN (Named Entity Normalization) labels
that convert entity mentions into unambiguous forms, e.g., Washington (Person) and Washington
(State). Liu et al. [142] incorporated EL with NEN tasks utilizing a factor graph model, forming
CRF chains for word entity types and their target nodes. Likewise, MINTREE [143] introduces a
tree-based pair-linking model for collective tasks.

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                           66:15


         Mary Puth     Mary was   was with      her husband                                         s(her husband,   s(Mary Puth,
                                                              Andy W   .
                                                                               s(ùúñ, Mary Puth)      Andy W)          Andy W)
Mention Score
Span                                                                           =0
Representation                                                                    Singleton
Span Feature                                                                                                 Softmax
                                                                           ‚Ä¶   Coreference
Aggregator
                                                                               Score
                                                                               Antecedent
                             Context Feature Extractor                         Score
                                                                               Mention
                                    Embedding                                  Score

                                                     , Andy W                                Mary      her
                 Mary Puth was with her husband                   .                                                    Andy W
                                                                                             Puth      husband


Fig. 8. Architecture of the standard deep end-to-end model (based on [15]). A deep learning model performs
a two-stage procedure to tackle coreference resolution tasks: 1) Mention detection, which discovers entity
mentions as spans from text; 2) Coreference detection, which score the antecedents in the span to match
coreference mention pairs as outputs. Spans include combinations of all word sequences. This figure displays
simplified results.
   Researchers explore more strategies for flexible NER tasks. Transfer Learning shares knowledge
between different domains or models. Pan et al. [130] propose Transfer Joint Embedding (TJE)
to jointly embed output labels and input samples from different domains for blending intrinsic
entity features. Lin et al. apply [131] a neural network with adaptation layers to transfer parameter
features from a model pre-trained on a different domain. Reinforcement Learning (RL) puts NER
models to interact with the environment domain through a behavior agency with a reward policy,
such as the Markov decision process (MDP-based) model [132] and Q-network enhanced model
[133]. Noticeably, researchers [134] also leveraged the RL model for noise reduction in distant-
supervised NER data. Adversarial Learning generates counterexamples or perturbations to enforce
the robustness of NER models, such as DATNet [135] imposing perturbations on word represen-
tations and counterexamples generators ([136], [137]). Moreover, Active Learning, which queries
users to annotate selected samples, has also been applied for NER. Shen et al. [138] incrementally
chose the most samples for NER labeling during the training procedures to mitigate the reliance on
tagged samples.

4.2    Coreference Resolution
Coreference expressions often appear in unstructured text. As such, coreference resolution (CO)
tasks detect mentions that refer to the same entities (including aliases and pronouns). A mention
will be a singleton if no other mentions refer to it. Given some unstructured sentences, such tasks
will output co-referred word span pairs. Fig. 7 presents this process.
4.2.1 Statistic-based Models.
   Early attempts to capture co-referred linguistic objects focused on the statistical features of
entities, mentions, and antecedents.
   Cluster-based solutions handle the CO task as a pairwise binary classification task (co-referred
or not). Early cluster models aim at mention-pair features. Soon et al. [148] propose a single-link
clustering strategy to detect anaphoric pairs. Recasens et al. [149] further develop a mention-pair-
based cluster to emanate a coreference chain or a singleton leaf. Later, researchers concentrate
on entity-based features to exploit complex anaphoric features. Rahman and Ng [150] propose a
mention-ranking clustering model to dive into entity characteristics. Stoyanov and Eisner [151]
develop agglomerative clustering to merge the best clusters with entity features.


                                                 ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:16                                                                                                                      Lingfeng Zhong, et al.

             Data                                 Fact                                               Open RE
                                        Biden                  U.S.A
                                                                                                          - Predefined
                                            <<president-of>>                          + Long-term           Schemas
 Biden is the current president of
 U.S.A.                                 (Biden, U.S.A, president-of)                     context     Relation    + Given Entities     Domain-specific
                                                                         DocRE
                                                                                                     Extraction                            RC
                                                                       + Low-resource                     + Joint           + Noisy Data
The statement declares                       A B C
                                                                           Data                             Learning
that A, B and C are co-authors.              <<co-author>>                                                                           Distance-supervised
                                            (A, B, C, co-author)           Joint RE                 Few-shot RC                            RE/RC
                             (a) The goal of RE tasks                                               (b) Configurations of RE tasks


Fig. 9. Relation extraction. The goal of relation extraction tasks is to extract factual triples from data and find
edges to link nodes together. For ùëõ-ary relations, the link is a super-edge that covers multiple nodes.
   Tree-based models and graph-based models are also popular designs for converting coreference
resolution into a partition task. These models construct a hypergraph from the given document, in
which each edge can link more than two nodes for modeling coreferences among multiple mentions.
Cai and Strube [144] learn statistical features to weight edges and obtain coreference partitions via
clustering algorithms. Sapena et al. [145] further employ relaxed labeling to interpret coreferences.
Researchers have also simplified graphs for coreference resolution to adapt to tree-based methods.
For example, Bean and Riloff [146] introduced a decision tree model to distinguish anaphoric
mentions combined with context features. Fernandes et al. [147] leverage a voted perceptron
algorithm to detect mention-pair coreference trees.
4.2.2 Deep Learning-based Models.
   Deep learning models automatically convert a document input into word representations to
collect features for detecting coreference mention pairs.
   Many early models are based on CNNs. Xi et al. [152] resolve coreferences by incorporating
distant features with hierarchical mention-pair features and also score mention pairs via a softmax
layer. Wu et al. [153] develop a CO model to effectively handle coreference and singleton expressions
with abundant multi-scale contexts, incorporating context feature combinations of antecedents,
mentions, and mention pairs features via convolution and concatenation.
   RNN and its variants better extract global features between word mention pairs. Wiseman et
al. [154] propose an RNN-based CO model. Lee et al. [15] develop an end-to-end LSTM-based
model, detecting internal dependencies within mentions spans to comprehend global contexts that
surround the spans. Gu et al. [155] apply a cluster modification algorithm to LSTM to rule out
dissimilar pairs. Fig. 8 depicts a standard deep end-to-end CO model.
   Attention mechanisms model semantic interactions for CO tasks. A good example of this is
the Bi-LSTM structure enhanced with the word-level attention presented in [15]. However, many
different coreference resolution-specific attention mechanisms have been developed to exploit
coreference features. These include: the biaffine attention model for CO tasks [156] that captures
word span interactions for detecting linked expressions; and the mutual attention model [157]
that incorporates syntactic features with interactive features between dependency structures and
antecedents for word spans. Further, Clark and Manning et al. [158] employ RL-based strategy to
enhance the robustness of their neural CO model, which uses a heuristic policy network to filter
out wrong coreference matching actions.
   Researchers also focus on embedding-based distribution models over multiple semantic structures
to handle coreference resolution. Durrett and Klein [159] utilize antecedents representations to
enable coreference inference through distribution features. Martschat and Strube [160] explore
distribution semantics over mention-pairs and tree models to enhance coreference representations,
directly picking robust features to optimize the CO task. Chakrabarti et al. [161] further employ
the MapReduce framework to cover anaphoric entity names through query context similarity.

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                            66:17

                                                                                                        ùíÜùíäùíîùüè        ùíÜùíäùíîùüê         (rel)       ùíÜùíäùíìùüè
                                                                                       Copy
                                            BERT                                                                             ‚Ä¶
                                                                                 Attention
                    [CLS] ùíòùíîùüè ùíòùíîùíè [SEP] ùíÜùüèùüè    ùíÜùüèùíè  [SEP]  ùíÜùíä‚àíùüè
                                                            ùüè    ùíÜùíä‚àíùüè
                                                                  ùíè    [SEP]
                     original sentence 1ùë†ùë° extraction (ùëñ ‚àí 1)
                                                               ùë°‚Ñé
                                                                  extraction                           (subj)              ùëñ ùë°‚Ñé extraction
                                                          (a) Encoder-decoder Model (IMOJIE)
  Twain     ùíòùíïùüè
  was       ùíòùíïùüê        C                                                                        Unlabeled Novel
                                                                                                                                             Testing Instances
  an        ùíòùíïùüë            max       FC                                                            Relation
                       N
  author    ùíòùíïùüí        N                        ùíóùíï
  of        ùíòùíïùüì                                            classifier                                          metric                    clustering
                                                                                                                              RSN
  America   ùíòùíïùüî                  distance                                                                      learning
  Yeats    ùíòùíìùüè                                                       probabilistic
  was      ùíòùíìùüê         C   max       FC                             of relation type          Pre-defined Relations                          Novel Relations
  an       ùíòùíìùüë         N                                                                            (Labeled)                                  (Extracted)
  poet     ùíòùíìùüí                                  ùíóùíì
                       N
  of       ùíòùíìùüì                              sample
  Ireland ùíòùíìùüî                             embeddings
       embeddings
                                 Relational Siamese Network (RSN)                                                 Extraction Procedure
                                                       (b) Metric-based Knowledge Transfer Model (RSN)


Fig. 10. Two paradigms of deep learning-based open relation extraction. In this figure, (a) shows the IMOJIE
model [187], which extracts facts via a encoder-decoder design. (b) portrays a model [188] that uses the RSN
to compare relational patterns, then leverages clustering to collect the relations.

4.3    Relation Extraction
Relation extraction tasks extract relational facts from unstructured or semi-structured data to
indicate interactions and properties among entities. Relation extraction, as a downstream task,
is often called relation classification. Binary relation extraction extracts relation triples between
entity pairs, while n-ary relation extraction obtains relation triples over multiple entities, such as
co-authors. Relation extraction endows a knowledge graph with semantic links. Fig. 9 presents an
overview of the relation extraction tasks.
4.3.1 Open Relation Extraction from semi-structured data vs unstructured data.
   Open relation extraction tasks discover facts from unstructured data without pre-defined relation
types. These techniques detect nominal words (as the subject or object) and verbal phrases (as the
predicate) from free text to form knowledge triples like (subject, predicate, object).
   Statistical approaches are also trending solutions for open relation extraction. In terms of rela-
tion detection, models based on probabilistic-graph are popular designs for allowing contextual
information to flow through semi-structured structures or unstructured free text. Mulwad et al.
[176] put forward a probabilistic graph on semi-structured tables and semantic message passing
for tagging relationships. Chen and Cafarella [177] leveraged a module based on the CRF structure
with a frame finder to tag cells with their location labels (such as left, middle, and right). From this,
a hierarchical tree is built where relation triples can be recovered through parent-child structures.
Researchers have also applied probabilistic models to relation classification with text. As an example,
StatSnowball [178] employs Markov logic networks to identity relationships.
   Methods focusing rules are the earliest attempts for RE tasks on different data structure kinds,
gathering strings that fit in hand-craft templates, e.g., ‚Äú$PEOPLE is born in $LOCATION.‚Äù refers to
($PEOPLE, born-in, $LOCATION). However, these unsupervised strategies rely on complex linguist
knowledge to label data. Later, researchers concentrate on automatical pattern discovery for triples
mining. Semi-supervision design is an enlightening strategy to reduce hand-craft features and data
labeling that uncovers more reliable patterns based on a small group of annotated samples, such
as DIPRE [179] iteratively extracting patterns with seeds, bootstrapping-based KnowItAll [7] and
Snowball [180] equipping DIPRE with confidence evaluation. Some rule-based models consider

                                                        ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:18                                                                                             Lingfeng Zhong, et al.


  output tag               ùíì                                                                  ùíì

                       Classifier                                                         Classifier
  sentence
  representation           ùíî                                                          Attention Mechanism
                                              Max/min/avg pooling                     ‚Ä¶ ùíâùíÜùíâ ‚Ä¶ ùíâùíÜùíï ‚Ä¶ ùíâùëª
                   Pooling/MLP                Lexical features                   ùíâùüè
                                              Dependency features
         ùíòùüè        ùíÜùíâ        ùíÜùíï          ùíòùíè                                                ‚Üê     ‚Üê LSTM
               ‚Ä¶          ‚Ä¶          ‚Ä¶                                         ùíâ‚Üê    ‚Üê
                                                                                ùüè ‚Ä¶ ùíâùíÜùíâ ‚Ä¶ ùíâùíÜùíï ‚Ä¶ ùíâùëª
                          CNN                     ‚Ä¶
                                                                                  ùíâ‚Üí     ‚Üí     ‚Üí    ‚Üí
                                                                                   ùüè ‚Ä¶ ùíâùíÜùíâ ‚Ä¶ ùíâùíÜùíï ‚Ä¶ ùíâùëª
          ùíôùüè       ùíôùíÜ ùíâ      ùíôùíÜ ùíï        ùíôùíè
               ‚Ä¶         ‚Ä¶        ‚Ä¶                                            ùíôùüè ‚Ä¶   ùíôùíÜùíâ ‚Ä¶ ùíôùíÜùíï ‚Ä¶        ùíôùëª
                       Embedding              Position features
                                              Lexical features
                                              Dependency features                      Embedding
         ùë•1 ‚Ä¶      ùë•ùëí‚Ñé    ‚Ä¶    ùë•ùëíùë° ‚Ä¶     ùë•ùëõ   Pre-trained vectors
                                              ‚Ä¶‚Ä¶                               ùë•1 ‚Ä¶   ùë•ùëí‚Ñé ‚Ä¶ ùë•ùëíùë° ‚Ä¶ ùë• ùëá
                      (a) CNN framework                                                (b) LSTM framework
        ùõº1,ùëñ ùõºùëí‚Ñé,ùëñ ùõºùëíùë°,ùëñ ùõºùëõ,ùëñ
                           ‚Ä¶                          ùíöùüè ùíöùüê ‚Ä¶ ùíöùíè               GCN
           ‚Ä¶       ‚Ä¶
                                                ùíôùüè
          Attention Layer                       ‚Ä¶                    ùëí‚Ñé   ùëíùë°                                  ùëí‚Ñé   ùëíùë°
                                                ùíôùíÜùíï
                                                ‚Ä¶
                                                ùíôùíÜùíâ
                                                ‚Ä¶                    Graph                 Non-linear
  ùíôùüè ‚Ä¶ ùíôùíÜùíâ ‚Ä¶ ùíôùíÜùíï ‚Ä¶                  ùíôùíè   ùíöùíä     ùíôùíè                                           Layer
                                                                                 ‚Ä¶                        Embeddings
            Attention unit                  Attention matrix
                    (c) Attention mechanism                                            (d) GCN framework

Fig. 11. Some frameworks of classic relation classification models. In this figure, (a), (b), (d) display the
architectures of CNNs, LSTMs, GCNs, while (c) displays the structure of the widely-used attention mechanism.

more lexical objects for mining. OLLIE [61] incorporates lexical structure patterns with relational
dependency paths in texts. MetaPAD [181] combines lexical segmentation and synonymous cluster-
ing to meta patterns that are sufficiently informative, frequent, and accurate for relational triples.
Specifically for semi-structured tables, researchers design table structure-based rules to acquire
relationships arranged in rows, columns, and table headers, such as [182]. Furthermore, Some
semi-structured extraction systems utilizing distant supervision tolerate potential errors, which
directly query external databases like DBpedia and Wikipedia to acquire relationships for the found
entities in tabular data, such as the previous methods [122], [176], and [183]. Similarly, Mu√±oz et al.
[184] look up the Wikipedia tables for labeling relationships in tabular forms. Krause et al. [185]
also expand rule sets for relation extraction via distant supervision.
   Deep learning models have also been developed to handle open relation extraction. A common
framework is an encoder-decoder model designed to acquire factual patterns. CopyAttention [186]
includes a mechanism to copy words from input to output sequences via a neural bootstrapping
strategy. IMOJIE [187] improves CopyAttention with BERT-LSTM structures while incorporating
an unsupervised aggregation scheme to perform iterative extraction. Another direction in open
relation extraction is to transfer supervised knowledge to a model so as to adapt known relations
to obtain unsupervised relations. In this vein, Wu et al. [188] developed a metric learning-based
solution that combines Relation Siamese Net (RSN) with the clustering strategy to discover new
facts. Two deep learning paradigms are illustrated in Fig. 10.
4.3.2 Domain-specific Relation Classification from unstructured sentence-level data.
   Given unstructured sentences with conceptual (entities) mentions, domain-specific relation
classification tasks label the given mentions with relation tags in a pre-defined relation set given the
context of the sentences. Kernel methods and deep learning frameworks typically handle relation
classification as a multi-label single-class classification task.
   SVM kernel-based methods employ the feature vectors of words to train a classifier for supervised
relation classification tasks on unstructured text. These models map specific semantic objects onto

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                                                   66:19


Table 4. Comparison of designs of classical and recent sentence-level RC models (arranged in terms of
publication year in each category).

          Category                       Model                                     Architecture                                              Background Information
                                       CNN [165]                                 CNN + max pooling                                   WordNet hypernyms, position features
                                Multi-kernel CNN [166]                    multi-kernel CNN + max pooling                                      Position embeddings
    Local context-aware
                                 Attention-CNN [168]                     CNN + word-level attention + MLP                Pre-trained word-vectors, position embeddings, WordNet, POS
                               Multi-level Attention [169]   word-level input attention + CNN + attention-based pooling          Pre-trained word-vectors, position embeddings
                                  BiLSTM + Att [17]                        BiLSTM + word-level attention                                    Pre-trained word-vectors
 Global context-aware models
                                    TreeLSTM [167]                   BiTreeLSTM + compound label embedding                           SPTree, WordNet, position embeddings
                                      EPGNN [170]            BERT + CNN (sentence encoder)/GCN (topological encoder) Pre-defined entity pair graph, pre-trained model, position embeddings
 Graph context-aware models          AGGCN [171]                      GCN + Multi-head Attention + DC + FF               pre-trained word-vectors, position features, dependency graph
                                       RIFRE [172]                                 BERT + HGCN                                                  pre-trained model
   Task conversion-based                QA [173]                           BERT + Span Prediction Model                         Converted questions/answers, pre-trained model



a feature space via a kernel function for classification, such as with a lexical-kernel based SVM
(with POS and entity tags) [162], a dependency-tree-kernel based SVM [163], or a shallow-parse-
tree-kernel based SVM [164]. However, a high-performance kernel function can be hard to design.
   Deep learning-based frameworks automatically collect entity-related contextual information for
relation classification tasks. Given a sentence that needs its relations classified {ùë• 1, ùë• 2, ùë•ùëí‚Ñé , ..., ùë•ùëíùë° , ùë•ùëõ },
let ùë•ùëí‚Ñé and ùë•ùëíùë° stand for head and tail entities, respectively. Deep learning models will generate
a representation for each word: {w1, ..., e‚Ñé , ..., eùë° , xùëõ }, then the feature extractor will derive a vec-
tor r to indicate the probability of each relation type. Models based on convolution, such as a
feature-based CNN combined [165] with lexical features and a max-pooling strategy, focus on local
contexts in neighborhood words. Nguyen and Grishman [166] use multiscale convolution windows
to enhance local feature aggregation. Some studies focus on global context awareness between
sentences using an LSTM framework that captures long-distance reliances. Zhou et al. [17] use a
BiLSTM that employs inter-word attention to capture the long-distance dependencies of relations,
while Miwa and Bansal [167] incorporate tree structures into an LSTM framework. Many designs
have also incorporated global context features into CNN structure via attention mechanisms to
model salient interactions, such as Attention-CNN [168] selecting entity-relevant contexts with
the word-level attention and Multi-level CNN [169] developing an input attention mechanism with
attention-based pooling. Some of the more recent studies have explored graph-level contexts via
GCNs and extracting background knowledge via pre-trained models. Examples of this approach
include EPGNN [170], which includes an entity pair graph for a GCN (with a pre-trained BERT
model), AGGCN [171], which integrates a multi-head attention mechanism for graph convolution
and RIFRE [172], which further employs a heterogeneous graph network to merge high-order
features. Cohen et al. [173] converted relation classification into a question-answering task and
incorporated BERT embeddings for classification. Fig. 11 depicts some of the classic frameworks of
relation classification models and Table 4 compares key design aspects of the popular models.
   Some tasks require a model to handle n-ary relationships between multiple entities. To this end,
semantic role labeling solutions have been devised to decompose n-ary relations into binary ones.
Examples include NNF [174] and dependency path embedding [175].
4.3.3 Distant Supervised Relation Extraction/Classification.
   Fully-supervised relation extraction/classification on large datasets will generally require a for-
midable amount of laborious label tagging. To cope with this problem, Mintz et al. [45] developed a
distant supervision strategy for automatically annotating relation labels with an external knowledge
base (Freebase in the original work). The strategy assumes that entity pairs appearing in different
sentences reflect the same relationships that link them in the knowledge base. However, distant
supervision does not fully consider the data context, hence, inevitably suffers from noise.
   Data noise hampers relation classification tasks in traditional models. Some methods try to
overcome this problem by enhancing the feature extractors, e.g., piecewise convolution (PCNN)
[16]. This approach divides a sentence into three separate pieces for convolution according to

                                                                          ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:20                                                                                                                   Lingfeng Zhong, et al.

                                                                                                  ùíì

                                                                                     Classifier
                     ùëê3
   ùë§1                  ùëê2ùëê                                                                                 ùíî
   ùë§2                    1                                                                                          Sentence bag
   ùë§3                                        classifier                                                             representation
   ùëí‚Ñé                                                       ùíì
   ‚Ä¶




               ‚Ä¶




   ùëíùë°                        ùëöùëéùë•(ùëê13 )                                              ùú∂ùüê                ùú∂ùüí            Sentence-level attention
  ùë§ùëõ‚àí1                                                                       ùú∂ùüè             ùú∂ùüë
   ùë§ùëõ
                                                                        ùíîùüè          ùíîùüê       ùíîùüë                ùíîùíè
    embeddings convolution piecewise                probabilistic
                          max pooling                 vector of       CNN         CNN      CNN         CNN
                                                   relation types                                                   ùë†ùëñ is the sentence with the
                                                                        ùë†1          ùë†2       ùë†3                ùë†ùëõ   same entity pair of (h, t).
                    (a) PCNN                                                     (b) Selective Attention
                                                                                     Bag
                                                                               Representation
                      Sentences                                                  (Entity-pair)
                      with entity pair (h,t).                   ùíîùüè ùíîùüê ùíîùíè     max
                                 ùëÜ1 (‚Ñé, ùë°)                                                            ùíì
                                                                                          Classifier
                                                                    ‚Ä¶




                                 ùëÜ2 (‚Ñé, ùë°)                                   max
                                   te
                                    ‚Ä¶




                                ùëÜùëõ (‚Ñé, ùë°)
                                                              Sentence Pooling
                              Bag                           Representation
                                                          (c) MIML CNN


                                     Fig. 12. Milestone models for distant supervision.

entities to preserve critical contextual features. See also Fig. 12(a). Hierarchical attention mechanism
[189] models long-tail labels to enhance decoder features. Some models involve improved learning
strategies designed to promote robustness to noise. Transition matrix structure [190] learns incorrect
patterns to prevent noise. Huang et al. [191] adapt collaborative learning to handle the interaction
contexts, while Qin et al. [192] leverage reinforcement learning to remove wrongly-labeled samples.
Further, DSGAN [193] picks reliable samples for training via adversarial learning.
   More recently, efforts have focused on designing instance selector structures to compare reliable
features of instances in sample bags. For instance, Riedel et al. [23] developed the ‚Äúat-least-one‚Äù
hypothesis for multi-instance multi-label Learning (MIML). The hypothesis holds that at least
one of the samples containing the same entity pairs will express the given distantly-supervised
relation (i.e., the sample is correct). Based on that, selective attention [196] presents a classic design
that groups sentences labeled with the same relation tags. See also Fig. 12(b). MIML CNN [194]
uses a CNN to proceed with each sentence bag, then leverages a cross-sentence pooling operation
to derive an entity-pair representation for multi-label relation modeling. See Fig. 12(c). Ji et al.
[195] combine entity descriptions to enhance the MIML CNN. Another direction for implementing
instance-level feature extraction is instance-level attention mechanisms. The contribution of each
sentence representation is then scored across different groups with the same relation tags. Last, an
attention-weighted contextual representation is generated for each relation type. Many models
extend this idea with MIML designs. One example is Intra/Inter-Bag Attention [197]. This method
captures the sentence features of inner relations and outer bag-relation interactions via compound
attention mechanisms and cross-relation attention [198], where Baye‚Äôs rule is used to acquire
the global similarities of bags of different relation types. The main goal of devising an instance
selector is to emphasize instructive features in correct samples while muting dummy features in
wrong-labeled data.

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                          66:21


 Table 5. Comparison of popular models for distant supervision relation extraction/relation classification.

            Category                       Model                                   Architecture                                  Background Information
                                         PCNN [16]                               PCNN + pooling                                   position embeddings
 Enhanced feature extractor-based         TM [190]                 PCNN + Transition matrix + Bag embedding                       position embeddings
                                         HAtt [189]                    CNN/PCNN + hierarchical attention                position embeddings, relation hierarchy
                                       RL-based [192]    RL-based data redistributor + CNN/PCNN + Result-driven reward            position embeddings
 Enhanced learning strategy-based      DSGAN [193]                       GAN + CNN/PCNN + Attention                               position embeddings
                                       CCL-CT [191]               CNN/PCNN + [Net Att + Self Att] + CCL-CT                        position embeddings
                                       Lin et al.[196]           CNN/PCNN + selective attention + max-pooling                     position embeddings
                                      MIML CNN [194]             CNN (sentence) + Cross-sentence max-pooling                      position embeddings
      Instance feature-based
                                        Ye et al. [197]              CNN/PCNN + Intra/inner bag attention                          pre-trained model
                                      Yuan et al. [198]  PCNN (Sentence) + Cross-relation Cross-bag Selective Attention           position embeddings
                                    MIML CNN + ED [195]              description embeddings + MIML CNN +                entity description, position embeddings
 Background information-enhanced       RESIDE [200]                   Bi-GRU (sentence) + Syntactic GCNN                    Dependency graph, external KB
                                      Zhang et al. [199]   CNN/PCNN (sentence) + GCN + Knowledge-aware attention           external KG, position embeddings



   Deep learning approaches also consider external knowledge to improve distance supervised rela-
tion extraction, such as incorporating the knowledge graph embeddings of entities into models [199].
RESIDE [200] further uses a syntactic graph with side information for GCN-based representations.
We compare these popular achievements in Table 5.
4.3.4 Few-shot Relation Classification.
   Low-resource scenarios, specifically, few-shot and zero-shot relation classification, require a deep
learning model to learn from a few examples. Few/Zero-shot Learning, also called meta-learning,
only fuels a few samples to drive DL models, specifically, few-shot, zero-shot learning. Few-shot
learning feeds a support data set in the N-way K-shot form that provides K instances for each
relation type of the general N ways (N*K samples in total) and predicts data labels in the query set
based on the given support set. Ulteriorly, Zero-shot learning follows the above form, but query
sets contain unseen sample labels that do not appear in the support sets. It is noticeable that in the
big data environment, the long-tail phenomenon exists in knowledge bases where the majority of
knowledge types express with few samples. [201] Meta-learning configurations commonly appear
in various sub-tasks of knowledge acquisition and knowledge refinement. Generally, researchers
have tried to amplify the usable characteristics of these low-resource configurations through three
methods: metric-learning, meta-learning, and domain adaptation.
   Meta-learning enhances optimizers by reserving conveyable meta-information from limited
supervision. Model-agnostic machine learning (MAML) [208] improves batch learning through
a two-stage multiple gradient descent. Here, the model is trained to estimate the gradients of
each relation type before all the sample types undergo general optimization with the estimations.
Task-sensitive meta-information of respective relation types is hoarded in partial gradient values.
Gradient estimation through separate backpropagation is also applied by other models. MetaNet
[209] utilizes the fast-slow mechanism to obtain high-order implicit relational meta-features of
samples and the specific task. Both the meta learner and the base learner contain a group of slow
weights and fast weights for optimization. Another critical problem is catastrophic forgetting. To
deal with this issue, Wu et al. [210] developed a curriculum-meta learning strategy that reviews
samples in order and preserves the learned features in a memory mechanism.
   Metric learning aims at finding metric spaces with which to compare different relation types.
To determine the relation types in a query sample, ProtoNet [202], for example, averages the
embeddings of each relation type in a support set as a prototypical support vector. LM-ProtoNet
[203] exploits the fine-grained features of relational context to build support vectors, concatenating
phrase embeddings with sentence embeddings induced by a CNN. Noises in low-resource samples
attract impertinent meta-features, reducing the robustness of deep learning models. Gao et al. [204]
combine feature-level attention with instance-level attention to emphasize reliable prototypical
features. Furthermore, Matching Network [205] presents an attention-based embedding strategy for

                                                              ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:22                                                                                                                      Lingfeng Zhong, et al.

                              Query embeddings                                                                     0.97     Similarity Score
   Relation feature space
    of support samples                    ùíîùë∏      Feature Extractor
                                                                                                            Distance Function

                                               John is born in 1995. ùë†ùëû
             ùíìùüè                    ùíìùüë                                                                        Parameter
                                                     Query sentence                       Encoder                               Encoder
                        ùíìùüê                                                                                    sharing
                                                ùíì(ùíîùë∏ ) ‚âà ùíìùüë                                                  ùë†1                                  ùë†2
                                                                                  John is born in 1995.           Allen's birthday is in 1968.
                  (a) ProtoNet
                                                                                                         (b) RSN (Relation Siamese Network)
                             (ùë†1 , ùëü1 )
                                                                                                                      ùëü1
                             (ùë†2 , ùëü2 )                                                                               ùëü2
                                                       ùëîùúÉ
                             (ùë†3 , ùëü3 )                                                                               ùëü3
                                                                                                ùëìùúÉ

                                                                      attention              (ùë†1 , ? )            ‡∑ç                ùëü3
                                                                   (c) Matching Network


Fig. 13. The metric-based few-shot relation classification models. In this figure, (a) shows ProtoNet [202],
which compares the distances of a query sample among support vectors of different relation types. (b) shows
RSN [206], which calculates the similarity of sample pairs. (c) shows Matching Network [205], which uses an
attention mechanism to tag a query by matching it with different-tagged support samples.

classification, calculating the attention scores of the query sample for each support sample through
vector multiplication. RSN [206] compares the similarity of the sample embeddings. Another
approach, called multi-Level matching and aggregation network (MLMAN) [207], aggregates the
local and instance features by aggregating the support vectors with the query vector to match the
correct long-tail class label for the query sample. Fig. 13 outlines the classic metric-based paradigms.
   Few-shot RC designs also consider feature augmentation strategies to mitigate data deficiency
with intriguing model designs and background knowledge. Similar to [173], Levy et al. [211] turn
zero-shot RC into a reading comprehension problem to comprehend unseen labels by a template
converter. Soares et al. [212] compose a compound relation representation for each sentence by
the BERT contextualized embeddings of entity pairs and the corresponding sentence. GCNs also
deliver extra graph-level features for few-shot learning. Satorras and Estrach [213] propose a novel
GCN framework to determine the relation tag of a query sample by calculating the similarity
between nodes. Moreover, Qu et al. [214] employ posterior distribution for prototypical vectors.
Some designs also avail semi-supervised data augmentation based on metric learning. The previous
Neural Snowball [206] (based on RSN) labels the query set via the Siamese network while drawing
a similar sample candidate from external distant-supervised sample sets to enrich the support set.
   Few-shot domain adaptation maps unseen labels for classification. BERT-PAIR pairs with do-
main adaptation strategies for unseen ‚Äúnone-of-the-above‚Äù types. Gao et al. [215] discuss domain
adaptation for few-shot relation classification as a game process for searching domain-invariant
features. They implement domain adaptation via adversarial training. More domain adaptation
strategies for few-shot relation classification can be found in [24].
4.3.5 Joint Relation Extraction Models.
   Conventional pipeline-based relation extraction (relation classification) models suffer from
error propagation in each stage, while also undermining inter-task interactions. Early researchers
concentrate on intriguing statistical-based features for fast end-to-end joint relation extraction,
such as Integer Linear Programming-based (ILP) algorithm [216] solving entities and relations
via conditional probabilistic model, semi-Markov chain model [217] jointly decoding global-level
relation features, and Markov Logic Networks (MLN) [218] modeling joint logic rules of entity labels
and relationships. Early attempts deliver prototypes of entity-relationship interactions. However,
statistical patterns are not explicit for intricate contexts. The recourse for researchers has been

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                                             66:23

Parameter-sharing model                                    ùëü
           O        B         I         S         classifier
                                                                                                                     Entity Loss                Relation Loss
               ‚Ä¶                  ‚Ä¶
                                                    CNN
                                                                                                                                ùëü1 ùëü2
                    ùíâùüè ‚Ä¶ ùíÜ ùüè            ùíâùüë       ‚Ä¶ ùíÜùüê                   Input         Bi-LSTM                                      ùëü3
                                                                                                              Bi-GCN            1st predict
 BiLSTM
 encoder                                                                        Entity Loss           Relation Loss
               ùíôùüè                  ùíôùüë                                                                                                      ùëü3
                       ‚Ä¶ ùíôùüê              ‚Ä¶
                                                 ùíôùëª                                           ùëü1     ùëü2                               ùëü2        relational
                                                                                                   ùëü3 ùëü                          ùëü1               graph
                         Embedding                                                                     1

               ùë•1      ‚Ä¶ ùë•2  ùë•3 ‚Ä¶ ùë• ùëá                                                         2nd predict                  Bi-GCN
                (a) LSTM + CNN framework                                                                    (b) GraphRel
Novel tagging schema                                  ùíòùüè ùíòùüê ùíÜùüèùüè      ùíÜùüêùüè ùíòùüì ùíòùüî ùíÜùüèùüê ùíòùüèùüé ùíÜùüèùüë ùíÜùüêùüë ùíòùüèùüè
                                            ùëü3
                          Object            ùëü2        ùíòùüè ùíòùüê ùíÜùüèùüè      ùíÜùüêùüè ùíòùüì ùíòùüî ùíÜùüèùüê ùíòùüèùüé ùíÜùüèùüë ùíÜùüêùüë ùíòùüèùüè
                          tagger                      ùíòùüè ùíòùüê ùíÜùüèùüè
                                            ùëü1                       ùíÜùüêùüè ùíòùüì ùíòùüî ùíÜùüèùüê ùíòùüèùüé ùíÜùüèùüë ùíÜùüêùüë ùíòùüèùüè                          (ùëí1 , ùëí2 , ùëü1 )
                                                                           ùíâùëµ + ùíóùíîùíñùíÉ                                        (ùëí3 , ùëí1 , ùëü2 )
                                                                                 ùíå
                                                                       ùíóùíîùíñùíÉ     ùíâùëµ ùíóùíîùíñùíÉ      ùíóùíîùíñùíÉ
                                                                                               ùüë
                                                                                                                            (ùëí2 , ùëí3 , ùëü3 )
                                                                         ùüè           ùüê
                          Subject                     ùíòùüè ùíòùüê ùíÜùüèùüè       ùíÜùüêùüè ùíòùüì ùíòùüî ùíÜùüèùüê ùíòùüèùüé ùíÜùüèùüë ùíÜùüêùüë ùíòùüèùüè
                          Tagger
                                                                         BERT
                                                      ùë§1       ùë§2 ùë§3 ùë§4 ùë§5 ùë§6 ùë§7 ùë§8 ùë§9 ùë§10 ùë§11
                                                                        (c) CasRel


  Fig. 14. The joint extraction model paradigms. (a) depicts [219], (b) depicts [220] and (c) depicts [222].

to turn to joint extraction models, with the mainstream high-performance designs focusing on
parameter-sharing strategies and novel tagging schemas.
   Parameter-sharing strategies merge neural architectures for various types of tasks. They share
weights and use different output layers to fetch entities that have relationships. Zheng et al. [219]
merge double BiLSTM layers for NER and RC tasks to share parameters, then use a CNN and an
LSTM Network to label relationships and entities respectively. Miwa and Bansal [167] also integrate
the dependency features associated with NER and RC with a combination of a Bi-LSTM and a Bi-
TreeLSTM layer. Some models focus on delicate strategies for distributing cross-task characteristics.
The GraphRel model [220], for example, intuitively leverages two-phase supervision to dedicate
cross-task interaction through two respective BiGCN layers. The GCN frameworks incorporates a
dependency graph with a relation-entity graph for exploiting deep features.
   To handle overlapping labels, novel tagging schemes set joint decoding targets for the output
layers with compound labeling. Zheng et al. [221] extend BIES labels with the relationship types
and roles of a word (e.g., the subject or object of a sentence) to develop a sequence tagging task
comprising named entity recognition and relation classification. Wei et al. [222] intuitively label all
object candidates of a subject entity via a cascade map function for each relation type to contain
overlapping mentions. Further, Wang et al. [223] developed a hand-shaking scheme to alleviate
exposure bias within overlapping entities. Bekoulis et al. [224] devised a multi-head selection
mechanism to explore all entity/relation combinations. Li et al. [225] turned entity-relation tagging
into a multi-turn question answering problem, leveraging the machine reading comprehensive
(MRC) model for long-range semantics between entities. Unlike previous schemes, KGGen [226]
directly generates triples via an encoder-decoder/generator structure based on a pre-trained model
combined with adversarial learning, which overcomes feature reliance on entity co-occurrence
information. Fig. 14 shows some seminal joint extraction models.
   Novel distribution embedding-based models are also proposed to model the cross-task distri-
butions to bridge the semantic gaps between NER and RC. Ren et al. [227] propose a knowledge-
enhanced distribution CoType model for joint extraction Task. In this model, entity pairs are firstly
mapped onto their mentions in the knowledge base, then tagged with entity types and all relation

                                                                 ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:24                                                                                                                                          Lingfeng Zhong, et al.


Table 6. Comparison of model designs for document-level relation extraction (arranged in terms of publication
year in each category).

         Category                   Model           Word Encoder       Long-context Encoder                 Inference                         Cross-sentence Feature
                               Graph LSTM[229]        Embedding             Graph-LSTM                      Softmax                  Root-linked cross-sentence dependency tree
                             Graph-state LSTM [230]       FFN           Graph-state LSTM                    Softmax                  Root-linked cross-sentence dependency tree
    Statistic Graph-based
                                 AGGCN [171]             LSTM       GCN + Multi-head Attention           DC + softmax                Root-linked cross-sentence dependency tree
                                Sahu et al. [231]     embeddings                GCN                        MIL-based                     Coreference/Adjacent sentence edges
                                GP-GNNs [233]           Bi-LSTM                GCNs                      MLP + softmax               Inter-node graph with generated parameters
                                   EoG [232]            BiLSTM                 GCNN            Node-feature aggregation + softmax        Sentence-mention-entity pair graph
                                 GraphRel [220]         BiLSTM                BiGCN                     Threshold-based                        Relation-weighted graph
                                  DyGIE [238]       ELmo + BiLSTM    GCN + Span enumeration                   FFN                                Dynamic span graph
 Dynamic Graph-based Model
                                   LSR [234]         BiLSTM/BERT                GCN                    FFN + GCN + DC                       Weighted dependency graphs
                                  GAIN [236]             LSTM                   GCN                     FFN + Attention                               hMG + EG
                                 Xu et al. [235]        BiLSTM             AGGCN [171]                  LSTM + softmax              Reconstructed hetergenous S-M-E graph [232]
                                   DRN [239]            BiLSTM              GAIN [236]                Aggregation + MLP                Hetergenous document-level meta-paths
                                  RARE [237]             BERT                 R-GCN                      MLP + softmax                    Rationale graph, pre-trained model
                                  ATLOP [242]            BERT        Localized Context Pooling           Group bilinear                            Pre-train model
           Others
                                  U-Net [241]            BERT                2D-Conv                     Matrix-based                            Feature visualization




candidates provided by the knowledge base. This model learns embeddings of relation mentions
with contextualized lexical and syntax features while training embeddings of the entity mentions
with their types, then the contextual relation mention will be derived by its head and tail entities
embeddings via Translation embedding (TranE) [228] model. The CoType model assumes interac-
tive cooccurrence between entities and their relation labels, filling the distribution discrepancy
with knowledge from the external domain and extra type features. Noticeably, this model also
effectively prevents noises in distant-supervised datasets. However, feature engineering and extra
KBs are also needed.
4.3.6 Document-level Relation Extraction.
   Entities in a document can express relationships via complex cross-sentence contexts, which
defeats most of the traditional sentence-level context encoders. Novel architectures have therefore
been conceived to capture document-level contexts.
   Intra-sentence semantic passages are critical to document-level extraction. As such, researchers
initially developed variants of an LSTM fitting graph structure to handle long-term dependencies,
such as Graph LSTM [229] and Graph-state LSTM [230]. More recently, however, researchers have
been focusing on GCN-based models to explore diverse linguistic features with novel cross-sentence
graph structures. Many approaches handle inter-sentence semantic contexts using static document
graphs. For instance, for ùëõ-ary relation extraction, AGGCN [171] links the roots of dependency
trees of adjacent sentences via attention-guided GCN layers, which also overcomes the reliance on
semantic role labeling. Sahu et al. [231] introduce coreference edges and adjacent word edges to
form a homogeneous document graph. Christopoulou et al. [232] employ mention/sentence/entity
(M, S, E) nodes to create a heterogeneous semantic graph distinguishing various linguistic roles,
while reasoning via the EoG interference layer using the above intermedia node structures.
   Researchers then developed dynamic document graph models for high-order reasoning. Many
models leverage dynamic edges. GP-GNNs [233] deduces hidden semantic logic with dynamic edge
weights in a fully-connected graph for reasoning. LSR [234] regards graph structures as a latent
variable to iteratively refine links and weights for constituting logical features from contexts. Xu et
al. [235] considers reconstructing dependency paths to reweight relational entity pairs. GraphRel
[220] jointly extracts entities and relationships via a two-stage procedure that incorporates static
dependencies with dynamic relation-weighted graphs to enhance multi-hop reasoning. Some models
also consider feature extraction with multiple graphs. For example, Zeng et al. [236] designed a
heterogeneous mention-level graph with an entity-level graph for multi-hop inference.
   Another direction for document-level relation extraction is reasoning with evidence. Zhang et al.
[237] develop a rationale graph with external tagged co-occurrence evidence features for capturing
long-term relational dependencies. Dynamic graphs with alterable nodes have also been considered

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                               66:25


       KG             ? ? ?                            Knowledge   <<birthday>>
    Completion                 Triple Completion                                         <<birthday>>    Attribute
                                                        Fusion    <<day-of-birth>>
                             Knowledge                          ?                                        Alignment
                             Reasoning                                                             Entity Matching
                                                                 ?
                           ‚úî Triple
                           X Classification                      ?                                Entity Alignment




                                        Existing KGs                     Other KGs

                               Fig. 15. Illustration of knowledge refinement.

within the realms of complex reasoning. DyGIE [238] prunes mute low-confident entity spans
nodes through gate mechanisms for document-level feature exploitation. Other approaches seek to
understand the common sense rules implicit in the different contexts. Discriminative reasoning
network (DRN) [239] recognizes common-sense relationships while performing intra-sentence
reasoning through heterogeneous graph representation features. The method is based on the
assumption that multi-scale contexts with syntactic structures contain distinguishable common-
sense features. Background common-sense features can also be acquired from pre-trained models
like COMET [240]. However, understanding how common sense is expressed over contexts and
how it unfolds in human logic remains challenging.
   U-Net [241] employs a U-shaped segmentation for document-level reasoning via a multilayer
convolution. Further, it treats a document as visual semantic information. ATLOP [242] introduces
localized context pooling to distill the entity-relevant features of BERTs while using an adaptive
threshold for decoding reliable relations. This technique does not rely on graph structures. We
compare the designs of the typical milestone models in Table 6.

5     KNOWLEDGE GRAPH REFINEMENT FROM STRUCTURED DATA
Raw knowledge graphs constructed from unstructured or semi-structured data can be sparse, and
the knowledge triples can be incomplete or corrupted. Knowledge graph refinement repairs these
problems through background semantics or by populating knowledge triples with additional knowl-
edge graphs (structured data). The sub-tasks of knowledge graph refinement include knowledge
graph completion and knowledge fusion. The general procedure is shown in Fig. 15.

5.1     Knowledge Graph Completion
Knowledge graph completion fills in incomplete triples while deriving new triples from completed
ones. In terms of completed triples, knowledge graph completion evaluates the accountability of
each triple through triple classification. By accountability, we mean the correctness of the triples.
5.1.1 Embedding-based Triple Completion.
   An embedding-based link prediction model leverages distribution representations to search for
elements that can fill missing parts formulated as (h, ?, t) or (?, r, t) (entity prediction), and (h, ?, t)
(relation prediction). For example, the TransE-based model [112] searches the head entity h, the
tail entity t, and the relation r, whose representations approach h + r = t to complete a triple. Later,
researchers discovered that the previous symmetrical TransE model does not consider one-to-many
relationships. Focus then turned to importing hyperspace structures with distance-based translation
models for link prediction, such as TransR [243], TransH [244], and TranSparse [245]. Some models,
such as RESCAL [246], TuckerER [247], DistMult [248] and NTN [249], consider matching entity
pair representations to a latent relational semantic space for predictions with large graphs.

                                          ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:26                                                                              Lingfeng Zhong, et al.


   More recently, researchers have focused on semantic knowledge structures. HAKE [250], for
instance, uses the polar coordinate system to model semantic hierarchies in knowledge graphs,
like hypernyms, hyponyms, and the apposition of an entity‚Äôs ontological associations, which
differentiate various-layered entity vectors by mold and angle constraints. CAKE [251] boosts
negative sampling with common sense rules. Many models, such as SimKGC [252] and HaLE [253],
optimize negative sampling for low-dimension embeddings via contrastive learning. CAFE [254]
introduces a neighborhood sub-graph feature set to enhance relevant link information. Further,
there has been interest in decomposing the semantic constituents of knowledge representations with
the sub-structures of knowledge graphs via semantic diffusion mechanisms of GCNs. DisenKGAT
[255] discerns the high-order neighbor node features of a knowledge graph by disentangling
the representation components into distinct semantics implied in the sub-graph structures. The
hypothesis behind these models is that a large knowledge graph should contain sufficient subsets
that can be reduced into k components to reason about linked entity nodes.


5.1.2 Relation Path Reasoning.
   Relation path reasoning deduces new facts through completed triple sequences as support
evidence, such as ‚Äú(B, lives-in, Seattle)‚Üê (A, works-in, Microsoft), (Microsoft, located-in, Seattle)‚Äù.
   Early attempts develop random-walk models for relation path reasoning that infer relational
logic paths in a latent variable logic graphic model. Path-Ranking Algorithm (PRA) [256] generates
a feature matrix to sample potential relation paths. However, the feature sparsity in the graph
impedes random walk approaches. Semantic enrichment strategies are proposed to mitigate this
bottleneck, such as inducing vector space similarity [257] and clustering associated relations [258].
   Later, researchers model the relation path reasoning tasks as a Markov decision process so as
to recognize logical constraints within the knowledge environment. Deep reinforcement learning
achieves this idea by learning a policy agent that assesses each selection step and expands the
reasoning path. DeepPath [259] models the state space as (pre-trained) translation-based repre-
sentations of entities and their induced relations. The taken actions then find the best matching
relation labels via the feature space of entity pairs. Rewards for actions are calculated by a binary
function. However, low-quality evaluations by the binary reward function will mean a RL-based
model that is not well generalized to handling incomplete knowledge structures [260]. To this end,
Lin et al. [260] devised a soft reward shaping function based on the vector spaces of relations and
entities, while Li et al. [261] employ multiple agents to select entity pairs and relations. M-Walk
[262] leverages an RNN to capture chronological state dependencies among pathing decisions.
   More designs leverage neural networks that capture global features to find reasonable paths.
Path-RNN [263] recursively aggregates relation path features for multi-hop reasoning. The chains-
of-reason model [264] enhances a path-RNN with attention mechanisms to emphasize multiple-path
dependencies with type information in the entities. Chen et al. [265] unify path-reasoning and
path-finding tasks via variational encoding.
   Some methods further focus on attention mechanisms to augment features for reinforcement
learning. ADRL [266] leverages a self-attention mechanism to emphasize neighborhood entity-
relation interaction features. Similarly, Wang et al. [267] introduce a graph attention mechanism to
enhance knowledge features. Recent research interest has been drawn into incorporating neural
structures that handle intricate semantic features, such as Zheng et al.‚Äôs hierarchical policy network
[268] and DAPath [269], which incorporates a distant-aware mechanism to issue rewards via
path length features. MemoryPath [270] is an attention-based memory component that preserves
knowledge features for reinforcement learning and alleviates the model‚Äôs reliance on pre-trained
embeddings.


ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                              66:27


   Many efforts also focus on automatically mine logic rules to pave reasoning paths. There are
methods for rule discovering, such as AMIE [271], RLvLR [272] and RuleN [273]. Instead of searching
for promising relation path patterns approaching the symbolic essence of knowledge, the rule
mining approaches extract and prune logic rules from a reasonable KG structure, then perform link
prediction via the collected rule templates. However, unseen knowledge paths cannot be easily
derived by logical rules in incomplete graphs.
   Another research direction is to fuel logic rules into neural models to boost path reasoning.
KALE [274] jointly embeds first-order logic rules with knowledge embedding to enhance relation
inference. RUGE [275] iteratively rectifies KG embeddings via learned soft rules, then performs
relation path reasoning. Logic rules are also leveraged as the side semantic information into
neural models. NeuralLP [276] proposes a neural framework that encodes logic rule structures into
vectorized embeddings with an attention mechanism. pLogicNet [277] introduce the Markov logic
network to model uncertain rules for reasoning. ExpressGNN [278] further employs GCNN to solve
neighborhood graphic semantics with logic rules. These rule-based neural models are also regarded
as the application of differentiable learning availing for gradient-based optimization algorithms on
logic programming.
5.1.3 Interpretable Relation Reasoning.
   Interpretability serves to make a machine learning model understandable to human users [279],
and this plays a critical role in assessing a model‚Äôs reliability and ability to respond to different
data environments. Interpretation models include self-explained pre-hoc models and inspectable
post-hoc models.
   Pre-hoc reasoning models that comprise transparent decision processes can be self-interpreted
through their inner structures by introspection. Logic rule-mining approaches such as AMIE [271]
and RLvLR [272] can feed back the logic rules to explain linkage decisions to users. Some models
only contain some components that are interpretable to humans (e.g., the learned rules). Users
can observe these learned rules as side information when reasoning with rule-finding approaches
based on neural models such as NeuralLP [276], pLogicNet [277] and ExpressGNN [278]. However,
these neural networks are still black-boxed. Mainstream partial pre-hoc models also include models
based on random-walk (probabilistic values for potential paths), reinforcement learning (reward
values for each action), and attention (attention score for salient correlation).
   Post-hoc interpretation methods develop proxies to probe into implicit features in black-box
models like matrices and neural network frameworks. Some proxies extract rules or learn a prob-
abilistic distribution to reproduce a model. Carmona et al. [280] train Bayesian networks with
first-order logic to extract rules from embedding models. OXKBC [281] generates plausible explana-
tion paths through the similarities between relationships and entities. Model simplification cannot
decompose the features of non-linear neural models that are entwined. One solution is to conduct
a sensitivity analysis to exploit the deep features. The analysis would involve imposing small
perturbations on the models so as to observe how the output changes. These changes reveal the
influential features. GNNExplainer [282] explores sub-graph structures that affect single-instance
and multi-instance predictions. CRIAGE [283] generates false facts to evaluate model performance
and to locate obtrusive fact triples for each relation.
5.1.4 Triple Classification.
   Triple classification aims to distinguish triples with surety from abnormal (untrue) triples in a
knowledge graph. Many semantic models are designed for this task of judging suspicious triples in
a knowledge graph that is constantly updated with novel relation types and facts.
   Negative triple samples give knowledge representation models expressiveness to judge disordered
triples. CKRL [284], for example, includes an index system for determining reliable triples, including

                                         ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:28                                                                              Lingfeng Zhong, et al.


local triple confidence, which compares the distance between a triple and a negative sample; global
path confidence, which tests the global resources of the reasoning paths that form a triple; and
adaptive path confidence, which scores a local reasoning path deriving a triple.
   However, many potentially reasonable triples are not covered due to insufficient negative sam-
pling ‚Äì specifically, one-to-many relations [35]. Hence, researchers have leveraged more sophis-
ticated semantic structures to alleviate this issue. In this vein, Dong et al. [285] expand entity
embeddings into n-ball structures that are leveraged to incorporate fine-grained type chains as
a way to classify triples. Amador-Dom√≠nguez et al. [286] add ontological information to enhance
model-agnostic expressiveness. Some models focus on advanced neural network embeddings to
detect credible triples. For example, R-MeN [287] captures latent dependencies among triples by
employing a multi-head attention mechanism that generates memory-based embeddings.

5.2     Knowledge Fusion
Real-world knowledge is usually open for updates. In most scenarios, users should be able to add
external knowledge to enrich existing external knowledge graphs. In this way, knowledge fusion is
designed to merge semantically-equivalent elements such as ‚ÄúTrump‚Äù and ‚ÄúDonald Trump‚Äù so as to
integrate new knowledge within novel concepts or facts. The sub-tasks of knowledge fusion include
attribute alignment, entity matching with small-scale incoming triples, and entity alignment with a
complete knowledge graph.
5.2.1 Attribute Alignment.
   An attribute triple indicates a property of a concept with a description value like a color, date,
number, or character string. Users may use different terms to refer to the same attribute, such as
‚Äúbirthday‚Äù and ‚Äúdate of birth‚Äù, where synonyms may lead to semantic sparse. Attribute alignment is
thus purposed to unify attribute notations.
   Many methods focus on aligning the semantic embeddings of attributes, with the premise
being that two attribute names should be identical if their embeddings are close to each other.
Some models leverage the similarity between attribute name strings to generate distributional
embeddings, such as in [288] and [289]. Yang et al. [290] leverage a bag-of-words model to learn
the contextual embeddings of attributes. Similarly, JAPE [291] leverages the Skip-gram model for
attribute embedding to model co-occurring attributes that are frequently used together to describe
an entity, such as ‚Äúlatitude‚Äù and ‚Äúlongitude‚Äù for a position.
   Attribute embeddings also provide side information for entity alignment tasks, such as definitions
and descriptions. However, an attribute can also carry data that is not particularly informative,
like a telephone number, which can be challenging when attempting to generate knowledge-level
representations. Some models then consider using neural networks to generate embeddings based
on contextual values. For example, AttrE [292] embeds each character of an attribute value with
an LSTM framework so as to compose an attribute embedding for predicting potential phases
in monolingual expressions. The approach incorporates an attribute-name predicate alignment
strategy to handle unseen attributes.
5.2.2 Entity Matching with Small-scale Knowledge Graph.
   In its preliminary stages, a knowledge base will only contain a few triple mentions with insuffi-
cient information for rigorous concepts. Therefore, entity matching models integrate multi-source
knowledge with the available linguistic information in small-scale data. The more recent models
treat entity matching as a machine learning classification task. For example, Magellan [293] in-
tegrates multiple similarity functions with random forest, such that the approach also considers
numerical attributes. MSejrKu [294] explores the feasibility of leveraging the classifier layer includ-
ing the logic regression and MLP classifier to judge identical entity pairs. DeepMatcher [295] is a

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                 66:29


                   Existing KGs
                                                                   ùíÜùüè ‚â° ùíÜ‚Ä≤ùüè
                              Source KG
                        ùíÜùüè    ùíÜùüê     ùíìùüê
                                                                   ùíÜùüê + ùíìùüê ‚âÖ ùíÜùüë     Reliable = 1
                                       ùíÜùüë
                 Alignment                                                          Reliable =
                                  ?                               ùíÜ‚Ä≤ùüê + ùíìùüê ‚âÖ ùíÜùüë
                 Seeds                                                              ùëπ(ùíÜùüê, ùíÜ‚Ä≤ùüê )
                     ùíÜ‚Ä≤ùüè ùíÜ‚Ä≤       Target KG
                             ùüê          ùíÜ‚Ä≤ùüë                  ùë¨(ùíÜùüè, ùíÜ‚Ä≤ùüè )= ùíÜùüè + ùíìùë¨ùüè‚Üíùê∏ ùüè ‚àíùíÜ‚Ä≤ùüè (a)
                                                                                        ‚Ä≤


                                                             ùë¨(ùíÜùüè, ùíÜ‚Ä≤ùüè )= ùë¥ùë¨ùüè‚Üíùê∏ ùüè ùíÜùüè ‚àíùíÜ‚Ä≤ùüè
                                                                                 ‚Ä≤
                                                                                            (b)


Fig. 16. IPtranE [308]. IPtranE scores entity pairs via (a) translation models and (b) linear transformation
models, and merges identical pairs via hard or soft alignment.
deep learning system that incorporates an RNN structure with attention mechanisms to represent
attribute words for entity matching. Compared to conventional models, models based on deep
learning are better at handling noise in text, especially the concept-enrichment tasks [296] with
WordNet.
   Early attempts also aim at the unique attributes of entities for entity matching. Many models
leverage distance-based approaches to distributional representations of entity descriptions or
definitions. VCU [297] proposes first-order and second-order vector models to embed the description
words of an entity pair for comprehensively measuring the conceptual distance. TALN [298]
leverages sense-based embedding derived by BabelNet to combine the definitional description
of words, which first generates the embedding of each filtered definition word combing with
POS-tagger, syntax feature via BabelNet, then averages them to obtain a centroid sense to obtain
the best matching candidates. String-similarity-based models available for entity matching also
include TF-IDF [299], I-Sub [300].
   Graph-based methods achieve feasible performance for entity matching on the small-scale KG
that can consist of hierarchical graph structures. ETF [301] learns concept representations through
semantic features and graph-based features, including Katz similarity, random walk betweenness
centrality, and information propagation score. ParGenFS [302] leverages a graph-based fuzzy cluster
algorithm to conceptualize a new entity. This method stimulates the thematic distribution to acquire
distinctive concept clusters to search the corresponding location of an entity update in a target
knowledge graph.
   Entity matching tasks can also be handled by text-similarity-based models that detect surficial
similarity between entities when considering the trade-off between performance and computation
cost. Rdf-ai [303] proposes a systematic model to match two entity node graphs, which leverages the
string-matching and lexical-feature-similarity comparing algorithms to align available attributes,
then calculates the entity similarity for alignment. Similarly, Lime [304] further leverages metric
spaces to detect aligned entity pairs, which first generate entity exemplars to filter alignable
candidates before similarity computation for entity fusion. Different from small-scale KGs, the
shaped large KGs contain meaningful relational paths and enriched concept taxonomy. HolisticEM
[305] employs IDF score to calculate the surficial similarity of entity names for seed generating and
utilizes Personalized PageRank (PPR) to measure distances between entity graphs by respectively
traversing their neighbor nodes.
   Autonomous communities may input unique information to a KG system, such as nicknames,
telephone numbers, and other personalized data. Such knowledge can only be known by users.
Strategies to detect unique missing parts and ask users to fill them in are necessary. Active learning
methods [306] that judge information or solve conflicts by querying users are the most reliable
solutions and are indispensable in these scenarios.

                                            ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:30                                                                                                  Lingfeng Zhong, et al.


                                                                                c1                c2           Knowledge
            Condition KG
                                                                                                                Dynamic
            Statement      A will be B, when C satisfies D.
                             <<satisfies>> D                                              ?      ?         ?   Condition
            Condition      C                                                  Condition
                           A  <<is>>                                                      ?       ?        ?   Knowledge
                Fact                         B                                  Fact                            Complete
            Statement       E will be F, when C satisfies G.                  Condition                        Condition
            Condition      C <<satisfies>> G                                    Fact                           Knowledge
               Fact        E    <<is>>         F                                                               Acquisition
                                                                                              Statement
                                 ‚Ä¶‚Ä¶
                                    D                                                                  E

Fig. 17. Knowledge evolution. Evolution analysis tasks presented in (b) manufacture data into groups of
knowledge graphs (either conditional or fact knowledge graphs) displayed in (a) to portray knowledge under
various dynamic conditions.
5.2.3 Entity Alignment with Large-scale Knowledge Graph.
   Large-scale knowledge graphs usually comprise sufficient property information and graph
structures that can form knowledge-aware structures with conceptual entities and relational links.
Entity alignment tasks aim to integrate structured data with well-built large-scale knowledge
graphs containing semantic structures at the knowledge level.
   Embedding-based models learn inter-graph entity mappings for entity alignment tasks via seed
entities that have the knowledge embeddings of triples. Sun et al. [307] point out that vanilla
negative samples for link prediction can impair the ability to distinguish different entities of the
same type. Hence, they use near entities in the feature space of a corresponding target entity to
generate negative samples. IPTransE [308] is an iterative joint embedding strategy for knowledge
representation and learning entity mappings. It leverages a path translation embedding approach
to embed different relation paths linking the same entity pair. These are regarded as links with
identical effects. A soft alignment strategy is then used to alleviate matching errors. See Fig. 16.
MultiEA [309] considers the multi-view features of entity graph attributes, links, and neighbor
nodes. BootEA [307] includes a bootstrapped ‚Äúlikely alignment‚Äù labeling algorithm that iteratively
adds reliable seeds for aligning. In cross-lingual scenarios, MtransE [310] generates axis calibration
and translation vectors to model feature space invariance in different languages. Additionally, some
models consider self-supervision strategies to exploit seed information, such as SS-AGA [311] and
SelfKG [312].
   One critical challenge with entity alignment is that many entities do not possess surface or
structural distribution features. Thus, many entity alignment models also use attribute represen-
tation to augment the features. KDCoE [313], for example, leverages a co-training strategy with
description attributes. JarKA [314] models interactions among attributes in a sparse multi-lingual
knowledge graph to infer equivalent entities. Some models leverage deep learning-based neural
networks for attribute context embeddings. For example, AttrE [292] leverages an LSTM to derive
the dependency features of attribute values. Unlike previous methods, JAPE [291] consolidates
attribute embeddings with overlay relationship graph structures to capture cross-lingual disparities.
   Another challenging issue is semantic graph structures for alignment. GCN-Align [315] was the
first to propose a GCN-based framework for entity alignment tasks. Since then, recent research
has focused on complicated graph semantics using GCN-based models. For instance, RNM [316]
matches neighborhood nodes features to compare entity pairs. RDGCN [317] leverages a dual
relation graph to solve contradictory representations in triangular entity graph structures.
   Large-scale knowledge graphs typically contain distinctive semantic sub-graph structures for
alignment. Here, graph matching neural network (GMNN) [318] builds a topic entity graph that

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                          66:31


           Multi-output Module      {ùë≠ùíÇùíÑùíïùüè , ùë≠ùíÇùíÑùíïùüê , ‚Ä¶ , ùë≠ùíÇùíÑùíïùíè }                                {ùë™ùíêùíèùíÖùüè , ùë™ùíêùíèùíÖùüê , ‚Ä¶ , ùë™ùíêùíèùíÖùíè }
                                      ùíá              ùíá               ùíá                              ùíá            ùíá                 ùíá
                                     ùíìùüè             ùíìùüê             ùíìùüê                             ùíìùüè            ùíìùüê        ‚Ä¶      ùíìùüê
                                    ùíë[ùüè:ùëµ] ,       ùíë[ùüè:ùëµ]      ‚Ä¶   ùíë[ùüè:ùëµ]                        ùíë[ùüè:ùëµ] ,      ùíë[ùüè:ùëµ]            ùíë[ùüè:ùëµ]

          Tuple completion          Softmax                        Softmax                      Softmax                       Softmax
          Tagging layer
                                                                                                  FFN             ‚Ä¶              FFN
                                     FFN              ‚Ä¶             FFN


                                               ùíá         ùíá
                                          {ùíìùüè , ‚Ä¶ , ùíìùíè }                                                 {ùíìùíÑùüè , ‚Ä¶ , ùíìùíé
                                                                                                                     ùíÑ
                                                                                                                       }
                                                               fact          Relation name                           condition
                                                             Softmax                               Softmax
                    Relation name
                    tagging layer                             FFN                                    FFN

                                                                                                        Input Gates

                                                                                        Multi-head Decoder
                                                    LSTMd
                                                                                                            Input Gates

                                                                                        Multi-head Encoder
                                                   External
                                                   feature                                                  Input Gates
                                                   Multi-input
                                                                                         Statement Sentence
                                                   Module


       Fig. 18. The architecture of MIMO model [26] for extracting facts with conditions over texts.

links neighboring nodes to merge identical entities. AttrGNN [319] partitions a knowledge graph
according to attribute triple types to understand heterogeneous entity information.
   Recent research direction also aims at modeling cross-graph interaction. MuGNN [320], for
example, proposes a cross-knowledge graph attention mechanism with a multi-channel GNN
encoder that can model inter-graph structural features consistently. Similarly, GTEA [321] involves
a joint graph attention mechanism to fuse cross-graph relational information.

6     KNOWLEDGE EVOLUTION
Recently, researchers have focused on how knowledge evolves given environmental conditions.
Conditional knowledge graphs serve this goal by reflecting facts established under certain conditions.
A conditional tuple is formulated as (h, r, t, ùõæ), where ùõæ can be a prerequisite triple of a fact. Many
researchers have studied this in its simplified case, as a temporal knowledge graph, where ùõæ is
some kind of temporal information (like a timestamp) - for example (Biden, job, vice president,
2009-2017), (Biden, job, president, 2020-). Fig. 17 shows a schematic of knowledge evolution.

6.1    Condition Knowledge Acquisition
Many scientific facts are established upon certain conditions, especially in the biomedical field.
Early efforts have not comprehensively considered this scenario in a systematic view. Hence,
Jiang et al. [322] developed a new tagging schema to describe conditional tuples formatted as
‚ÄúB/I-XYZ‚Äù, where ‚ÄúBI‚Äù stands for positional information (begin/intermediate), ‚ÄúX‚Äù is the logic role
(fact/condition), ‚ÄúY‚Äù marks the tuple role (subject/object), and ‚ÄúZ‚Äù denotes the constituent type
(concept/attribute/predicate). Conditional knowledge extraction achieves three goals: it extracts
fact tuples, it collects conditional tuples, and it connects fact conditions. Jiang et al. [26] noted
that the traditional extraction systems merge conditional information into entities to form factual
triples, which will compromise entity linking. Further, the same tokens can be both subjects and
objects of different tuples in an unstructured statement. They therefore devised a joint extraction
method based on the multi-input multi-output sequence labeling (MIMO) to tackle this problem.

                                                   ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:32                                                                                 Lingfeng Zhong, et al.


Their MIMO model leverages a relation name tagging layer that denotes the relationship tags for
each token via factual and conditional tagging sub-layers, respectively. A tuple completion tagging
layer is then used to distinguish the logic roles of each token with different relationship names.
However, Zheng et al. [323] point out that the MIMO tagging schema cannot effectively handle
overlapping triples. They therefore leveraged hierarchical parsing to simplify the multi-output
schema in MIMO models into a one-output schema. Fig. 18 illustrates the MIMO model.
   Another popular trend in conditional knowledge extraction is temporal knowledge extraction,
where a conditional triple is simplified into time. Many previous models leverage RNN structures to
capture temporal dependencies and therefore identify the temporal relationships within sentences,
such as [324] and [325]. In terms of extracting fine-grained temporal knowledge, Vashishtha et al.
[326] model events, states, and durations to match their timeline via multiple stacked attention
layers. Recent research has improved solutions to handle document-level temporal knowledge
extraction. For instance, TIMERS [327] is a rhetoric-aware graph for GCN models to interpret an
intricate contiguous ‚Äúelementary discourse unit‚Äù through the document‚Äôs expressions. Here, an
elementary discourse unit is the minimal semantic unit involved in temporal activities.

6.2     Condition Knowledge Graph Completion
Condition Knowledge Graph Completion tasks fills incomplete triples in a Condition KG, such as
(h, ?, t, ùõæ), (h, r, ?, ùõæ), and (h, r, t, ?). Note that, in this section, our main focus is on methods for
completing temporal knowledge graphs.
   Researchers can predict incomplete temporal tuples by temporal information embedding models.
TTransE [328] extends TransE with temporal embedding vectors. HyTE [329] treats the timestamp
as a hyperplane for matching entity and relation embeddings. Another promising direction is
temporal-aware embeddings. In this stream, the LSTM-based model [330] interprets time-encoding
sequences, while the CNN-based model [331] captures the temporal consistency of contexts.
   Temporal knowledge graph representations can be regarded as tensor structures along the tem-
poral dimension, which means tensor decomposition can be used to complete temporal knowledge
graphs. The main solutions for tensor decomposition include canonical polyadic decomposition and
Tucker decomposition. Canonical polyadic decomposition uses the sum of several one-rank tensors
to approach a target tensor. Many temporal knowledge graph completion models use canonical
polyadic decomposition, e.g., [332] and [333]. Tucker decomposition factorizes a target tensor into
the multiplication between a kernel tensor and multiple tensors along each dimension of the target
tensor. Shao et al. [334] developed a model based on Tucker-decomposition to interpret temporal
semantic associations that increases the flexibility of representations that include timestamps.
SpliMe [335] obtains time-viewed entity embeddings via a static model.
   Another critical topic for temporal knowledge graph completion is temporal knowledge reasoning.
Recent research interest has focused on GCN-based methods. Here, Han et al. [25] exploit historical
contexts by expanding a query-dependent interference subgraph based on edge attention scores.
Jung et al. [336] achieve multi-hop temporal reasoning via edge-based attention propagation, while
Liu et al. [337] enhance temporal knowledge graph reasoning via a model based on reinforcement
learning. Moreover, facts in a timeline cannot ignore temporal dependencies, such as ‚Äúborn-in‚Äù
before ‚Äúworks-at‚Äù. Jiang et al. [338] defines a scoring function that contains an asymmetric matrix
to preserve temporal ordering constraints for reasoning.
   Filling in incomplete general conditional tuples is open for further exploration. Tuples may
contain more than one condition, such as chemical reactions that only occur within a certain
temperature range. A systematic solution should be put into these complex scenarios. We suggest
that readers also consider causality discovery methods [339].

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                               66:33


                  Mary and Henry planned for a trip. They went to England last week. Mary believed the Avon River was the most
 Text             romantic sight in England, while Henry felt honored to be a compatriot of Shakespeare while walking around their
                  hometown. They were sure that their daughter Lily would like this place as well.
 Inference                      Fact                                                           Detail

 Coreference         (Mary, Entity-Destination, England)
 Reasoning           (Henry, Entity-Destination, England)      Mary and Henry planned for a trip. They visited England ‚Ä¶‚Ä¶
 Pattern
                     (the Avon River, part-of, England)         $X was ‚Ä¶‚Ä¶ sight in $Y
 Recognition

 Logic                                                         (Henry, compatriot-of, Shakespeare)
                                                                                                        (Henry, nationality, England)
 Reasoning           (Henry, nationality, England)             (Shakespeare, nationality, England)

 Commonsesnse                                                  (Mary, daughter, Lily)
                     (Mary, partner, Henry)                                                  (Mary, partner, Henry)
 Reasoning                                                     (Henry, daughter, Lily)


                   Fig. 19. An example of relation inference over long context in a document.

6.3     Knowledge Dynamic
Many researchers have contributed to the literature on knowledge dynamics. A good proportion
uses RNN structures to understand diachronic dependencies so as to predict state changes. For
example, Know-evolve [340] involves a multivariate temporal point process with an enhanced RNN
structure that learns a temporal evolutionary representation function. RE-NET [341] incorporates
a neighborhood aggregator to seize concurrent interactions between entity nodes. Models have
also been designed that contain evolutionary representations, such as MGraph [342] and DyERNIE
[343]. Gracious et al. [344] systematically construct a neural latent space model that combines
the evolutionary information of a heterogeneous knowledge graph. Yan et al. [345] improves a
GCN model‚Äôs ability to capture topology-invariant features. The idea is to align nodes in different
temporal knowledge graph snapshots and build a dynamic profile of concepts.
   How knowledge evolves when different kinds of conditions change remains challenging ‚Äì take
the conditions needed to end the COVID-19 outbreak as an example. We recommend that readers
refer to causality feature selection methods [339] along with experts and multi-source evidence.

7     KNOWLEDGE GRAPH STORAGE
In this section, we provide a brief overview of KG storage tools for different data environments.
   Early efforts at graph storage used relational models to perpetuate constructed knowledge
graphs. Traditional RDBMS provides reliable and swift CRUD operations for table-formed databases.
Developers have also employed graph algorithms like depth-first traverse and shortest-path search
to enhance relational databases [32]. Representative examples of this type of algorithm include
PostgreSQL [346] and filament 10 . However, it can be very costly for a relational database to handle
sparse KGs or perform data partition for distribution storage.
   Key/value databases are lightweight solutions for saving clusters in large knowledge graphs.
Further, they support distributed storage with a simplified and flexible data format. Trinity [347]
provides a high-performance in-memory Key/Value storage system to manage large knowledge
graphs with billions of nodes, such as Probase. CouchDB [348] uses a replication mechanism to
maintain dynamic knowledge graphs. MapReduce technology automatically transforms data groups
into key/value mappings. Hadoop 11 enables high-throughput parallel computing for knowledge

10 https://filament.sourceforge.net
11 http://hadoop.apache.org



                                                     ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:34                                                                                                Lingfeng Zhong, et al.


                         A saw B with a telescope.
                                                                              (A, B, saw)
                                                                              (A, telescope, with)
                                                       B
                                     A
                                                                              (A, B, saw)
                                                                              (B, telescope, with)
                                      A         B
                                                                              (A, B, saw)
                                    No Image
                                                                              (?, telescope, with)

Fig. 20. An example of solving information incompleteness via cross-modal dependency. In this case, the
textual expression ‚ÄúA saw B with a telescope.‚Äù is unclear. An extractor can only determine the relationship
between people and the ‚Äútelescope‚Äù by interpreting the side information in the image data.

graph storage via MapReduce. Pregel [349] develops a superstep mechanism to share messages
between vertices for parallel computing.
   Another promising direction is to design graph databases that fit in knowledge triple structures.
Neo4j[350] is a lightweight NoSQL-based graph database that supports embedded dynamic knowl-
edge graph storage. SOnes 12 provides object-oriented queries for KG database. Novel languages
have also been developed for knowledge storage, such as resource description framework (RDF)
and web ontology language (OWL) 13 . Some graph databases based on RDF optimize the storage of
graph structures. For example, gStore [349] improves RDF-structured knowledge graph databases
via sub-graph matching algorithms.

8     DISCUSSION ON KNOWLEDGE GRAPH CONSTRUCTION
Researchers have contributed various solutions to different aspects of knowledge graph construction.
However, some challenging issues and research directions are still open for further discussion.

8.1      Long and Intricate Contexts for KG Construction
Intricate cross-sentence or cross-paragraph contexts impedes different KG construction sub-tasks
for practical use, especially relation extraction tasks. It is worth reminding readers that complex
contexts do not merely relate to long-term dependency. Yao et al. [22] point out that four kinds of
inferences include pattern recognition, coreference reasoning, logic reasoning, and commonsense
reasoning, are critical to contain high-order contextual semantics. A specific example is presented
in Fig. 19.
   A model that handles complex long contexts should focus on intricate cross-sentence patterns
while performing reasoning over multiple linguistic objects. Besides document-level extraction
models in section 4.3.6, Some efforts in section 4.1.2 also model document-level contexts via
heterogeneous models for entity typing. Noticeably, ambiguous expressions may occur in user-
generated texts, which are usually not correctly interpreted by models without external information.
Another challenging issue for reasoning is multi-hop reasoning. More linguistic structures should
be explored to comprehend tortuous expressions.
   Out-of-context expressions requiring background knowledge to handle are bottlenecks for KG
construction. The obstacles are mainly two-fold: 1) spontaneous knowledge, and 2) evidence
support. Commonsense knowledge spontaneously generated is often utilized to derive new facts,
12 http://github.com/sones/sones
13 RDF   and OWL are both standards of w3c, see also http://www.w3.org/RDF


ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                 66:35

                                          Data-invisible
                                            features
                                                    Federated
                                                      Model
                                Model               Encrypted              Model
                                 A                   training               B

                                                   Collaborator
                                                   Encrypted
                                                Entity Alignment


                               Provider                                   Provider
                                  A                                          B
                                                No Data Exchange


Fig. 21. An illustration of building a federated model from different knowledge providers while protecting
privacy. In this procedure, an encrypted entity alignment process is performed before training separate models
on multi-source data parts, then a collaborator calculates and aggregates encrypted gradients of each model
to prevent leakage. A federated model only reserves data-invisible crowd-sourced knowledge features.

e.g., man and woman who have kids should be couples/partners, despite such convictions sometimes
inaccuracy. How to obtain commonsense rules and adapt them to suitable scenarios is an important
direction. Meanwhile, many document-level datasets do not contain evidence information for
correct logic paths. Efforts like [357] have probed into document-level evidence structures for
relation mentions. However, it is not likely to foresee that a model can learn to organize clues
correctly to resolve facts in all scenarios (e.g., validating the conclusion in a philosophical book).
We believe long-context is not merely an NLP question, and models [358] understanding linguistic
expressions will be a critical direction. Furthermore, conditions like temporal and geographical
information in provided data sources should also be considered for rigorously comprehending
contexts.

8.2   Multi-modal Knowledge Graph Construction and Completion
Multi-modal knowledge graphs can entirely express and store heterogeneous information for
display. Multi-modal knowledge can also be applied to detect fake or low-quality content, such as
text with mismatched images (e.g., a document labeled Paris with a picture of London). MMKG
[353] is a model for completing multi-modal tuples that reasons over image information, while
Dost et al. [354] probe into cross-modal entity linking with text and images. Another problem for
multi-modal knowledge graphs is solving semantic incompleteness in one-modal expression via
cross-modal dependencies. We illustrate this challenge with a specific example in Fig. 20.

8.3   Federated Learning
Federated Learning is an enlightening direction for the essential requirements of privacy protection.
A federated setting for KGs that trains model ensembles from multi-sources is one of the popular
strategies. Significant advances have been conducted to federated knowledge embeddings, such
as FKGE [355] and FedE [356], which prohibit data exchange while incorporating cross-modal
features during training. However, entity alignment is a paradoxical bottleneck that impedes
federated learning, requiring multi-source KGs to be shared before model learning, which will
exchange sensitive information during knowledge fusion. How to create a privacy-reserved super
feature space for encrypted entity alignment while federating features is still open for exploration.

                                            ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:36                                                                                               Lingfeng Zhong, et al.


                                                             Answer                           Ask
  KB                         John
                                                                                                                HI
                                    <<friend>>      ?       <<friend>>                                     (Unique Data
         <<work_at>>                                                                   <<friend>>
                                                                           HAO-based                         Provider)
                               <<nationality>>     ?                         Active
      Microsoft                                            <<nationality>>
  <<located_in>>                                                            Learning <<nationality>>           OI
                                    <<live_in>>    ?                                                (Authority/Organized
         Seattle                                                                                       Data Mangers)
                                                            <<live_in>>
                                                                                                               01
                                                                                         <<live_in>>           AI

Fig. 22. An HAO-based active learning case for knowledge graph construction. HAO-based active learning
models select users with appropriate roles to label uncertain samples. In this case (if the privacy policy allows),
John‚Äòs nationality will be labeled by the authority (OI), while his friends will be found by asking users (HI) in
his social network. The AI will then derive his place of living from known facts.

Designing more privacy-friendly models for constructing KGs is critical for sensitive data scenarios.
We illustrate the procedure of developing a federated model in Fig. 21.

8.4     Advanced Semantic and Dynamic in Knowledge Graph Construction Tasks
Recent research has extended to advanced semantic evaluation tasks, such as detecting equivoque
[351] and validating facts with common sense [352] to handle complex lingual phenomena. Inter-
preting literary expressions, such as similes and metaphors, is a future direction for intelligent
knowledge graph construction, e.g., ‚ÄúTom went to heaven in 2008.‚Äù means ‚Äú Tom, died-in, 2008‚Äù.
Developing or fine-tuning pre-trained models with advanced semantics will be a starting point for
high productivity.
   Furthermore, many studies have been conducted on the dynamics of temporal knowledge graphs.
However, how knowledge semantics evolves with the general associated conditions remains an
unexplored field. Diving into heuristic questions such as ‚ÄúHow do the professional social networks
of medical staff change with the phases of a pandemic?‚Äù may help us detect implicit factors for
boosting policy making in public health. Capturing the dynamics of how associated conditions
affect related facts is the ultimate direction for simulating general human knowledge.

8.5     Human-machine Synergy for Knowledge Graph Construction
Asking appropriate users to complete and correct knowledge graphs is the ultimate solution for
obtaining unknown facts in the open world. To this end, Wu et al. [8] devised the HAO model to
solve different construction problems by having humans and machines collaborate. An HAO-based
active learning model that automatically identifies different roles (e.g., field experts (HI), organized
authorities (OI), computing systems (AI), etc.) and assigns undetermined data to appropriate users
to tag will be a promising direction to endow wisdom to knowledge graph construction frameworks.
We present an illustration of this significant idea in Fig. 22.

8.6     Cross-lingual Knowledge Graph
Building cross-lingual knowledge graphs is a long-term goal that refers to integrating imbalanced
resources distributed in different languages. Xlore [42] provides an enlightening example of aligning
cross-lingual entities via deep learning approaches. However, machine translation remains a
formidable bottleneck to cross-lingual tasks. Firstly, errors and conflicts generated in the process of
translation will compromise the effort of refinement. Secondly, data resources expressed in minority
languages may be insufficient for machine learning. To accurately perform automatic low-resource
knowledge translation while resolving cross-lingual conflicts is a promising direction.

ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                           66:37


8.7    End-to-end Unified Framework for Construction
End-to-end extraction methods, such as GCN-based frameworks, unify the sub-tasks of knowledge
acquisition into one unified extraction task, surpassing pipeline designs. However, incorporating
knowledge acquisition with knowledge refinement tasks to build an integrated joint model remains
a formidable bottleneck. Searching for end-to-end frameworks that unify both extraction and the
refinement of knowledge graphs could be an enlightening future direction. Providing a high-quality
off-the-shelf solution avoids the need for manual adjustments to components, and one that considers
cross-task semantics would be a worthwhile undertaking. Further, training a framework that unifies
the general procedures of knowledge graph construction would be a worth-to-solve challenging
multi-task learning problem.

9     CONCLUSION
With this paper, we delivered a comprehensive survey on the topic of knowledge graph construction.
Specifically, we reviewed the tasks, methods, challenges, and related resources used to construct,
refine, and integrate KGs from various data types in different scenarios. To probe into the essential
topics for the big data environment, we systematically presented the paragon models for obtaining
fine-grained concepts (entity typing), dealing with low-resource knowledge (extraction tasks in few-
shot scenarios), understanding large linguistic objects (document-level relation extraction), complex
reasoning (logic and interpretable reasoning) and handling conditional structures (temporal and
general conditions) in knowledge graphs. Moreover, we provided briefs on practical KG toolkits
and projects. In conclusion, knowledge graph construction has become a critical topic for enabling
human intelligence in AI applications. In the future, the research community will certainly be
searching for more paradigms to empower KGs with wisdom in massive heterogeneous, autonomous,
complex, and evolving data environments while enhancing collaborations between knowledge
communities.

REFERENCES
  [1] J. Liu, J. Ren, W. Zheng, L. Chi, I. Lee, and F. Xia, ‚ÄúWeb of scholars: A scholar knowledge graph,‚Äù in SIGIR , 2020,
      pp. 2153‚Äì2156, 2020.
  [2] X. Wang, X. He, Y. Cao, M. Liu, and T. Chua, ‚ÄúKGAT: knowledge graph attention network for recommendation,‚Äù in
      KDD, 2019, pp. 950‚Äì958, 2019.
  [3] J. Bao, N. Duan, Z. Yan, M. Zhou, and T. Zhao, ‚ÄúConstraint-based question answering with knowledge graph,‚Äù in Proc.
      COLING, 2016, pp. 2503‚Äì2514, 2016.
  [4] K. D. Bollacker, R. P. Cook, and P. Tufts, ‚ÄúFreebase: A shared database of structured general human knowledge,‚Äù in
      Proc. AAAI-07, 2007, pp. 1962‚Äì1963, 2007.
  [5] D. Vrandecic, ‚ÄúWikidata: a new platform for collaborative data collection,‚Äù in Proc. WWW,2012, 2012 (Companion
      Volume), pp. 1063‚Äì1064, 2012.
  [6] A. Yates, M. Banko, M. Broadhead, M. J. Cafarella, O. Etzioni, and S. Soderland, ‚ÄúTextrunner: Open information
      extraction on the web,‚Äù in HLT-NAACL, Proceedings, 2007, pp. 25‚Äì26, 2007.
  [7] O. Etzioni, M. J. Cafarella, D. Downey, S. Kok, A. Popescu, T. Shaked, S. Soderland, D. S. Weld, and A. Yates, ‚ÄúWeb-scale
      information extraction in knowitall: (preliminary results),‚Äù in Proc. WWW, 2004, pp. 100‚Äì110, 2004.
  [8] M. Wu and X. Wu, ‚ÄúOn big wisdom,‚Äù Knowl. Inf. Syst., vol. 58, no. 1, pp. 1‚Äì8, 2019.
  [9] Z. Huang, W. Xu, and K. Yu, ‚ÄúBidirectional LSTM-CRF models for sequence tagging,‚Äù CoRR, vol. abs/1508.01991, 2015.
 [10] X. Ma and E. H. Hovy, ‚ÄúEnd-to-end sequence labeling via bi-directional lstm-cnns-crf,‚Äù in Proc. ACL, 2016, Volume 1:
      Long Papers, 2016.
 [11] P. Xu and D. Barbosa, ‚ÄúNeural fine-grained entity type classification with hierarchy-aware loss,‚Äù in Proc. NAACL-HLT,
      2018, Volume 1 (Long Papers), pp. 16‚Äì25, 2018.
 [12] X. Ren, W. He, M. Qu, C. R. Voss, H. Ji, and J. Han, ‚ÄúLabel noise reduction in entity typing by heterogeneous partial-label
      embedding,‚Äù in KDD, 2016, pp. 1825‚Äì1834, 2016.
 [13] O. Ganea and T. Hofmann, ‚ÄúDeep joint entity disambiguation with local neural attention,‚Äù in Proc. EMNLP , 2017,
      pp. 2619‚Äì2629, 2017.


                                                 ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:38                                                                                                   Lingfeng Zhong, et al.


 [14] P. Le and I. Titov, ‚ÄúImproving entity linking by modeling latent relations between mentions,‚Äù in Proc. ACL , 2018,
      Volume 1: Long Papers, pp. 1595‚Äì1604, 2018.
 [15] K. Lee, L. He, M. Lewis, and L. Zettlemoyer, ‚ÄúEnd-to-end neural coreference resolution,‚Äù in Proc. EMNLP, 2017,
      pp. 188‚Äì197, 2017.
 [16] D. Zeng, K. Liu, Y. Chen, and J. Zhao, ‚ÄúDistant supervision for relation extraction via piecewise convolutional neural
      networks,‚Äù in Proc. EMNLP, 2015, pp. 1753‚Äì1762, 2015.
 [17] P. Zhou, W. Shi, J. Tian, Z. Qi, B. Li, H. Hao, and B. Xu, ‚ÄúAttention-based bidirectional long short-term memory
      networks for relation classification,‚Äù in Proc. ACL, 2016, Volume 2: Short Papers, 2016.
 [18] H. Zhang, D. Khashabi, Y. Song, and D. Roth, ‚ÄúTransomcs: From linguistic graphs to commonsense knowledge,‚Äù in
      Proc. IJCAI, 2020, pp. 4004‚Äì4010, 2020.
 [19] H. Zhang, X. Liu, H. Pan, H. Ke, J. Ou, T. Fang, and Y. Song, ‚ÄúASER: towards large-scale commonsense knowledge
      acquisition via higher-order selectional preference over eventualities,‚Äù CoRR, vol. abs/2104.02137, 2021.
 [20] W. Xin-Dong, S. Shao-Jing, J. Ting-Ting, B. Chen-Yang, and W. Ming-Hui, ‚ÄúHuapu-cp: from knowledge graphs to a
      data central-platform,‚Äù Acta Automatica Sinica, vol. 46, no. 10, pp. 2045‚Äì2059, 2020.
 [21] J. Devlin, M. Chang, K. Lee, and K. Toutanova, ‚ÄúBERT: pre-training of deep bidirectional transformers for language
      understanding,‚Äù in NAACL-HLT , 2019, Volume 1 (Long and Short Papers), pp. 4171‚Äì4186, 2019.
 [22] Y. Yao, D. Ye, P. Li, X. Han, Y. Lin, Z. Liu, Z. Liu, L. Huang, J. Zhou, and M. Sun, ‚ÄúDocred: A large-scale document-level
      relation extraction dataset,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 764‚Äì777, 2019.
 [23] S. Riedel, L. Yao, and A. McCallum, ‚ÄúModeling relations and their mentions without labeled text,‚Äù in ECML PKDD,
      2010, Proceedings, Part III, vol. 6323, pp. 148‚Äì163, 2010.
 [24] X. Wang, X. Han, Y. Lin, Z. Liu, and M. Sun, ‚ÄúAdversarial multi-lingual neural relation extraction,‚Äù in Proc. COLING,
      2018, pp. 1156‚Äì1166, 2018.
 [25] Z. Han, P. Chen, Y. Ma, and V. Tresp, ‚ÄúExplainable subgraph reasoning for forecasting on temporal knowledge graphs,‚Äù
      in ICLR, 2021.
 [26] T. Jiang, T. Zhao, B. Qin, T. Liu, N. V. Chawla, and M. Jiang, ‚ÄúMulti-input multi-output sequence labeling for joint
      extraction of fact and condition tuples from scientific text,‚Äù in Proc. EMNLP-IJCNLP, 2019, pp. 302‚Äì312, 2019.
 [27] A. Pradhan, K. K. Todi, A. Selvarasu, and A. Sanyal, ‚ÄúKnowledge graph generation with deep active learning,‚Äù in
      IJCNN , 2020, pp. 1‚Äì8, 2020.
 [28] X. Wu, X. Zhu, G. Wu, and W. Ding, ‚ÄúData mining with big data,‚Äù IEEE Trans. Knowl. Data Eng., vol. 26, no. 1,
      pp. 97‚Äì107, 2014.
 [29] A. Hogan, E. Blomqvist, M. Cochez, C. d‚ÄôAmato, G. de Melo, C. Guti√©rrez, S. Kirrane, J. E. L. Gayo, R. Navigli,
      S. Neumaier, A. N. Ngomo, A. Polleres, S. M. Rashid, A. Rula, L. Schmelzeisen, J. Sequeda, S. Staab, and A. Zimmermann,
      Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge, Morgan & Claypool Publishers, 2021.
 [30] H. Paulheim, ‚ÄúKnowledge graph refinement: A survey of approaches and evaluation methods,‚Äù Semantic Web, vol. 8,
      no. 3, pp. 489‚Äì508, 2017.
 [31] X. Wu, J. Wu, X. Fu, J. Li, P. Zhou, and X. Jiang, ‚ÄúAutomatic knowledge graph construction: A report on the 2019
      ICDM/ICBK contest,‚Äù in ICDM, 2019, pp. 1540‚Äì1545, 2019.
 [32] J. Yan, C. Wang, W. Cheng, M. Gao, and A. Zhou, ‚ÄúA retrospective of knowledge graphs,‚Äù Frontiers Comput. Sci., vol. 12,
      no. 1, pp. 55‚Äì74, 2018.
 [33] T. Nayak, N. Majumder, P. Goyal, and S. Poria, ‚ÄúDeep neural approaches to relation triplets extraction: a comprehensive
      survey,‚Äù Cogn. Comput., vol. 13, no. 5, pp. 1215‚Äì1232, 2021.
 [34] S. Pawar, P. Bhattacharyya, and G. K. Palshikar, ‚ÄúTechniques for jointly extracting entities and relations: A survey,‚Äù
      CoRR, vol. abs/2103.06118, 2021.
 [35] S. Ji, S. Pan, E. Cambria, P. Marttinen, and P. S. Yu, ‚ÄúA survey on knowledge graphs: Representation, acquisition, and
      applications,‚Äù IEEE Trans. Neural Networks Learn. Syst., vol. 33, no. 2, pp. 494‚Äì514, 2022.
 [36] S. Arora, ‚ÄúA survey on graph neural networks for knowledge graph completion,‚Äù CoRR, vol. abs/2007.12374, 2020.
 [37] B. Cai, Y. Xiang, L. Gao, H. Zhang, Y. Li, and J. Li, ‚ÄúTemporal knowledge graph completion: A survey,‚Äù CoRR,
      vol. abs/2201.08236, 2022.
 [38] Q. Wang, Z. Mao, B. Wang, and L. Guo, ‚ÄúKnowledge graph embedding: A survey of approaches and applications,‚Äù
      IEEE Trans. Knowl. Data Eng., vol. 29, no. 12, pp. 2724‚Äì2743, 2017.
 [39] L. Ehrlinger and W. W√∂√ü, ‚ÄúTowards a definition of knowledge graphs,‚Äù in SEMANTiCS, SuCCESS‚Äô16, 2016, vol. 1695 of
      CEUR Workshop Proceedings, 2016.
 [40] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. G. Ives, ‚ÄúDbpedia: A nucleus for a web of open data,‚Äù
      in ISWC + ASWC, 2007, vol. 4825, pp. 722‚Äì735, 2007.
 [41] W. Wu, H. Li, H. Wang, and K. Q. Zhu, ‚ÄúProbase: a probabilistic taxonomy for text understanding,‚Äù in SIGMOD , 2012,
      pp. 481‚Äì492, 2012.



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                          66:39


 [42] Z. Wang, J. Li, Z. Wang, S. Li, M. Li, D. Zhang, Y. Shi, Y. Liu, P. Zhang, and J. Tang, ‚ÄúXlore: A large-scale english-
      chinese bilingual knowledge graph,‚Äù in Proc. ISWC, 2013, Posters & Demonstrations Track, vol. 1035 of CEUR Workshop
      Proceedings, pp. 121‚Äì124, 2013.
 [43] B. Xu, Y. Xu, J. Liang, C. Xie, B. Liang, W. Cui, and Y. Xiao, ‚ÄúCn-dbpedia: A never-ending chinese knowledge extraction
      system,‚Äù in IEA/AIE, 2017, Proceedings, Part II, vol. 10351, pp. 428‚Äì438, 2017.
 [44] F. M. Suchanek, G. Kasneci, and G. Weikum, ‚ÄúYago: a core of semantic knowledge,‚Äù in Proc. WWW, 2007, pp. 697‚Äì706,
      2007.
 [45] M. Mintz, S. Bills, R. Snow, and D. Jurafsky, ‚ÄúDistant supervision for relation extraction without labeled data,‚Äù in Proc.
      ACL , 2009, pp. 1003‚Äì1011, 2009.
 [46] J. Chen, A. Wang, J. Chen, Y. Xiao, Z. Chu, J. Liu, J. Liang, and W. Wang, ‚ÄúCn-probase: A data-driven approach for
      large-scale chinese taxonomy construction,‚Äù in Proc. ICDE, 2019, pp. 1706‚Äì1709, 2019.
 [47] G. A. Miller, ‚ÄúWordnet: A lexical database for english,‚Äù Commun. ACM, vol. 38, no. 11, pp. 39‚Äì41, 1995.
 [48] R. Navigli and S. P. Ponzetto, ‚ÄúBabelnet: Building a very large multilingual semantic network,‚Äù in Proc. ACL, 2010,
      pp. 216‚Äì225, 2010.
 [49] H. Liu and P. Singh, ‚ÄúConceptnet‚Äîa practical commonsense reasoning tool-kit,‚Äù BT technology journal, vol. 22, no. 4,
      pp. 211‚Äì226, 2004.
 [50] Z. Dong and Q. Dong, ‚ÄúHownet - a hybrid language and knowledge resource,‚Äù in ICNLP, 2003 , Proceedings, pp. 820‚Äì824,
      2003.
 [51] S. Han, Y. Zhang, Y. Ma, C. Tu, Z. Guo, Z. Liu, and M. Sun, ‚ÄúThuocl: Tsinghua open chinese lexicon,‚Äù Tsinghua
      University, 2016.
 [52] C. Matuszek, J. Cabral, M. J. Witbrock, and J. DeOliveira, ‚ÄúAn introduction to the syntax and content of cyc,‚Äù in Papers
      from the 2006 AAAI Spring Symposium, Technical Report SS-06-05, 2006, pp. 44‚Äì49, 2006.
 [53] T. Steiner, R. Verborgh, R. Troncy, J. Gabarr√≥, and R. V. de Walle, ‚ÄúAdding realtime coverage to the google knowledge
      graph,‚Äù in Proc. ISWC, 2012, vol. 914 of CEUR Workshop Proceedings, 2012.
 [54] R. J. Roberts, ‚ÄúPubmed central: The genbank of the published literature,‚Äù Proceedings of the National Academy of
      Sciences of the United States of America, vol. 98, no. 2, p. 381, 2001.
 [55] D. S. Wishart, C. Knox, A. Guo, S. Shrivastava, M. Hassanali, P. Stothard, Z. Chang, and J. Woolsey, ‚ÄúDrugbank: a
      comprehensive resource for in silico drug discovery and exploration,‚Äù Nucleic Acids Res., vol. 34, no. Database-Issue,
      pp. 668‚Äì672, 2006.
 [56] J. Tang, D. Zhang, and L. Yao, ‚ÄúSocial network extraction of academic researchers,‚Äù in Proc. ICDM, 2007, pp. 292‚Äì301,
      2007.
 [57] F. Zhang, X. Liu, J. Tang, Y. Dong, P. Yao, J. Zhang, X. Gu, Y. Wang, B. Shao, R. Li, and K. Wang, ‚ÄúOAG: toward linking
      large-scale heterogeneous entity graphs,‚Äù in KDD, 2019, pp. 2585‚Äì2595, 2019.
 [58] H. Chen, N. Hu, G. Qi, H. Wang, Z. Bi, J. Li, and F. Yang, ‚ÄúOpenkg chain: A blockchain infrastructure for open
      knowledge graphs,‚Äù Data Intell., vol. 3, no. 2, pp. 205‚Äì227, 2021.
 [59] W. Gong-Qing, H. Jun, L. Li, X. Zhe-Hao, L. Peng-Cheng, H. Xue-Gang, and W. Xin-Dong, ‚ÄúOnline web news extraction
      via tag path feature fusion. ruan jian xue bao,‚Äù Journal of Software, vol. 27, no. 3, pp. 714‚Äì735, 2016.
 [60] A. Fader, S. Soderland, and O. Etzioni, ‚ÄúIdentifying relations for open information extraction,‚Äù in Proc. EMNLP, 2011.
 [61] Mausam, M. Schmitz, S. Soderland, R. Bart, and O. Etzioni, ‚ÄúOpen language learning for information extraction,‚Äù in
      Proc. EMNLP-CoNLL, ACL 2012, pp. 523‚Äì534, 2012.
 [62] S. Bird, ‚ÄúNLTK: the natural language toolkit,‚Äù in ACL, 2006 (N. Calzolari, C. Cardie, and P. Isabelle, eds.), 2006.
 [63] C. D. Manning, M. Surdeanu, J. Bauer, J. R. Finkel, S. Bethard, and D. McClosky, ‚ÄúThe stanford corenlp natural language
      processing toolkit,‚Äù in Proc. ACL, 2014, pp. 55‚Äì60, 2014.
 [64] Z. Zhang, ‚ÄúEffective and efficient semantic table interpretation using tableminer+ ,‚Äù Semantic Web, vol. 8, no. 6,
      pp. 921‚Äì957, 2017.
 [65] M. Cremaschi, A. Rula, A. Siano, and F. D. Paoli, ‚ÄúMantistable: A tool for creating semantic annotations on tabular
      data,‚Äù in ESWC 2019 Satellite Events, 2019, Revised Selected Papers, vol. 11762, pp. 18‚Äì23, 2019.
 [66] M. Honnibal and I. Montani, ‚ÄúspaCy 2: Natural language understanding with Bloom embeddings, convolutional
      neural networks and incremental parsing.‚Äù To appear, 2017.
 [67] X. Han, T. Gao, Y. Yao, D. Ye, Z. Liu, and M. Sun, ‚ÄúOpenNRE: An open and extensible toolkit for neural relation
      extraction,‚Äù in Proceedings of EMNLP-IJCNLP: System Demonstrations, pp. 169‚Äì174, 2019.
 [68] X. Han, S. Cao, X. Lv, Y. Lin, Z. Liu, M. Sun, and J. Li, ‚ÄúOpenke: An open toolkit for knowledge embedding,‚Äù in Proc.
      EMNLP, 2018, pp. 139‚Äì144, 2018.
 [69] Z. Sun, Q. Zhang, W. Hu, C. Wang, M. Chen, F. Akrami, and C. Li, ‚ÄúA benchmarking study of embedding-based entity
      alignment for knowledge graphs,‚Äù Proc. VLDB Endow., vol. 13, no. 11, pp. 2326‚Äì2340, 2020.
 [70] A. Grover and J. Leskovec, ‚Äúnode2vec: Scalable feature learning for networks,‚Äù in Proceedings of KDD, pp. 855‚Äì864,
      2016.


                                                 ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:40                                                                                                    Lingfeng Zhong, et al.


 [71] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, ‚ÄúLine: Large-scale information network embedding,‚Äù in
      Proceedings of WWW, pp. 1067‚Äì1077, 2015.
 [72] W. Hu and Y. Qu, ‚ÄúFalcon-ao: A practical ontology matching system,‚Äù J. Web Semant., vol. 6, no. 3, pp. 237‚Äì239, 2008.
 [73] C. Chang, C. Hsu, and S. Lui, ‚ÄúAutomatic information extraction from semi-structured web pages by pattern discovery,‚Äù
      Decis. Support Syst., vol. 35, no. 1, pp. 129‚Äì147, 2003.
 [74] C. Hsu and M. Dung, ‚ÄúGenerating finite-state transducers for semi-structured data extraction from the web,‚Äù Inf. Syst.,
      vol. 23, no. 8, pp. 521‚Äì538, 1998.
 [75] P. B. Golgher, A. S. da Silva, A. H. F. Laender, and B. A. Ribeiro-Neto, ‚ÄúBootstrapping for example-based data extraction,‚Äù
      in Proc. CIKM, 2001, pp. 371‚Äì378, 2001.
 [76] A. Carlson and C. Schafer, ‚ÄúBootstrapping information extraction from semi-structured web pages,‚Äù in ECML/PKDD,
      2008, Proceedings, Part I, vol. 5211, pp. 195‚Äì210, 2008.
 [77] B. Adelberg, ‚ÄúNodose - A tool for semi-automatically extracting semi-structured data from text documents,‚Äù in
      SIGMOD, 1998 (L. M. Haas and A. Tiwary, eds.), pp. 283‚Äì294, 1998.
 [78] A. H. F. Laender, B. A. Ribeiro-Neto, and A. S. da Silva, ‚ÄúDebye - data extraction by example,‚Äù Data Knowl. Eng., vol. 40,
      no. 2, pp. 121‚Äì154, 2002.
 [79] A. Finn, N. Kushmerick, and B. Smyth, ‚ÄúFact or fiction: Content classification for digital libraries,‚Äù in DELOS , 2001,
      vol. 01/W03 of ERCIM Workshop Proceedings, 2001.
 [80] T. Weninger, W. H. Hsu, and J. Han, ‚ÄúCETR: content extraction via tag ratios,‚Äù in Proc. WWW, 2010, pp. 971‚Äì980, 2010.
 [81] F. Sun, D. Song, and L. Liao, ‚ÄúDOM based content extraction via text density,‚Äù in SIGIR, 2011, pp. 245‚Äì254, 2011.
 [82] G. Wu, L. Li, X. Hu, and X. Wu, ‚ÄúWeb news extraction via path ratios,‚Äù in CIKM, 2013, pp. 2059‚Äì2068, 2013.
 [83] D. Cai, S. Yu, J. Wen, and W. Ma, ‚ÄúExtracting content structure for web pages based on visual representation,‚Äù in
      APWeb, 2003, Proceedings, vol. 2642, pp. 406‚Äì417, 2003.
 [84] Y. Wang and J. Hu, ‚ÄúA machine learning based approach for table detection on the web,‚Äù in WWW, 2002, pp. 242‚Äì250,
      2002.
 [85] M. J. Cafarella, A. Y. Halevy, Y. Zhang, D. Z. Wang, and E. Wu, ‚ÄúUncovering the relational web,‚Äù in 11th International
      Workshop on the Web and Databases, WebDB, 2008.
 [86] J. Eberius, K. Braunschweig, M. Hentsch, M. Thiele, A. Ahmadov, and W. Lehner, ‚ÄúBuilding the dresden web table
      corpus: A classification approach,‚Äù in BDC , 2015, pp. 41‚Äì50, 2015.
 [87] M. J. Cafarella, A. Y. Halevy, and N. Khoussainova, ‚ÄúData integration for the relational web,‚Äù Proc. VLDB Endow., vol. 2,
      no. 1, pp. 1090‚Äì1101, 2009.
 [88] S. Zhang and K. Balog, ‚ÄúWeb table extraction, retrieval, and augmentation: A survey,‚Äù ACM Trans. Intell. Syst. Technol.,
      vol. 11, no. 2, pp. 13:1‚Äì13:35, 2020.
 [89] N. Kushmerick, ‚ÄúWrapper induction: Efficiency and expressiveness,‚Äù Artificial intelligence, vol. 118, no. 1-2, pp. 15‚Äì68,
      2000.
 [90] D. Buttler, L. Liu, and C. Pu, ‚ÄúA fully automated object extraction system for the world wide web,‚Äù in Proc. ICDCS
      ,2001, pp. 361‚Äì370, 2001.
 [91] B. M. Sundheim, ‚ÄúThe message understanding conferences,‚Äù in TIPSTER TEXT PROGRAM PHASE II: Proceedings of a
      Workshop held at Vienna, 1996, pp. 35‚Äì37, 1996.
 [92] S. Thenmalar, B. Jagan, and T. V. Geetha, ‚ÄúSemi-supervised bootstrapping approach for named entity recognition,‚Äù
      CoRR, vol. abs/1511.06833, 2015.
 [93] G. Zhou and J. Su, ‚ÄúNamed entity recognition using an hmm-based chunk tagger,‚Äù in Proc. ACL, 2002, pp. 473‚Äì480,
      2002.
 [94] J. R. Finkel, T. Grenager, and C. D. Manning, ‚ÄúIncorporating non-local information into information extraction systems
      by gibbs sampling,‚Äù in Proc. ACL, 2005, pp. 363‚Äì370, 2005.
 [95] J. Zhu, Z. Nie, J. Wen, B. Zhang, and W. Ma, ‚Äú2d conditional random fields for web information extraction,‚Äù in Proc.
      ICML, 2005, vol. 119, pp. 1044‚Äì1051, 2005.
 [96] C. Sutton, K. Rohanimanesh, and A. McCallum, ‚ÄúDynamic conditional random fields: factorized probabilistic models
      for labeling and segmenting sequence data,‚Äù in Proc. ICML, 2004, vol. 69, 2004.
 [97] J. Zhu, Z. Nie, J. Wen, B. Zhang, and W. Ma, ‚ÄúSimultaneous record detection and attribute labeling in web data
      extraction,‚Äù in KDD, 2006, pp. 494‚Äì503, 2006.
 [98] A. Finn and N. Kushmerick, ‚ÄúMulti-level boundary classification for information extraction,‚Äù in Proc. ECML, 2004,
      vol. 3201, pp. 111‚Äì122, 2004.
 [99] J. Li, A. Sun, J. Han, and C. Li, ‚ÄúA survey on deep learning for named entity recognition,‚Äù IEEE Trans. Knowl. Data
      Eng., vol. 34, no. 1, pp. 50‚Äì70, 2022.
[100] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. P. Kuksa, ‚ÄúNatural language processing (almost)
      from scratch,‚Äù J. Mach. Learn. Res., vol. 12, pp. 2493‚Äì2537, 2011.



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                              66:41


[101] E. Strubell, P. Verga, D. Belanger, and A. McCallum, ‚ÄúFast and accurate entity recognition with iterated dilated
      convolutions,‚Äù in Proc. EMNLP, 2017, pp. 2670‚Äì2680, 2017.
[102] L. Li, L. Jin, Z. Jiang, D. Song, and D. Huang, ‚ÄúBiomedical named entity recognition based on extended recurrent
      neural networks,‚Äù in BIBM , 2015, pp. 649‚Äì652, 2015.
[103] T. H. Nguyen, A. Sil, G. Dinu, and R. Florian, ‚ÄúToward mention detection robustness with recurrent neural networks,‚Äù
      CoRR, vol. abs/1602.07749, 2016.
[104] L. Luo, Z. Yang, P. Yang, Y. Zhang, L. Wang, H. Lin, and J. Wang, ‚ÄúAn attention-based bilstm-crf approach to
      document-level chemical named entity recognition,‚Äù Bioinform., vol. 34, no. 8, pp. 1381‚Äì1388, 2018.
[105] A. Z. Gregoric, Y. Bachrach, P. Minkovsky, S. Coope, and B. Maksak, ‚ÄúNeural named entity recognition using a
      self-attention mechanism,‚Äù in ICTAI, 2017, pp. 652‚Äì656, 2017.
[106] A. Cetoli, S. Bragaglia, A. D. O‚ÄôHarney, and M. Sloan, ‚ÄúGraph convolutional networks for named entity recognition,‚Äù
      in Proc. TLT, 2018, pp. 37‚Äì45, 2018.
[107] C. Dogan, A. Dutra, A. Gara, A. Gemma, L. Shi, M. Sigamani, and E. Walters, ‚ÄúFine-grained named entity recognition
      using elmo and wikidata,‚Äù CoRR, vol. abs/1904.10503, 2019.
[108] M. Liu, Z. Tu, T. Zhang, T. Su, X. Xu, and Z. Wang, ‚ÄúLtp: A new active learning strategy for crf-based named entity
      recognition,‚Äù Neural Processing Letters, pp. 1‚Äì22, 2022.
[109] I. Yamada, A. Asai, H. Shindo, H. Takeda, and Y. Matsumoto, ‚ÄúLUKE: deep contextualized entity representations with
      entity-aware self-attention,‚Äù in EMNLP, 2020, pp. 6442‚Äì6454, 2020.
[110] S. Shimaoka, P. Stenetorp, K. Inui, and S. Riedel, ‚ÄúNeural architectures for fine-grained entity type classification,‚Äù in
      Proc. EACL, 2017, Volume 1: Long Papers, pp. 1271‚Äì1280, 2017.
[111] S. Zhang, K. Duh, and B. V. Durme, ‚ÄúFine-grained entity typing through increased discourse context and adaptive
      classification thresholds,‚Äù in Proc. *SEM@NAACL-HLT, 2018, pp. 173‚Äì179, 2018.
[112] C. Moon, P. Jones, and N. F. Samatova, ‚ÄúLearning entity type embeddings for knowledge graph completion,‚Äù in Proc.
      CIKM, 2017, pp. 2215‚Äì2218, 2017.
[113] J. Hao, M. Chen, W. Yu, Y. Sun, and W. Wang, ‚ÄúUniversal representation learning of knowledge bases by jointly
      embedding instances and ontological concepts,‚Äù in KDD, 2019, pp. 1709‚Äì1719, 2019.
[114] Y. Zhao, A. Zhang, R. Xie, K. Liu, and X. Wang, ‚ÄúConnecting embeddings for knowledge graph entity typing,‚Äù in Proc.
      ACL, 2020, pp. 6419‚Äì6428, 2020.
[115] H. Jin, L. Hou, and J. Li, ‚ÄúType hierarchy enhanced heterogeneous network embedding for fine-grained entity typing
      in knowledge bases,‚Äù in NLP-NABD, 2018, Proceedings, vol. 11221, pp. 170‚Äì182, 2018.
[116] H. Jin, L. Hou, J. Li, and T. Dong, ‚ÄúAttributed and predictive entity embedding for fine-grained entity typing in
      knowledge bases,‚Äù in Proc. COLING , 2018, pp. 282‚Äì292, 2018.
[117] Y. Cao, L. Hou, J. Li, Z. Liu, C. Li, X. Chen, and T. Dong, ‚ÄúJoint representation learning of cross-lingual words and
      entities via attentive distant supervision,‚Äù in Proc. EMNLP, 2018, pp. 227‚Äì237, 2018.
[118] G. Limaye, S. Sarawagi, and S. Chakrabarti, ‚ÄúAnnotating and searching web tables using entities, types and relation-
      ships,‚Äù Proc. VLDB Endow., vol. 3, no. 1, pp. 1338‚Äì1347, 2010.
[119] C. S. Bhagavatula, T. Noraset, and D. Downey, ‚ÄúTabel: Entity linking in web tables,‚Äù in ISWC, 2015, Proceedings, Part I,
      vol. 9366, pp. 425‚Äì441, 2015.
[120] T. Wu, S. Yan, Z. Piao, L. Xu, R. Wang, and G. Qi, ‚ÄúEntity linking in web tables with multiple linked knowledge bases,‚Äù
      in JIST, 2016, Revised Selected Papers, vol. 10055, pp. 239‚Äì253, 2016.
[121] V. Efthymiou, O. Hassanzadeh, M. Rodriguez-Muro, and V. Christophides, ‚ÄúMatching web tables with knowledge base
      entities: From entity lookups to entity embeddings,‚Äù in Proc. ISWC, 2017, Part I, vol. 10587, pp. 260‚Äì277, 2017.
[122] V. Mulwad, T. Finin, Z. Syed, and A. Joshi, ‚ÄúUsing linked data to interpret tables,‚Äù in Proceedings of the First International
      Workshop on Consuming Linked Data, 2010, vol. 665 of CEUR Workshop Proceedings, 2010.
[123] Y. Guo, W. Che, T. Liu, and S. Li, ‚ÄúA graph-based method for entity linking,‚Äù in IJCNLP, 2011, pp. 1010‚Äì1018, 2011.
[124] X. Han, L. Sun, and J. Zhao, ‚ÄúCollective entity linking in web text: a graph-based method,‚Äù in SIGIR, 2011, pp. 765‚Äì774,
      2011.
[125] W. Shen, J. Wang, P. Luo, and M. Wang, ‚ÄúLIEGE: : link entities in web lists with knowledge base,‚Äù in KDD, 2012,
      pp. 1424‚Äì1432, 2012.
[126] A. Bagga and B. Baldwin, ‚ÄúEntity-based cross-document coreferencing using the vector space model,‚Äù in COLING-ACL
      , 1998, Proceedings of the Conference, pp. 79‚Äì85, 1998.
[127] I. Lasek and P. Vojt√°s, ‚ÄúVarious approaches to text representation for named entity disambiguation,‚Äù in IIWAS , 2012,
      pp. 256‚Äì262, 2012.
[128] H. Huang, L. P. Heck, and H. Ji, ‚ÄúLeveraging deep neural networks and knowledge graphs for entity disambiguation,‚Äù
      CoRR, vol. abs/1504.07678, 2015.
[129] W. Fang, J. Zhang, D. Wang, Z. Chen, and M. Li, ‚ÄúEntity disambiguation by knowledge and text jointly embedding,‚Äù in
      SIGNLL, CoNLL, ACL, 2016, pp. 260‚Äì269, 2016.


                                                   ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:42                                                                                                    Lingfeng Zhong, et al.


[130] S. J. Pan, Z. Toh, and J. Su, ‚ÄúTransfer joint embedding for cross-domain named entity recognition,‚Äù ACM Trans. Inf.
      Syst., vol. 31, no. 2, p. 7, 2013.
[131] B. Y. Lin and W. Lu, ‚ÄúNeural adaptation layers for cross-domain named entity recognition,‚Äù in Proc. EMNLP, 2018,
      pp. 2012‚Äì2022, 2018.
[132] K. Narasimhan, A. Yala, and R. Barzilay, ‚ÄúImproving information extraction by acquiring external evidence with
      reinforcement learning,‚Äù in Proc. EMNLP, 2016, pp. 2355‚Äì2365, 2016.
[133] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. A. Riedmiller, A. Fidjeland,
      G. Ostrovski, S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis,
      ‚ÄúHuman-level control through deep reinforcement learning,‚Äù Nat., vol. 518, no. 7540, pp. 529‚Äì533, 2015.
[134] Y. Yang, W. Chen, Z. Li, Z. He, and M. Zhang, ‚ÄúDistantly supervised NER with partial annotation learning and
      reinforcement learning,‚Äù in Proc. COLING, 2018, pp. 2159‚Äì2169, 2018.
[135] J. T. Zhou, H. Zhang, D. Jin, H. Zhu, M. Fang, R. S. M. Goh, and K. Kwok, ‚ÄúDual adversarial neural transfer for
      low-resource named entity recognition,‚Äù in Proc. ACL , 2019, Volume 1: Long Papers, pp. 3461‚Äì3471, 2019.
[136] P. Cao, Y. Chen, K. Liu, J. Zhao, and S. Liu, ‚ÄúAdversarial transfer learning for chinese named entity recognition with
      self-attention mechanism,‚Äù in Proc. EMNLP, 2018, pp. 182‚Äì192, 2018.
[137] J. Li, D. Ye, and S. Shang, ‚ÄúAdversarial transfer for named entity boundary detection with pointer networks,‚Äù in Proc.
      IJCAI, 2019, pp. 5053‚Äì5059, 2019.
[138] Y. Shen, H. Yun, Z. C. Lipton, Y. Kronrod, and A. Anandkumar, ‚ÄúDeep active learning for named entity recognition,‚Äù
      in ICLR, 2018, Conference Track Proceedings, 2018.
[139] Y. Ma, E. Cambria, and S. Gao, ‚ÄúLabel embedding for zero-shot fine-grained named entity typing,‚Äù in COLING, 2016,
      Proceedings of the Conference: Technical Papers, pp. 171‚Äì180, 2016.
[140] T. Zhang, C. Xia, C. Lu, and P. S. Yu, ‚ÄúMZET: memory augmented zero-shot fine-grained named entity typing,‚Äù in
      Proc. COLING, 2020, pp. 77‚Äì87, 2020.
[141] A. Sil and A. Yates, ‚ÄúRe-ranking for joint named-entity recognition and linking,‚Äù in CIKM, 2013, pp. 2369‚Äì2374, 2013.
[142] X. Liu, M. Zhou, X. Zhou, Z. Fu, and F. Wei, ‚ÄúJoint inference of named entity recognition and normalization for tweets,‚Äù
      in Proc. ACL,2012, Volume 1: Long Papers, pp. 526‚Äì535, 2012.
[143] M. C. Phan, A. Sun, Y. Tay, J. Han, and C. Li, ‚ÄúPair-linking for collective entity disambiguation: Two could be better
      than all,‚Äù IEEE Trans. Knowl. Data Eng., vol. 31, no. 7, pp. 1383‚Äì1396, 2019.
[144] J. Cai and M. Strube, ‚ÄúEnd-to-end coreference resolution via hypergraph partitioning,‚Äù in Proc. COLING, 2010, pp. 143‚Äì
      151, 2010.
[145] E. Sapena, L. Padr√≥, and J. Turmo, ‚ÄúA constraint-based hypergraph partitioning approach to coreference resolution,‚Äù
      Comput. Linguistics, vol. 39, no. 4, pp. 847‚Äì884, 2013.
[146] D. L. Bean and E. Riloff, ‚ÄúUnsupervised learning of contextual role knowledge for coreference resolution,‚Äù in HLT-
      NAACL, 2004, pp. 297‚Äì304, 2004.
[147] E. R. Fernandes, C. N. dos Santos, and R. L. Milidi√∫, ‚ÄúLatent structure perceptron with feature induction for unrestricted
      coreference resolution,‚Äù in EMNLP-CoNLL, ACL, 2012, pp. 41‚Äì48, 2012.
[148] W. M. Soon, H. T. Ng, and C. Y. Lim, ‚ÄúA machine learning approach to coreference resolution of noun phrases,‚Äù
      Comput. Linguistics, vol. 27, no. 4, pp. 521‚Äì544, 2001.
[149] M. Recasens, M. de Marneffe, and C. Potts, ‚ÄúThe life and death of discourse entities: Identifying singleton mentions,‚Äù
      in NAACL-HLT, Proceedings, 2013, pp. 627‚Äì633, 2013.
[150] M. A. ur Rahman and V. Ng, ‚ÄúSupervised models for coreference resolution,‚Äù in Proc. EMNLP, 2009, A meeting of
      SIGDAT, a Special Interest Group of the ACL, pp. 968‚Äì977, 2009.
[151] V. Stoyanov and J. Eisner, ‚ÄúEasy-first coreference resolution,‚Äù in Proc. COLING ,2012, pp. 2519‚Äì2534, 2012.
[152] X. Xi, G. Zhou, F. Hu, and B. Fu, ‚ÄúA convolutional deep neural network for coreference resolution via modeling
      hierarchical features,‚Äù in IScIDE, 2015, Revised Selected Papers, Proceedings, Part II, vol. 9243, pp. 361‚Äì372, 2015.
[153] J. Wu and W. Ma, ‚ÄúA deep learning framework for coreference resolution based on convolutional neural network,‚Äù in
      ICSC , 2017, pp. 61‚Äì64, 2017.
[154] S. Wiseman, A. M. Rush, and S. M. Shieber, ‚ÄúLearning global features for coreference resolution,‚Äù in NAACL-HLT,
      2016, pp. 994‚Äì1004, 2016.
[155] J. Gu, Z. Ling, and N. Indurkhya, ‚ÄúA study on improving end-to-end neural coreference resolution,‚Äù in NLP-NABD,
      2018, Proceedings, vol. 11221, pp. 159‚Äì169, 2018.
[156] R. Zhang, C. N. dos Santos, M. Yasunaga, B. Xiang, and D. R. Radev, ‚ÄúNeural coreference resolution with deep biaffine
      attention by joint mention detection and mention clustering,‚Äù in Proc. ACL, 2018, Volume 2: Short Papers, pp. 102‚Äì107,
      2018.
[157] J. Ma, J. Liu, Y. Li, X. Hu, Y. Pan, S. Sun, and Q. Lin, ‚ÄúJointly optimized neural coreference resolution with mutual
      attention,‚Äù in WSDM , 2020, pp. 402‚Äì410, 2020.



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                           66:43


[158] K. Clark and C. D. Manning, ‚ÄúDeep reinforcement learning for mention-ranking coreference models,‚Äù in Proc. EMNLP,
      2016, pp. 2256‚Äì2262, 2016.
[159] G. Durrett and D. Klein, ‚ÄúEasy victories and uphill battles in coreference resolution,‚Äù in Proc. EMNLP, 2013, A meeting
      of SIGDAT, a Special Interest Group of the ACL, pp. 1971‚Äì1982, 2013.
[160] S. Martschat and M. Strube, ‚ÄúLatent structures for coreference resolution,‚Äù Trans. Assoc. Comput. Linguistics, vol. 3,
      pp. 405‚Äì418, 2015.
[161] K. Chakrabarti, S. Chaudhuri, T. Cheng, and D. Xin, ‚ÄúA framework for robust discovery of entity synonyms,‚Äù in KDD,
      2012, pp. 1384‚Äì1392, 2012.
[162] R. C. Bunescu and R. J. Mooney, ‚ÄúLearning to extract relations from the web using minimal supervision,‚Äù in Proc. ACL,
      2007.
[163] F. Reichartz, H. Korte, and G. Paass, ‚ÄúSemantic relation extraction with kernels over typed dependency trees,‚Äù in KDD,
      2010, pp. 773‚Äì782, 2010.
[164] D. Zelenko, C. Aone, and A. Richardella, ‚ÄúKernel methods for relation extraction,‚Äù in Proc. EMNLP, 2002, pp. 71‚Äì78,
      2002.
[165] D. Zeng, K. Liu, S. Lai, G. Zhou, and J. Zhao, ‚ÄúRelation classification via convolutional deep neural network,‚Äù in Proc.
      COLING, 2014, pp. 2335‚Äì2344, 2014.
[166] T. H. Nguyen and R. Grishman, ‚ÄúRelation extraction: Perspective from convolutional neural networks,‚Äù in Proc.
      VS@NAACL-HLT, 2015, pp. 39‚Äì48, 2015.
[167] M. Miwa and M. Bansal, ‚ÄúEnd-to-end relation extraction using lstms on sequences and tree structures,‚Äù in Proc. ACL,
      2016, Volume 1: Long Papers, 2016.
[168] Y. Shen and X. Huang, ‚ÄúAttention-based convolutional neural network for semantic relation extraction,‚Äù in Proc.
      COLING, 2016, pp. 2526‚Äì2536, 2016.
[169] L. Wang, Z. Cao, G. de Melo, and Z. Liu, ‚ÄúRelation classification via multi-level attention cnns,‚Äù in Proc. ACL 2016,
      Volume 1: Long Papers, 2016.
[170] Y. Zhao, H. Wan, J. Gao, and Y. Lin, ‚ÄúImproving relation classification by entity pair graph,‚Äù in Proc. ACML, 2019,
      vol. 101, pp. 1156‚Äì1171, 2019.
[171] Z. Guo, Y. Zhang, and W. Lu, ‚ÄúAttention guided graph convolutional networks for relation extraction,‚Äù in Proc.
      ACL,2019, Volume 1: Long Papers, pp. 241‚Äì251, 2019.
[172] K. Zhao, H. Xu, Y. Cheng, X. Li, and K. Gao, ‚ÄúRepresentation iterative fusion based on heterogeneous graph neural
      network for joint entity and relation extraction,‚Äù Knowl. Based Syst., vol. 219, p. 106888, 2021.
[173] A. D. N. Cohen, S. Rosenman, and Y. Goldberg, ‚ÄúRelation extraction as two-way span-prediction,‚Äù CoRR,
      vol. abs/2010.04829, 2020.
[174] N. FitzGerald, O. T√§ckstr√∂m, K. Ganchev, and D. Das, ‚ÄúSemantic role labeling with neural network factors,‚Äù in Proc.
      EMNLP, 2015, pp. 960‚Äì970, 2015.
[175] M. Roth and M. Lapata, ‚ÄúNeural semantic role labeling with dependency path embeddings,‚Äù in Proc. ACL 2016, Volume
      1: Long Papers, 2016.
[176] V. Mulwad, T. Finin, and A. Joshi, ‚ÄúSemantic message passing for generating linked data from tables,‚Äù in ISWC, 2013 ,
      Proceedings, Part I, vol. 8218, pp. 363‚Äì378, 2013.
[177] Z. Chen and M. J. Cafarella, ‚ÄúAutomatic web spreadsheet data extraction,‚Äù in 3RD International Workshop on Semantic
      Search over the Web, SSW ‚Äô13, 2013, pp. 1:1‚Äì1:8, 2013.
[178] J. Zhu, Z. Nie, X. Liu, B. Zhang, and J. Wen, ‚ÄúStatsnowball: a statistical approach to extracting entity relationships,‚Äù in
      Proc. WWW, 2009, pp. 101‚Äì110, 2009.
[179] S. Brin, ‚ÄúExtracting patterns and relations from the world wide web,‚Äù in The World Wide Web and Databases, Interna-
      tional Workshop WebDB‚Äô98 , 1998, Selected Papers, vol. 1590, pp. 172‚Äì183, 1998.
[180] E. Agichtein and L. Gravano, ‚ÄúSnowball: extracting relations from large plain-text collections,‚Äù in Proc. ACM, 2000,
      pp. 85‚Äì94, 2000.
[181] M. Jiang, J. Shang, T. Cassidy, X. Ren, L. M. Kaplan, T. P. Hanratty, and J. Han, ‚ÄúMetapad: Meta pattern discovery from
      massive text corpora,‚Äù in KDD, 2017, pp. 877‚Äì886, 2017.
[182] Y. Ahmad, T. Antoniu, S. Goldwater, and S. Krishnamurthi, ‚ÄúA type system for statically detecting spreadsheet errors,‚Äù
      in ASE , 2003, pp. 174‚Äì183, 2003.
[183] Y. A. Sekhavat, F. D. Paolo, D. Barbosa, and P. Merialdo, ‚ÄúKnowledge base augmentation using tabular data,‚Äù in Proc.
      WWW, 2014, vol. 1184 of CEUR Workshop Proceedings, 2014.
[184] E. Mu√±oz, A. Hogan, and A. Mileo, ‚ÄúUsing linked data to mine RDF from wikipedia‚Äôs tables,‚Äù in WSDM, 2014,
      pp. 533‚Äì542, 2014.
[185] S. Krause, H. Li, H. Uszkoreit, and F. Xu, ‚ÄúLarge-scale learning of relation-extraction rules with distant supervision
      from the web,‚Äù in ISWC, 2012, Proceedings, Part I, vol. 7649, pp. 263‚Äì278, 2012.



                                                  ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:44                                                                                                 Lingfeng Zhong, et al.


[186] L. Cui, F. Wei, and M. Zhou, ‚ÄúNeural open information extraction,‚Äù in Proc. ACL, 2018, Volume 2: Short Papers,
      pp. 407‚Äì413, 2018.
[187] K. Kolluru, S. Aggarwal, V. Rathore, Mausam, and S. Chakrabarti, ‚ÄúImojie: Iterative memory-based joint open
      information extraction,‚Äù in Proc. ACL,2020, pp. 5871‚Äì5886, 2020.
[188] R. Wu, Y. Yao, X. Han, R. Xie, Z. Liu, F. Lin, L. Lin, and M. Sun, ‚ÄúOpen relation extraction: Relational knowledge
      transfer from supervised data to unsupervised data,‚Äù in Proc. EMNLP-IJCNLP, 2019, pp. 219‚Äì228, 2019.
[189] X. Han, P. Yu, Z. Liu, M. Sun, and P. Li, ‚ÄúHierarchical relation extraction with coarse-to-fine grained attention,‚Äù in
      Proc. EMNLP, 2018, pp. 2236‚Äì2245, 2018.
[190] B. Luo, Y. Feng, Z. Wang, Z. Zhu, S. Huang, R. Yan, and D. Zhao, ‚ÄúLearning with noise: Enhance distantly supervised
      relation extraction with dynamic transition matrix,‚Äù in ACL, 2017, Volume 1: Long Papers, pp. 430‚Äì439, 2017.
[191] Y. Huang and J. Du, ‚ÄúSelf-attention enhanced cnns and collaborative curriculum learning for distantly supervised
      relation extraction,‚Äù in Proc. EMNLP-IJCNLP, 2019, pp. 389‚Äì398, 2019.
[192] P. Qin, W. Xu, and W. Y. Wang, ‚ÄúRobust distant supervision relation extraction via deep reinforcement learning,‚Äù in
      Proc. ACL, 2018, Volume 1: Long Papers, pp. 2137‚Äì2147, 2018.
[193] P. Qin, W. Xu, and W. Y. Wang, ‚ÄúDSGAN: generative adversarial training for distant supervision relation extraction,‚Äù
      in Proc. ACL, 2018, Volume 1: Long Papers, pp. 496‚Äì505, 2018.
[194] X. Jiang, Q. Wang, P. Li, and B. Wang, ‚ÄúRelation extraction with multi-instance multi-label convolutional neural
      networks,‚Äù in COLING, 2016 Proceedings of the Conference: Technical Papers, pp. 1471‚Äì1480, 2016.
[195] G. Ji, K. Liu, S. He, and J. Zhao, ‚ÄúDistant supervision for relation extraction with sentence-level attention and entity
      descriptions,‚Äù in Proc. AAAI-17, 2017, pp. 3060‚Äì3066, 2017.
[196] Y. Lin, S. Shen, Z. Liu, H. Luan, and M. Sun, ‚ÄúNeural relation extraction with selective attention over instances,‚Äù in
      Proc. ACL, 2016, Volume 1: Long Papers, 2016.
[197] Z. Ye and Z. Ling, ‚ÄúDistant supervision relation extraction with intra-bag and inter-bag attentions,‚Äù in Proc. NAACL-HLT
      , 2019, Volume 1 (Long and Short Papers), pp. 2810‚Äì2819, 2019.
[198] Y. Yuan, L. Liu, S. Tang, Z. Zhang, Y. Zhuang, S. Pu, F. Wu, and X. Ren, ‚ÄúCross-relation cross-bag attention for
      distantly-supervised relation extraction,‚Äù in AAAI, IAAI, EAAI , 2019, pp. 419‚Äì426, 2019.
[199] N. Zhang, S. Deng, Z. Sun, G. Wang, X. Chen, W. Zhang, and H. Chen, ‚ÄúLong-tail relation extraction via knowledge
      graph embeddings and graph convolution networks,‚Äù in Proc. NAACL-HLT, 2019, Volume 1 (Long and Short Papers),
      pp. 3016‚Äì3025, 2019.
[200] S. Vashishth, R. Joshi, S. S. Prayaga, C. Bhattacharyya, and P. P. Talukdar, ‚ÄúRESIDE: improving distantly-supervised
      neural relation extraction using side information,‚Äù in Proc. EMNLP, 2018, pp. 1257‚Äì1266, 2018.
[201] W. Xiong, M. Yu, S. Chang, X. Guo, and W. Y. Wang, ‚ÄúOne-shot relational learning for knowledge graphs,‚Äù in Proc.
      EMNLP, 2018, pp. 1980‚Äì1990, 2018.
[202] J. Snell, K. Swersky, and R. S. Zemel, ‚ÄúPrototypical networks for few-shot learning,‚Äù in NeurIPS, 2017, pp. 4077‚Äì4087,
      2017.
[203] M. Fan, Y. Bai, M. Sun, and P. Li, ‚ÄúLarge margin prototypical network for few-shot relation classification with
      fine-grained features,‚Äù in Proc. CIKM, 2019, pp. 2353‚Äì2356, 2019.
[204] T. Gao, X. Han, Z. Liu, and M. Sun, ‚ÄúHybrid attention-based prototypical networks for noisy few-shot relation
      classification,‚Äù in AAAI, IAAI, EAAI, 2019, pp. 6407‚Äì6414, 2019.
[205] O. Vinyals, C. Blundell, T. Lillicrap, K. Kavukcuoglu, and D. Wierstra, ‚ÄúMatching networks for one shot learning,‚Äù in
      NeurIPS, 2016, pp. 3630‚Äì3638, 2016.
[206] T. Gao, X. Han, R. Xie, Z. Liu, F. Lin, L. Lin, and M. Sun, ‚ÄúNeural snowball for few-shot relation learning,‚Äù in AAAI,
      IAAI, EAAI, 2020, pp. 7772‚Äì7779, 2020.
[207] Z. Ye and Z. Ling, ‚ÄúMulti-level matching and aggregation network for few-shot relation classification,‚Äù in Proc. ACL,
      2019, Volume 1: Long Papers, pp. 2872‚Äì2881, 2019.
[208] C. Finn, P. Abbeel, and S. Levine, ‚ÄúModel-agnostic meta-learning for fast adaptation of deep networks,‚Äù in Proc. ICML,
      2017, vol. 70, pp. 1126‚Äì1135, 2017.
[209] T. Munkhdalai and H. Yu, ‚ÄúMeta networks,‚Äù in ICML, 2017, vol. 70, pp. 2554‚Äì2563, 2017.
[210] T. Wu, X. Li, Y. Li, G. Haffari, G. Qi, Y. Zhu, and G. Xu, ‚ÄúCurriculum-meta learning for order-robust continual relation
      extraction,‚Äù in AAAI, IAAI, EAAI, 2021, pp. 10363‚Äì10369, 2021.
[211] O. Levy, M. Seo, E. Choi, and L. Zettlemoyer, ‚ÄúZero-shot relation extraction via reading comprehension,‚Äù in Proc.
      CoNLL, ACL, 2017, pp. 333‚Äì342, 2017.
[212] L. B. Soares, N. FitzGerald, J. Ling, and T. Kwiatkowski, ‚ÄúMatching the blanks: Distributional similarity for relation
      learning,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 2895‚Äì2905, 2019.
[213] V. G. Satorras and J. B. Estrach, ‚ÄúFew-shot learning with graph neural networks,‚Äù in ICLR, 2018, Conference Track
      Proceedings, 2018.



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                          66:45


[214] M. Qu, T. Gao, L. A. C. Xhonneux, and J. Tang, ‚ÄúFew-shot relation extraction via bayesian meta-learning on relation
      graphs,‚Äù in Proc. ICML, 2020, vol. 119, pp. 7867‚Äì7876, 2020.
[215] T. Gao, X. Han, H. Zhu, Z. Liu, P. Li, M. Sun, and J. Zhou, ‚ÄúFewrel 2.0: Towards more challenging few-shot relation
      classification,‚Äù in Proc. EMNLP-IJCNLP, 2019, pp. 6249‚Äì6254, 2019.
[216] D. Roth and W. Yih, ‚ÄúA linear programming formulation for global inference in natural language tasks,‚Äù in HLT-NAACL,
      2004, pp. 1‚Äì8, 2004.
[217] Q. Li and H. Ji, ‚ÄúIncremental joint extraction of entity mentions and relations,‚Äù in ACL, 2014, Volume 1: Long Papers,
      pp. 402‚Äì412, 2014.
[218] S. Pawar, P. Bhattacharyya, and G. K. Palshikar, ‚ÄúEnd-to-end relation extraction using neural networks and markov
      logic networks,‚Äù in Proceedings of the 15th Conference of the European Chapter of the Association for Computational
      Linguistics, EACL 2017, Valencia, Spain, April 3-7, 2017, Volume 1: Long Papers (M. Lapata, P. Blunsom, and A. Koller,
      eds.), pp. 818‚Äì827, Association for Computational Linguistics, 2017.
[219] S. Zheng, Y. Hao, D. Lu, H. Bao, J. Xu, H. Hao, and B. Xu, ‚ÄúJoint entity and relation extraction based on a hybrid
      neural network,‚Äù Neurocomputing, vol. 257, pp. 59‚Äì66, 2017.
[220] T. Fu, P. Li, and W. Ma, ‚ÄúGraphrel: Modeling text as relational graphs for joint entity and relation extraction,‚Äù in Proc.
      ACL, 2019, Volume 1: Long Papers, pp. 1409‚Äì1418, 2019.
[221] S. Zheng, F. Wang, H. Bao, Y. Hao, P. Zhou, and B. Xu, ‚ÄúJoint extraction of entities and relations based on a novel
      tagging scheme,‚Äù in Proc. ACL 2017, Volume 1: Long Papers, pp. 1227‚Äì1236, 2017.
[222] Z. Wei, J. Su, Y. Wang, Y. Tian, and Y. Chang, ‚ÄúA novel cascade binary tagging framework for relational triple
      extraction,‚Äù in Proc. ACL, 2020, pp. 1476‚Äì1488, 2020.
[223] Y. Wang, B. Yu, Y. Zhang, T. Liu, H. Zhu, and L. Sun, ‚ÄúTplinker: Single-stage joint extraction of entities and relations
      through token pair linking,‚Äù in Proc. COLING, 2020, pp. 1572‚Äì1582, 2020.
[224] G. Bekoulis, J. Deleu, T. Demeester, and C. Develder, ‚ÄúJoint entity recognition and relation extraction as a multi-head
      selection problem,‚Äù Expert Syst. Appl., vol. 114, pp. 34‚Äì45, 2018.
[225] X. Li, F. Yin, Z. Sun, X. Li, A. Yuan, D. Chai, M. Zhou, and J. Li, ‚ÄúEntity-relation extraction as multi-turn question
      answering,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 1340‚Äì1350, 2019.
[226] H. Chen, C. Zhang, J. Li, P. S. Yu, and N. Jing, ‚ÄúKggen: A generative approach for incipient knowledge graph population,‚Äù
      IEEE Trans. Knowl. Data Eng., vol. 34, no. 5, pp. 2254‚Äì2267, 2022.
[227] X. Ren, Z. Wu, W. He, M. Qu, C. R. Voss, H. Ji, T. F. Abdelzaher, and J. Han, ‚ÄúCotype: Joint extraction of typed entities
      and relations with knowledge bases,‚Äù in Proc. WWW, 2017, pp. 1015‚Äì1024, 2017.
[228] A. Bordes, N. Usunier, A. Garc√≠a-Dur√°n, J. Weston, and O. Yakhnenko, ‚ÄúTranslating embeddings for modeling
      multi-relational data,‚Äù in NeurIPS, Proceedings , 2013, pp. 2787‚Äì2795, 2013.
[229] N. Peng, H. Poon, C. Quirk, K. Toutanova, and W. Yih, ‚ÄúCross-sentence n-ary relation extraction with graph lstms,‚Äù
      Trans. Assoc. Comput. Linguistics, vol. 5, pp. 101‚Äì115, 2017.
[230] L. Song, Y. Zhang, Z. Wang, and D. Gildea, ‚ÄúN-ary relation extraction using graph-state LSTM,‚Äù in Proc. EMNLP, 2018,
      pp. 2226‚Äì2235, 2018.
[231] S. K. Sahu, F. Christopoulou, M. Miwa, and S. Ananiadou, ‚ÄúInter-sentence relation extraction with document-level
      graph convolutional neural network,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 4309‚Äì4316, 2019.
[232] F. Christopoulou, M. Miwa, and S. Ananiadou, ‚ÄúConnecting the dots: Document-level neural relation extraction with
      edge-oriented graphs,‚Äù in Proc. EMNLP-IJCNLP , 2019, pp. 4924‚Äì4935, 2019.
[233] H. Zhu, Y. Lin, Z. Liu, J. Fu, T. Chua, and M. Sun, ‚ÄúGraph neural networks with generated parameters for relation
      extraction,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 1331‚Äì1339, 2019.
[234] G. Nan, Z. Guo, I. Sekulic, and W. Lu, ‚ÄúReasoning with latent structure refinement for document-level relation
      extraction,‚Äù in Proc. ACL, 2020, pp. 1546‚Äì1557, 2020.
[235] W. Xu, K. Chen, and T. Zhao, ‚ÄúDocument-level relation extraction with reconstruction,‚Äù in AAAI, IAAI, EAAI, 2021,
      pp. 14167‚Äì14175, 2021.
[236] S. Zeng, R. Xu, B. Chang, and L. Li, ‚ÄúDouble graph based reasoning for document-level relation extraction,‚Äù in Proc.
      EMNLP, 2020, pp. 1630‚Äì1640, 2020.
[237] Z. Zhang, B. Yu, X. Shu, M. Xue, T. Liu, and L. Guo, ‚ÄúFrom what to why: Improving relation extraction with rationale
      graph,‚Äù in Findings of the Association for Computational Linguistics: ACL/IJCNLP , 2021, vol. ACL/IJCNLP 2021, pp. 86‚Äì95,
      2021.
[238] Y. Luan, D. Wadden, L. He, A. Shah, M. Ostendorf, and H. Hajishirzi, ‚ÄúA general framework for information extraction
      using dynamic span graphs,‚Äù in Proc. NAACL-HLT, 2019, Volume 1 (Long and Short Papers), pp. 3036‚Äì3046, 2019.
[239] W. Xu, K. Chen, and T. Zhao, ‚ÄúDiscriminative reasoning for document-level relation extraction,‚Äù in ACL/IJCNLP , 2021,
      pp. 1653‚Äì1663, 2021.
[240] A. Bosselut, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi, ‚ÄúCOMET: commonsense transformers for
      automatic knowledge graph construction,‚Äù in Proc. ACL, 2019 , Volume 1: Long Papers, pp. 4762‚Äì4779, 2019.


                                                 ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:46                                                                                                  Lingfeng Zhong, et al.


[241] N. Zhang, X. Chen, X. Xie, S. Deng, C. Tan, M. Chen, F. Huang, L. Si, and H. Chen, ‚ÄúDocument-level relation extraction
      as semantic segmentation,‚Äù in Proc. IJCAI ,2021, pp. 3999‚Äì4006, 2021.
[242] W. Zhou, K. Huang, T. Ma, and J. Huang, ‚ÄúDocument-level relation extraction with adaptive thresholding and localized
      context pooling,‚Äù in AAAI, IAAI, EAAI, 2021, pp. 14612‚Äì14620, 2021.
[243] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, ‚ÄúLearning entity and relation embeddings for knowledge graph completion,‚Äù
      in Proc. AAAI-15, 2015, pp. 2181‚Äì2187, 2015.
[244] Z. Wang, J. Zhang, J. Feng, and Z. Chen, ‚ÄúKnowledge graph embedding by translating on hyperplanes,‚Äù in Proc.
      AAAI-14, 2014, pp. 1112‚Äì1119, 2014.
[245] G. Ji, K. Liu, S. He, and J. Zhao, ‚ÄúKnowledge graph completion with adaptive sparse transfer matrix,‚Äù in Proc. AAAI-16,
      2016, pp. 985‚Äì991, 2016.
[246] M. Nickel, V. Tresp, and H. Kriegel, ‚ÄúA three-way model for collective learning on multi-relational data,‚Äù in Proc. ICML,
      2011, pp. 809‚Äì816, 2011.
[247] I. Balazevic, C. Allen, and T. M. Hospedales, ‚ÄúTucker: Tensor factorization for knowledge graph completion,‚Äù in Proc.
      EMNLP-IJCNLP, 2019, pp. 5184‚Äì5193, 2019.
[248] B. Yang, W. Yih, X. He, J. Gao, and L. Deng, ‚ÄúEmbedding entities and relations for learning and inference in knowledge
      bases,‚Äù in ICLR, 2015, Conference Track Proceedings, 2015.
[249] R. Socher, D. Chen, C. D. Manning, and A. Y. Ng, ‚ÄúReasoning with neural tensor networks for knowledge base
      completion,‚Äù in NeurIPS, 2013, Proceedings, pp. 926‚Äì934, 2013.
[250] Z. Zhang, J. Cai, Y. Zhang, and J. Wang, ‚ÄúLearning hierarchy-aware knowledge graph embeddings for link prediction,‚Äù
      in AAAI, IAAI, EAAI, 2020, pp. 3065‚Äì3072, 2020.
[251] G. Niu, B. Li, Y. Zhang, and S. Pu, ‚ÄúCAKE: A scalable commonsense-aware framework for multi-view knowledge
      graph completion,‚Äù in Proc. ACL, 2022.
[252] L. Wang, W. Zhao, Z. Wei, and J. Liu, ‚ÄúSimkgc: Simple contrastive knowledge graph completion with pre-trained
      language models,‚Äù in Proc. ACL, 2022.
[253] K. Wang, Y. Liu, and Q. Z. Sheng, ‚ÄúSwift and sure: Hardness-aware contrastive learning for low-dimensional knowledge
      graph embeddings,‚Äù in WWW ‚Äô22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022
      (F. Laforest, R. Troncy, E. Simperl, D. Agarwal, A. Gionis, I. Herman, and L. M√©dini, eds.), pp. 838‚Äì849, ACM, 2022.
[254] A. Borrego, D. Ayala, I. Hern√°ndez, C. R. Rivero, and D. Ruiz, ‚ÄúCAFE: knowledge graph completion using neighborhood-
      aware features,‚Äù Eng. Appl. Artif. Intell., vol. 103, p. 104302, 2021.
[255] J. Wu, W. Shi, X. Cao, J. Chen, W. Lei, F. Zhang, W. Wu, and X. He, ‚ÄúDisenkgat: Knowledge graph embedding with
      disentangled graph attention network,‚Äù in CIKM , 2021, pp. 2140‚Äì2149, 2021.
[256] N. Lao and W. W. Cohen, ‚ÄúRelational retrieval using a combination of path-constrained random walks,‚Äù Mach. Learn.,
      vol. 81, no. 1, pp. 53‚Äì67, 2010.
[257] M. Gardner, P. P. Talukdar, J. Krishnamurthy, and T. M. Mitchell, ‚ÄúIncorporating vector space similarity in random
      walk inference over knowledge bases,‚Äù in Proc. EMNLP, 2014, A meeting of SIGDAT, a Special Interest Group of the ACL,
      pp. 397‚Äì406, 2014.
[258] Q. Wang, J. Liu, Y. Luo, B. Wang, and C. Lin, ‚ÄúKnowledge base completion via coupled path ranking,‚Äù in Proc. ACL,
      2016, Volume 1: Long Papers, 2016.
[259] W. Xiong, T. Hoang, and W. Y. Wang, ‚ÄúDeeppath: A reinforcement learning method for knowledge graph reasoning,‚Äù
      in Proc. EMNLP, 2017, pp. 564‚Äì573, 2017.
[260] X. V. Lin, R. Socher, and C. Xiong, ‚ÄúMulti-hop knowledge graph reasoning with reward shaping,‚Äù in Proc. EMNLP,
      2018, pp. 3243‚Äì3253, 2018.
[261] Z. Li, X. Jin, S. Guan, Y. Wang, and X. Cheng, ‚ÄúPath reasoning over knowledge graph: A multi-agent and reinforcement
      learning based method,‚Äù in ICDM Workshops, 2018, pp. 929‚Äì936, 2018.
[262] Y. Shen, J. Chen, P. Huang, Y. Guo, and J. Gao, ‚ÄúM-walk: Learning to walk over graphs using monte carlo tree search,‚Äù
      in NeurIPS, 2018, pp. 6787‚Äì6798, 2018.
[263] A. Neelakantan, B. Roth, and A. McCallum, ‚ÄúCompositional vector space models for knowledge base completion,‚Äù in
      ACL, 2015, Volume 1: Long Papers, pp. 156‚Äì166, 2015.
[264] R. Das, A. Neelakantan, D. Belanger, and A. McCallum, ‚ÄúChains of reasoning over entities, relations, and text using
      recurrent neural networks,‚Äù in Proc. EACL, 2017, Volume 1: Long Papers, pp. 132‚Äì141, 2017.
[265] Y. Zhang, H. Dai, Z. Kozareva, A. J. Smola, and L. Song, ‚ÄúVariational reasoning for question answering with knowledge
      graph,‚Äù in AAAI, IAAI, EAAI, 2018, pp. 6069‚Äì6076, 2018.
[266] S. Kardani-Moghaddam, R. Buyya, and K. Ramamohanarao, ‚ÄúADRL: A hybrid anomaly-aware deep reinforcement
      learning-based resource scaling in clouds,‚Äù IEEE Trans. Parallel Distributed Syst., vol. 32, no. 3, pp. 514‚Äì526, 2021.
[267] H. Wang, S. Li, R. Pan, and M. Mao, ‚ÄúIncorporating graph attention mechanism into knowledge graph reasoning
      based on deep reinforcement learning,‚Äù in Proc. EMNLP-IJCNLP, 2019, pp. 2623‚Äì2631, 2019.



ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                                66:47


[268] M. Zheng, Y. Zhou, and Q. Cui, ‚ÄúHierarchical policy network with multi-agent for knowledge graph reasoning based
      on reinforcement learning,‚Äù in KSEM, 2021, Proceedings, Part I, vol. 12815, pp. 445‚Äì457, 2021.
[269] P. Tiwari, H. Zhu, and H. M. Pandey, ‚ÄúDapath: Distance-aware knowledge graph reasoning based on deep reinforcement
      learning,‚Äù Neural Networks, vol. 135, pp. 1‚Äì12, 2021.
[270] S. Li, H. Wang, R. Pan, and M. Mao, ‚ÄúMemorypath: A deep reinforcement learning framework for incorporating
      memory component into knowledge graph reasoning,‚Äù Neurocomputing, vol. 419, pp. 273‚Äì286, 2021.
[271] L. A. Gal√°rraga, C. Teflioudi, K. Hose, and F. M. Suchanek, ‚ÄúAMIE: association rule mining under incomplete evidence
      in ontological knowledge bases,‚Äù in WWW , 2013, pp. 413‚Äì422, 2013.
[272] P. G. Omran, K. Wang, and Z. Wang, ‚ÄúScalable rule learning via learning representation,‚Äù in Proc. IJCAI, 2018,
      pp. 2149‚Äì2155, 2018.
[273] C. Meilicke, M. Fink, Y. Wang, D. Ruffinelli, R. Gemulla, and H. Stuckenschmidt, ‚ÄúFine-grained evaluation of rule- and
      embedding-based systems for knowledge graph completion,‚Äù in ISWC, 2018, Proceedings, Part I, vol. 11136, pp. 3‚Äì20,
      2018.
[274] S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo, ‚ÄúJointly embedding knowledge graphs and logical rules,‚Äù in Proc.
      EMNLP, 2016, pp. 192‚Äì202, 2016.
[275] S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo, ‚ÄúKnowledge graph embedding with iterative guidance from soft
      rules,‚Äù in AAAI, IAAI, EAAI, 2018, pp. 4816‚Äì4823, 2018.
[276] F. Yang, Z. Yang, and W. W. Cohen, ‚ÄúDifferentiable learning of logical rules for knowledge base reasoning,‚Äù in NeurIPS,
      2017, pp. 2319‚Äì2328, 2017.
[277] M. Qu and J. Tang, ‚ÄúProbabilistic logic neural networks for reasoning,‚Äù in NeurIPS, 2019, pp. 7710‚Äì7720, 2019.
[278] Y. Zhang, X. Chen, Y. Yang, A. Ramamurthy, B. Li, Y. Qi, and L. Song, ‚ÄúEfficient probabilistic logic reasoning with
      graph neural networks,‚Äù in ICLR, 2020.
[279] T. Miller, ‚ÄúExplanation in artificial intelligence: Insights from the social sciences,‚Äù Artif. Intell., vol. 267, pp. 1‚Äì38, 2019.
[280] V. I. S. Carmona, T. Rockt√§schel, S. Riedel, and S. Singh, ‚ÄúTowards extracting faithful and descriptive representations
      of latent variable models,‚Äù in AAAI Spring Symposia, 2015.
[281] Y. Nandwani, A. Gupta, A. Agrawal, M. S. Chauhan, P. Singla, and Mausam, ‚ÄúOxkbc: Outcome explanation for
      factorization based knowledge base completion,‚Äù in AKBC, 2020.
[282] Z. Ying, D. Bourgeois, J. You, M. Zitnik, and J. Leskovec, ‚ÄúGnnexplainer: Generating explanations for graph neural
      networks,‚Äù in NeurIPS, 2019, pp. 9240‚Äì9251, 2019.
[283] P. Pezeshkpour, Y. Tian, and S. Singh, ‚ÄúInvestigating robustness and interpretability of link prediction via adversarial
      modifications,‚Äù in Proc. NAACL-HLT, 2019, Volume 1 (Long and Short Papers), pp. 3336‚Äì3347, 2019.
[284] R. Xie, Z. Liu, F. Lin, and L. Lin, ‚ÄúDoes william shakespeare REALLY write hamlet? knowledge representation learning
      with confidence,‚Äù in AAAI, IAAI, EAAI, 2018, pp. 4954‚Äì4961, 2018.
[285] T. Dong, Z. Wang, J. Li, C. Bauckhage, and A. B. Cremers, ‚ÄúTriple classification using regions and fine-grained entity
      typing,‚Äù in AAAI , IAAI, EAAI, 2019, pp. 77‚Äì85, 2019.
[286] E. Amador-Dom√≠nguez, E. Serrano, D. Manrique, P. Hohenecker, and T. Lukasiewicz, ‚ÄúAn ontology-based deep
      learning approach for triple classification with out-of-knowledge-base entities,‚Äù Inf. Sci., vol. 564, pp. 85‚Äì102, 2021.
[287] D. Q. Nguyen, T. Nguyen, and D. Phung, ‚ÄúA relational memory-based embedding model for triple classification and
      search personalization,‚Äù in Proc. ACL, 2020, pp. 3429‚Äì3435, 2020.
[288] T. Sun, J. Zhai, and Q. Wang, ‚ÄúNovea: A novel model of entity alignment using attribute triples and relation triples,‚Äù
      in KSEM , 2020, Proceedings, Part I, vol. 12274, pp. 161‚Äì173, 2020.
[289] F. He, Z. Li, Q. Yang, A. Liu, G. Liu, P. Zhao, L. Zhao, M. Zhang, and Z. Chen, ‚ÄúUnsupervised entity alignment using
      attribute triples and relation triples,‚Äù in DASFAA , 2019, Proceedings, Part I, vol. 11446, pp. 367‚Äì382, 2019.
[290] H. Yang, Y. Zou, P. Shi, W. Lu, J. Lin, and X. Sun, ‚ÄúAligning cross-lingual entities with multi-aspect information,‚Äù in
      Proc. EMNLP-IJCNLP , 2019, pp. 4430‚Äì4440, 2019.
[291] Z. Sun, W. Hu, and C. Li, ‚ÄúCross-lingual entity alignment via joint attribute-preserving embedding,‚Äù in ISWC, 2017,
      Proceedings, Part I, vol. 10587, pp. 628‚Äì644, 2017.
[292] B. D. Trisedya, J. Qi, and R. Zhang, ‚ÄúEntity alignment between knowledge graphs using attribute embeddings,‚Äù in
      AAAI, IAAI, EAAI, 2019, pp. 297‚Äì304, 2019.
[293] W. Tan, ‚ÄúTechnical perspective: Entity matching with magellan,‚Äù Commun. ACM, vol. 63, no. 8, p. 82, 2020.
[294] M. S. Schlichtkrull and H. M. Alonso, ‚ÄúMsejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking,‚Äù
      in Proc. SemEval@NAACL-HLT, 2016, pp. 1337‚Äì1341, 2016.
[295] S. Mudgal, H. Li, T. Rekatsinas, A. Doan, Y. Park, G. Krishnan, R. Deep, E. Arcaute, and V. Raghavendra, ‚ÄúDeep learning
      for entity matching: A design space exploration,‚Äù in Proc. SIGMOD, 2018, pp. 19‚Äì34, 2018.
[296] D. Jurgens and M. T. Pilehvar, ‚ÄúSemeval-2016 task 14: Semantic taxonomy enrichment,‚Äù in Proc. SemEval@NAACL-HLT,
      2016, pp. 1092‚Äì1102, 2016.



                                                    ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:48                                                                                                    Lingfeng Zhong, et al.


[297] B. T. McInnes, ‚ÄúVCU at semeval-2016 task 14: Evaluating definitional-based similarity measure for semantic taxonomy
      enrichment,‚Äù in Proc. SemEval@NAACL-HLT, 2016, pp. 1351‚Äì1355, 2016.
[298] L. E. Anke, F. Ronzano, and H. Saggion, ‚ÄúTALN at semeval-2016 task 14: Semantic taxonomy enrichment via sense-
      based embeddings,‚Äù in Proc. SemEval@NAACL-HLT, 2016, pp. 1332‚Äì1336, 2016.
[299] K. S. Jones, ‚ÄúA statistical interpretation of term specificity and its application in retrieval,‚Äù J. Documentation, vol. 60,
      no. 5, pp. 493‚Äì502, 2004.
[300] G. Stoilos, G. B. Stamou, and S. D. Kollias, ‚ÄúA string metric for ontology alignment,‚Äù in ISWC , 2005, Proceedings,
      vol. 3729, pp. 624‚Äì637, 2005.
[301] N. Vedula, P. K. Nicholson, D. Ajwani, S. Dutta, A. Sala, and S. Parthasarathy, ‚ÄúEnriching taxonomies with functional
      domain knowledge,‚Äù in SIGIR, 2018, pp. 745‚Äì754, 2018.
[302] D. Frolov, S. Nascimento, T. I. Fenner, and B. G. Mirkin, ‚ÄúUsing taxonomy tree to generalize a fuzzy thematic cluster,‚Äù
      in FUZZ-IEEE , 2019, pp. 1‚Äì6, 2019.
[303] F. Scharffe, Y. Liu, and C. Zhou, ‚ÄúRdf-ai: an architecture for rdf datasets matching, fusion and interlink,‚Äù in Proc. IJCAI
      workshop on IR-KR, 2019, p. 23, 2009.
[304] A. N. Ngomo and S. Auer, ‚ÄúLIMES - A time-efficient approach for large-scale link discovery on the web of data,‚Äù in
      Proc. IJCAI, 2011, pp. 2312‚Äì2317, 2011.
[305] M. Pershina, M. Yakout, and K. Chakrabarti, ‚ÄúHolistic entity matching across knowledge graphs,‚Äù in IEEE BigData,
      2015, pp. 1585‚Äì1590, 2015.
[306] M. Berrendorf, E. Faerman, and V. Tresp, ‚ÄúActive learning for entity alignment,‚Äù in ECIR, 2021, Proceedings, Part I,
      vol. 12656, pp. 48‚Äì62, 2021.
[307] Z. Sun, W. Hu, Q. Zhang, and Y. Qu, ‚ÄúBootstrapping entity alignment with knowledge graph embedding,‚Äù in Proc.
      IJCAI, 2018, pp. 4396‚Äì4402, 2018.
[308] H. Zhu, R. Xie, Z. Liu, and M. Sun, ‚ÄúIterative entity alignment via joint knowledge embeddings,‚Äù in Proc. IJCAI , 2017,
      pp. 4258‚Äì4264, 2017.
[309] Q. Zhang, Z. Sun, W. Hu, M. Chen, L. Guo, and Y. Qu, ‚ÄúMulti-view knowledge graph embedding for entity alignment,‚Äù
      in Proc. IJCAI, 2019, pp. 5429‚Äì5435, 2019.
[310] M. Chen, Y. Tian, M. Yang, and C. Zaniolo, ‚ÄúMultilingual knowledge graph embeddings for cross-lingual knowledge
      alignment,‚Äù in Proc. IJCAI, 2017, pp. 1511‚Äì1517, 2017.
[311] Z. Huang, Z. Li, H. Jiang, T. Cao, H. Lu, B. Yin, K. Subbian, Y. Sun, and W. Wang, ‚ÄúMultilingual knowledge graph
      completion with self-supervised adaptive graph alignment,‚Äù in Proc. ACL, 2022.
[312] X. Liu, H. Hong, X. Wang, Z. Chen, E. Kharlamov, Y. Dong, and J. Tang, ‚ÄúSelfkg: Self-supervised entity alignment
      in knowledge graphs,‚Äù in WWW ‚Äô22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022
      (F. Laforest, R. Troncy, E. Simperl, D. Agarwal, A. Gionis, I. Herman, and L. M√©dini, eds.), pp. 860‚Äì870, ACM, 2022.
[313] M. Chen, Y. Tian, K. Chang, S. Skiena, and C. Zaniolo, ‚ÄúCo-training embeddings of knowledge graphs and entity
      descriptions for cross-lingual entity alignment,‚Äù in Proc. IJCAI, 2018, pp. 3998‚Äì4004, 2018.
[314] B. Chen, J. Zhang, X. Tang, H. Chen, and C. Li, ‚ÄúJarka: Modeling attribute interactions for cross-lingual knowledge
      alignment,‚Äù in PAKDD, 2020, Proceedings, Part I, vol. 12084, pp. 845‚Äì856, 2020.
[315] Z. Wang, Q. Lv, X. Lan, and Y. Zhang, ‚ÄúCross-lingual knowledge graph alignment via graph convolutional networks,‚Äù
      in Proc. EMNLP, 2018, pp. 349‚Äì357, 2018.
[316] Y. Zhu, H. Liu, Z. Wu, and Y. Du, ‚ÄúRelation-aware neighborhood matching model for entity alignment,‚Äù in AAAI,
      IAAI, EAAI, 2021, pp. 4749‚Äì4756, 2021.
[317] Y. Wu, X. Liu, Y. Feng, Z. Wang, R. Yan, and D. Zhao, ‚ÄúRelation-aware entity alignment for heterogeneous knowledge
      graphs,‚Äù in Proc. IJCAI, 2019, pp. 5278‚Äì5284, 2019.
[318] K. Xu, L. Wang, M. Yu, Y. Feng, Y. Song, Z. Wang, and D. Yu, ‚ÄúCross-lingual knowledge graph alignment via graph
      matching neural network,‚Äù in Proc. ACL, 2019, Volume 1: Long Papers, pp. 3156‚Äì3161, 2019.
[319] Z. Liu, Y. Cao, L. Pan, J. Li, and T. Chua, ‚ÄúExploring and evaluating attributes, values, and structures for entity
      alignment,‚Äù in Proc. EMNLP, 2020, pp. 6355‚Äì6364, 2020.
[320] Y. Cao, Z. Liu, C. Li, Z. Liu, J. Li, and T. Chua, ‚ÄúMulti-channel graph neural network for entity alignment,‚Äù in Proc.
      ACL, 2019, Volume 1: Long Papers, pp. 1452‚Äì1461, 2019.
[321] S. Jiang, T. Nie, D. Shen, Y. Kou, and G. Yu, ‚ÄúEntity alignment of knowledge graph by joint graph attention and
      translation representation,‚Äù in WISA, 2021, Proceedings, vol. 12999, pp. 347‚Äì358, 2021.
[322] T. Jiang, T. Zhao, B. Qin, T. Liu, N. V. Chawla, and M. Jiang, ‚ÄúThe role of cÃàondition:Ãà A novel scientific knowledge
      graph representation and construction model,‚Äù in KDD, 2019, pp. 1634‚Äì1642, 2019.
[323] T. Zheng, Z. Xu, Y. Li, Y. Zhao, B. Wang, and X. Yang, ‚ÄúA novel conditional knowledge graph representation and
      construction,‚Äù in CICAI , 2021, Proceedings, Part II, vol. 13070, pp. 383‚Äì394, 2021.
[324] F. Cheng and Y. Miyao, ‚ÄúClassifying temporal relations by bidirectional LSTM over dependency paths,‚Äù in Proc. ACL,
      2017, Volume 2: Short Papers, pp. 1‚Äì6, 2017.


ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
A Comprehensive Survey on Automatic Knowledge Graph Construction                                                        66:49


[325] Y. Meng, A. Rumshisky, and A. Romanov, ‚ÄúTemporal information extraction for question answering using syntactic
      dependencies in an lstm-based architecture,‚Äù in Proc. EMNLP, 2017, pp. 887‚Äì896, 2017.
[326] S. Vashishtha, B. V. Durme, and A. S. White, ‚ÄúFine-grained temporal relation extraction,‚Äù in Proc. ACL, 2019, Volume 1:
      Long Papers, pp. 2906‚Äì2919, 2019.
[327] P. Mathur, R. Jain, F. Dernoncourt, V. I. Morariu, Q. H. Tran, and D. Manocha, ‚ÄúTIMERS: document-level temporal
      relation extraction,‚Äù in Proc. ACL/IJCNLP, 2021, Volume 2: Short Papers, pp. 524‚Äì533, 2021.
[328] J. Leblay and M. W. Chekol, ‚ÄúDeriving validity time in knowledge graph,‚Äù in WWW, 2018, pp. 1771‚Äì1776, 2018.
[329] S. S. Dasgupta, S. N. Ray, and P. P. Talukdar, ‚ÄúHyte: Hyperplane-based temporally aware knowledge graph embedding,‚Äù
      in Proc. EMNLP, 2018, pp. 2001‚Äì2011, 2018.
[330] A. Garc√≠a-Dur√°n, S. Dumancic, and M. Niepert, ‚ÄúLearning sequence encoders for temporal knowledge graph comple-
      tion,‚Äù in Proc. EMNLP, 2018, pp. 4816‚Äì4821, 2018.
[331] Y. Liu, W. Hua, K. Xin, and X. Zhou, ‚ÄúContext-aware temporal knowledge graph embedding,‚Äù in WISE , 2019, Proceedings,
      vol. 11881, pp. 583‚Äì598, 2019.
[332] L. Lin and K. She, ‚ÄúTensor decomposition-based temporal knowledge graph embedding,‚Äù in ICTAI, 2020, pp. 969‚Äì975,
      2020.
[333] T. Lacroix, G. Obozinski, and N. Usunier, ‚ÄúTensor decompositions for temporal knowledge base completion,‚Äù in ICLR,
      2020.
[334] P. Shao, D. Zhang, G. Yang, J. Tao, F. Che, and T. Liu, ‚ÄúTucker decomposition-based temporal knowledge graph
      completion,‚Äù Knowl. Based Syst., vol. 238, p. 107841, 2022.
[335] W. Radstok, M. Chekol, and Y. Velegrakis, ‚ÄúLeveraging static models for link prediction in temporal knowledge graphs,‚Äù
      in ICTAI , 2021, pp. 1034‚Äì1041, 2021.
[336] J. Jung, J. Jung, and U. Kang, ‚ÄúLearning to walk across time for interpretable temporal knowledge graph completion,‚Äù
      in KDD, 2021, pp. 786‚Äì795, 2021.
[337] H. Liu, S. Zhou, C. Chen, T. Gao, J. Xu, and M. Shu, ‚ÄúDynamic knowledge graph reasoning based on deep reinforcement
      learning,‚Äù Knowl. Based Syst., vol. 241, p. 108235, 2022.
[338] T. Jiang, T. Liu, T. Ge, L. Sha, S. Li, B. Chang, and Z. Sui, ‚ÄúEncoding temporal information for time-aware link
      prediction,‚Äù in Proc. EMNLP, 2016, pp. 2350‚Äì2354, 2016.
[339] K. Yu, X. Guo, L. Liu, J. Li, H. Wang, Z. Ling, and X. Wu, ‚ÄúCausality-based feature selection: Methods and evaluations,‚Äù
      ACM Comput. Surv., vol. 53, no. 5, pp. 111:1‚Äì111:36, 2020.
[340] R. Trivedi, H. Dai, Y. Wang, and L. Song, ‚ÄúKnow-evolve: Deep temporal reasoning for dynamic knowledge graphs,‚Äù in
      Proc. ICML 2017, vol. 70, pp. 3462‚Äì3471, 2017.
[341] W. Jin, C. Zhang, P. A. Szekely, and X. Ren, ‚ÄúRecurrent event network for reasoning over temporal knowledge graphs,‚Äù
      CoRR, vol. abs/1904.05530, 2019.
[342] X. Li, L. Liu, X. Wang, Y. Li, Q. Wu, and T. Qian, ‚ÄúTowards evolutionary knowledge representation under the big data
      circumstance,‚Äù Electron. Libr., vol. 39, no. 3, pp. 392‚Äì410, 2021.
[343] Z. Han, P. Chen, Y. Ma, and V. Tresp, ‚ÄúDyernie: Dynamic evolution of riemannian manifold embeddings for temporal
      knowledge graph completion,‚Äù in EMNLP, 2020, pp. 7301‚Äì7316, 2020.
[344] T. Gracious, S. Gupta, A. Kanthali, R. M. Castro, and A. Dukkipati, ‚ÄúNeural latent space model for dynamic networks
      and temporal knowledge graphs,‚Äù in AAAI, IAAI, EAAI, 2021, pp. 4054‚Äì4062, 2021.
[345] Y. Yan, L. Liu, Y. Ban, B. Jing, and H. Tong, ‚ÄúDynamic knowledge graph alignment,‚Äù in AAAI , IAAI, EAAI, 2021,
      pp. 4564‚Äì4572, 2021.
[346] B. Momjian, PostgreSQL: introduction and concepts, vol. 192. Addison-Wesley New York, 2001.
[347] B. Shao, H. Wang, and Y. Li, ‚ÄúTrinity: a distributed graph engine on a memory cloud,‚Äù in SIGMOD, 2013, pp. 505‚Äì516,
      2013.
[348] J. C. Anderson, J. Lehnardt, and N. Slater, ‚ÄúCouchdb: The definitive guide time to relax,‚Äù 2010.
[349] L. Zou, J. Mo, L. Chen, M. T. √ñzsu, and D. Zhao, ‚Äúgstore: Answering SPARQL queries via subgraph matching,‚Äù Proc.
      VLDB Endow., vol. 4, no. 8, pp. 482‚Äì493, 2011.
[350] J. Webber, ‚ÄúA programmatic introduction to neo4j,‚Äù in SPLASH, Proceedings , 2012, pp. 217‚Äì218, 2012.
[351] T. Miller, C. Hempelmann, and I. Gurevych, ‚ÄúSemeval-2017 task 7: Detection and interpretation of english puns,‚Äù in
      Proc. SemEval@ACL, 2017, pp. 58‚Äì68, 2017.
[352] C. Wang, S. Liang, Y. Jin, Y. Wang, X. Zhu, and Y. Zhang, ‚ÄúSemeval-2020 task 4: Commonsense validation and
      explanation,‚Äù in Proc. SemEval@COLING, 2020, pp. 307‚Äì321, 2020.
[353] Y. Liu, H. Li, A. Garc√≠a-Dur√°n, M. Niepert, D. O√±oro-Rubio, and D. S. Rosenblum, ‚ÄúMMKG: multi-modal knowledge
      graphs,‚Äù in ESWC, 2019, Proceedings, vol. 11503, pp. 459‚Äì474, 2019.
[354] S. Dost, L. Serafini, M. Rospocher, L. Ballan, and A. Sperduti, ‚ÄúAligning and linking entity mentions in image, text,
      and knowledge base,‚Äù Data Knowl. Eng., vol. 138, p. 101975, 2022.



                                                ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
66:50                                                                                             Lingfeng Zhong, et al.


[355] H. Peng, H. Li, Y. Song, V. W. Zheng, and J. Li, ‚ÄúDifferentially private federated knowledge graphs embedding,‚Äù in
      CIKM , 2021, pp. 1416‚Äì1425, 2021.
[356] M. Chen, W. Zhang, Z. Yuan, Y. Jia, and H. Chen, ‚ÄúFede: Embedding knowledge graphs in federated setting,‚Äù in IJCKG,
      2021, pp. 80‚Äì88, 2021.
[357] Y. Xie, J. Shen, S. Li, Y. Mao, and J. Han, ‚ÄúEider: Evidence-enhanced document-level relation extraction,‚Äù CoRR,
      vol. abs/2106.08657, 2021.
[358] H. Weld, X. Huang, S. Long, J. Poon, and S. C. Han, ‚ÄúA survey of joint intent detection and slot-filling models in
      natural language understanding,‚Äù CoRR, vol. abs/2101.08091, 2021.




ACM Comput. Surv., Vol. 36, No. 4, Article 66. Publication date: July 2022.
                      An Efficient Memory-Augmented Transformer for
                               Knowledge-Intensive NLP Tasks
             Yuxiang Wu ‚Ä†  Yu Zhao ‚Ä°       Baotian Hu ‚Ä°‚àó      Pasquale Minervini ¬ß‚Ä†
                                           ‚Ä†
                        Pontus Stenetorp         Sebastian Riedel ‚Ä†
‚Ä†
  University College London, London, UK ‚Ä° Harbin Institute of Technology, Shenzhen, PRC
                         ¬ß
                           University of Edinburgh, Edinburgh, UK
          {yuxiang.wu, p.stenetorp, s.riedel}@cs.ucl.ac.uk       p.minervini@ed.ac.uk
                       20s151163@stu.hit.edu.cn     hubaotian@hit.edu.cn

                         Abstract                               and accessing potentially large amounts of knowl-
                                                                edge. One approach is a parametric method that
        Access to external knowledge is essential for           trains a sequence-to-sequence generator to repre-
        many natural language processing tasks, such            sent knowledge within model parameters. Petroni
        as question answering and dialogue. Exist-              et al. (2019) find that pre-trained Language Mod-
        ing methods often rely on a parametric model
                                                                els (PLMs) learn a partial knowledge base in their
        that stores knowledge in its parameters, or use
        a retrieval-augmented model that has access             parameters, but its coverage is limited. Increasing
        to an external knowledge source. Parametric             model size can improve this issue (Raffel et al.,
        and retrieval-augmented models have comple-             2020; Roberts et al., 2020; Brown et al., 2020);
        mentary strengths in terms of computational             however, larger language models require signifi-
        efficiency and predictive accuracy. To com-             cant computational resources.
        bine the strength of both approaches, we pro-
        pose the Efficient Memory-Augmented Trans-
                                                                   Retrieval-augmented models (Guu et al., 2020;
        former (EMAT) ‚Äì it encodes external knowl-              Lewis et al., 2020b; Izacard and Grave, 2021; Das
        edge into a key-value memory and exploits the           et al., 2022), on the other hand, retrieve relevant
        fast maximum inner product search for mem-              passages from an external knowledge source (e.g.,
        ory querying. We also introduce pre-training            Wikipedia), and use the retrieved passages to in-
        tasks that allow EMAT to encode informa-                form generation. Despite being more accurate,
        tive key-value representations, and to learn an         retrieval-augmented models are often significantly
        implicit strategy to integrate multiple mem-
                                                                more costly computation-wise than their paramet-
        ory slots into the transformer. Experiments
        on various knowledge-intensive tasks such as            ric counterparts, since they require retrieving, en-
        question answering and dialogue datasets show           coding, and integrating the external knowledge at
        that, simply augmenting parametric models               inference time.
        (T5-base) using our method produces more                   To combine the strengths of both parametric and
        accurate results (e.g., 25.8 ‚Üí 44.3 EM on               retrieval-augmented models, we propose Efficient
        NQ) while retaining a high throughput (e.g.,
                                                                Memory-Augmented Transformers (EMATs) ‚Äì an
        1000 queries/s on NQ). Compared to retrieval-
        augmented models, EMAT runs substantially               extension to Transformer-based models augmented
        faster across the board and produces more ac-           with an efficient key-value memory module. EMAT
        curate results on WoW and ELI5.1                        first encodes the external knowledge source into
                                                                key embeddings and value embeddings, to con-
1       Introduction                                            struct the key-value memory (Section 3.1). We
                                                                choose PAQ (Lewis et al., 2021b), a large collection
NLP tasks often require knowledge that is not                   of question-answering generated from Wikipedia,
explicitly provided with the input. For example,                as our knowledge source; and we encode the ques-
Open-Domain Question Answering (ODQA) re-                       tions as keys and answers as values. The trans-
quires answering an open-domain question without                former model produces dense query vector, re-
given context passages (Chen et al., 2017), and like-           trieves from the key-value memory (Section 3.2),
wise for open-domain dialogue (Dinan et al., 2019).             and integrates the returned dense key-value vec-
To handle such tasks, one key challenge is storing              tors at different encoder layers to enhance gener-
    *                                                           ation (Section 3.3). Different from previous ap-
    Corresponding author.
    1
    Our code and datasets are available at https://github.      proaches (Lample et al., 2019; Fan et al., 2021;
com/uclnlp/EMAT.                                                Chen et al., 2022), our query representation is com-
                                                           5184
          Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5184 - 5196
                             December 7-11, 2022 ¬©2022 Association for Computational Linguistics
puted at an early transformer layer, whereas re-         Efficient OQDA Systems One simple approach
trieved key and value embeddings are incorporated        to accelerate ODQA is Closed-Book QA (CBQA)
into the model at a later layer. This design only        ‚Äì a sequence-to-sequence model (Sutskever et al.,
requires one forward pass through the transformer        2014; Kalchbrenner et al., 2014) such as T5 (Raf-
model, and allows memory retrieval to run concur-        fel et al., 2020) or BART (Lewis et al., 2020a) is
rently with the transformer forward pass, and hence      fine-tuned on ODQA data, by training it to pro-
reduces the computational overhead (see Fig. 1 for       duce the answer given the question. CBQA models
our architecture).                                       are substantially faster than retrieve-and-read ap-
   With this architecture, it is important that the      proaches. However, since they solely rely on their
key-value memory accurately represent the knowl-         parameters to store factual knowledge, their capac-
edge source, and the transformer learns a strategy       ity is limited by the model size, and hence they
to incorporate the retrieved key-value representa-       often produce less accurate results than retrieve-
tions into the model. Therefore, we introduce pre-       and-read methods (Lewis et al., 2021a; Liu et al.,
training tasks (Section 4.1), which include auto-        2021). Another efficient approach is retrieving
encoding objectives to represent the questions and       semantically similar questions from a large collec-
answers, and a question answering task to learn an       tion of QA pair and returning the corresponding
implicit strategy to incorporate multiple key-value      answers. Lewis et al. (2021b) propose PAQ, a 65
memory slots. Our ablation study (Section 6.1)           million QA dataset that is constructed with the
shows that our pre-training tasks are crucial for the    objective to cover the most probably-asked ques-
performance, and removing any of them could lead         tions in Wikipedia. RePAQ (Lewis et al., 2021b), a
to more than 10pp drop in EM score on ODQA               retrieval-based QA system built on PAQ, won the
datasets.                                                EfficientQA competition (Min et al., 2020) in 2020,
   Our contribution can be summarised as follows:        outperforming CBQA models by a large margin.
i) we introduce EMAT, an efficient memory ac-            In this work, we choose PAQ as our knowledge
cess module to augment the transformer architec-         source, but different from RePAQ, we develop a
ture; ii) we exploit PAQ as our knowledge source,        generative model. Our results show that EMAT
and propose pre-training objectives to encode QA-        outperforms RePAQ while matching its efficiency.
pairs as key-value memory and to learn integra-
tion strategy to incorporate multiple memory slots       Memory-Augmented Transformers Geva et al.
into transformers; iii) experimental results on vari-    (2021) show that the Feed-Forward Network (FFN)
ous knowledge-intensive tasks show that our pro-         layers in Transformer-based language models be-
posed method significantly outperforms vanilla           have similarly to like key-value memories, where
transformer baselines, while retaining a similar in-     keys capture input patterns, and values map to the
ference speed.                                           output vocabulary. Based on this finding, Yao et al.
                                                         (2022) propose to extend the FFN layers by con-
2   Related Work                                         catenating a dense representation of the corpus to
                                                         the layer weights. Fan et al. (2021) introduce a neu-
Retrieve-and-Read Models for ODQA Open-                  ral module to access a fixed external memory, show-
domain question answering is a task that aims to         ing that it can lead to significant improvements on
answer a open-domain question without given con-         downstream generative dialogue modelling tasks.
text passages. Many ODQA systems follow a two-           Concurrently to our work, Chen et al. (2022) pro-
steps retrieve-and-read architecture (Chen et al.,       pose QAMAT, a method to augment Transformer
2017) where, in the first step, a retriever model col-   layers with a key-value memory network encoding
lects a set of relevant passages, and then a reader      question-answer pairs. QAMAT requires two in-
model processes the retrieved passages and pro-          ference steps through the encoder: one to retrieve
duces the answer (Min et al., 2019; Yang et al.,         memory values, and another for concatenating the
2019; Wang et al., 2019; Karpukhin et al., 2020;         retrieved values to the input. In contrast, our pro-
Guu et al., 2020; Lewis et al., 2020b; Izacard and       posed method only requires a single inference steps,
Grave, 2021). Despite their high accuracy, retrieve-     resulting in a significantly smaller computational
and-read systems have a high computational foot-         footprint. Empirically, we show that our method is
print, since they need to process a potentially large    ‚âà 5 times faster than QAMAT, even when using
number of passages (Wu et al., 2020, 2021).              fewer hardware resources.
                                                     5185
                                 ‚Äúwho is ‚Ä¶ ?‚Äù                                                       Output
                  Key
                                  Decoder                                                           Decoder

              ConvLayer

                                   key layer                                                           ‚Ä¶‚Ä¶
                                                                         add
                                                                    value layer
                  ‚Ä¶‚Ä¶                                                                                  ‚Ä¶‚Ä¶
                                                                concatenate
                                                                   concat layer
                                                                                                                      ‚Ä¶‚Ä¶
        PREFIX ‚ÄúquesÔøΩon: who is ‚Ä¶ ?‚Äù
                                                                                    ConvLayer
                                                     Return Key-Value Pairs                     key layer
                                                                                                                      ‚Ä¶‚Ä¶
                                ‚ÄúBarack Obama‚Äù
                                                                                            Query
          Value
                                   Decoder                                                                   PREFIX        Input

                                       value layer


                  ‚Ä¶‚Ä¶



         PREFIX ‚Äúanswer: Barack Obama‚Äù                                  Key-Value Memory


Figure 1: Architecture of the proposed Efficient Key-Value Memory Augmented Transformers (EMAT): factual
knowledge is stored in a key-value memory (Section 3.1) where keys and values correspond to questions and
answers, respectively; during inference, the model retrieves information from the memory via MIPS (Section 3.2)
and uses it to condition the generation process.


3   Efficient Memory-Augmented                                            Fig. 1 (left) shows details regarding how key
    Transformer                                                        (question) and value (answer) are encoded in
                                                                       EMAT. To encode the key embeddings, we first
In this work we propose Efficient Memory-
                                                                       concatenate a prefix P REFIX of length P with the
Augmented Transformer (EMAT), a model archi-
                                                                       question q as input, and then obtain the hidden
tecture that uses a key-value memory to store mil-
                                                                       states at the lk -th layer hlk = [hl1k , ¬∑ ¬∑ ¬∑ , hlnk ], where
lions of dense question-answer representations to
                                                                       n is the length of the question q prepended with
inform its predictions (see Fig. 1). Given an input
                                                                       P REFIX. Then, hlk is passed through a convolu-
sequence X = (x1 , ¬∑ ¬∑ ¬∑ , x|X| ), EMAT‚Äôs encoder
                                                                       tional neural network layer to produce [c1 , ¬∑ ¬∑ ¬∑ , cn ],
first produces a dense query q to retrieve from the
                                                                       and we use the prefix part as our final key repre-
memory M. The returned key-value representa-
                                                                       sentation k = [c1 , ¬∑ ¬∑ ¬∑ , cP ] ‚àà RP√óh . For value
tions corresponding to the retrieved k key-value
                                                                       embeddings, we prepend a prefix to the answer,
pairs are Z = (z1 , ¬∑ ¬∑ ¬∑ , zk ). Finally, the decoder
                                                                       feed [P REFIX; a] into the model, and use the pre-
generates the target sequence Y = (y1 , ¬∑ ¬∑ ¬∑ , y|Y | )
                                                                       fix‚Äôs representation at the lv -th layer of encoder
conditioned on the input X and retrieved key-value
                                                                       v = [hl1v , ¬∑ ¬∑ ¬∑ , hlPv ] ‚àà RP√óh as our value represen-
pairs Z.
                                                                       tation, where h is the size of hidden representa-
3.1 Key-Value Memory                                                   tions.
The key-value memory M = (K, V) contains rep-
                                                                       3.2        Memory Retrieval
resentations of keys K and values V, with each
key ki mapping to one value vi . Since we use                          The goal of the retriever is to retrieve relevant en-
PAQ (Lewis et al., 2021b) as our knowledge source,                     tries from the key-value memory M to inform the
each key represents a question, and its value repre-                   downstream generation tasks. EMAT‚Äôs encoder
sents the corresponding answer. We use EMAT‚Äôs                          embeds the question into a query q using the same
encoder to encode the question and the answer sep-                     procedure as the key embeddings, described in Sec-
arately, and it produces key and value embeddings                      tion 3.1. We conduct an extra step of flattening
from lk -th and lv -th layer of encoder respectively.                  for both q and k by averaging: kÃÑ = flatten(k) =
                                                                5186
1   PP
P    j=1 kj . The key-value encoder shares the pa-        value auto-encoding (VAE) can be formalised as:
rameters with the question encoder, and we define
                                                                                  |X|
the query-key similarity by the inner product be-                                 X
tween the flattened query representation and key                   LKAE = ‚àí              log P (xi | k, x<i ),
                                                                                   i=1
representation sim(q, k) = ‚ü®qÃÑ, kÃÑ‚ü©. At inference
                                                                                  |Y |
time, this operation can be efficiently computed us-                              X
ing Maximum Inner Product Search (MIPS) to re-                     LVAE = ‚àí              log P (yi | v, y<i ).
                                                                                   i=1
trieve the top-k key-value pairs Z = {(ki , vi )}ki=1
based on the similarity. MIPS implementations             Generation Task Besides the problem of repre-
such as faiss (Johnson et al., 2019) enable search-       senting questions and answers in key-value mem-
ing across millions of vectors in milliseconds on         ory M, we also need the model to make use of M
a CPU. The retrieved key-value pairs Z are then           for downstream tasks. Thus, it is also critical to pre-
integrated in later layers of EMAT‚Äôs encoder.             train the model to learn the key-value integration
                                                          module defined in Section 3.3. Since PAQ provides
3.3 Key-Value Integration                                 a large number of QA pairs, we consider a genera-
                                                          tion task built on PAQ to pre-train the model. More
Once we have retrieves the top-k key-value pairs          concretely, for each QA pair (x, y) in PAQ, we use
Z, they need to be incorporated into the model.           the RePAQ model (Lewis et al., 2021b) to retrieve
More specifically, in the lc -th layer, all the key em-   10 other relevant QA pairs from PAQ, and retrieve
beddings in Z are ordered by their corresponding          their corresponding keys K‚Ä≤x = [k1 , ¬∑ ¬∑ ¬∑ , k10 ] and
similarity scores, and concatenated into a matrix         values Vx‚Ä≤ = [v1 , ¬∑ ¬∑ ¬∑ , v10 ] from the memory M.
K‚Ä≤ = [ki , ¬∑ ¬∑ ¬∑ , kk ] ‚àà RPk√óh . Then it is prepended    Then, the model is trained to generate the answer
to the lc -th layer‚Äôs hidden states. To distinguish       y given the question x and the key-value embed-
the different keys, we additionally add relative po-      dings corresponding to the retrieved QA pairs. The
sitional encodings to K‚Ä≤ . In the lv -th layer, the       objective can be defined as follows:
value embedding in Z are concatenated in the same
                                                                           |Y |
way to produce V‚Ä≤ , and it is added to the posi-                           X
                                                                LGen = ‚àí          log P (yi | x, K‚Ä≤x , Vx‚Ä≤ , y<i ).
tions where their corresponding key embeddings
                                                                           i=1
are prepended to. The updated hidden states con-
tinue the forward pass of the remaining transformer       We adopt a multi-task pre-training objective to min-
encoder layers. Finally, the decoder generates the        imise LKAE + LVAE + LGen .
answer condition on the output of the encoder,
which already integrates the retrieved key-value          4.2    Fine-Tuning on Downstream Tasks
representations.                                          After pre-training, we fine-tune both the memory
                                                          retrieval module and the generation of EMAT on
                                                          the downstream tasks.
4    Training Pipeline of EMAT
                                                          Retrieval Objective Learning to retrieve rele-
4.1 Pre-Training                                          vant key-value pairs that provide useful evidence
                                                          to solve a given task can be challenging due to the
Auto-encoding Tasks We use T5-base‚Äôs pre-                 lack of labelled data. To solve this problem, we
trained parameters to initialise EMAT, but the pre-       propose a weakly-supervised method to optimise
fix embeddings and key encoder‚Äôs convolutional            the retriever. Specifically, we first rank all retrieved
layer are trained from scratch. To obtain better rep-     key-value pairs retrieved from the memory M by
resentation of key and value, we pre-train EMAT           their inner product scores. We consider the top
with auto-encoding training objectives. We use            retrieved key-value pairs: for each retrieved key-
PAQ-L1, a simplified version of PAQ that consists         value pair, if its corresponding answer is lexically
of 14M QA pairs, as the pre-training corpus. The          matched with the target output, then the key-value
model is trained to recover the input question x          pair is selected as positive sample to optimise the
given the key embeddings k, and the answer y              retriever. For short output generation tasks such
given the value embeddings v, as shown in Fig. 1          as ODQA, we match the answer corresponding to
(left). The two tasks key auto-encoding (KAE) and         the retrieved value with the target answer. For long
                                                      5187
sequence generation tasks such as open-domain          4.3    Inference
dialogue and long-form QA, we normalise the tar-       During inference, we use a fast Hierarchical Navi-
get sequence (i.e., lower-casing and removing stop     gable Small World (HNSW, Malkov and Yashunin,
words), and check whether if the retrieved value       2020) graph index, generated by faiss, to search
(answer) is contained in the normalised target se-     and retrieve from the key-value memory M. If the
quence. Since these key-value pairs are more likely    lk < lc , the search process can run in parallel with
to lead to the correct answer, they can be used to     the evaluation of the layers lk + 1, ¬∑ ¬∑ ¬∑ , lc ‚àí 1 in
provide a weakly-supervised training signal to the     EMAT. Since the search process can be efficiently
retrieval component of EMAT.                           executed on CPU, it does not increase the GPU
   We denote the selected positive key-value pairs     memory requirements of the model.
as Z + = (z1+ , ¬∑ ¬∑ ¬∑ , zr+ ), where each pair zi+ =
(k+     +                                      +
   i , vi ) is composed by a key component ki and      5     Experiments
a value component vi+ . We sample a key-value pair
zi+ from Z + based on the similarity between the       5.1    Experimental Setup
corresponding key k+    i and the query q:              Datasets We consider several knowledge-
                                                        intensive NLP tasks, including Open-Domain
                                           +
                           exp(sim(q,    k   ))         Question Answering (ODQA), Open-Domain
      PŒ∑ (zi+ | q) = Pr                    i
                                               + ,
                          j=1 exp(sim(q,     k j ))     Dialogue (ODD), and Long-Form Question
                +
               z ‚àº PŒ∑ (¬∑ | q, Z ).+                     Answering (LFQA). In ODQA, the aim is to
                                                        answer factual questions using a large collection of
                                         ‚àí m
We then select m negative pairs {zj }j=1 that do        documents of diversified topics. We choose three
not match the target sequence. Finally, the positive    commonly used datasets ‚Äì NaturalQuestions (NQ,
                                     ‚àí
pairs z and the negative pairs z are used to train
        +                                               Kwiatkowski et al., 2019), TriviaQA (TQA, Joshi
the retriever, by optimising the following objective: et al., 2017), and WebQuestions (Berant et al.,
                                                        2013). In addition, we consider two generation
LRet =                                                  tasks from the Knowledge Intensive Language
                                                        Tasks (KILT, Petroni et al., 2021) benchmark
                       exp(sim(q, k+   i ))
 ‚àí log                         P m                  ‚àí . to test whether our method generalises to tasks
        exp(sim(q, k+  i )) +    j=1 exp(sim(q, kj ))   beyond ODQA. Specifically, we consider Wizard-
                                                        of-Wikipedia (WoW, Dinan et al., 2019) for ODD.
Memory Caching for More Efficient Training
                                                        This task requires modelling long dialogue history
As described above, EMAT uses MIPS for retriev-
                                                        and acquire relevant Wikipedia knowledge to
ing the key-value pairs that are the most relevant
                                                        produce a response utterance. Furthermore, we
to solve the current task. However, updating the
                                                        consider the Explain Like I‚Äôm Five (ELI5, Fan
memory M after each training update may not be
                                                        et al., 2019) dataset for LFQA. In ELI5, answers
feasible when the number of entries in M is very
                                                        are often more diverse and open-ended compared
large. To alleviate this problem, we design a mem-
                                                        to ODQA, and they tend to be significantly longer ‚Äì
ory caching mechanism. At the beginning of each
                                                        they can be composed by several sentences.
training epoch, we freeze the memory M and, for
each training example, we retrieve the top-n key- Knowledge Source We use PAQ (Lewis et al.,
value pairs. The memory M is updated only at the        2021b) as our knowledge source, and encode
end of the epoch by re-encoding all entries in the      question-answer pairs in the model‚Äôs key-value
knowledge source.                                       memory. Since the generative model used to gen-
                                                        erate the QA pairs in PAQ was trained on Natu-
Overall Fine-Tuning Objective The generator             ralQuestions and TriviaQA, PAQ has a high cov-
is optimised to generate the target y given the input   erage for these two ODQA datasets. In this work,
x and the top-n retrieved key-value pairs Z:            we also evaluate on tasks beyond ODQA, where it
                    |Y |
                                                        is not clear how PAQ can be used. Therefore, our
                   X                                    evaluation on ODD and LFQA aims to demonstrate
        LGen = ‚àí         log P (yi | x, Z, y<i ),
                    i=1
                                                        that EMAT generalises to different knowledge-
                                                        intensive generation tasks using PAQ as the un-
so the overall fine-tuning objective is LRet + LGen . derlying knowledge source.
                                                   5188
Baselines We compare our method with three                         Model
                                                                                                                NQ       TQA    WQ
                                                                                                           EM     Q/s    EM     EM
types of baselines: parametric models, retrieval-
                                                                   Parametric models
only approaches, and retrieval-augmented mod-                      T5-base (Roberts et al., 2020)          25.8   1600   24.4   26.6
els. Parametric models fine-tune sequence-to-                      T5-large (Roberts et al., 2020)         27.6    570   29.5   27.7
                                                                   T5-3B (Roberts et al., 2020)            30.4    55    35.1   33.6
sequence PLMs such as T5 (Raffel et al., 2020) or                  T5-11B (Roberts et al., 2020)           32.6     -    42.3   37.2
BART (Lewis et al., 2020a) on a datasets, by cast-                 BART-large (Lewis et al., 2020a)        26.5    570   26.7   27.4
ing each task as a sequence generation problem con-                Retrieval-only models
ditioned on the input. In our experiments, we con-                 Dense Retriever (Lewis et al., 2021a)   26.7      -   28.9    -
                                                                   DensePhrases (Lee et al., 2021)         40.9     18   50.7    -
sider parametric models of multiple sizes, includ-                 RePAQ-base (Lewis et al., 2021b)        40.9   1400   39.7   29.4
ing T5-base, T5-large, T5-3B, T5-11B (Roberts                      RePAQ-large (Lewis et al., 2021b)       41.2   1100    -      -
                                                                   RePAQ-xlarge (Lewis et al., 2021b)      41.5    800   41.3    -
et al., 2020), and BART-large (Lewis et al., 2020a).
                                                                   Retrieval-augmented models
Retrieval-only approaches retrieve the most rele-                  REALM (Guu et al., 2020)                40.4     -    55.8   40.7
vant information from the knowledge source (PAQ),                  DPR (Karpukhin et al., 2020)            41.5    2.7   57.9   42.4
                                                                   QAMAT (Chen et al., 2022)               44.7   240*   48.0   39.4
and return the top answer as output. In ODQA                       RePAQ rerank (Lewis et al., 2021b)      45.7    55    48.9   37.6
benchmark we use the RePAQ model proposed                          RAG (Lewis et al., 2020b)               44.5    9.6   56.8   45.2
by Lewis et al. (2021b); in ODD and LFQA, we use                   FiD-base (Izacard and Grave, 2021)      48.2    3.7   65.0   32.4
                                                                   FiD-large (Izacard and Grave, 2021)     51.4    1.4   67.6    -
the EMAT key retrieval module described in Sec-
                                                                   Ours
tion 3.2 as the retriever. Retrieval-augmented mod-                EMAT-FKSV                               44.3   1000   44.4   36.7
els such as RAG (Lewis et al., 2020b) or FiD (Izac-                EMAT-SKSV                               43.3   1200   43.7   33.2
ard and Grave, 2021) retrieve relevant passages
                                                                Table 1: Exact Match (EM) results for EMAT in compar-
from Wikipedia using a dense retriever such as
                                                                ison to recent state-of-the-art systems. ‚àó QAMAT runs
DPR (Karpukhin et al., 2020), and then use the                  on 32 TPU-v3 with 1024GB TPU memory, whereas
retrieved passages and the input sequence to condi-             ours run on A100 GPU with 40GB GPU memory.
tion the generation process.
Pre-Training and Fine-Tuning Configurations                     per second (Q/s). Compared with parametric
We base our EMAT on T5 (Raffel et al., 2020),                   models, our proposed method yields substantially
and initialise our model with the pre-trained pa-               higher EM scores across three datasets. EMAT-
rameters from T5-base.2 To evaluate the speed                   FKSV outperforms T5-base, which share the same
and accuracy of our proposed method under dif-                  backbone model, by 18.5, 20.0, 10.1 percentage
ferent computation environments, we pre-train and               points on NQ, TQA and WQ respectively. These
fine-tune EMAT using two settings. In the former                results indicate that our method of augmenting
setting, we set lk = 3, lc = 3, lv = 7, which em-               transformer with key-value memory effectively
ulates an environment where key embeddings has                  extends model‚Äôs knowledge capacity. Compared
fast access, but there is delay in acquiring value              with retrieval-only models, our method also demon-
embeddings; we refer to this setting as Fast Key,               strates strong performance. RePAQ baselines also
Slow Value (FKSV). In the latter setting, lk = 3,               exploit PAQ as knowledge source, and hence is
lc = 10, lv = 11, which corresponds to a scenario               comparable with our method. Our EMAT-FKSV
where both key querying and value reading can                   outperforms the best RePAQ retriever (RePAQ-
have significant delays. We refer to this setting as            large) by 2.8 and 3.1 percentage points on NQ
Slow Key, Slow Value (SKSV). All details on the                 and TQA respectively. Speed-wise, EMAT can
training hyperparameters the hardware used in our               answer 1000-1200 Q/s, which is a high throughput
experiments are available in Appendix B.                        in ODQA and is comparable to some of the fastest
                                                                parametric models and retrieval-only models.
5.2 Open-Domain Question Answering
                                                                   In ODQA, retrieval-augmented models are
Table 1 shows the experimental results on three                 known to be highly accurate, but are also com-
ODQA datasets: NQ (Kwiatkowski et al., 2019),                   putationally inefficient (Min et al., 2020). EMAT
TQA (Joshi et al., 2017), and WQ (Berant et al.,                is significantly faster than these models. For ex-
2013). We report the Exact Match (EM) scores and                ample, FiD-base uses the same backbone T5-base
the average inference speed measured by queries                 model as EMAT, but retrieves and concatenates 20
    2
      We use the original version of T5 without SSM to ensure   to 100 passages from Wikipedia. Despite being
that our results are comparable with the baselines.             less accurate on NQ and TQA, EMAT is two or-
                                                            5189
 Model                                F1     R-L     U/s          Model                                F1     R-L     Q/s
 Parametric models                                                Parametric models
 Trans MemNet (Dinan et al., 2019)   11.85   10.11     -          BART-large (Lewis et al., 2020a)    19.23   20.55   30
 BART-large (Lewis et al., 2020a)    12.86   11.77    55          T5-base (Raffel et al., 2020)       16.01   19.08   76
 T5-base (Raffel et al., 2020)       13.53   12.40   160
                                                                  Retrieval-augmented models
 Retrieval-augmented models                                       BART + DPR (Petroni et al., 2021)   17.88   17.41   0.2
 BART + DPR (Petroni et al., 2021)   15.19   13.23   0.7          RAG (Lewis et al., 2020b)           14.51   14.05   0.4
 RAG (Lewis et al., 2020b)           13.11   11.57   3.4
                                                                  Retrieval-only models
 Retrieval-only models                                            RePAQ w/ EMAT key encoder           1.40    1.65     -
 RePAQ w/ EMAT key encoder           1.84    1.48     -
                                                                  Ours
 Ours                                                             EMAT-FKSV                           18.42   20.61   67
 EMAT-FKSV                           15.78   14.73   141          EMAT-SKSV                           19.03   20.91   71
 EMAT-SKSV                           15.35   14.68   150
                                                              Table 3: Results on the ELI5 dataset from the KILT
Table 2: Results on the Wizard-of-Wikipedia dataset           benchmark.
from the KILT benchmark.

                                                              while generating 141 utterances per second. Sur-
ders of magnitude faster than FiD-base and more               prisingly, EMAT models also outperform retrieval-
accurate on WQ. On NaturalQuestions in terms                  augmented models such as RAG and BART+DPR,
of EM score, our method outperforms REALM                     which exploits Wikipedia as knowledge source. It
and DPR, and is comparable with QAMAT and                     indicates that our method that encodes PAQ as key-
RAG. QAMAT (Chen et al., 2022) is a concur-                   value memory is capable of represent crucial in-
rent work to ours and is the fastest among the                formation in Wikipedia, and generalises well to
retrieval-augmented models. But QAMAT runs                    tasks beyond ODQA. We also implement a RePAQ-
on 32 TPU-v3 (Jouppi et al., 2017), which have                equivalent retrieval-only model using EMAT‚Äôs key
roughly 1024GB TPU memory, and the MIPS                       encoder. Since PAQ is a collection of QA pairs,
search is conducted on TPU. In contrast, EMAT                 simply retrieving relevant QA pairs for dialogue
runs on a single A100 GPU with 40GB GPU mem-                  does not work well. The large gap between EMAT
ory, and the MIPS search is executed on CPU. De-              and RePAQ with EMAT key encoder, together with
spite using substantially fewer resources, EMAT-              the qualitative analysis in Section 6.2, demonstrates
FKSV is roughly 4.2 times faster than QAMAT,                  that EMAT decoder does not simply copy informa-
and EMAT-SKSV is 5 times faster.                              tion from the key-value memory, but exploits the
                                                              key-value embeddings to generate novel response.
5.3 Generalisation to Open-Domain Dialogue
    and Long-Form QA                                          Long-Form Question Answering Results on the
                                                              LFQA task ELI5 (Fan et al., 2019) (shown in Ta-
Open-Domain Dialogue Open-domain dialogue                     ble 3) reveals similar conclusions as in WoW. Both
is a dialogue task that requires accessing knowl-             EMAT-FKSV and EMAT-SKSV outperform the
edge from Wikipedia to produce dialogue response.             T5-base baseline by a large margin, 2.41pp and
Table 2 shows the results on the open-domain di-              3.01pp in F1, while retaining an inference speed
alogue dataset Wizard-of-Wikipedia (Dinan et al.,             to 67 Q/s and 71 Q/s, respectively. EMAT is both
2019) from the KILT (Petroni et al., 2021) bench-             faster and more accurate than retrieval-augmented
mark. The utterances from dialogue history are                models on ELI5 too. Compared to RAG, EMAT-
concatenated into a input sequence, and the output            SKSV is 4.52pp better in F1, 6.86pp better in
sequence is the corresponding response utterance.             ROUGE-L, and more than 160 times faster in in-
We follow Petroni et al. (2021) and evaluate the              ference speed.
models with F1 and ROUGE-L metrics, and we
also report the average number of utterances gener-           6      Analysis
ated per second (U/s) for speed evaluation.
   The results show that, our proposed EMAT out-              6.1     Ablation Study
performs parametric models while retaining a sim-             We conduct ablation study on the pre-training steps
ilar inference speed. EMAT-FKSV outperforms                   and the results are shown in Table 4. Without fine-
T5-base by 2.25 F1 and 2.28 ROUGE-L points,                   tuning, the pre-trained EMAT outperforms fine-
                                                           5190
 Model                          NQ     TQA    WQ                                           Natural Question

 EMAT-FKSV                      44.3   44.4   36.7          Q: who plays the judge in drop dead diva?                        A: Lex Medlin
                                                            EMAT: Lex Medlin
     ‚àí fine-tune                30.6   32.4   25.6
     ‚àí auto-encoding tasks      28.5   34.6   12.9          Retrieved Key-Values
                                                            Q: who plays jane on drop dead diva?                             A: Brooke Elliott
     ‚àí generation task          28.7   24.7   31.4
                                                            Q: who played fred in drop dead diva?                            A: Beverly Hills
     ‚àí all pre-training tasks   27.1   17.7    6.0          Q: who played empress katia on drop dead diva?                   A: Tobin
                                                            Q: who plays judge french in drop dead divorce season 4?         A: Lex Medlin
Table 4: Ablation on the pre-training steps used by         Q: who played ian holt on drop dead diva?                        A: Jeffrey Pierce
EMAT, described in Section 4.1, measured using EM on                                      Wizard-of-Wikipedia
NQ, TQA, and WQ: we analyse the impact of removing          Dialogue History
auto-encoding, generation, and all pre-training tasks       Apprentice: I like jazz.
                                                            Wizard:      That‚Äôs great! Jazz ... is originated in theafrican-american communitie.
from EMAT‚Äôs pre-training phase.                             Apprentice: When did it originate?

                                                            Response
                                                            Target: Jazz originated in the late 19th century
tuned T5-large on NQ and TQA, and has a com-                T5-base: It was first recorded in the late 18th century

petitive result on WQ. When we remove the auto-             EMAT: It originated in late 19th century in new orleans

encoding (KAE and VAE) tasks, the performance               Retrieved Key-Values
                                                            Q: where did the genre of jazz originate?                  A: New Orleans, US
on NQ and WQ drops significantly (36.7 ‚Üí 12.9               Q: when did jazz music start in the united states?         A: 1920s
on WQ). Ablating the generation task results in             Q: what type of music was jazz originally?                 A: dance music
substantially worse EM on NQ and TQA (44.4 ‚Üí                Q: what genre of music does rock come from?                A: blues
24.7 on TQA) The ablation results demonstrate               Q: what genre of music is hip hop?                         A: rap

that both auto-encoding task and generation task
                                                        Table 5: Examples from NQ and WoW. Noting that
are crucial to EMAT‚Äôs performance. Without all
                                                        EMAT only retrieves and integrates dense key-value
the pre-training tasks, EMAT perform very poorly,       pairs, but not accesses the presented text-based QAs.
and even worse than T5-base baseline. This may
be due to the fact that the key-value memory is
not well learned and hence incorporating them will      a more faithful and informative response than T5-
introduce noise to the model, thus leads to poor        base.
predictions.                                              More examples can be found in Table 6 in the
                                                        appendix. We find that EMAT retrieves useful key-
6.2 Qualitative Analysis                                value pairs and makes full use of them to generate
Table 5 shows some examples from NQ and WoW.            answers. This analysis also demonstrates the inter-
The presented QA pairs correspond to the top-5          pretability of EMAT, and the feasibility of only us-
retrieved dense key-value pairs. In NQ, we can see      ing dense key-value embeddings to provide knowl-
that EMAT retrieves useful key-value and generates      edge.
correct answer from the first example. Different
                                                        7        Conclusions
from retrieval-only models that only output the
top-1 retrieved QA, EMAT conducted some sort            In this work, we propose the Efficient Memory-
of reranking, and the decoder manages to use the        Augmented Transformer (EMAT) that combines
right key-value to generate the answer. In another      the strength of parametric model and retrieval-
example presented in Table 6, it demonstrates that      augmented model. It encodes external knowledge
EMAT‚Äôs output is not always from retrieved values.      into a key-value memory and exploits the fast MIPS
It will ignore the irrelevant key-value pairs, also     search for memory querying. We introduce pre-
uses evidences from keys, which are impossible for      training tasks to learn better key-value representa-
retrieval-only models.                                  tions and integration of multiple memory slots into
   In the example from WoW, it requires using the       transformer. Experiments on knowledge intensive
fine-grained knowledge 19th century to generate         tasks, including open-domain question answering,
response. We can see that EMAT retrieves context-       dialogue and long-form question answering, show
related key-value pairs, and mainly uses the two        both the accuracy and speediness of EMAT. In the
underlined evidences to generate response. In con-      future, we will seek to improve integrate more di-
trast, T5-base generates hallucinated response, pro-    verse knowledge into the memory and generalise
ducing the wrong time ‚Äú18th century‚Äù. This shows        our method to more downstream tasks.
that, with memory augmentation, EMAT generates
                                                     5191
Limitations                                                Annual Conference on Neural Information Process-
                                                           ing Systems 2020, NeurIPS 2020, December 6-12,
One limitation is that the memory retrieval module         2020, virtual.
requires weak supervision to train with. This may
mean that we define different weak supervision          Danqi Chen, Adam Fisch, Jason Weston, and Antoine
                                                          Bordes. 2017. Reading Wikipedia to answer open-
labels when apply to different downstream tasks.          domain questions. In Proceedings of the 55th Annual
One could use end-to-end training techniques such         Meeting of the Association for Computational Lin-
as the ones proposed by Paranjape et al. (2021);          guistics (Volume 1: Long Papers), pages 1870‚Äì1879,
Lewis et al. (2020b), to train the memory retrieval       Vancouver, Canada. Association for Computational
                                                          Linguistics.
module with gradients from the decoder, and we
leave this as future work. Another potential limita-    Wenhu Chen, Pat Verga, Michiel de Jong, John Wieting,
tion is that, we need to store the dense key-value        and William Cohen. 2022. Augmenting pre-trained
memory M, which requires around 300GB CPU                 language models with qa-memory for open-domain
                                                          question answering. CoRR, abs/2204.04581.
RAM. But since it is relatively easy to get machine
with more CPU RAM than GPU memory, and the              Rajarshi Das, Patrick Lewis, Sewon Min, June Thai,
fact that most deep learning workstations can reach       and Manzil Zaheer, editors. 2022. Proceedings of the
this requirement, we believe this is not too much a       1st Workshop on Semiparametric Methods in NLP:
                                                          Decoupling Logic from Knowledge. Association for
constraint. Besides, we can use LRU cache to save
                                                          Computational Linguistics, Dublin, Ireland and On-
RAM in low memory resource situations.                    line.

Acknowledgements                                        Emily Dinan, Stephen Roller, Kurt Shuster, Angela
                                                          Fan, Michael Auli, and Jason Weston. 2019. Wizard
Pasquale and Pontus were partially funded by              of wikipedia: Knowledge-powered conversational
the European Union‚Äôs Horizon 2020 research                agents. In 7th International Conference on Learning
and innovation programme under grant agree-               Representations, ICLR 2019, New Orleans, LA, USA,
ment no. 875160, and by an industry grant                 May 6-9, 2019. OpenReview.net.
from Cisco. Baotian Hu and Yu Zhao were                 Angela Fan, Claire Gardent, Chlo√© Braud, and Antoine
funded by grants: Natural Science Founda-                 Bordes. 2021. Augmenting transformers with KNN-
tion of China (No.62006061), Stable Support               based composite memory for dialog. Transactions of
Program for Higher Education Institutions of              the Association for Computational Linguistics, 9:82‚Äì
                                                          99.
Shenzhen (No.        GXWD20201230155427003-
20200824155011001). The authors would also like         Angela Fan, Yacine Jernite, Ethan Perez, David Grang-
to thank Patrick Lewis, Wenhu Chen, and Zetian            ier, Jason Weston, and Michael Auli. 2019. ELI5:
Sun for their help and feedback.                          Long form question answering. In Proceedings of
                                                          the 57th Annual Meeting of the Association for Com-
                                                          putational Linguistics, pages 3558‚Äì3567, Florence,
                                                          Italy. Association for Computational Linguistics.
References
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy    Mor Geva, Roei Schuster, Jonathan Berant, and Omer
  Liang. 2013. Semantic parsing on Freebase from         Levy. 2021. Transformer feed-forward layers are key-
  question-answer pairs. In Proceedings of the 2013      value memories. In Proceedings of the 2021 Confer-
  Conference on Empirical Methods in Natural Lan-        ence on Empirical Methods in Natural Language Pro-
  guage Processing, pages 1533‚Äì1544, Seattle, Wash-      cessing, pages 5484‚Äì5495, Online and Punta Cana,
  ington, USA. Association for Computational Linguis-    Dominican Republic. Association for Computational
  tics.                                                  Linguistics.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie        Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-
  Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind        pat, and Ming-Wei Chang. 2020. REALM: retrieval-
  Neelakantan, Pranav Shyam, Girish Sastry, Amanda        augmented language model pre-training. CoRR,
  Askell, Sandhini Agarwal, Ariel Herbert-Voss,           abs/2002.08909.
  Gretchen Krueger, Tom Henighan, Rewon Child,
  Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,         Gautier Izacard and Edouard Grave. 2021. Leveraging
  Clemens Winter, Christopher Hesse, Mark Chen, Eric      passage retrieval with generative models for open do-
  Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,     main question answering. In Proceedings of the 16th
  Jack Clark, Christopher Berner, Sam McCandlish,         Conference of the European Chapter of the Associ-
  Alec Radford, Ilya Sutskever, and Dario Amodei.         ation for Computational Linguistics: Main Volume,
  2020. Language models are few-shot learners. In Ad-     pages 874‚Äì880, Online. Association for Computa-
  vances in Neural Information Processing Systems 33:     tional Linguistics.

                                                    5192
Jeff Johnson, Matthijs Douze, and Herv√© J√©gou. 2019.       Guillaume    Lample,    Alexandre    Sablayrolles,
   Billion-scale similarity search with GPUs. IEEE           Marc‚ÄôAurelio Ranzato, Ludovic Denoyer, and
   Transactions on Big Data, 7(3):535‚Äì547.                   Herv√© J√©gou. 2019. Large memory layers with
                                                             product keys. In Advances in Neural Information
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke             Processing Systems 32: Annual Conference on
 Zettlemoyer. 2017. TriviaQA: A large scale distantly        Neural Information Processing Systems 2019,
 supervised challenge dataset for reading comprehen-         NeurIPS 2019, December 8-14, 2019, Vancouver,
 sion. In Proceedings of the 55th Annual Meeting of          BC, Canada, pages 8546‚Äì8557.
 the Association for Computational Linguistics (Vol-
 ume 1: Long Papers), pages 1601‚Äì1611, Vancouver,          Jinhyuk Lee, Mujeen Sung, Jaewoo Kang, and Danqi
 Canada. Association for Computational Linguistics.           Chen. 2021. Learning dense representations of
                                                              phrases at scale. In Proceedings of the 59th Annual
                                                              Meeting of the Association for Computational Lin-
Norman P. Jouppi, Cliff Young, Nishant Patil, David A.        guistics and the 11th International Joint Conference
  Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah            on Natural Language Processing (Volume 1: Long
  Bates, Suresh Bhatia, Nan Boden, Al Borchers,               Papers), pages 6634‚Äì6647, Online. Association for
  Rick Boyle, Pierre-luc Cantin, Clifford Chao, Chris         Computational Linguistics.
  Clark, Jeremy Coriell, Mike Daley, Matt Dau, Jeffrey
  Dean, Ben Gelb, Tara Vazir Ghaemmaghami, Ra-             Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
  jendra Gottipati, William Gulland, Robert Hagmann,         Ghazvininejad, Abdelrahman Mohamed, Omer Levy,
  C. Richard Ho, Doug Hogberg, John Hu, Robert               Veselin Stoyanov, and Luke Zettlemoyer. 2020a.
  Hundt, Dan Hurt, Julian Ibarz, Aaron Jaffey, Alek          BART: Denoising sequence-to-sequence pre-training
  Jaworski, Alexander Kaplan, Harshit Khaitan, Daniel        for natural language generation, translation, and com-
  Killebrew, Andy Koch, Naveen Kumar, Steve Lacy,            prehension. In Proceedings of the 58th Annual Meet-
  James Laudon, James Law, Diemthu Le, Chris Leary,          ing of the Association for Computational Linguistics,
  Zhuyuan Liu, Kyle Lucke, Alan Lundin, Gordon               pages 7871‚Äì7880, Online. Association for Computa-
  MacKean, Adriana Maggiore, Maire Mahony, Kieran            tional Linguistics.
  Miller, Rahul Nagarajan, Ravi Narayanaswami, Ray
  Ni, Kathy Nix, Thomas Norrie, Mark Omernick,             Patrick Lewis, Pontus Stenetorp, and Sebastian Riedel.
  Narayana Penukonda, Andy Phelps, Jonathan Ross,            2021a. Question and answer test-train overlap in
  Matt Ross, Amir Salek, Emad Samadiani, Chris Sev-          open-domain question answering datasets. In Pro-
  ern, Gregory Sizikov, Matthew Snelham, Jed Souter,         ceedings of the 16th Conference of the European
  Dan Steinberg, Andy Swing, Mercedes Tan, Gre-              Chapter of the Association for Computational Lin-
  gory Thorson, Bo Tian, Horia Toma, Erick Tuttle,           guistics: Main Volume, pages 1000‚Äì1008, Online.
  Vijay Vasudevan, Richard Walter, Walter Wang, Eric         Association for Computational Linguistics.
  Wilcox, and Doe Hyun Yoon. 2017. In-datacenter
  performance analysis of a tensor processing unit. In     Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Min-
  ISCA, pages 1‚Äì12. ACM.                                     ervini, Heinrich K√ºttler, Aleksandra Piktus, Pontus
                                                             Stenetorp, and Sebastian Riedel. 2021b. PAQ: 65
                                                             million probably-asked questions and what you can
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-        do with them. Transactions of the Association for
  som. 2014. A convolutional neural network for mod-         Computational Linguistics, 9:1098‚Äì1115.
  elling sentences. In Proceedings of the 52nd Annual
  Meeting of the Association for Computational Lin-        Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-
  guistics (Volume 1: Long Papers), pages 655‚Äì665,           tus, Fabio Petroni, Vladimir Karpukhin, Naman
  Baltimore, Maryland. Association for Computational         Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih,
  Linguistics.                                               Tim Rockt√§schel, Sebastian Riedel, and Douwe
                                                             Kiela. 2020b. Retrieval-augmented generation for
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick          knowledge-intensive NLP tasks. In Advances in Neu-
  Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and           ral Information Processing Systems 33: Annual Con-
  Wen-tau Yih. 2020. Dense passage retrieval for open-       ference on Neural Information Processing Systems
  domain question answering. In Proceedings of the           2020, NeurIPS 2020, December 6-12, 2020, virtual.
  2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP), pages 6769‚Äì6781,            Linqing Liu, Patrick S. H. Lewis, Sebastian Riedel,
  Online. Association for Computational Linguistics.         and Pontus Stenetorp. 2021. Challenges in gener-
                                                             alization in open domain question answering. CoRR,
                                                             abs/2109.01156.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
  field, Michael Collins, Ankur Parikh, Chris Alberti,     Yury A. Malkov and Dmitry A. Yashunin. 2020. Effi-
  Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-     cient and robust approximate nearest neighbor search
  ton Lee, Kristina Toutanova, Llion Jones, Matthew          using hierarchical navigable small world graphs.
  Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob               IEEE Trans. Pattern Anal. Mach. Intell., 42(4):824‚Äì
  Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-           836.
  ral questions: A benchmark for question answering
  research. Transactions of the Association for Compu-     Sewon Min, Jordan L. Boyd-Graber, Chris Alberti,
  tational Linguistics, 7:452‚Äì466.                           Danqi Chen, Eunsol Choi, Michael Collins, Kelvin

                                                       5193
  Guu, Hannaneh Hajishirzi, Kenton Lee, Jenni-              Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.
  maria Palomaki, Colin Raffel, Adam Roberts, Tom             How much knowledge can you pack into the param-
  Kwiatkowski, Patrick S. H. Lewis, Yuxiang Wu,               eters of a language model? In Proceedings of the
  Heinrich K√ºttler, Linqing Liu, Pasquale Minervini,          2020 Conference on Empirical Methods in Natural
  Pontus Stenetorp, Sebastian Riedel, Sohee Yang,             Language Processing (EMNLP), pages 5418‚Äì5426,
  Minjoon Seo, Gautier Izacard, Fabio Petroni, Lu-            Online. Association for Computational Linguistics.
  cas Hosseini, Nicola De Cao, Edouard Grave,
  Ikuya Yamada, Sonse Shimaoka, Masatoshi Suzuki,           Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
  Shumpei Miyawaki, Shun Sato, Ryo Takahashi, Jun              Sequence to sequence learning with neural networks.
  Suzuki, Martin Fajcik, Martin Docekal, Karel On-             In Advances in Neural Information Processing Sys-
  drej, Pavel Smrz, Hao Cheng, Yelong Shen, Xi-                tems 27: Annual Conference on Neural Information
  aodong Liu, Pengcheng He, Weizhu Chen, Jianfeng              Processing Systems 2014, December 8-13 2014, Mon-
  Gao, Barlas Oguz, Xilun Chen, Vladimir Karpukhin,            treal, Quebec, Canada, pages 3104‚Äì3112.
  Stan Peshterliev, Dmytro Okhonko, Michael Sejr
  Schlichtkrull, Sonal Gupta, Yashar Mehdad, and            Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallap-
  Wen-tau Yih. 2020. Neurips 2020 efficientqa com-            ati, and Bing Xiang. 2019. Multi-passage BERT: A
  petition: Systems, analyses and lessons learned. In         globally normalized BERT model for open-domain
  NeurIPS (Competition and Demos), volume 133 of              question answering. In Proceedings of the 2019 Con-
  Proceedings of Machine Learning Research, pages             ference on Empirical Methods in Natural Language
  86‚Äì111. PMLR.                                               Processing and the 9th International Joint Confer-
                                                              ence on Natural Language Processing (EMNLP-
                                                              IJCNLP), pages 5878‚Äì5882, Hong Kong, China. As-
Sewon Min, Danqi Chen, Hannaneh Hajishirzi, and
                                                              sociation for Computational Linguistics.
  Luke Zettlemoyer. 2019. A discrete hard EM ap-
  proach for weakly supervised question answering. In       Yuxiang Wu, Pasquale Minervini, Pontus Stenetorp,
  Proceedings of the 2019 Conference on Empirical             and Sebastian Riedel. 2021. Training adaptive com-
  Methods in Natural Language Processing and the              putation for open-domain question answering with
  9th International Joint Conference on Natural Lan-          computational constraints. In Proceedings of the 59th
  guage Processing (EMNLP-IJCNLP), pages 2851‚Äì                Annual Meeting of the Association for Computational
  2864, Hong Kong, China. Association for Computa-            Linguistics and the 11th International Joint Confer-
  tional Linguistics.                                         ence on Natural Language Processing (Volume 2:
                                                              Short Papers), pages 447‚Äì453, Online. Association
Ashwin Paranjape, Omar Khattab, Christopher Potts,            for Computational Linguistics.
  Matei Zaharia, and Christopher D. Manning. 2021.
  Hindsight: Posterior-guided training of retrievers for    Yuxiang Wu, Sebastian Riedel, Pasquale Minervini, and
  improved open-ended generation. ArXiv preprint,             Pontus Stenetorp. 2020. Don‚Äôt read too much into
  abs/2110.07752.                                             it: Adaptive computation for open-domain question
                                                              answering. In EMNLP (1), pages 3029‚Äì3039. Asso-
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick         ciation for Computational Linguistics.
  Lewis, Majid Yazdani, Nicola De Cao, James Thorne,
  Yacine Jernite, Vladimir Karpukhin, Jean Maillard,        Wei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen
  Vassilis Plachouras, Tim Rockt√§schel, and Sebastian        Tan, Kun Xiong, Ming Li, and Jimmy Lin. 2019.
  Riedel. 2021. KILT: a benchmark for knowledge               End-to-end open-domain question answering with
  intensive language tasks. In Proceedings of the 2021        BERTserini. In Proceedings of the 2019 Confer-
  Conference of the North American Chapter of the             ence of the North American Chapter of the Associa-
  Association for Computational Linguistics: Human            tion for Computational Linguistics (Demonstrations),
  Language Technologies, pages 2523‚Äì2544, Online.             pages 72‚Äì77, Minneapolis, Minnesota. Association
  Association for Computational Linguistics.                  for Computational Linguistics.
                                                            Yunzhi Yao, Shaohan Huang, Ningyu Zhang, Li Dong,
Fabio Petroni, Tim Rockt√§schel, Sebastian Riedel,             Furu Wei, and Huajun Chen. 2022. Kformer: Knowl-
  Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and               edge injection in transformer feed-forward layers.
  Alexander Miller. 2019. Language models as knowl-           CoRR, abs/2201.05742.
  edge bases? In Proceedings of the 2019 Confer-
  ence on Empirical Methods in Natural Language Pro-
  cessing and the 9th International Joint Conference
  on Natural Language Processing (EMNLP-IJCNLP),
  pages 2463‚Äì2473, Hong Kong, China. Association
  for Computational Linguistics.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
  Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
  Wei Li, and Peter J. Liu. 2020. Exploring the limits
  of transfer learning with a unified text-to-text trans-
  former. J. Mach. Learn. Res., 21:140:1‚Äì140:67.

                                                        5194
A    Data Efficiency                                                                                                                                                                                    B                Hyperparameters
                                                                                                                                                                                                        Model Settings The length of P REFIX is 2 in
Fig. 2 shows how the number of retrieved key-value
                                                                                                                                                                                                        EMAT. EMAT contains 225M parameters, and
pairs from PAQ-L1 influences the downstream EM
                                                                                                                                                                                                        T5-base contains 221M parameters. The memory
score on Natural Questions, TriviaQA, and We-
                                                                                                                                                                                                        cache size is set to 384 in all downstream tasks. The
bQuestions. The results show that, as the number
                                                                                                                                                                                                        retrieval loss weight and generation loss weight are
of retrieved memory entries increases, EMAT‚Äôs EM
                                                                                                                                                                                                        both set to 1.
score monotonically increases, which indicates that
the model can handle noise in the retrieved memory                                                                                                                                                      Pre-Training We pre-train for 5 epochs on PAQ-
entries and benefit from larger number of retrieved                                                                                                                                                     L1, using learning rate warm-ups for the first 5000
memory entries. In Fig. 3 we analyse the scaling                                                                                                                                                        training steps to 10‚àí4 , and linear rate decay in the
effects induced by using larger subsets of PAQ for                                                                                                                                                      remaining steps. For each QA in PAQ-L1, we use
creating the key-value memory M. The results                                                                                                                                                            RePAQ to retrieve 10 relevant QAs from PAQ-L1.
demonstrate that EMAT‚Äôs predictive accuracy in-                                                                                                                                                         To force the model use relevant QAs‚Äô information,
creases with the number of PAQ questions across                                                                                                                                                         we sample 10% examples to retain itself in the
all considered ODQA datasets.                                                                                                                                                                           relevant QA set. The weights of auto-encoding loss
                                                                                                                                                                                                        and generation loss is set to 0.5 and 1.0.
                                      œ∞ œ∞
                                                                                                                                                                                                        ODQA For NQ and TQA, the learning rate warm-
                                      œ∞ œÆ
                                                                                                                                                                                                        ups for the first 1000 steps to 5 √ó 10‚àí5 , and linear
             , ≈ù ∆ö Œõ œ≠  ^ ƒê ≈Ω ∆å ƒû




                                      œ∞ œ¨
                                                                                                           E Y  Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø                                                                  rate decay in the remaining steps. For WQ, the
                                      œØ œ¥                                                                  d Y   Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø
                                                                                                           t Y  Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø                                                                  learning rate is fixed to 4 √ó 10‚àí5 during training.
                                      œØ œ≤
                                                                                                                                                                                                        We fine-tune 30 epochs on ODQA tasks, using
                                      œØ œ∞
                                      œØ œÆ
                                                                                                                                                                                                        early stop with patients of 8 epochs. We use greedy
                                                     œÆ œ¨             œØ œ¨            œ∞ œ¨           œ± œ¨                      œ≤ œ¨                                                                          decoding algorithm to generate answers.
                                                                 ^ ≈ù «å ƒû  ≈Ω ƒ®  W  Y  Õ¨ ≈µ ≈ù ≈Ø ≈Ø ≈ù ≈Ω ≈∂

                                             a) EMAT-retriever Hit@1                                                                                                                                    WoW We fine-tune 20 epochs on WoW with
                                                                                                                                                                                                        8 √ó 10‚àí5 learning rate. The scheduler is same
                                      œ∞ œ∞
                                                                                                                                                                                                        to ODQA. We use greedy decoding algorithm to
                                      œ∞ œÆ                                                                                                                                                               generate responses.
              «Ü ƒÇ ƒê ∆ö  D ƒÇ ∆ö ƒê ≈ö




                                                                                                      E Y  Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø
                                      œ∞ œ¨
                                                                                                                                                                                                        ELI5 We fine-tune 8 epochs on ELI5 with 5 √ó
                                                                                                      d Y   Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø
                                                                                                      t Y  Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø
                                      œØ œ¥
                                                                                                                                                                                                        10‚àí5 learning rate. The scheduler is same to
                                      œØ œ≤                                                                                                                                                               ODQA. We use beam-sample decoding algorithm
                                                     œÆ œ¨             œØ œ¨            œ∞ œ¨           œ± œ¨                      œ≤ œ¨                                                                          to generate answers, where beam-size is 5, top-k
                                                                 ^ ≈ù «å ƒû  ≈Ω ƒ®  W  Y  Õ¨ ≈µ ≈ù ≈Ø ≈Ø ≈ù ≈Ω ≈∂
                                                                                                                                                                                                        is 64. We force the model do not generate repeat
                                              b) EMAT-generator EM                                                                                                                                      phrases by setting no_repeat_n_gram to 8.
Figure 3: Analysis of how the number of PAQ entries                                                                                                                                                     Hardware The machine used to measure the
used to populate the memory M influences the down-                                                                                                                                                      speed is a machine learning workstation with In-
stream predictive accuracy on several ODQA datasets.                                                                                                                                                    tel(R) Xeon(R) Platinum 8358 CPU, 512GB of
                                                                                                                                                                                                        CPU RAM and one 40GB NVIDIA A100 GPU.


                                                                                                                                                            œ∞ œÆ Õò œ¨                                                                                                           œ∞ œÆ
                                   œ∞ œ≠ Õò œ±
                                                                                                                                                                                                                                                                              œ∞ œ¨
                                                                                                                                                            œ∞ œ≠ Õò œ±
           «Ü ƒÇ ƒê ∆ö  D ƒÇ ∆ö ƒê ≈ö




                                                                                                                                    «Ü ƒÇ ƒê ∆ö  D ƒÇ ∆ö ƒê ≈ö




                                                                                                                                                                                                                                                      «Ü ƒÇ ƒê ∆ö  D ƒÇ ∆ö ƒê ≈ö




                                   œ∞ œ≠ Õò œ¨                                                                                                                                                                                                                                    œØ œ¥
                                                                                          E Y  Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø                                     œ∞ œ≠ Õò œ¨                                               d Y   Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø                                                                                  t Y  Õæ ≈ê ƒû ≈∂ ƒû ∆å ƒÇ ∆ö ≈ù ≈Ω ≈∂ Õø
                                   œ∞ œ¨ Õò œ±                                                E Y  Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø                                                                                             d Y   Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø                               œØ œ≤                                                  t Y  Õæ ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒÇ ≈Ø Õø
                                                                                                                                                            œ∞ œ¨ Õò œ±
                                   œ∞ œ¨ Õò œ¨                                                                                                                                                                                                                                    œØ œ∞
                                                                                                                                                            œ∞ œ¨ Õò œ¨
                                                                                                                                                                                                                                                                              œØ œÆ
                                   œØ œµ Õò œ±
                                                   œÆ              œ∞               œ≤               œ¥              œ≠ œ¨                                                        œÆ              œ∞               œ≤               œ¥              œ≠ œ¨                                            œÆ              œ∞                œ≤                œ¥               œ≠ œ¨
                                              E ∆µ ≈µ ƒè ƒû ∆å  ≈Ω ƒ®  ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒû ƒö  ≈¨ ƒû «á Õ≤ «Ä ƒÇ ≈Ø ∆µ ƒû  ∆â ƒÇ ≈ù ∆å ∆ê                                                    E ∆µ ≈µ ƒè ƒû ∆å  ≈Ω ƒ®  ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒû ƒö  ≈¨ ƒû «á Õ≤ «Ä ƒÇ ≈Ø ∆µ ƒû  ∆â ƒÇ ≈ù ∆å ∆ê                                         E ∆µ ≈µ ƒè ƒû ∆å  ≈Ω ƒ®  ∆å ƒû ∆ö ∆å ≈ù ƒû «Ä ƒû ƒö  ≈¨ ƒû «á Õ≤ «Ä ƒÇ ≈Ø ∆µ ƒû  ∆â ƒÇ ≈ù ∆å ∆ê

                                             a) Natural Questions                                                                                                              b) TriviaQA                                                                                               c) WebQuestions

Figure 2: Analysis of how changing the number of retrieved key-value pairs influences the downstream Exact Match
accuracy on several ODQA datasets.

                                                                                                                                                                                          5195
                                               Natural Questions
Question           who plays the judge in drop dead diva
Answer             [Lex Medlin]
EMAT Predict:      Lex Medlin
Retrieved          question: who plays jane on drop dead diva? answer: Brooke Elliott
                   question: who plays judge french in drop dead divorce season 4? answer: Lex Medlin
                   question: who played fred in drop dead diva? answer: Beverly Hills, California
Question           how long did the menendez brothers get in prison for killing their parents
Answer             [life imprisonment, life]
EMAT Predict:      life
Retrieved          question: when did the menendez brothers kill their parents? answer: 1989
                   question: where did the menendez brothers kill their parents? answer: Beverly Hills, California
                   question: who sentenced the menendez brothers to life in prison? answer: Judge Weisberg
Question           how long is a whale shark in meters
Answer             [12.65m, estimated at 9.7m, 9.7m]
Predict:           few meters
Retrieved          question: how long does a whale shark live? answer: 70 to 100 years
                   question: how long does it take a whale shark to mature? answer: around 30 years
                   question: how long does it take a blue whale to dive? answer: 10 minutes
                                             Wizard-of-Wikipedia
                   Wizard: Red the color at the end of the visible light spectrum looks good on everyone.
Dialogue history
                   Apprentice: I am more of a fan of green. That would leave us only one primary color: Blue.
Ground Truth       But the dominant wavelength of red is approximately 625‚Äì740. That‚Äôs impressive!
T5 Predict         I agree. It is the color between green and red.
EMAT Predict       it is color between violet and green on spectrum of visible light
Retrieved          question: what is the next color in this series: green, white, red, green, ? answer: Blue
                   question: what is the color of light between violet and green? answer: Blue
                   question: what color looks more blue as it brightens? answer: Violet
                 Apprentice: I like jazz.
Dialogue history Wizard: That‚Äôs great! Jazz is a music genre that originated in the african-american communities.
                 Apprentice: When did it originate?
Ground Truth     Jazz originated in the late 19th century
T5 Predict       It was first recorded in the late 18th century
EMAT Predict     It originated in late 19th century in new orleans
Retrieved        question: where did the genre of jazz originate? answer: New Orleans, United States
                 question: when did jazz music start in the united states? answer: 1920s
                 question: what genre of music does rock come from? answer: blues

                       Table 6: More examples of EMAT‚Äôs prediction on NQ and WoW.




                                                      5196
                A Unified Generative Framework for Various NER Subtasks
            Hang Yan1 , Tao Gui2 , Junqi Dai1 , Qipeng Guo1 , Zheng Zhang3 , Xipeng Qiu1,4‚àó
            1
            Shanghai Key Laboratory of Intelligent Information Processing, Fudan University
                             1
                               School of Computer Science, Fudan University
                  2
                    Institute of Modern Languages and Linguistics, Fudan University
                                           3
                                             New York University
                                     4
                                       Pazhou Lab, Guangzhou, China
               {hyan19,tgui16,jqdai19,qpguo16,xpqiu}@fudan.edu.cn
                                               zz@nyu.edu

                          Abstract                                         B-Per            I-Per            O         O          O       O       B-Loc
                                                                      S1: Barack         Obama               was      born        in     the      US
                                                                                     Person                                                    Location
        Named Entity Recognition (NER) is the task                                 (a) Sequence labelling for flat NER
        of identifying spans that represent entities in                                             The Lincoln
        sentences. Whether the entity spans are nested                                               Memorial

        or discontinuous, the NER task can be cate-                                             the               Lincoln
                                                                                              Lincoln            Memorial
        gorized into the flat NER, nested NER, and
                                                                                        the           Lincoln             Memorial
        discontinuous NER subtasks. These subtasks
        have been mainly solved by the token-level                             S2:     The           Lincoln              Memorial
                                                                                                        Person
        sequence labelling or span-level classification.                                                   Location
                                                                             (b) Span-based classification for nested NER
        However, these solutions can hardly tackle the
                                                                    Actions: OUT      OUT            SHIFT        SHIFT LEFT-REDUCE COMPLETE ‚Ä¶
        three kinds of NER subtasks concurrently. To
                                                                      S3: have        much          muscle         pain     and        fatigue
        that end, we propose to formulate the NER                                                                                      Disorder
                                                                                                         Disorder
        subtasks as an entity span sequence genera-
                                                                          (c) Transition-based method for discontinuous NER
        tion task, which can be solved by a unified
                                                                      S1: Barack Obama <Person> US <Location>
        sequence-to-sequence (Seq2Seq) framework.
                                                                      S2: The Lincoln Memorial <Location> Lincoln <Person>
        Based on our unified framework, we can lever-
                                                                      S2: muscle pain < Disorder > muscle fatigue <Disorder>
        age the pre-trained Seq2Seq model to solve                       (d) A unified generative solution for all NER tasks
        all three kinds of NER subtasks without the
        special design of the tagging schema or ways            Figure 1: Examples of three kinds of NER subtasks.
        to enumerate spans. We exploit three types              (a) - (c) illustrate flat NER, nested NER, discontinuous
        of entity representations to linearize entities         NER, and their corresponding mainstream solutions re-
        into a sequence. Our proposed framework is              spectively. (d) Our proposed generative solution to
        easy-to-implement and achieves state-of-the-            solve all NER subtasks in a unified way.
        art (SoTA) or near SoTA performance on eight
        English NER datasets, including two flat NER
        datasets, three nested NER datasets, and three              The sequence labelling formulation, which will
        discontinuous NER datasets 1 .                           assign a tag to each token in the sentence, has
                                                                 been widely used in the flat NER field (McCal-
1       Introduction
                                                                 lum and Li, 2003; Collobert et al., 2011; Huang
Named entity recognition (NER) has been a funda-                 et al., 2015; Chiu and Nichols, 2016; Lample et al.,
mental task of Natural Language Processing (NLP),                2016; StrakovaÃÅ et al., 2019; Yan et al., 2019; Li
and three kinds of NER subtasks have been recog-                 et al., 2020a). Inspired by sequence labelling‚Äôs
nized in previous work (Sang and Meulder, 2003;                  success in the flat NER subtask, Metke-Jimenez
Pradhan et al., 2013a; Doddington et al., 2004; Kim              and Karimi (2016); Muis and Lu (2017) tried to
et al., 2003; Karimi et al., 2015), including flat               formulate the nested and discontinuous NER into
NER, nested NER, and discontinuous NER. As                       the sequence labelling problem. For the nested and
shown in Figure 1, the nested NER contains over-                 discontinuous NER subtasks, instead of assigning
lapping entities, and the entity in the discontinuous            labels to each token directly, Xu et al. (2017); Wang
NER may contain several nonadjacent spans.                       and Lu (2019); Yu et al. (2020); Li et al. (2020b)
        ‚àó                                                        tried to enumerate all possible spans and conduct
    Corresponding author.
    1
   Code is available at https://github.com/yhcc/                 the span-level classification. Another way to effi-
BARTNER.                                                         ciently represent spans is to use the hypergraph (Lu

                                                           5808
                    Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics
                 and the 11th International Joint Conference on Natural Language Processing, pages 5808‚Äì5822
                               August 1‚Äì6, 2021. ¬©2021 Association for Computational Linguistics
and Roth, 2015; Katiyar and Cardie, 2018; Wang                        ‚Ä¢ We propose a novel and simple generative
and Lu, 2018; Muis and Lu, 2016).                                       solution to solve the flat NER, nested NER,
   Although the sequence labelling formulation has                      and discontinuous NER subtasks in a unified
dramatically advanced the NER task, it has to de-                       framework, in which NER subtasks are for-
sign different tagging schemas to fit various NER                       mulated as an entity span sequence generation
subtasks. One tagging schema can hardly fit for                         problem.
all three NER subtasks2 (Ratinov and Roth, 2009;                      ‚Ä¢ We incorporate the pre-trained Seq2Seq
Metke-Jimenez and Karimi, 2016; StrakovaÃÅ et al.,                       model BART into our framework and exploit
2019; Dai et al., 2020). While the span-based mod-                      three kinds of entity representations to lin-
els need to enumerate all possible spans, which is                      earize entities into sequences. The results
quadratic to the length of the sentence and is almost                   can shed some light on further exploration
impossible to enumerate in the discontinuous NER                        of BART into the entity sequence generation.
scenario (Yu et al., 2020). Therefore, span-based                     ‚Ä¢ The proposed framework not only avoids the
methods usually will set a maximum span length                          sophisticated design of tagging schema or
(Xu et al., 2017; Luan et al., 2019; Wang and Lu,                       span enumeration but also achieves SoTA
2018). Although hypergraphs can efficiently rep-                        or near SoTA performance on eight popu-
resent all spans (Lu and Roth, 2015; Katiyar and                        lar datasets, including two flat NER datasets,
Cardie, 2018; Muis and Lu, 2016), it suffers from                       three nested NER datasets, and three discon-
the spurious structure problem, and structural am-                      tinuous NER datasets.
biguity issue during inference and the decoding is
quite complicated (Muis and Lu, 2017). Because                    2     Background
the problems lie in different formulations, no publi-
                                                                  2.1    NER Subtasks
cation has tested their model or framework in three
NER subtasks simultaneously to the best of our                    The term ‚ÄúNamed Entity‚Äù was coined in the Sixth
knowledge.                                                        Message Understanding Conference (MUC-6) (Gr-
   In this paper, we propose using a novel and sim-               ishman and Sundheim, 1996). After that, the re-
ple sequence-to-sequence (Seq2Seq) framework                      lease of CoNLL-2003 NER dataset has greatly ad-
with the pointer mechanism (Vinyals et al., 2015)                 vanced the flat NER subtask (Sang and Meulder,
to generate the entity sequence directly. On the                  2003). Kim et al. (2003) found that in the field of
source side, the model inputs the sentence, and                   molecular biology domain, some entities could be
on the target side, the model generates the entity                nested. Karimi et al. (2015) provided a corpus that
pointer index sequence. Since flat, continuous and                contained medical forum posts on patient-reported
discontinuous entities can all be represented as en-              Adverse Drug Events (ADEs), some entities recog-
tity pointer index sequences, this formulation can                nized in this corpus may be discontinuous. Despite
tackle all the three kinds of NER subtasks in a uni-              the difference between the three kinds of NER sub-
fied way. Besides, this formulation can even solve                tasks, the methods adopted by previous publica-
the crossing structure entity3 and multi-type en-                 tions can be roughly divided into three types.
tity4 . By converting the NER task into a Seq2Seq                    Token-level classification The first line of work
generation task, we can smoothly use the Seq2Seq                  views the NER task as a token-level classification
pre-training model BART (Lewis et al., 2020) to                   task, which assigns to each token a tag that usually
enhance our model. To better utilize the pre-trained              comes from the Cartesian product between entity
BART, we propose three kinds of entity representa-                labels and the tag scheme, such as BIO and BILOU
tions to linearize entities into entity pointer index             (Ratinov and Roth, 2009; Collobert et al., 2011;
sequences.                                                        Huang et al., 2015; Chiu and Nichols, 2016; Lam-
   Our contribution can be summarized as follows:                 ple et al., 2016; Alex et al., 2007; StrakovaÃÅ et al.,
                                                                  2019; Metke-Jimenez and Karimi, 2016; Muis and
   2
      Attempts made for discontinuous constituent parsing may     Lu, 2017; Dai et al., 2020), then Conditional Ran-
tackle three NER subtasks in one tagging schema (Vilares and
GoÃÅmez-Rodrƒ±ÃÅguez, 2020).                                         dom Fields (CRF) (Lafferty et al., 2001) or tag
    3
      Namely, for span ABCD, both ABC and BCD are entities.       sequence generation methods can be used for de-
Although this is rare, it exists (Dai et al., 2020).              coding. Though the work of (StrakovaÃÅ et al., 2019;
    4
      An entity can have multiple entity types, as proteins can
be annotated as drug/compound in the EPPI corpus (Alex            Wang et al., 2019; Zhang et al., 2018; Chen and
et al., 2007).                                                    Moschitti, 2018) are much like our method, they all

                                                             5809
tried to predict a tagging sequence. Therefore, they     and decoder layers, like the transformer model used
still need to design tagging schemas for different       in the machine translation (Vaswani et al., 2017).
NER subtasks.                                            BART‚Äôs pre-training task is to recover corrupted
   Span-level classification When applying the se-       text into the original text. BART uses the encoder
quence labelling method to the nested NER and            to input the corrupted sentence and the decoder
discontinous NER subtasks, the tagging will be           to recover the original sentence. BART has base
complex (StrakovaÃÅ et al., 2019; Metke-Jimenez and       and large versions. The base version has 6 encoder
Karimi, 2016) or multi-level (Ju et al., 2018; Fisher    layers and 6 decoder layers, while the large version
and Vlachos, 2019; Shibuya and Hovy, 2020).              has 12. Therefore, the number of parameters is
Therefore, the second line of work directly con-         similar to its equivalently sized BERT 5 .
ducted the span-level classification. The main dif-
ference between publications in this line of work is     3       Proposed Method
how to get the spans. Finkel and Manning (2009)          In this part, we first introduce the task formulation,
regarded the parsing nodes as a span. Xu et al.          then we describe how we use the Seq2Seq model
(2017); Luan et al. (2019); Yamada et al. (2020); Li     with the pointer mechanism to generate the entity
et al. (2020b); Yu et al. (2020); Wang et al. (2020a)    index sequences. After that, we present the detailed
tried to enumerate all spans. Following Lu and           formulation of our model with BART.
Roth (2015), hypergraph methods which can effec-
tively represent exponentially many possible nested      3.1      NER Task
mentions in a sentence have been extensively stud-
                                                         The three kinds of NER tasks can all be formulated
ied in the NER tasks (Katiyar and Cardie, 2018;
                                                         as follows, given an input sentence of n tokens
Wang and Lu, 2018; Muis and Lu, 2016).
                                                         X = [x1 , x2 , ..., xn ], the target sequence is Y =
   Combined token-level and span-level classifi-         [s11 , e11 , ..., s1j , e1j , t1 , ..., si1 , ei1 , ..., sik , eik , ti ],
cation To avoid enumerating all possible spans           where s, e are the start and end index of a span,
and incorporate the entity boundary information          since an entity may contain one (for flat and
into the model, Wang and Lu (2019); Zheng et al.         nested NER) or more than one (for discontinu-
(2019); Lin et al. (2019); Wang et al. (2020b); Luo      ous NER) spans, each entity is represented as
and Zhao (2020) proposed combining the token-            [si1 , ei1 , ..., sij , eij , ti ], where ti is the entity tag
level classification and span-level classification.      index. We use G = [g1 , ..., gl ] to denote the entity
                                                         tag tokens (such as ‚ÄúPerson‚Äù, ‚ÄúLocation‚Äù, etc.),
2.2   Sequence-to-Sequence Models                        where l is the number of entity tags. We make
The Seq2Seq framework has been long studied and          ti ‚àà (n, n + l], the n shift is to make sure ti is not
adopted in NLP (Sutskever et al., 2014; Cho et al.,      confusing with pointer indexes (pointer indexes
2014; Luong et al., 2015; Vaswani et al., 2017;          will be in range [1, n]).
Vinyals et al., 2015). Gillick et al. (2016) pro-
posed a Seq2Seq model to predict the entity‚Äôs start,     3.2      Seq2Seq for Unified Decoding
span length and label for the NER task. Recently,        Since we formulate the NER task in a generative
the amazing performance gain achieved by PTMs            way, we can view the NER task as the following
(pre-trained models) (Qiu et al., 2020; Peters et al.,   equation:
2018; Devlin et al., 2019; Dai et al., 2021; Yan
                                                                                          m
et al., 2020) has attracted several attempts to pre-                                      Y
                                                                        P (Y |X) =              P (yt |X, Y<t )               (1)
train a Seq2Seq model (Song et al., 2019; Lewis
                                                                                          t=1
et al., 2020; Raffel et al., 2020). We mainly focus
on the newly proposed BART (Lewis et al., 2020)          where y0 is the special ‚Äústart of sentence‚Äù control
model because it can achieve better performance          token.
than MASS (Song et al., 2019). And the sentence-           We use the Seq2Seq framework with the pointer
piece tokenization used in T5 (Raffel et al., 2020)      mechanism to tackle this task. Therefore, our
will cause different tokenizations for the same to-      model consists of two components:
ken, making it hard to generate pointer indexes to           5
                                                             Because of the cross-attention between encoder and de-
conduct the entity extraction.                           coder, the number of parameters of BART is about 10% larger
   BART is formed by several transformer encoder         than its equivalently sized of BERT (Lewis et al., 2020).

                                                    5810
 Input: <s> have muscle pain and fatigue </s>
 Output: 2 3 7 2 5 6
                                                                                                          Final Prediction Prob.
                                                                                        Prob.

                                                                                                                        fatigue
                                                                                                                                                          score
                                                                             score
                                                                                                                  and                    <dis>
                                                                                          have
                                                                                                 muscle
                                                                                                          pain                    </s>                                           Entity Tag Embedding

                              √ó(1 ‚àí ùõº)           +                   ‚®Ç
                                                                                           1       2          3    4      5        6       7
                                                                                                                                                                             ‚®Ç         <dis>



                                                 √óùõº                      Pointer distribution                                                             Tag distribution


                                                 MLP

                                                                                        Output:               2               3             7         2           5

                                                                                                          TG              TG               TG        TG           TG




                                     BART Encoder                                                                             BART Decoder                                   Index2Token Conversion



  Token Embedding:
                      +        +         +   +         +      +      +                                     +               +               +          +           +
Position Embedding:      0     1         2   3         4       5     6                                     0                  1             2         3           4

             Input:   <s>     have muscle pain         and fatigue   </s>         Decoder Input:          <s>           muscle            pain       <dis>     muscle

                                             ‚®Ç   Dot-product                Shared Embedding                      TG          Target Generator



Figure 2: Model structure used in our method. The encoder encodes input sentences, and the decoder uses the
pointer mechanism to generate indexes autoregressively. ‚Äú<s>‚Äù and ‚Äú</s>‚Äù are the predefined start-of-sentence
and end-of-sentence tokens in BART. In the output sequence, ‚Äú7‚Äù means the entity tag ‚Äú<dis>‚Äù, and other numbers
indicate the pointer index (in range [1, 6]).


  (1) Encoder encodes the input sentence X into                                        achieve the index probability distribution Pt
vectors He , which formulates as follows:
                                                                                                  Ee = TokenEmbed(X)                                                                               (5)
                                                                                                          e                                      e
                      He = Encoder(X)                                       (2)                   HÃÇ = MLP(H )                                                                                     (6)
                                                                                                  HÃÑe = Œ± ‚àó HÃÇe + (1 ‚àí Œ±) ‚àó Ee                                                                     (7)
                                                                                                       d
where He ‚àà Rn√ód , and d is the hidden dimension.                                                 G = TokenEmbed(G)                                                                                 (8)
   (2) Decoder is to get the index probability distri-                                              Pt = Softmax([HÃÑe ‚äó hdt ; Gd ‚äó hdt ])                                                          (9)
bution for each step Pt = P (yt |X, Y<t ). However,
since Y<t contains the pointer and tag index, it can-                                  where TokenEmbed is the embeddings shared be-
not be directly inputted to the Decoder. We use the                                    tween the Encoder and Decoder; Ee , HÃÇe , HÃÑe ‚àà
Index2Token conversion to convert indexes into                                         Rn√ód ; Œ± ‚àà R is a hyper-parameter; Gd ‚àà Rl√ód ;
tokens                                                                                 [ ¬∑ ; ¬∑ ] means concatenation in the first dimension;
                                                                                       ‚äó means the dot product.
                         ¬Æ                                                                 During the training phase, we use the negative
                             Xyt ,    if yt ‚â§ n,
                 yÃÇt =                                                      (3)        log-likelihood loss and the teacher forcing method.
                             Gyt ‚àín , if yt > n                                        During the inference, we use an autoregressive
                                                                                       manner to generate the target sequence. We use
   After converting each yt this way, we can get the                                   the decoding algorithm presented in Algorithm 1
last hidden state hdt ‚àà Rd with YÃÇ<t = [yÃÇ1 , ..., yÃÇt‚àí1 ]                             to convert the index sequence into entity spans.
as follows                                                                             3.3          Detailed Entity Representation with
                                                                                                    BART
                  hdt = Decoder(He ; YÃÇ<t )                                 (4)        Since our model is a Seq2Seq model, it is natural
                                                                                       to utilize the pre-training Seq2Seq model BART to
Then, we can use the following equations to                                            enhance our model. We present a visualization of

                                                                               5811
Algorithm 1 Decoding Algorithm to Convert the                             entity word. If this entity includes multiple discon-
Entity Representation Sequence into Entity Spans                          tinuous spans of words, each span is represented in
Input: Target sequence Y = [y1 , ..., ym ] and yi ‚àà                       the same way.
    [1, n + |G|]                                                             BPE The position indexes of all BPEs of the
Output: Entity spans E = {(e1 , t1 ), ..., (ei , ti )}                    entity words.
 1: E = {}, e = [], i = 1                                                    Word Only the position index of the first BPE
 2: while i <= m do                                                       of each entity word is used.
 3:     yi = Y [i]                                                           For all cases, we will append the entity tag to
 4:     if yi > n then                                                    the entity representation. An example of the entity
 5:          if len(e) > 0 then                                           representations is presented in Figure 3. If a word
 6:               E.add((e, Gyi ‚àín ))                                     does not belong to any entity, it will not appear in
 7:          end if                                                       the target sequence. If a whole sentence has no
 8:          e = []                                                       entity, the prediction should be an empty sequence
 9:     else                                                              (only contains the ‚Äústart of sentence‚Äù (<s>) token
10:          e.append(yi )                                                and the ‚Äúend of sentence‚Äù (</s>) token ).
11:     end if
12:     i=i+1                                                             4       Experiment
13: end while
                                                                          4.1      Datasets
14: return E
                                                                          To show that our proposed method can be used in
                                   PER                                    various NER subtasks, we conducted experiments
                                                   LOC ORG
  Sentence:               x1             x2    x3        x4       x5      on eight datasets.
                                                                             Flat NER Datasets We adopt the CoNLL-2003
  After BPE: b111b1211b13111b2111b22111b31111b4111b42111b51               (Sang and Meulder, 2003) and the OntoNotes
Position Index:   0   1        2   3      4   5      6        7   8
                                                                          dataset 6 (Pradhan et al., 2013b). For CoNLL-2003,
 Three entity representations:
                                                                          we follow Lample et al. (2016); Yu et al. (2020) to
       Span: [0,2,5,5,PER] [0,7,LOC]                     [6,7, ORG]
                                                                          train our model on the concatenation of the train
         BPE: [0,1,2,5,PER] [0,1,2,3,4,5,6,7,LOC] [6,7, ORG]
                                                                          and development sets. For the OntoNotes dataset,
       Word: [0,5,PER]             [0,3,5,6,LOC]         [6, ORG]
                                                                          we use the same train, development, test splits as
Figure 3: The bottom three lines are examples                             Pradhan et al. (2012); Yu et al. (2020), and the New
of the three kinds of entity representations to de-                       Testaments portion were excluded since there is no
termine the entity in the sentence unambiguously.                         entity in this portion (Chiu and Nichols, 2016).
Words in the boxes are entity words, words within                            Nested NER Datasets We conduct experiments
the same color box belong to the same entity,                             on ACE 20047 (Doddington et al., 2004), ACE
and their corresponding entity representation is also
                                                                          20058 (Walker and Consortium, 2005), Genia
with the same color.          There are three entities,
(x1 , x3 , P ER), (x1 , x2 , x3 , x4 , LOC), (x4 , F AC),                 corpus (Kim et al., 2003). For ACE2004 and
where LOC, P ER, F AC are their corresponding en-                         ACE2005, we use the same data split as Lu and
tity tags. The underlined position index means this is                    Roth (2015); Muis and Lu (2017); Yu et al. (2020),
the starting BPE of a word.                                               the ratio between train, development and test set is
                                                                          8:1:1. For Genia, we follow Wang et al. (2020b);
                                                                          Shibuya and Hovy (2020) to use five types of enti-
our model based on BART in Figure 2. However,                             ties and split the train/dev/test as 8.1:0.9:1.0.
BART‚Äôs adoption is non-trivial because the Byte-
                                                                              6
Pair-Encoding (BPE) tokenization used in BART                                  https://catalog.ldc.upenn.edu/
                                                                          LDC2013T19
might tokenize one token into several BPEs. To                               7
                                                                               https://catalog.ldc.upenn.edu/
exploit how to use BART efficiently, we propose                           LDC2005T09
                                                                             8
three kinds of pointer-based entity representations                            https://catalog.ldc.upenn.edu/
                                                                          LDC2006T06
to locate entities in the original sentence unam-                            9
                                                                               In the reported experiments, they included the document
biguously. The three entity representations are as                        context. We rerun their code with only the sentence context.
follows:                                                                  The lack of document context might cause performance
                                                                          degradation is also confirmed by the author himself in
   Span The position index of the first BPE of the                        https://github.com/juntaoy/biaffine-ner/
starting entity word and the last BPE of the ending                       issues/8#issuecomment-650813813.

                                                                       5812
                                                               CoNLL2003                 OntoNotes
                               Models                         P    R    F           P        R     F
                 Clark et al. (2018)[GloVe300d]      -     -               92.6   -     -     -
                   Peters et al. (2018)[ELMo]        -     -              92.22 -       -     -
                    Akbik et al. (2019)[Flair]       -     -              93.18 -       -     -
               StrakovaÃÅ et al. (2019)[BERT-Large]   -     -              93.07 -       -     -
              Yamada et al. (2020)[RoBERTa-Large] -        -              92.40 -       -     -
                 Li et al. (2020b)[BERT-Large]‚Ä†    92.47 93.27            92.87 91.34 88.39 89.84
                 Yu et al. (2020)[BERT-Large]‚Ä°     92.85 92.15            92.5 89.92 89.74 89.83
                     Ours(Span)[BART-Large]               92.31 93.45 92.88 88.94 90.33 89.63
                     Ours(BPE)[BART-Large]                92.60 93.22 92.96 90.00 89.52 89.76
                     Ours(Word)[BART-Large]               92.61 93.87 93.24 89.99 90.77 90.38

Table 1: Results for the flat NER datasets. ‚Äú‚Ä†‚Äù indicates we rerun their code. ‚Äú‚Ä°‚Äù means our reproduction with only
the sentence-level context 9 .

                                                       ACE2004                ACE2005                    Genia
                    Models                         P     R     F          P     R     F           P       R       F
       Luan et al. (2019)[ELMO]                   -       -       84.7     -       -      82.9     -       -      76.2
   StrakovaÃÅ et al. (2019)[BERT-Large]            -       -      84.33     -       -     83.42     -       -     76.44
 Shibuya and Hovy (2020)[BERT-Large]?           85.23   84.72    84.97   83.30   84.69   83.99   77.46   76.65   77.05
     Li et al. (2020b)[BERT-Large]‚Ä†             85.83   85.77    85.80   85.01   84.13   84.57   81.25   76.36   78.72
     Yu et al. (2020)[BERT-Large] ‚Ä°             85.42   85.92    85.67   84.50   84.72   84.61   79.43   78.32   78.87
    Wang et al. (2020a)[BERT-Large]?            86.08   86.48    86.28   83.95   85.39   84.66   79.45   78.94   79.19
          Ours(Span)[BART-Large]                84.81 83.64 84.22 81.41 83.24 82.31 78.87 79.6 79.23
          Ours(BPE)[BART-Large]                 86.69 83.83 85.24 82.08 83.44 82.75 78.15 79.06 78.60
          Ours(Word)[BART-Large]                87.27 86.41 86.84 83.16 86.38 84.74 78.57 79.3 78.93

Table 2: Results for nested NER datasets,‚Äú‚Ä†‚Äù means our rerun of their code. ‚Äú‚Ä°‚Äù means our reproduction with only
sentence-level context9 . ‚Äú?‚Äù for a fair comparison, we only present results with the BERT-Large model.


   Discontinuous NER Datasets We follow Dai                5     Results
et al. (2020) to use CADEC (Karimi et al., 2015),
                                                           5.1     Results on Flat NER
ShARe13 (Pradhan et al., 2013a) and ShARe14
(Mowery et al., 2014) corpus. Since only the Ad-           Results are shown in Table 1. We do not com-
verse Drug Events (ADEs) entities include discon-          pare with Yamada et al. (2020) since they added
tinuous annotation, only these entities were consid-       entity information during the pre-training process.
ered (Dai et al., 2020; Metke-Jimenez and Karimi,          Clark et al. (2018); Peters et al. (2018); Akbik et al.
2016; Tang et al., 2018).                                  (2019); StrakovaÃÅ et al. (2019) assigned a label to
                                                           each token, and Li et al. (2020b); Yu et al. (2020)
4.2   Experiment Setup                                     are based on span-level classifications, while our
                                                           method is based on the entity sequence generation.
We use the BART-Large model, whose encoder                 And for both datasets, our method achieves better
and decoder each has 12 layers for all experiments,        performance. We will discuss the performance dif-
making it the same number of transformer layers as         ference between our three entity representations in
the BERT-Large and RoBERTa-Large model. We                 Section 5.4.
did not use any other embeddings, and the BART
model is fine-tuned during the optimization. We            5.2     Results on Nested NER
put more detailed experimental settings in the Sup-        Table 2 presents the results for the three nested
plementary Material. We report the span-level F1.          NER datasets, and our proposed BART-based gen-

                                                       5813
                                                    CADEC                 ShARe13               ShARe14
                     Model                      P     R   F           P      R    F         P      R    F
      Metke-Jimenez and Karimi (2016) 64.4 56.5 60.2  -    -    -    -    -    -
             Tang et al. (2018)       67.8 64.9 66.3  -    -    -    -    -    -
          Dai et al. (2020)[ELMo]     68.9 69.0 69.0 80.5 75.0 77.7 78.1 81.2 79.6
          Ours(Span)[BART-Large]              71.55 68.59 70.04 80.42 78.15 79.27 76.85 83.59 80.08
          Ours(BPE)[BART-Large]               69.45 70.51 69.97 82.07 76.45 79.16 75.88 84.37 79.90
          Ours(Word)[BART-Large]              70.08 71.21 70.64 82.09 77.42 79.69 77.2 83.75 80.34

                                 Table 3: Results for discontinuous NER datasets.


    Entity           Flat NER             Nested NER         Discontinuous NER
 Representation CoNLL2003 OntoNotes ACE2004 ACE2005 Genia CADEC ShARe13 ShARe14
      Span           3.0/3.0       3.0/3.0      3.0/3.0     3.0/3.0 3.0/3.0 3.17/3.0 3.15/3.0              3.2/3.0
      BPE            3.55/3.0      3.39/3.0     4.15/3.0    3.84/3.0 5.21/5.0 4.08/4.0 3.92/3.0           4.34/4.0
      Word           2.44/2.0      2.86/2.0     3.53/2.0    3.26/2.0 3.09/3.0 2.72/3.0 2.63/3.0           3.74/3.0

Table 4: The average (before /) and median entity length (including the entity label) for each entity representations
in the respective testing set.


erative models are comparable to the token-level             average entity length in CoNLL2003, OntoNotes,
classication (StrakovaÃÅ et al., 2019; Shibuya and            CADEC, ShARe13 achieves better performance
Hovy, 2020) and span-level classification (Luan              in these datasets. However, although the aver-
et al., 2019; Li et al., 2020b; Wang et al., 2020a)          age entity length of the ‚ÄúBPE‚Äù representation is
models.                                                      longer than the ‚ÄúSpan‚Äù representation, it achieves
                                                             better performance in CoNLL2003, OntoNotes,
5.3   Results on Discontinuous NER                          ACE2004, ACE2005, this is because the ‚ÄúBPE‚Äù
Results in Table 3 show the comparison between               representation is more similar to the pre-training
our model and other models in three discontinuous            task, namely, predicting continuous BPEs. And
NER datasets. Although Dai et al. (2020) tried to           we believe this task similarity is also the reason
utilize BERT to enhance the model performance,              why the ‚ÄúWord‚Äù representation (Most of the words
they found that ELMo worked better. In all three            will be tokenized into a single BPE, making the
datasets, our model achieves better performance.            ‚ÄúWord‚Äù representation still continuous.) achieves
                                                             better performance than the ‚ÄúSpan‚Äù representation
5.4   Comparison Between Different Entity                    in ACE2004, ACE2005, and ShARe14, although
      Representations                                        the former has longer entity length.
In this part, we discuss the performance differ-                A clear outlier is the Genia dataset, where the
ence between the three entity representations. The          ‚ÄúSpan‚Äù representation achieves better performance
‚ÄúWord‚Äù entity representation achieves better perfor-         than the other two. We presume this is because
mance almost in all datasets. And the comparison             in this dataset, a word will be tokenized into a
between the ‚ÄúSpan‚Äù and ‚ÄúBPE‚Äù representations is              longer BPE sequence (this can be inferred from the
more involved. To investigate the reason behind              large entity length gap between the ‚ÄúWord‚Äù and
these results, we calculate the average and median          ‚ÄúBPE‚Äù representation.) so that the ‚ÄúWord‚Äù repre-
length of entities when using different entity rep-          sentation will also be dissimilar to the pre-training
resentations, and the results are presented in Table         tasks. For example, the protein ‚Äúlipoxygenase iso-
4. It is clear that for a generative framework, the          forms‚Äù will be tokenized into the sequence ‚Äú[‚ÄòGÃálip‚Äô,
shorter the entity representation the better perfor-        ‚Äòoxy‚Äô, ‚Äògen‚Äô, ‚Äòase‚Äô, ‚ÄòGÃáiso‚Äô, ‚Äòforms‚Äô]‚Äù, which makes
mance it should achieve. Therefore, as shown in              the target sequence of the ‚ÄúWord‚Äù representation be
Table 4, the ‚ÄúWord‚Äù representation with smaller             ‚Äú[‚ÄòGÃálip‚Äô, ‚ÄòGÃáiso‚Äô]‚Äù, resulting a discontiguous BPE

                                                       5814
                              Flat NER            Nested NER          Discontinuous NER
                  Errors CoNLL2003 OntoNotes ACE2004 ACE2005 Genia CADEC ShARe13 ShARe14
                   E1           0.05%              0.02%                   0.23%            0.06%          0.0%         0.31%                 0.0%            0.01%
                   E2           0.04%              0.03%                   0.13%            0.22%         0.11% 1.02%                        0.18%            0.16%
                   E3           0.05%              0.02%                   0.30%            0.26%         0.06%         0.0%                 0.08%            0.02%

Table 5: Different invalid prediction probability for the ‚ÄúWord‚Äù entity representation. E1 means the predicted
indexes contain index which is not the start index of a word, E2 means the predicted indexes within an entity are
not increasing, E3 means duplicated entity prediction.

                                OntoNotes                                                   Genia                                                     ShARe14
             93                                                       80                                                         92
                                                                      78                                                         90
             92
    Recall




                                                             Recall




                                                                                                                        Recall
                                                                                                                                 88
                                                                      76
             91                                                                                                                  86
                                                                      74
                                                                                                                                 84
                                                                      72
             90                                                                                                                  82
                  1(4.6) 2(2.7) 3(1.7) 4(1) 5(0.6) 6+(0.7)                 1(1.6) 2(1.3) 3(1.0) 4(0.7) 5(0.4) 6+(0.5)                 1(4.9) 2(1.7) 3(0.7) 4(0.3) 5(0.1) 6+(0.2)
                         Entity Position(# of Entities)                           Entity Position(# of Entities)                             Entity Position(# of Entities)


Figure 4: The recall of entities in different entity sequence positions, the number of entities in that position is the
number in the bracket (the unit is 1000).


sequence. Therefore, the shorter ‚ÄúSpan‚Äù represen-                                               table shows that the BART model can learn the
tation achieves better performance in this dataset.                                             prediction representations quite well since, in most
                                                                                                cases, the invalid prediction is less than 1%. We
6            Analysis                                                                           exclude all these invalid predictions during evalua-
6.1               Recall of Discontinuous Entities                                              tion.

Since only about 10% of entities in the discontin-                                              6.3     Entity Order Vs. Entity Recall
uous NER datasets are discontinuous, only evalu-
                                                                                               Its appearance order in the sentence determines
ating the whole dataset may not show our model
                                                                                               the entity order, and we want to study whether the
can recognize the discontinuous entities. Therefore,
                                                                                               entity that appears later in the target sequence will
like in Dai et al. (2020); Muis and Lu (2016) we re-
                                                                                               have worse recall than entities that appear early.
port our model‚Äôs performance on the discontinuous
                                                                                               The results are provided in Figure 4. The latter the
entities in Table 6. As shown in Table 6, our model
                                                                                               entity appears, the larger probability that it can be
can predict the discontinuous named entities and
                                                                                               recalled for the flat NER and discontinuous NER.
achieve better performance.
                                                                                               While for the nested NER, the recall curve is quite
                                                                                               involved. We assume this phenomenon is because,
                                      ShARe13                 ShARe14
                                                                                               for the flat NER and discontinuous NER (more than
                  Model              P   R   F               P   R   F
                                                                                               91.1% of entities are continuous) datasets, different
 Dai et al. (2020) 78.5 39.4 52.5 56.1 43.8 49.2                                               entities have less dependence on each other. While
  Ours(Word) 57.5 52.8 55.0 49.6 56.2 52.7                                                     in the nested NER dataset, entities in the latter
                                                                                               position may be the outermost entity that contains
Table 6: Performance on the discontinuous entities of                                          the former entities. The wrong prediction of former
the tesing dataset of ShARe13 and ShARe14.                                                     entities may negatively influence the later entities.

6.2               Invalid Prediction                                                            7     Conclusion
In this part, we mainly focus on the analysis of the                                            In this paper, we formulate NER subtasks as an en-
‚ÄúWord‚Äù representation since it generally achieves                                               tity span sequence generation problem, so that we
better performance. We do not restrict the output                                               can use a unified Seq2Seq model with the pointer
distribution; therefore, the entity prediction may                                              mechanism to tackle flat, nested, and discontinu-
contain invalid predictions as show in Table 5, this                                            ous NER subtasks. The Seq2Seq formulation en-

                                                                                         5815
ables us to smoothly incorporate the pre-training          Beatrice Alex, Barry Haddow, and Claire Grover. 2007.
Seq2Seq model BART to enhance the performance.               Recognising nested named entities in biomedical
                                                             text. In Biological, translational, and clinical
To better utilize BART, we test three types of en-
                                                             language processing, BioNLP@ACL 2007, Prague,
tity representation methods to linearize the entity          Czech Republic, June 29, 2007, pages 65‚Äì72. Asso-
span into sequences. Results show that the entity            ciation for Computational Linguistics.
representation with a shorter length and more sim-
ilar to continuous BPE sequences achieves better           Lingzhen Chen and Alessandro Moschitti. 2018.
                                                             Learning to progressively recognize new named en-
performance. Our proposed method achieves SoTA               tities with sequence to sequence models. In Pro-
or near SoTA performance for eight different NER             ceedings of the 27th International Conference on
datasets, proving its generality to various NER sub-         Computational Linguistics, COLING 2018, Santa
tasks.                                                       Fe, New Mexico, USA, August 20-26, 2018, pages
                                                             2181‚Äì2191. Association for Computational Linguis-
                                                             tics.
Acknowledgements
                                                           Jason P. C. Chiu and Eric Nichols. 2016. Named en-
We would like to thank the anonymous reviewers                tity recognition with bidirectional lstm-cnns. Trans.
for their insightful comments. The discussion with            Assoc. Comput. Linguistics, 4:357‚Äì370.
colleagues in AWS Shanghai AI Lab was quite
fruitful. We also thank the developers of fastNLP10        Kyunghyun Cho, Bart van Merrienboer, CÃßaglar
                                                             GuÃàlcÃßehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
and fitlog11 . We thank Juntao Yu for helpful discus-
                                                             ger Schwenk, and Yoshua Bengio. 2014. Learning
sion about dataset processing. This work was sup-            phrase representations using RNN encoder-decoder
ported by the National Key Research and Develop-             for statistical machine translation. In Proceedings of
ment Program of China (No. 2020AAA0106700)                   the 2014 Conference on Empirical Methods in Nat-
and National Natural Science Foundation of China             ural Language Processing, EMNLP 2014, October
                                                             25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a
(No. 62022027).                                              Special Interest Group of the ACL, pages 1724‚Äì1734.
                                                             ACL.
Ethical Considerations
                                                           Kevin Clark, Minh-Thang Luong, Christopher D. Man-
For the consideration of ethical concerns, we would          ning, and Quoc V. Le. 2018. Semi-supervised se-
make detailed description as following:                      quence modeling with cross-view training. In Pro-
   (1) All of the experiments are conducted on ex-           ceedings of the 2018 Conference on Empirical Meth-
                                                             ods in Natural Language Processing, Brussels, Bel-
isting datasets, which are derived from public sci-
                                                             gium, October 31 - November 4, 2018, pages 1914‚Äì
entific papers.                                              1925. Association for Computational Linguistics.
   (2) We describe the characteristics of the datasets
in a specific section. Our analysis is consistent with     Ronan Collobert, Jason Weston, LeÃÅon Bottou, Michael
                                                             Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa.
the results.
                                                             2011. Natural language processing (almost) from
   (3) Our work does not contain identity character-         scratch. J. Mach. Learn. Res., 12:2493‚Äì2537.
istics. It does not harm anyone.
   (4) Our experiments do not need a lots of com-          Junqi Dai, Hang Yan, Tianxiang Sun, Pengfei Liu, and
puter resources compared to pre-trained models.              Xipeng Qiu. 2021. Does syntax matter? A strong
                                                             baseline for aspect-based sentiment analysis with
                                                             roberta. CoRR, abs/2104.04986.
References                                                 Xiang Dai, Sarvnaz Karimi, Ben Hachey, and CeÃÅcile
Alan Akbik, Tanja Bergmann, and Roland Vollgraf.             Paris. 2020. An effective transition-based model for
  2019. Pooled contextualized embeddings for named           discontinuous NER. In Proceedings of the 58th An-
  entity recognition. In Proceedings of the 2019 Con-        nual Meeting of the Association for Computational
  ference of the North American Chapter of the Asso-         Linguistics, ACL 2020, Online, July 5-10, 2020,
  ciation for Computational Linguistics: Human Lan-          pages 5860‚Äì5870. Association for Computational
  guage Technologies, NAACL-HLT 2019, Minneapo-              Linguistics.
  lis, MN, USA, June 2-7, 2019, Volume 1 (Long and
  Short Papers), pages 724‚Äì728. Association for Com-       Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
  putational Linguistics.                                     Kristina Toutanova. 2019. BERT: pre-training of
                                                              deep bidirectional transformers for language under-
   10
      https://github.com/fastnlp/fastNLP.                     standing. In Proceedings of the 2019 Conference
FastNLP is a natural language processing python package.      of the North American Chapter of the Association
   11                                                         for Computational Linguistics: Human Language
      https://github.com/fastnlp/fitlog. Fit-
log is an experiment tracking package.                       Technologies, NAACL-HLT 2019, Minneapolis, MN,

                                                       5816
  USA, June 2-7, 2019, Volume 1 (Long and Short Pa-        Sarvnaz Karimi, Alejandro Metke-Jimenez, Madonna
  pers), pages 4171‚Äì4186. Association for Computa-           Kemp, and Chen Wang. 2015. Cadec: A corpus of
  tional Linguistics.                                        adverse drug event annotations. J. Biomed. Infor-
                                                             matics, 55:73‚Äì81.
George R. Doddington, Alexis Mitchell, Mark A. Przy-
  bocki, Lance A. Ramshaw, Stephanie M. Strassel,          Arzoo Katiyar and Claire Cardie. 2018. Nested named
  and Ralph M. Weischedel. 2004. The automatic con-          entity recognition revisited. In Proceedings of the
  tent extraction (ACE) program - tasks, data, and eval-     2018 Conference of the North American Chapter
  uation. In Proceedings of the Fourth International         of the Association for Computational Linguistics:
  Conference on Language Resources and Evaluation,           Human Language Technologies, NAACL-HLT 2018,
  LREC 2004, May 26-28, 2004, Lisbon, Portugal. Eu-          New Orleans, Louisiana, USA, June 1-6, 2018, Vol-
  ropean Language Resources Association.                     ume 1 (Long Papers), pages 861‚Äì871. Association
                                                             for Computational Linguistics.
Jenny Rose Finkel and Christopher D. Manning. 2009.
   Nested named entity recognition. In Proceedings of      Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and
   the 2009 Conference on Empirical Methods in Natu-          Jun‚Äôichi Tsujii. 2003. GENIA corpus - a semanti-
   ral Language Processing, EMNLP 2009, 6-7 August            cally annotated corpus for bio-textmining. In Pro-
  2009, Singapore, A meeting of SIGDAT, a Special             ceedings of the Eleventh International Conference
  Interest Group of the ACL, pages 141‚Äì150. ACL.              on Intelligent Systems for Molecular Biology, June
                                                              29 - July 3, 2003, Brisbane, Australia, pages 180‚Äì
Joseph Fisher and Andreas Vlachos. 2019. Merge and            182.
   label: A novel neural network architecture for nested
   NER. In Proceedings of the 57th Conference of           John D. Lafferty, Andrew McCallum, and Fernando
   the Association for Computational Linguistics, ACL        C. N. Pereira. 2001. Conditional random fields:
  2019, Florence, Italy, July 28- August 2, 2019, Vol-       Probabilistic models for segmenting and labeling se-
   ume 1: Long Papers, pages 5840‚Äì5850. Association          quence data. In Proceedings of the Eighteenth Inter-
   for Computational Linguistics.                            national Conference on Machine Learning.
Dan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag
                                                           Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
  Subramanya. 2016. Multilingual language process-
                                                             ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
  ing from bytes. In NAACL HLT 2016, The 2016
                                                             Neural architectures for named entity recognition.
  Conference of the North American Chapter of the
                                                             In NAACL HLT 2016, The 2016 Conference of the
  Association for Computational Linguistics: Human
                                                             North American Chapter of the Association for Com-
  Language Technologies, San Diego California, USA,
                                                             putational Linguistics: Human Language Technolo-
  June 12-17, 2016, pages 1296‚Äì1306. The Associa-
                                                             gies, San Diego California, USA, June 12-17, 2016,
  tion for Computational Linguistics.
                                                             pages 260‚Äì270. The Association for Computational
Ralph Grishman and Beth Sundheim. 1996. Mes-                 Linguistics.
  sage understanding conference- 6: A brief history.
  In 16th International Conference on Computational        Mike Lewis, Yinhan Liu, Naman Goyal, Mar-
  Linguistics, Proceedings of the Conference, COL-           jan Ghazvininejad, Abdelrahman Mohamed, Omer
  ING 1996, Center for Sprogteknologi, Copenhagen,           Levy, Veselin Stoyanov, and Luke Zettlemoyer.
  Denmark, August 5-9, 1996, pages 466‚Äì471.                  2020. BART: denoising sequence-to-sequence pre-
                                                             training for natural language generation, translation,
Jiatao Gu, James Bradbury, Caiming Xiong, Vic-               and comprehension. In Proceedings of the 58th An-
   tor O. K. Li, and Richard Socher. 2018. Non-              nual Meeting of the Association for Computational
   autoregressive neural machine translation. In 6th         Linguistics, ACL 2020, Online, July 5-10, 2020,
   International Conference on Learning Representa-          pages 7871‚Äì7880. Association for Computational
   tions, ICLR 2018, Vancouver, BC, Canada, April 30         Linguistics.
   - May 3, 2018, Conference Track Proceedings. Open-
   Review.net.                                             Xiaonan Li, Hang Yan, Xipeng Qiu, and Xuanjing
                                                             Huang. 2020a. FLAT: chinese NER using flat-lattice
Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-               transformer. In Proceedings of the 58th Annual
  rectional LSTM-CRF models for sequence tagging.            Meeting of the Association for Computational Lin-
  CoRR, abs/1508.01991.                                      guistics, ACL 2020, Online, July 5-10, 2020, pages
                                                             6836‚Äì6842. Association for Computational Linguis-
Meizhi Ju, Makoto Miwa, and Sophia Ananiadou.                tics.
 2018. A neural layered model for nested named en-
 tity recognition. In Proceedings of the 2018 Confer-      Xiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong
 ence of the North American Chapter of the Associ-           Han, Fei Wu, and Jiwei Li. 2020b. A unified MRC
 ation for Computational Linguistics: Human Lan-             framework for named entity recognition. In Pro-
 guage Technologies, NAACL-HLT 2018, New Or-                 ceedings of the 58th Annual Meeting of the Associ-
 leans, Louisiana, USA, June 1-6, 2018, Volume 1             ation for Computational Linguistics, ACL 2020, On-
 (Long Papers), pages 1446‚Äì1459. Association for             line, July 5-10, 2020, pages 5849‚Äì5859. Association
 Computational Linguistics.                                  for Computational Linguistics.

                                                      5817
Hongyu Lin, Yaojie Lu, Xianpei Han, and Le Sun.             Pradhan, Guergana K. Savova, and Wendy W. Chap-
  2019. Sequence-to-nuggets: Nested entity men-             man. 2014. Task 2: Share/clef ehealth evaluation
  tion detection via anchor-region networks. In Pro-        lab 2014. In Working Notes for CLEF 2014 Confer-
  ceedings of the 57th Conference of the Association        ence, Sheffield, UK, September 15-18, 2014, volume
  for Computational Linguistics, ACL 2019, Florence,        1180 of CEUR Workshop Proceedings, pages 31‚Äì42.
  Italy, July 28- August 2, 2019, Volume 1: Long Pa-        CEUR-WS.org.
  pers, pages 5182‚Äì5192. Association for Computa-
  tional Linguistics.                                    Aldrian Obaja Muis and Wei Lu. 2016. Learning to rec-
                                                           ognize discontiguous entities. In Proceedings of the
Wei Lu and Dan Roth. 2015. Joint mention extraction        2016 Conference on Empirical Methods in Natural
  and classification with mention hypergraphs. In Pro-     Language Processing, EMNLP 2016, Austin, Texas,
  ceedings of the 2015 Conference on Empirical Meth-       USA, November 1-4, 2016, pages 75‚Äì84. The Asso-
  ods in Natural Language Processing, EMNLP 2015,          ciation for Computational Linguistics.
 Lisbon, Portugal, September 17-21, 2015, pages          Aldrian Obaja Muis and Wei Lu. 2017. Labeling gaps
  857‚Äì867. The Association for Computational Lin-          between words: Recognizing overlapping mentions
  guistics.                                                with mention separators. In Proceedings of the 2017
                                                           Conference on Empirical Methods in Natural Lan-
Yi Luan, Dave Wadden, Luheng He, Amy Shah, Mari            guage Processing, EMNLP 2017, Copenhagen, Den-
   Ostendorf, and Hannaneh Hajishirzi. 2019. A gen-        mark, September 9-11, 2017, pages 2608‚Äì2618. As-
   eral framework for information extraction using dy-     sociation for Computational Linguistics.
   namic span graphs. In Proceedings of the 2019 Con-
   ference of the North American Chapter of the Asso-    Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt
   ciation for Computational Linguistics: Human Lan-      Gardner, Christopher Clark, Kenton Lee, and Luke
   guage Technologies, NAACL-HLT 2019, Minneapo-          Zettlemoyer. 2018. Deep contextualized word rep-
   lis, MN, USA, June 2-7, 2019, Volume 1 (Long and       resentations. In Proceedings of the 2018 Confer-
  Short Papers), pages 3036‚Äì3046. Association for         ence of the North American Chapter of the Associ-
   Computational Linguistics.                             ation for Computational Linguistics: Human Lan-
                                                          guage Technologies, NAACL-HLT 2018, New Or-
Ying Luo and Hai Zhao. 2020. Bipartite flat-graph net-    leans, Louisiana, USA, June 1-6, 2018, Volume 1
  work for nested named entity recognition. In Pro-       (Long Papers), pages 2227‚Äì2237. Association for
  ceedings of the 58th Annual Meeting of the Associ-      Computational Linguistics.
  ation for Computational Linguistics, ACL 2020, On-
  line, July 5-10, 2020, pages 6408‚Äì6418. Association    Sameer Pradhan, NoeÃÅmie Elhadad, Brett R. South,
  for Computational Linguistics.                           David Martƒ±ÃÅnez, Lee M. Christensen, Amy Vogel,
                                                           Hanna Suominen, Wendy W. Chapman, and Guer-
Thang Luong, Hieu Pham, and Christopher D. Man-            gana K. Savova. 2013a. Task 1: Share/clef ehealth
  ning. 2015. Effective approaches to attention-based      evaluation lab 2013. In Working Notes for CLEF
  neural machine translation. In Proceedings of the        2013 Conference , Valencia, Spain, September 23-
  2015 Conference on Empirical Methods in Natural          26, 2013, volume 1179 of CEUR Workshop Proceed-
  Language Processing, EMNLP 2015, Lisbon, Portu-          ings. CEUR-WS.org.
  gal, September 17-21, 2015, pages 1412‚Äì1421. The
  Association for Computational Linguistics.             Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
                                                           Hwee Tou Ng, Anders BjoÃàrkelund, Olga Uryupina,
Andrew McCallum and Wei Li. 2003. Early results for        Yuchen Zhang, and Zhi Zhong. 2013b. Towards
  named entity recognition with conditional random         robust linguistic analysis using ontonotes. In Pro-
  fields, feature induction and web-enhanced lexicons.     ceedings of the Seventeenth Conference on Compu-
  In Proceedings of the Seventh Conference on Natu-        tational Natural Language Learning, CoNLL 2013,
  ral Language Learning, CoNLL 2003, Held in coop-         Sofia, Bulgaria, August 8-9, 2013, pages 143‚Äì152.
  eration with HLT-NAACL 2003, Edmonton, Canada,           ACL.
  May 31 - June 1, 2003, pages 188‚Äì191. ACL.             Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
                                                           Olga Uryupina, and Yuchen Zhang. 2012. Conll-
Alejandro Metke-Jimenez and Sarvnaz Karimi. 2016.          2012 shared task: Modeling multilingual unre-
  Concept identification and normalisation for adverse     stricted coreference in ontonotes. In Joint Con-
  drug event discovery in medical forums. In Proceed-      ference on Empirical Methods in Natural Lan-
  ings of the First International Workshop on Biomed-      guage Processing and Computational Natural Lan-
  ical Data Integration and Discovery (BMDID 2016)         guage Learning - Proceedings of the Shared Task:
  co-located with The 15th International Semantic          Modeling Multilingual Unrestricted Coreference in
  Web Conference (ISWC 2016), Kobe, Japan, Octo-           OntoNotes, EMNLP-CoNLL 2012, July 13, 2012,
  ber 17, 2016, volume 1709 of CEUR Workshop Pro-          Jeju Island, Korea, pages 1‚Äì40. ACL.
  ceedings. CEUR-WS.org.
                                                         Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao,
Danielle L. Mowery, Sumithra Velupillai, Brett R.          Ning Dai, and Xuanjing Huang. 2020. Pre-trained
  South, Lee M. Christensen, David Martƒ±ÃÅnez, Liadh        models for natural language processing: A survey.
  Kelly, Lorraine Goeuriot, NoeÃÅmie Elhadad, Sameer        CoRR, abs/2003.08271.

                                                     5818
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine           Empirical Methods in Natural Language Process-
  Lee, Sharan Narang, Michael Matena, Yanqi Zhou,             ing, EMNLP 2020, Online, November 16-20, 2020,
  Wei Li, and Peter J. Liu. 2020. Exploring the limits        pages 2771‚Äì2785. Association for Computational
  of transfer learning with a unified text-to-text trans-     Linguistics.
  former. J. Mach. Learn. Res., 21:140:1‚Äì140:67.
                                                            Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly.
Lev-Arie Ratinov and Dan Roth. 2009. Design chal-             2015. Pointer networks. In Advances in Neural
  lenges and misconceptions in named entity recog-            Information Processing Systems 28: Annual Con-
  nition. In Proceedings of the Thirteenth Confer-            ference on Neural Information Processing Systems
  ence on Computational Natural Language Learning,            2015, December 7-12, 2015, Montreal, Quebec,
  CoNLL 2009, Boulder, Colorado, USA, June 4-5,               Canada, pages 2692‚Äì2700.
  2009, pages 147‚Äì155. ACL.
                                                            C. Walker and Linguistic Data Consortium. 2005. ACE
Erik F. Tjong Kim Sang and Fien De Meulder.                    2005 Multilingual Training Corpus. LDC corpora.
   2003. Introduction to the conll-2003 shared task:           Linguistic Data Consortium.
   Language-independent named entity recognition. In
  Proceedings of the Seventh Conference on Natural          Bailin Wang and Wei Lu. 2018. Neural segmental hy-
  Language Learning, CoNLL 2003, Held in cooper-              pergraphs for overlapping mention recognition. In
   ation with HLT-NAACL 2003, Edmonton, Canada,               Proceedings of the 2018 Conference on Empirical
  May 31 - June 1, 2003, pages 142‚Äì147. ACL.                  Methods in Natural Language Processing, Brussels,
                                                              Belgium, October 31 - November 4, 2018, pages
Takashi Shibuya and Eduard H. Hovy. 2020. Nested              204‚Äì214. Association for Computational Linguis-
  named entity recognition via second-best sequence           tics.
  learning and decoding. Trans. Assoc. Comput. Lin-
  guistics, 8:605‚Äì620.                                      Bailin Wang and Wei Lu. 2019. Combining spans
                                                              into entities: A neural two-stage approach for rec-
Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-           ognizing discontiguous entities. In Proceedings of
  Yan Liu. 2019. MASS: masked sequence to se-                 the 2019 Conference on Empirical Methods in Nat-
  quence pre-training for language generation. In Pro-        ural Language Processing and the 9th International
  ceedings of the 36th International Conference on            Joint Conference on Natural Language Processing,
  Machine Learning, ICML 2019, 9-15 June 2019,                EMNLP-IJCNLP 2019, Hong Kong, China, Novem-
  Long Beach, California, USA, volume 97 of Pro-              ber 3-7, 2019, pages 6215‚Äì6223. Association for
  ceedings of Machine Learning Research, pages                Computational Linguistics.
  5926‚Äì5936. PMLR.
                                                            Jue Wang, Lidan Shou, Ke Chen, and Gang Chen.
Jana StrakovaÃÅ, Milan Straka, and Jan Hajic. 2019. Neu-       2020a. Pyramid: A layered model for nested named
   ral architectures for nested NER through lineariza-        entity recognition. In Proceedings of the 58th An-
   tion. In Proceedings of the 57th Conference of             nual Meeting of the Association for Computational
   the Association for Computational Linguistics, ACL         Linguistics, ACL 2020, Online, July 5-10, 2020,
  2019, Florence, Italy, July 28- August 2, 2019, Vol-        pages 5918‚Äì5928. Association for Computational
   ume 1: Long Papers, pages 5326‚Äì5331. Association           Linguistics.
   for Computational Linguistics.
                                                            Yu Wang, Yun Li, Hanghang Tong, and Ziye Zhu.
Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.          2020b. HIT: nested named entity recognition via
   Sequence to sequence learning with neural networks.        head-tail pair and token interaction. In Proceed-
   In Advances in Neural Information Processing Sys-          ings of the 2020 Conference on Empirical Methods
   tems 27: Annual Conference on Neural Informa-              in Natural Language Processing, EMNLP 2020, On-
   tion Processing Systems 2014, December 8-13 2014,          line, November 16-20, 2020, pages 6027‚Äì6036. As-
   Montreal, Quebec, Canada, pages 3104‚Äì3112.                 sociation for Computational Linguistics.

Buzhou Tang, Jianglu Hu, Xiaolong Wang, and Qing-           Yu Wang, Yun Li, Ziye Zhu, Bin Xia, and Zheng
  cai Chen. 2018. Recognizing continuous and dis-             Liu. 2019.     SC-NER: A sequence-to-sequence
  continuous adverse drug reaction mentions from so-          model with sentence classification for named entity
  cial media using LSTM-CRF. Wirel. Commun. Mob.              recognition. In Advances in Knowledge Discovery
  Comput., 2018.                                              and Data Mining - 23rd Pacific-Asia Conference,
                                                              PAKDD 2019, Macau, China, April 14-17, 2019,
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob              Proceedings, Part I, volume 11439 of Lecture Notes
  Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz               in Computer Science, pages 198‚Äì209. Springer.
  Kaiser, and Illia Polosukhin. 2017. Attention is all
  you need. In Advances in Neural Information Pro-          Mingbin Xu, Hui Jiang, and Sedtawut Watcharawit-
  cessing Systems, pages 5998‚Äì6008.                           tayakul. 2017. A local detection approach for named
                                                              entity recognition and mention detection. In Pro-
David Vilares and Carlos GoÃÅmez-Rodrƒ±ÃÅguez. 2020.             ceedings of the 55th Annual Meeting of the Associa-
  Discontinuous constituent parsing as sequence la-           tion for Computational Linguistics, ACL 2017, Van-
  beling. In Proceedings of the 2020 Conference on            couver, Canada, July 30 - August 4, Volume 1: Long

                                                       5819
  Papers, pages 1237‚Äì1247. Association for Computa-
  tional Linguistics.
Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki
  Takeda, and Yuji Matsumoto. 2020. LUKE: deep
   contextualized entity representations with entity-
   aware self-attention. In Proceedings of the 2020
  Conference on Empirical Methods in Natural Lan-
   guage Processing, EMNLP 2020, Online, Novem-
   ber 16-20, 2020, pages 6442‚Äì6454. Association for
   Computational Linguistics.
Hang Yan, Bocao Deng, Xiaonan Li, and Xipeng Qiu.
  2019. TENER: adapting transformer encoder for
  named entity recognition. CoRR, abs/1911.04474.
Hang Yan, Xipeng Qiu, and Xuanjing Huang. 2020. A
  graph-based model for joint chinese word segmenta-
  tion and dependency parsing. Trans. Assoc. Comput.
  Linguistics, 8:78‚Äì92.
Juntao Yu, Bernd Bohnet, and Massimo Poesio. 2020.
  Named entity recognition as dependency parsing. In
  Proceedings of the 58th Annual Meeting of the As-
  sociation for Computational Linguistics, ACL 2020,
  Online, July 5-10, 2020, pages 6470‚Äì6476. Associa-
  tion for Computational Linguistics.
Yuan Zhang, Hongshen Chen, Yihong Zhao, Qun Liu,
  and Dawei Yin. 2018. Learning tag dependencies
  for sequence tagging. In Proceedings of the Twenty-
  Seventh International Joint Conference on Artificial
  Intelligence, IJCAI 2018, July 13-19, 2018, Stock-
  holm, Sweden, pages 4581‚Äì4587. ijcai.org.

Changmeng Zheng, Yi Cai, Jingyun Xu, Ho-fung Le-
  ung, and Guandong Xu. 2019. A boundary-aware
  neural model for nested named entity recognition.
  In Proceedings of the 2019 Conference on Empiri-
  cal Methods in Natural Language Processing and
  the 9th International Joint Conference on Natural
  Language Processing, EMNLP-IJCNLP 2019, Hong
  Kong, China, November 3-7, 2019, pages 357‚Äì366.
  Association for Computational Linguistics.




                                                     5820
                                                                                         OntoNotes
A     Supplemental Material
                                                                         89.49

A.1    Hyper-parameters                                                  89.48

The detailed hyper-parameter used in different




                                                                    F1
                                                                         89.47
datasets are listed in Table 7. We use the slanted
                                                                         89.46
triangular learning rate warmup. All experiments
are conducted in the Nvidia Ge-Force RTX-3090                            89.45
                                                                                 1   2    3     4    5   6
Graphical Card with 24G graphical memory.                                                Beam Size
                                                                                         ACE2004

                                                                         86.67
 Hyper            Value
                                                                         86.66
 Epoch            30




                                                                    F1
 Warmup step      0.01                                                   86.65


 Learning rate    [1e-5,2e-5,4e-5]                                       86.64

 Batch size       16                                                     86.63
 BART             Large                                                          1   2    3     4    5   6
                                                                                         Beam Size
 Œ±                0.5                                                                    ShARe13
 Beam size        [1, 4]                                                 76.40

                                                                         76.20

                                                                         76.00
Table 7: Hyper-parameters used for CoNLL2003,
                                                                         75.80
OntoNotes, ACE2004, ACE2005, Genia, CADEC,


                                                                    F1
                                                                         75.60
ShARe13, ShARe14.
                                                                         75.40

                                                                         75.20

A.2    Beam Search                                                               1   2    3     4
                                                                                         Beam Size
                                                                                                     5   6


Since our framework is based on generation, we
                                                       Figure 5: The F1 change curve with the increment of
want to study whether using beam search will in-
                                                       beam size. The beam size has limited effect on the F1
crease the performance, results are depicted in Fig-   score.
ure 5, it shows the beam search almost has no effect
on the model performance. The litte effect on the
F1 value might be caused the the small searching       where Wa ‚àà Rd√ó|T | and |T | is the number of tags,
space when generating.                                 ba ‚àà R|T | , Wb ‚àà Rd√ód , bb ‚àà Rd , F ‚àà Rn√ó|T |
                                                       is the tag probability distribution. Then we use
A.3    Efficiency Metrics                              the negative log likelihood loss. And during the
In this section, we compare the memory footprint,      inference, for each token, the tag index with the
training and inference time of our proposed model      largest probability is deemed as the prediction.
and BERT-based models. The experiments are                For the BERT-CRF model, we use the condi-
conducted on the flat NER datasets, CoNLL-2003         tional random fields (CRF) (Lafferty et al., 2001)
(Sang and Meulder, 2003) and OntoNotes (Pradhan        to decode tags. We assue the golden label sequence
et al., 2012). We use the BERT-MLP and BERT-           is Y = [y1 , ..., yn ], then we use the following equa-
CRF models as our baseline models. BERT-MLP            tions to get the probability of Y
and BERT-CRF are sequence labelling based mod-
                                                                M = max(HWb + bb , 0)Wa + ba                 (12)
els. For an input sentence X = [x1 , ..., xn ], both
models use BERT (Devlin et al., 2019) to encode                 M = log softmax(M)                (13)
                                                                        Pn M[i,yi ]+T[yi‚àí1 ,yi ]
X as follows                                                                  e
                                                          P (Y |X) = PY(s)i=1
                                                                           Pn M[i,y0 ]+T[y0 ,y0 ] ,
                                                                              i=1 e
                                                                                     i      i‚àí1 i
                 H = BERT(X)                   (10)                    y0
                                                                                                  (14)
where H ‚àà Rn√ód , d is the hidden state dimension.
   Then for the BERT-MLP model, it decodes the         where M ‚àà Rn√ó|T | , Y(s) is all valid label se-
tags as follows                                        quences, T ‚àà R|T |√ó|T | is the transitation matrix, an
                                                       entry (i, j) in T means the transition score from tag
    F = Softmax(max(HWb + bb , 0)Wa + ba )             i to tag j. After getting the P (Y |X), we use nega-
                                        (11)           tive log likelihood loss to optimize the model. Dur-

                                                   5821
             Dataset      Model                   Memory      Training Time     Evaluation Time
                          BERT-MLP                    7G           98s                 3s
          CoNLL-2003      BERT-CRF                    7G           122s                5s
                          Ours(Word)[BART]            8G           115s                12s
                          BERT-MLP                    7G           421s                 9s
           OntoNotes      BERT-CRF                    7G           523s                13s
                          Ours(Word)[BART]            7G           493s                38s

   Table 8: The training memory usage, training time and evaluation time comparison between three models.


ing the inference, the Viterbi Algorithm is used to
find the label sequence achieves the highest score.
   We use the BERT-base version and BART-base
version to calculate the memory footprint during
training, seconds needed to iterate one epoch (one
epoch means iterating over all training samples),
and seconds needed to evaluate the development
set. The batch size is 16 and 48 for training and
evaluation, respectively. The comparison is pre-
sented in Table 8.
   During the training phase, we can use the casual
mask to make the training of our model in paral-
lel. Therefore, our proposed model can train faster
than the BERT-CRF model, which needs sequential
computation. While during the evaluating phase,
we have to autoregressively generate tokens, which
will make the inference slow. Therefore, further
work like the usage of a non-autoregressive method
can be studied to speed up the decoding (Gu et al.,
2018).




                                                   5822
                                                                                                                     Bioinformatics, 2019, 1‚Äì7
                                                                                                            doi: 10.1093/bioinformatics/btz682
                                                                                    Advance Access Publication Date: 10 September 2019
                                                                                                                         Original Paper




                                                                                                                                                                      Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
Data and text mining
BioBERT: a pre-trained biomedical language
representation model for biomedical text mining
                             1,‚Ä†
Jinhyuk Lee                       , Wonjin Yoon 1,‚Ä†, Sungdong Kim                                            2
                                                                                                              , Donghyeon Kim                    1
                                                                                                                                                  ,
                              1
Sunkyu Kim                      , Chan Ho So 3 and Jaewoo Kang                                             1,3,
                                                                                                               *
1
 Department of Computer Science and Engineering, Korea University, Seoul 02841, Korea, 2Clova AI Research, Naver Corp, Seong-
Nam 13561, Korea and 3Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul 02841, Korea
*To whom correspondence should be addressed.
‚Ä†
 The authors wish it to be known that the first two authors contributed equally.
Associate Editor: Jonathan Wren
Received on May 16, 2019; revised on July 29, 2019; editorial decision on August 25, 2019; accepted on September 5, 2019


Abstract
Motivation: Biomedical text mining is becoming increasingly important as the number of biomedical documents
rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from bio-
medical literature has gained popularity among researchers, and deep learning has boosted the development of ef-
fective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text min-
ing often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical
corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted
for biomedical corpora.
Results: We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text
Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora.
With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art
models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains
performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the
following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score
improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering
(12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to
understand complex biomedical texts.
Availability and implementation: We make the pre-trained weights of BioBERT freely available at https://github.
com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/
biobert.
Contact: kangj@korea.ac.kr



1 Introduction                                                                              Recent progress of biomedical text mining models was made
The volume of biomedical literature continues to rapidly increase.                      possible by the advancements of deep learning techniques used in
On average, more than 3000 new articles are published every day in                      natural language processing (NLP). For instance, Long Short-Term
peer-reviewed journals, excluding pre-prints and technical reports                      Memory (LSTM) and Conditional Random Field (CRF) have greatly
such as clinical trial reports in various archives. PubMed alone has a                  improved performance in biomedical named entity recognition
total of 29M articles as of January 2019. Reports containing valu-                      (NER) over the last few years (Giorgi and Bader, 2018; Habibi
able information about new discoveries and new insights are con-                        et al., 2017; Wang et al., 2018; Yoon et al., 2019). Other deep learn-
tinuously added to the already overwhelming amount of literature.                       ing based models have made improvements in biomedical text min-
Consequently, there is increasingly more demand for accurate bio-                       ing tasks such as relation extraction (RE) (Bhasuran and Natarajan,
medical text mining tools for extracting information from the                           2018; Lim and Kang, 2018) and question answering (QA) (Wiese
literature.                                                                             et al., 2017).




C The Author(s) 2019. Published by Oxford University Press.
V                                                                                                                                                                1
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits
unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.
2                                                                                                                                       J.Lee et al.


    However, directly applying state-of-the-art NLP methodologies            ‚Ä¢   Compared with most previous biomedical text mining models
to biomedical text mining has limitations. First, as recent word rep-            that are mainly focused on a single task such as NER or QA, our
resentation models such as Word2Vec (Mikolov et al., 2013), ELMo                 model BioBERT achieves state-of-the-art performance on various
(Peters et al., 2018) and BERT (Devlin et al., 2019) are trained and
                                                                                 biomedical text mining tasks, while requiring only minimal
tested mainly on datasets containing general domain texts (e.g.
Wikipedia), it is difficult to estimate their performance on datasets            architectural modifications.
                                                                             ‚Ä¢   We make our pre-processed datasets, the pre-trained weights of
containing biomedical texts. Also, the word distributions of general




                                                                                                                                                       Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
and biomedical corpora are quite different, which can often be a                 BioBERT and the source code for fine-tuning BioBERT publicly
problem for biomedical text mining models. As a result, recent mod-              available.
els in biomedical text mining rely largely on adapted versions of
word representations (Habibi et al., 2017; Pyysalo et al., 2013).
    In this study, we hypothesize that current state-of-the-art word         3 Materials and methods
representation models such as BERT need to be trained on biomed-
ical corpora to be effective in biomedical text mining tasks.                BioBERT basically has the same structure as BERT. We briefly dis-
Previously, Word2Vec, which is one of the most widely known con-             cuss the recently proposed BERT, and then we describe in detail the
text independent word representation models, was trained on bio-             pre-training and fine-tuning process of BioBERT.
medical corpora which contain terms and expressions that are
usually not included in a general domain corpus (Pyysalo et al.,
                                                                             3.1 BERT: bidirectional encoder representations from
2013). While ELMo and BERT have proven the effectiveness of con-
textualized word representations, they cannot obtain high perform-           transformers
ance on biomedical corpora because they are pre-trained on only              Learning word representations from a large amount of unannotated
general domain corpora. As BERT achieves very strong results on              text is a long-established method. While previous models (e.g.
various NLP tasks while using almost the same structure across the           Word2Vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014))
tasks, adapting BERT for the biomedical domain could potentially             focused on learning context independent word representations, re-
benefit numerous biomedical NLP researches.                                  cent works have focused on learning context dependent word repre-
                                                                             sentations. For instance, ELMo (Peters et al., 2018) uses a
                                                                             bidirectional language model, while CoVe (McCann et al., 2017)
2 Approach                                                                   uses machine translation to embed context information into word
                                                                             representations.
In this article, we introduce BioBERT, which is a pre-trained language           BERT (Devlin et al., 2019) is a contextualized word representa-
representation model for the biomedical domain. The overall process          tion model that is based on a masked language model and pre-
of pre-training and fine-tuning BioBERT is illustrated in Figure 1. First,   trained using bidirectional transformers (Vaswani et al., 2017). Due
we initialize BioBERT with weights from BERT, which was pre-                 to the nature of language modeling where future words cannot be
trained on general domain corpora (English Wikipedia and                     seen, previous language models were limited to a combination of
BooksCorpus). Then, BioBERT is pre-trained on biomedical domain              two unidirectional language models (i.e. left-to-right and right-to-
corpora (PubMed abstracts and PMC full-text articles). To show the ef-       left). BERT uses a masked language model that predicts randomly
fectiveness of our approach in biomedical text mining, BioBERT is            masked words in a sequence, and hence can be used for learning bi-
fine-tuned and evaluated on three popular biomedical text mining tasks       directional representations. Also, it obtains state-of-the-art perform-
(NER, RE and QA). We test various pre-training strategies with differ-       ance on most NLP tasks, while requiring minimal task-specific
ent combinations and sizes of general domain corpora and biomedical          architectural modification. According to the authors of BERT,
corpora, and analyze the effect of each corpus on pre-training. We also      incorporating information from bidirectional representations, rather
provide in-depth analyses of BERT and BioBERT to show the necessity          than unidirectional representations, is crucial for representing words
of our pre-training strategies.                                              in natural language. We hypothesize that such bidirectional repre-
    The contributions of our paper are as follows:                           sentations are also critical in biomedical text mining as complex
                                                                             relationships between biomedical terms often exist in a biomedical
‚Ä¢   BioBERT is the first domain-specific BERT based model pre-               corpus (Krallinger et al., 2017). Due to the space limitations, we
    trained on biomedical corpora for 23 days on eight NVIDIA                refer readers to Devlin et al. (2019) for a more detailed description
    V100 GPUs.                                                               of BERT.
‚Ä¢   We show that pre-training BERT on biomedical corpora largely
    improves its performance. BioBERT obtains higher F1 scores in            3.2 Pre-training BioBERT
    biomedical NER (0.62) and biomedical RE (2.80), and a higher             As a general purpose language representation model, BERT was pre-
    MRR score (12.24) in biomedical QA than the current state-of-            trained on English Wikipedia and BooksCorpus. However, biomed-
    the-art models.                                                          ical domain texts contain a considerable number of domain-specific




Fig. 1. Overview of the pre-training and fine-tuning of BioBERT
BioBERT                                                                                                                                         3


Table 1. List of text corpora used for BioBERT                            Table 2. Pre-training BioBERT on different combinations of the fol-
                                                                          lowing text corpora: English Wikipedia (Wiki), BooksCorpus
Corpus                          Number of words             Domain        (Books), PubMed abstracts (PubMed) and PMC full-text articles
                                                                          (PMC)
English Wikipedia                     2.5B                  General
BooksCorpus                           0.8B                  General       Model                                 Corpus combination
PubMed Abstracts                      4.5B                  Biomedical




                                                                                                                                                     Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
PMC Full-text articles               13.5B                  Biomedical    BERT (Devlin et al., 2019)            Wiki √æ Books
                                                                          BioBERT (√æPubMed)                     Wiki √æ Books √æ PubMed
                                                                          BioBERT (√æPMC)                        Wiki √æ Books √æ PMC
proper nouns (e.g. BRCA1, c.248T>C) and terms (e.g. transcrip-            BioBERT (√æPubMed √æ PMC)               Wiki √æ Books √æ PubMed √æ PMC
tional, antimicrobial), which are understood mostly by biomedical
researchers. As a result, NLP models designed for general purpose
language understanding often obtains poor performance in biomed-          (Rajpurkar et al., 2016). We used the BioASQ factoid datasets be-
ical text mining tasks. In this work, we pre-train BioBERT on             cause their format is similar to that of SQuAD. Token level proba-
PubMed abstracts (PubMed) and PubMed Central full-text articles           bilities for the start/end location of answer phrases are computed
(PMC). The text corpora used for pre-training of BioBERT are listed       using a single output layer. However, we observed that about 30%
in Table 1, and the tested combinations of text corpora are listed in     of the BioASQ factoid questions were unanswerable in an extractive
Table 2. For computational efficiency, whenever the Wiki √æ Books          QA setting as the exact answers did not appear in the given pas-
corpora were used for pre-training, we initialized BioBERT with the       sages. Like Wiese et al. (2017), we excluded the samples with un-
pre-trained BERT model provided by Devlin et al. (2019). We define        answerable questions from the training sets. Also, we used the same
BioBERT as a language representation model whose pre-training             pre-training process of Wiese et al. (2017), which uses SQuAD, and
corpora includes biomedical corpora (e.g. BioBERT (√æ PubMed)).            it largely improved the performance of both BERT and BioBERT.
    For tokenization, BioBERT uses WordPiece tokenization (Wu             We used the following evaluation metrics from BioASQ: strict accur-
et al., 2016), which mitigates the out-of-vocabulary issue. With          acy, lenient accuracy and mean reciprocal rank.
WordPiece tokenization, any new words can be represented by fre-
quent subwords (e.g. Immunoglobulin ¬º> I ##mm ##uno ##g ##lo
##bul ##in). We found that using cased vocabulary (not lower-
casing) results in slightly better performances in downstream tasks.
Although we could have constructed new WordPiece vocabulary               4 Results
based on biomedical corpora, we used the original vocabulary of
BERTBASE for the following reasons: (i) compatibility of BioBERT
                                                                          4.1 Datasets
with BERT, which allows BERT pre-trained on general domain cor-           The statistics of biomedical NER datasets are listed in Table 3. We
pora to be re-used, and makes it easier to interchangeably use exist-     used the pre-processed versions of all the NER datasets provided by
ing models based on BERT and BioBERT and (ii) any new words               Wang et al. (2018) except the 2010 i2b2/VA, JNLPBA and Species-
may still be represented and fine-tuned for the biomedical domain         800 datasets. The pre-processed NCBI Disease dataset has fewer
using the original WordPiece vocabulary of BERT.                          annotations than the original dataset due to the removal of duplicate
                                                                          articles from its training set. We used the CoNLL format (https://
                                                                          github.com/spyysalo/standoff2conll) for pre-processing the 2010
3.3 Fine-tuning BioBERT                                                   i2b2/VA and JNLPBA datasets. The Species-800 dataset was pre-
With minimal architectural modification, BioBERT can be applied           processed and split based on the dataset of Pyysalo (https://github.
to various downstream text mining tasks. We fine-tune BioBERT on          com/spyysalo/s800). We did not use alternate annotations for the
the following three representative biomedical text mining tasks:          BC2GM dataset, and all NER evaluations are based on entity-level
NER, RE and QA.                                                           exact matches. Note that although there are several other recently
    Named entity recognition is one of the most fundamental bio-          introduced high quality biomedical NER datasets (Mohan and Li,
medical text mining tasks, which involves recognizing numerous do-        2019), we use datasets that are frequently used by many biomedical
main-specific proper nouns in a biomedical corpus. While most             NLP researchers, which makes it much easier to compare our work
previous works were built upon different combinations of LSTMs            with theirs. The RE datasets contain gene‚Äìdisease relations and pro-
and CRFs (Giorgi and Bader, 2018; Habibi et al., 2017; Wang et al.,       tein‚Äìchemical relations (Table 4). Pre-processed GAD and EU-ADR
2018), BERT has a simple architecture based on bidirectional trans-       datasets are available with our provided codes. For the
formers. BERT uses a single output layer based on the representa-         CHEMPROT dataset, we used the same pre-processing procedure
tions from its last layer to compute only token level BIO2                described in Lim and Kang (2018). We used the BioASQ factoid
probabilities. Note that while previous works in biomedical NER           datasets, which can be converted into the same format as the
often used word embeddings trained on PubMed or PMC corpora               SQuAD dataset (Table 5). We used full abstracts (PMIDs) and
(Habibi et al., 2017; Yoon et al., 2019), BioBERT directly learns         related questions and answers provided by the BioASQ organizers.
WordPiece embeddings during pre-training and fine-tuning. For the         We have made the pre-processed BioASQ datasets publicly avail-
evaluation metrics of NER, we used entity level precision, recall and     able. For all the datasets, we used the same dataset splits used in pre-
F1 score.                                                                 vious works (Lim and Kang, 2018; Tsatsaronis et al., 2015; Wang
    Relation extraction is a task of classifying relations of named       et al., 2018) for a fair evaluation; however, the splits of LINAAEUS
entities in a biomedical corpus. We utilized the sentence classifier of   and Species-800 could not be found from Giorgi and Bader (2018)
the original version of BERT, which uses a [CLS] token for the clas-      and may be different. Like previous work (Bhasuran and Natarajan,
sification of relations. Sentence classification is performed using a     2018), we reported the performance of 10-fold cross-validation on
single output layer based on a [CLS] token representation from            datasets that do not have separate test sets (e.g. GAD, EU-ADR).
BERT. We anonymized target named entities in a sentence using                 We compare BERT and BioBERT with the current state-of-the-
pre-defined tags such as @GENE$ or @DISEASE$. For instance, a             art models and report their scores. Note that the state-of-the-art
sentence with two target entities (gene and disease in this case) is      models each have a different architecture and training procedure.
represented as ‚ÄúSerine at position 986 of @GENE$ may be an inde-          For instance, the state-of-the-art model by Yoon et al. (2019) trained
pendent genetic predictor of angiographic @DISEASE$.‚Äù The preci-          on the JNLPBA dataset is based on multiple Bi-LSTM CRF models
sion, recall and F1 scores on the RE task are reported.                   with character level CNNs, while the state-of-the-art model by
    Question answering is a task of answering questions posed in          Giorgi and Bader (2018) trained on the LINNAEUS dataset uses a
natural language given related passages. To fine-tune BioBERT for         Bi-LSTM CRF model with character level LSTMs and is additional-
QA, we used the same BERT architecture used for SQuAD                     ly trained on silver-standard datasets. On the other hand, BERT and
4                                                                                                                                      J.Lee et al.


Table 3. Statistics of the biomedical named entity recognition               to use BERTLARGE, we used only BERTBASE due to the computational
datasets                                                                     complexity of BERTLARGE.
                                                                                 We used a single NVIDIA Titan Xp (12GB) GPU to fine-tune
Dataset                                    Entity type        Number of      BioBERT on each task. Note that the fine-tuning process is more
                                                              annotations    computationally efficient than pre-training BioBERT. For fine-
                                                                             tuning, a batch size of 10, 16, 32 or 64 was selected, and a learning
NCBI Disease (Dogan et al., 2014)         Disease               6881        rate of 5e5, 3e5 or 1e5 was selected. Fine-tuning BioBERT on




                                                                                                                                                      Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
2010 i2b2/VA (Uzuner et al., 2011)         Disease              19 665       QA and RE tasks took less than an hour as the size of the training
BC5CDR (Li et al., 2016)                   Disease              12 694       data is much smaller than that of the training data used by Devlin
BC5CDR (Li et al., 2016)                   Drug/Chem.           15 411       et al. (2019). On the other hand, it takes more than 20 epochs for
BC4CHEMD (Krallinger et al., 2015)         Drug/Chem.           79 842       BioBERT to reach its highest performance on the NER datasets.
BC2GM (Smith et al., 2008)                 Gene/Protein         20 703
JNLPBA (Kim et al., 2004)                  Gene/Protein         35 460
LINNAEUS (Gerner et al., 2010)             Species               4077        4.3 Experimental results
Species-800 (Pafilis et al., 2013)         Species               3708        The results of NER are shown in Table 6. First, we observe that
                                                                             BERT, which was pre-trained on only the general domain corpus is
  Note: The number of annotations from Habibi et al. (2017) and Zhu et al.   quite effective, but the micro averaged F1 score of BERT was lower
(2018) is provided.                                                          (2.01 lower) than that of the state-of-the-art models. On the other
                                                                             hand, BioBERT achieves higher scores than BERT on all the data-
                                                                             sets. BioBERT outperformed the state-of-the-art models on six out
Table 4. Statistics of the biomedical relation extraction datasets
                                                                             of nine datasets, and BioBERT v1.1 (√æ PubMed) outperformed the
                                                                             state-of-the-art models by 0.62 in terms of micro averaged F1 score.
Dataset                                  Entity type          Number of      The relatively low scores on the LINNAEUS dataset can be attrib-
                                                              relations      uted to the following: (i) the lack of a silver-standard dataset for
                                                                             training previous state-of-the-art models and (ii) different training/
GAD (Bravo et al., 2015)                 Gene‚Äìdisease            5330        test set splits used in previous work (Giorgi and Bader, 2018), which
EU-ADR (Van Mulligen et al., 2012)       Gene‚Äìdisease              355       were unavailable.
CHEMPROT (Krallinger et al., 2017)       Protein‚Äìchemical       10 031           The RE results of each model are shown in Table 7. BERT
                                                                             achieved better performance than the state-of-the-art model on the
   Note: For the CHEMPROT dataset, the number of relations in the train-     CHEMPROT dataset, which demonstrates its effectiveness in RE.
ing, validation and test sets was summed.                                    On average (micro), BioBERT v1.0 (√æ PubMed) obtained a higher
                                                                             F1 score (2.80 higher) than the state-of-the-art models. Also,
                                                                             BioBERT achieved the highest F1 scores on 2 out of 3 biomedical
Table 5. Statistics of biomedical question answering datasets                datasets.
                                                                                 The QA results are shown in Table 8. We micro averaged the
Dataset                                            Number        Number      best scores of the state-of-the-art models from each batch. BERT
                                                   of train      of test     obtained a higher micro averaged MRR score (7.0 higher) than the
                                                                             state-of-the-art models. All versions of BioBERT significantly out-
BioASQ 4b-factoid (Tsatsaronis et al., 2015)           327         161       performed BERT and the state-of-the-art models, and in particular,
BioASQ 5b-factoid (Tsatsaronis et al., 2015)           486         150       BioBERT v1.1 (√æ PubMed) obtained a strict accuracy of 38.77, a le-
BioASQ 6b-factoid (Tsatsaronis et al., 2015)           618         161       nient accuracy of 53.81 and a mean reciprocal rank score of 44.77,
                                                                             all of which were micro averaged. On all the biomedical QA data-
                                                                             sets, BioBERT achieved new state-of-the-art performance in terms
                                                                             of MRR.
BioBERT have exactly the same structure, and use only the gold
standard datasets and not any additional datasets.
                                                                             5 Discussion
                                                                             We used additional corpora of different sizes for pre-training and
4.2 Experimental setups                                                      investigated their effect on performance. For BioBERT v1.0 (√æ
We used the BERTBASE model pre-trained on English Wikipedia and              PubMed), we set the number of pre-training steps to 200K and var-
BooksCorpus for 1M steps. BioBERT v1.0 (√æ PubMed √æ PMC) is                   ied the size of the PubMed corpus. Figure 2(a) shows that the per-
the version of BioBERT (√æ PubMed √æ PMC) trained for 470 K                    formance of BioBERT v1.0 (√æ PubMed) on three NER datasets
steps. When using both the PubMed and PMC corpora, we found                  (NCBI Disease, BC2GM, BC4CHEMD) changes in relation to the
that 200K and 270K pre-training steps were optimal for PubMed                size of the PubMed corpus. Pre-training on 1 billion words is quite
and PMC, respectively. We also used the ablated versions of                  effective, and the performance on each dataset mostly improves until
BioBERT v1.0, which were pre-trained on only PubMed for 200K                 4.5 billion words. We also saved the pre-trained weights from
steps (BioBERT v1.0 (√æ PubMed)) and PMC for 270K steps                       BioBERT v1.0 (√æ PubMed) at different pre-training steps to meas-
(BioBERT v1.0 (√æ PMC)). After our initial release of BioBERT v1.0,           ure how the number of pre-training steps affects its performance on
we pre-trained BioBERT on PubMed for 1M steps, and we refer to               fine-tuning tasks. Figure 2(b) shows the performance changes of
this version as BioBERT v1.1 (√æ PubMed). Other hyper-parameters              BioBERT v1.0 (√æ PubMed) on the same three NER datasets in rela-
such as batch size and learning rate scheduling for pre-training             tion to the number of pre-training steps. The results clearly show
BioBERT are the same as those for pre-training BERT unless stated            that the performance on each dataset improves as the number of
otherwise.                                                                   pre-training steps increases. Finally, Figure 2(c) shows the absolute
    We pre-trained BioBERT using Naver Smart Machine Learning                performance improvements of BioBERT v1.0 (√æ PubMed √æ PMC)
(NSML) (Sung et al., 2017), which is utilized for large-scale experi-        over BERT on all 15 datasets. F1 scores were used for NER/RE, and
ments that need to be run on several GPUs. We used eight NVIDIA              MRR scores were used for QA. BioBERT significantly improves per-
V100 (32GB) GPUs for the pre-training. The maximum sequence                  formance on most of the datasets.
length was fixed to 512 and the mini-batch size was set to 192,                  As shown in Table 9, we sampled predictions from BERT and
resulting in 98 304 words per iteration. It takes more than 10 days          BioBERT v1.1 (√æPubMed) to see the effect of pre-training on down-
to pre-train BioBERT v1.0 (√æ PubMed √æ PMC) nearly 23 days for                stream tasks. BioBERT can recognize biomedical named entities
BioBERT v1.1 (√æ PubMed) in this setting. Despite our best efforts            that BERT cannot and can find the exact boundaries of named
BioBERT                                                                                                                                                            5


Table 6. Test results in biomedical named entity recognition

                                                                 BERT                  BioBERT v1.0                                                  BioBERT v1.1

Type                  Datasets          Metrics       SOTA       (Wiki √æ Books)        (√æ PubMed)         (√æ PMC)        (√æ PubMed √æ PMC)            (√æ PubMed)

Disease            NCBI disease         P             88.30           84.12                86.76            86.16                89.04                   88.22




                                                                                                                                                                        Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
                                        R             89.00           87.19                88.02            89.48                89.69                   91.25
                                        F             88.60           85.63                87.38            87.79                89.36                   89.71
                   2010 i2b2/VA         P             87.44           84.04                85.37            85.55                87.50                   86.93
                                        R             86.25           84.08                85.64            85.72                85.44                   86.53
                                        F             86.84           84.06                85.51            85.64                86.46                   86.73
                   BC5CDR               P             89.61           81.97                85.80            84.67                85.86                   86.47
                                        R             83.09           82.48                86.60            85.87                87.27                   87.84
                                        F             86.23           82.41                86.20            85.27                86.56                   87.15
Drug/chem.         BC5CDR               P             94.26           90.94                92.52            92.46                93.27                   93.68
                                        R             92.38           91.38                92.76            92.63                93.61                   93.26
                                        F             93.31           91.16                92.64            92.54                93.44                   93.47
                   BC4CHEMD             P             92.29           91.19                91.77            91.65                92.23                   92.80
                                        R             90.01           88.92                90.77            90.30                90.61                   91.92
                                        F             91.14           90.04                91.26            90.97                91.41                   92.36
Gene/protein       BC2GM                P             81.81           81.17                81.72            82.86                85.16                   84.32
                                        R             81.57           82.42                83.38            84.21                83.65                   85.12
                                        F             81.69           81.79                82.54            83.53                84.40                   84.72
                   JNLPBA               P             74.43           69.57                71.11            71.17                72.68                   72.24
                                        R             83.22           81.20                83.11            82.76                83.21                   83.56
                                        F             78.58           74.94                76.65            76.53                77.59                   77.49
Species            LINNAEUS             P             92.80           91.17                91.83            91.62                93.84                   90.77
                                        R             94.29           84.30                84.72            85.48                86.11                   85.83
                                        F             93.54           87.60                88.13            88.45                89.81                   88.24
                   Species-800          P             74.34           69.35                70.60            71.54                72.84                   72.80
                                        R             75.96           74.05                75.75            74.71                77.97                   75.36
                                        F             74.98           71.63                73.08            73.09                75.31                   74.06

   Notes: Precision (P), Recall (R) and F1 (F) scores on each dataset are reported. The best scores are in bold, and the second best scores are underlined. We list
the scores of the state-of-the-art (SOTA) models on different datasets as follows: scores of Xu et al. (2019) on NCBI Disease, scores of Sachan et al. (2018) on
BC2GM, scores of Zhu et al. (2018) (single model) on 2010 i2b2/VA, scores of Lou et al. (2017) on BC5CDR-disease, scores of Luo et al. (2018) on
BC4CHEMD, scores of Yoon et al. (2019) on BC5CDR-chemical and JNLPBA and scores of Giorgi and Bader (2018) on LINNAEUS and Species-800.



Table 7. Biomedical relation extraction test results

                                                                   BERT                  BioBERT v1.0                                                BioBERT v1.1

Relation                  Datasets          Metrics     SOTA       (Wiki √æ Books)        (√æ PubMed)        (√æ PMC)       (√æ PubMed √æ PMC)            (√æ PubMed)

Gene‚Äìdisease           GAD                  P           79.21           74.28               76.43            75.20                75.95                  77.32
                                            R           89.25           85.11               87.65            86.15                88.08                  82.68
                                            F           83.93           79.29               81.61            80.24                81.52                  79.83
                       EU-ADR               P           76.43           75.45               78.04            81.05                80.92                  77.86
                                            R           98.01           96.55               93.86            93.90                90.81                  83.55
                                            F           85.34           84.62               84.44            86.51                84.83                  79.74
Protein‚Äìchemical       CHEMPROT             P           74.80           76.02               76.05            77.46                75.20                  77.02
                                            R           56.00           71.60               74.33            72.94                75.09                  75.90
                                            F           64.10           73.74               75.18            75.13                75.14                  76.46

  Notes: Precision (P), Recall (R) and F1 (F) scores on each dataset are reported. The best scores are in bold, and the second best scores are underlined. The scores
on GAD and EU-ADR were obtained from Bhasuran and Natarajan (2018), and the scores on CHEMPROT were obtained from Lim and Kang (2018).


entities. While BERT often gives incorrect answers to simple bio-                    architectural modification, BioBERT outperforms previous models
medical questions, BioBERT provides correct answers to such ques-                    on biomedical text mining tasks such as NER, RE and QA.
tions. Also, BioBERT can provide longer named entities as answers.                       The pre-released version of BioBERT (January 2019) has already
                                                                                     been shown to be very effective in many biomedical text mining tasks
                                                                                     such as NER for clinical notes (Alsentzer et al., 2019), human
                                                                                     phenotype-gene RE (Sousa et al., 2019) and clinical temporal RE (Lin
6 Conclusion                                                                         et al., 2019). The following updated versions of BioBERT will be avail-
In this article, we introduced BioBERT, which is a pre-trained lan-                  able to the bioNLP community: (i) BioBERTBASE and BioBERTLARGE
guage representation model for biomedical text mining. We showed                     trained on only PubMed abstracts without initialization from the exist-
that pre-training BERT on biomedical corpora is crucial in applying                  ing BERT model and (ii) BioBERTBASE and BioBERTLARGE trained on
it to the biomedical domain. Requiring minimal task-specific                         domain-specific vocabulary based on WordPiece.
6                                                                                                                                                       J.Lee et al.


Table 8. Biomedical question answering test results

                                                     BERT                     BioBERT v1.0                                                            BioBERT v1.1

Datasets             Metrics         SOTA            (Wiki √æ Books)           (√æ PubMed)            (√æ PMC)           (√æ PubMed √æ PMC)                (√æ PubMed)

BioASQ 4b            S               20.01                  27.33                 25.47               26.09                    28.57                      27.95




                                                                                                                                                                         Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
                     L               28.81                  44.72                 44.72               42.24                    47.82                      44.10
                     M               23.52                  33.77                 33.28               32.42                    35.17                      34.72
BioASQ 5b            S               41.33                  39.33                 41.33               42.00                    44.00                      46.00
                     L               56.67                  52.67                 55.33               54.67                    56.67                      60.00
                     M               47.24                  44.27                 46.73               46.93                    49.38                      51.64
BioASQ 6b            S               24.22                  33.54                 43.48               41.61                    40.37                      42.86
                     L               37.89                  51.55                 55.90               55.28                    57.77                      57.77
                     M               27.84                  40.88                 48.11               47.02                    47.48                      48.43

   Notes: Strict Accuracy (S), Lenient Accuracy (L) and Mean Reciprocal Rank (M) scores on each dataset are reported. The best scores are in bold, and the
second best scores are underlined. The best BioASQ 4b/5b/6b scores were obtained from the BioASQ leaderboard (http://participants-area.bioasq.org).




     (a)                                              (b)                                                (c)




Fig. 2. (a) Effects of varying the size of the PubMed corpus for pre-training. (b) NER performance of BioBERT at different checkpoints. (c) Performance improvement of
BioBERT v1.0 (√æ PubMed √æ PMC) over BERT




Table 9. Prediction samples from BERT and BioBERT on NER and QA datasets

Task         Dataset                          Model             Sample

NER          NCBI disease                     BERT              WT1 missense mutations, associated with male pseudohermaphroditism in Denys‚ÄìDrash syn-
                                                                     drome, fail to . . .
                                              BioBERT           WT1 missense mutations, associated with male pseudohermaphroditism in Denys‚ÄìDrash syn-
                                                                     drome, fail to . . .
             BC5CDR (Drug/Chem.)              BERT              . . . a case of oral penicillin anaphylaxis is described, and the terminology . . .
                                              BioBERT           . . . a case of oral penicillin anaphylaxis is described, and the terminology . . .
             BC2GM                            BERT              Like the DMA, but unlike all other mammalian class II A genes, the zebrafish gene codes for
                                                                     two cysteine residues . . .
                                              BioBERT           Like the DMA, but unlike all other mammalian class II A genes, the zebrafish gene codes for
                                                                     two cysteine residues . . .
QA           BioASQ 6b-factoid                                  Q: Which type of urinary incontinence is diagnosed with the Q tip test?
                                              BERT              A total of 25 women affected by clinical stress urinary incontinence (SUI) were enrolled.
                                                                     After undergoing (. . .) Q-tip test, . . .
                                              BioBERT           A total of 25 women affected by clinical stress urinary incontinence (SUI) were enrolled.
                                                                     After undergoing (. . .) Q-tip test, . . .
                                                                Q: Which bacteria causes erythrasma?
                                              BERT              Corynebacterium minutissimum is the bacteria that leads to cutaneous eruptions of eryth-
                                                                     rasma . . .
                                              BioBERT           Corynebacterium minutissimum is the bacteria that leads to cutaneous eruptions of eryth-
                                                                     rasma . . .

    Note: Predicted named entities for NER and predicted answers for QA are in bold.
BioBERT                                                                                                                                                                 7


Funding                                                                                   Mohan,S. and Li,D. (2019) Medmentions: a large biomedical corpus anno-
                                                                                            tated with UMLS concepts. arXiv preprint arXiv: 1902.09476.
This research was supported by the National Research Foundation of                        Pafilis,E. et al. (2013) The species and organisms resources for fast and accur-
Korea(NRF) funded by the Korea government (NRF-2017R1A2A1A17069645,                         ate identification of taxonomic names in text. PLoS One, 8, e65390.
NRF-2017M3C4A7065887, NRF-2014M3C9A3063541).                                              Pennington,J. et al. (2014) Glove: Global vectors for word representation. In:
                                                                                            Proceedings of the 2014 Conference on Empirical Methods in Natural
                                                                                            Language Processing (EMNLP), Doha, Qatar. pp. 1532‚Äì1543. Association




                                                                                                                                                                             Downloaded from https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019
References                                                                                  for Computational Linguistics. https://www.aclweb.org/anthology/D14-1162.
                                                                                          Peters,M.E. et al. (2018) Deep contextualized word representations. In:
Alsentzer,E. et al. (2019) Publicly available clinical bert embeddings. In: Proceedings     Proceedings of the 2018 Conference of the North American Chapter of the
  of the 2nd Clinical Natural Language Processing Workshop, Minneapolis, MN,                Association for Computational Linguistics: Human Language
  USA. pp. 72‚Äì78. Association for Computational Linguistics. https://www.acl                Technologies, Volume 1 (Long Papers), New Orleans, LA. pp. 2227‚Äì2237.
  web.org/anthology/W19-1909.                                                               Association for Computational Linguistics. https://www.aclweb.org/anthol
Bhasuran,B. and Natarajan,J. (2018) Automatic extraction of gene-disease                    ogy/N18-1202.
  associations from literature using joint ensemble learning. PLoS One, 13,               Pyysalo,S. et al. (2013) Distributional semantics resources for biomedical text
  e0200699.                                                                                 processing. In: Proceedings of the 5th International Symposium on
Bravo,AÃÄ. et al. (2015) Extraction of relations between genes and diseases from             Languages in Biology and Medicine, Tokyo, Japan, pp. 39‚Äì43. https://aca
  text and large-scale data analysis: implications for translational research.              demic.oup.com/bioinformatics/article/33/14/i37/3953940.
  BMC Bioinformatics, 16, 55.                                                             Rajpurkar,P. et al. (2016) Squad: 100,000√æ questions for machine compre-
Devlin,J. et al. (2019) Bert: pre-training of deep bidirectional transformers for lan-      hension of text. In: Proceedings of the 2016 Conference on Empirical
  guage understanding. In: Proceedings of the 2019 Conference of the North                  Methods in Natural Language Processing, Austin, TX. pp. 2383‚Äì2392.
  American Chapter of the Association for Computational Linguistics: Human                  Association for Computational Linguistics. https://www.aclweb.org/anthol
  Language Technologies, Volume 1 (Long and Short Papers), Minneapolis,                     ogy/D16-1264.
  MN, USA. pp. 4171‚Äì4186. Association for Computational Linguistics. https://             Sachan,D.S. et al. (2018) Effective use of bidirectional language modeling for
  www.aclweb.org/anthology/N19-1423.                                                        transfer learning in biomedical named entity recognition. In: Finale,D.-V.
Dogan,R.I. et al. (2014) NCBI disease corpus: a resource for disease name rec-             et al. (eds.), Proceedings of Machine Learning Research, Palo Alto, CA, Vol.
  ognition and concept normalization. J. Biomed. Inform., 47, 1‚Äì10.                         85, pp. 383‚Äì402. PMLR. http://proceedings.mlr.press/v85/sachan18a.html.
Gerner,M. et al. (2010) Linnaeus: a species name identification system for bio-           Smith,L. et al. (2008) Overview of biocreative ii gene mention recognition.
  medical literature. BMC Bioinformatics, 11, 85.                                           Genome Biol., 9, S2.
Giorgi,J.M. and Bader,G.D. (2018) Transfer learning for biomedical named                  Sousa,D. et al. (2019) A silver standard corpus of human phenotype-gene rela-
  entity recognition with neural networks. Bioinformatics, 34, 4087.                        tions. In: Proceedings of the 2019 Conference of the North American Chapter
Habibi,M. et al. (2017) Deep learning with word embeddings improves bio-                    of the Association for Computational Linguistics: Human Language
  medical named entity recognition. Bioinformatics, 33, i37‚Äìi48.                            Technologies, Volume 1 (Long and Short Papers), Minneapolis, MN. pp.
Kim,J.-D. et al. (2004) Introduction to the bio-entity recognition task at                  1487‚Äì1492. Association for Computational Linguistics. https://www.aclweb.
  JNLPBA. In: Proceedings of the International Joint Workshop on Natural                    org/anthology/N19-1152.
  Language         Processing     in     Biomedicine        and    its    Applications    Sung,N. et al. (2017) NSML: A machine learning platform that enables you to
  (NLPBA/BioNLP), Geneva, Switzerland. pp. 73‚Äì78. COLING. https://                          focus on your models. arXiv preprint arXiv: 1712.05902.
  www.aclweb.org/anthology/W04-1213.                                                      Tsatsaronis,G. et al. (2015) An overview of the BIOASQ large-scale biomed-
Krallinger,M. et al. (2015) The chemdner corpus of chemicals and drugs and                  ical semantic indexing and question answering competition. BMC
  its annotation principles. J. Cheminform., 7.                                             Bioinformatics, 16, 138.
Krallinger,M. et al. (2017) Overview of the BioCreative VI chemical-protein               Uzuner,OÃà. et al. (2011) 2010 i2b2/VA challenge on concepts, assertions, and
  interaction track. In: Proceedings of the BioCreative VI Workshop,                        relations in clinical text. J. Am. Med. Inform. Assoc., 18, 552‚Äì556.
  Bethesda, MD, USA, pp. 141‚Äì146. https://academic.oup.com/database/art                   Van Mulligen,E.M. et al. (2012) The EU-ADR corpus: annotated drugs, dis-
  icle/doi/10.1093/database/bay073/5055578.                                                 eases, targets, and their relationships. J. Biomed. Inform., 45, 879‚Äì884.
Li,J. et al. (2016) Biocreative V CDR task corpus: a resource for chemical dis-           Vaswani,A. et al. (2017) Attention is all you need. In: Guyon,I. et al. (eds.),
  ease relation extraction. Database, 2016.                                                 Advances in Neural Information Processing Systems, pp. 5998‚Äì6008.
Lim,S. and Kang,J. (2018) Chemical‚Äìgene relation extraction using recursive                 Curran Associates, Inc. http://papers.nips.cc/paper/7181-attention-is-all-
  neural network. Database, 2018.                                                           you-need.pdf.
Lin,C. et al. (2019) A bert-based universal model for both within-and                     Wang,X. et al. (2018) Cross-type biomedical named entity recognition with
  cross-sentence clinical temporal relation extraction. In: Proceedings of the              deep multi-task learning. Bioinformatics, 35, 1745‚Äì1752.
  2nd Clinical Natural Language Processing Workshop, Minneapolis, MN,                     Wiese,G. et al. (2017) Neural domain adaptation for biomedical question
  USA. pp. 65‚Äì71. Association for Computational Linguistics. https://www.                   answering. In: Proceedings of the 21st Conference on Computational
  aclweb.org/anthology/W19-1908.                                                            Natural Language Learning (CoNLL 2017), Vancouver, Canada. pp.
Lou,Y. et al. (2017) A transition-based joint model for disease named entity                281‚Äì289. Association for Computational Linguistics. https://www.aclweb.
  recognition and normalization. Bioinformatics, 33, 2363‚Äì2371.                             org/anthology/K17-1029.
Luo,L. et al. (2018) An attention-based BiLSTM-CRF approach to document-level             Wu,Y. et al. (2016) Google‚Äôs neural machine translation system: Bridging the
  chemical named entity recognition. Bioinformatics, 34, 1381‚Äì1388.                         gap between human and machine translation. arXiv preprint arXiv:
McCann,B. et al. (2017) Learned in translation: contextualized word vectors.                1609.08144.
  In: Guyon,I. et al. (eds.), Advances in Neural Information Processing                   Xu,K. et al. (2019) Document-level attention-based BiLSTM-CRF incorporat-
  Systems 30, Curran Associates, Inc., pp. 6294‚Äì6305. http://papers.nips.cc/                ing disease dictionary for disease named entity recognition. Comput. Biol.
  paper/7209-learned-in-translation-contextualized-word-vectors.pdf.                        Med., 108, 122‚Äì132.
Mikolov,T. et al. (2013) Distributed representations of words and phrases and             Yoon,W. et al. (2019) Collabonet: collaboration of deep neural networks for
  their compositionality. In: Burges,C.J.C. (eds.), Advances in Neural                      biomedical named entity recognition. BMC Bioinformatics, 20, 249.
  Information Processing Systems 26, Curran Associates, Inc., pp.                         Zhu,H. et al. (2018) Clinical concept extraction with contextual word embed-
  3111‚Äì3119. http://papers.nips.cc/paper/5021-distributed-representations-                  ding. NIPS Machine Learning for Health Workshop. http://par.nsf.gov/bib
  of-words-and-phrases-and-their-compositionality.pdf.                                      lio/10098080.
2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON)
Galgotias University, Greater Noida, UP, India. Oct 2-4, 2020




              Building Knowledge Graph using Pre-trained
               Language Model for Learning Entity-aware
                            Relationships
           Abhijeet Kumar                        Abhishek Pandey                               Rohit Gadia                            Mridul Mishra
        Emerging Tech Team                     Emerging Tech Team                         Emerging Tech Team                      Emerging Tech Team
        Fidelity Investments,                  Fidelity Investments,                       Fidelity Investments,                  Fidelity Investments,
          Bangalore, India                        Bangalore, India                           Bangalore, India                        Bangalore, India
      Abhijeet.Kumar@fmr.com                 Abhishek.Pandey@fmr.com                      Rohit.Gadia@fmr.com                    Mridul.Mishra@fmr.com


      Abstract‚Äî Relations exhibited among entities from textual                       knowledge graph aggregates information around entities in a
  content can be a potential source of information for any business                   structural way across multiple content sources and links these
  domain. This paper encompasses a wholesome approach to mine                         entities together. Also, it has the capability to provide entity-
  entity-relation and building knowledge graph from textual                           specific properties such as type, specific relation at the same
  documents. The paper concentrates on two approaches to classify                     time. We created one such financial knowledge graph using
  directional entity relations. We build on extending pretrained                      Neo4J database [2] to visualize the relationships among entities
  language model i.e. BERT for text classification along-side                         like Persons, Organizations and Locations.
  providing entity and directionality information as input making
  it entity-aware BERT classifier. We also did ablation studies of                        There are numerous approaches for extracting relationship
  presented model in terms of various ways of providing entity                        among entities (feature based and kernel-based) which rely on
  information on the learning capabilities of model. We                               NLP stack using POS tagging and dependency parsing [3]-
  demonstrate the end to end pipeline for building an entity-                         [10]. The major concern of these approaches is inability to
  relation extraction system in a business application. The                           capture numerous ways of expressing the similar relationship.
  techniques proposed in the paper are also evaluated against                         The challenging variability in syntactic and semantic nature of
  SemEval-2010 Task 8, a popular relation classification dataset.                     a sentence creates a need for effective solution which can
  The experimental results demonstrate that learning entity-aware                     extract entities as well as context that defines the relationship.
  relations through language models outperforms almost all the
                                                                                      This paper presents a language-model based solution which
  previous state-of-the-art (SOTA) models.
                                                                                      captures relationship between entities contextually and not only
      Keywords‚Äîknowledge graph, entity relations, relationship                        syntactically.
  extraction, deep learning, BERT, language models, graph database                        In recent years, the research has moved towards deep
                                                                                      networks which are effective in contextual learning for a given
                            I.     INTRODUCTION
                                                                                      task. Various architectures of RNN, LSTM and CNNs have
      Entity relationship classification is the task of identifying                   been proposed for sequence modeling or classification task.
  the semantic relation between the entities present in the text.                     These models have been effectively implemented for entity
  For example,                                                                        relation classification also [11]-[15]. More recently, Attention
                                                                                      based models became SOTA techniques for most of NLP tasks.
      ‚ÄúAmazon recently acquired PillPack for $1 billion‚Äù.
                                                                                      A lot of research with attention-based models for learning
  Here, Amazon and PillPack are two entities which has relation                       entity relations had been presented as SOTA models in past
  of ‚Äúacquisition‚Äù. In another complex example,                                       [16]-[18]. In last couple of years, language models have taken
                                                                                      the driving seat in this research direction where a pre-trained
  ‚ÄúHe was chief executive of Worldpay when it was acquired by                         language model (like ELMO [19], GPT [20], BERT [21] etc.)
  Vantiv in a ¬£9.3 billion takeover in 2017‚Äù.                                         has been trained on huge texts in a self-supervised way to learn
  Vantiv and Worldpay are two entities with relation                                  the syntactics and semantics of text sentences.
  ‚Äúacquisition‚Äù. At times, it is also crucial to know the                                 This paper demonstrates two BERT based architectures
  directionality of the relation. In first example, directionality of                 which is effective for relationship classification between
  relation Acquisition was from Amazon (e1) to PillPack (e2)                          entities. Major contributions presented are:
  whereas the same relation is from Vantiv (e2) to Worldpay (e1)
  in second example.                                                                     1.    Two proposed techniques are 1) Training a full
                                                                                               (K*2+1) way classifier where ‚ÄòK‚Äô is number of relation
      This task is indispensable in various NLP applications.                                  classes. We keep an artificial class ‚ÄòOthers‚Äô for
  Imagine with a plethora of news and articles getting generated                               capturing sentences where entities are present but
  every day, there is immense potential of knowledge that can be                               without relation of our interest. 2) Training two
  extracted for any domain. Knowledge graph is a powerful tool                                 classifiers, one binary classifier for directionality
  for supporting a gamut of search applications along with                                     prediction between entities and another K-way
  ranking, recommendation and exploratory search [1]. A



978-1-7281-5070-3/20/$31.00 ¬©2020 IEEE                                          310
        Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
        classifier for relation class prediction and further                                         III.    PROPOSED METHODOLOGY
        combining the results.
                                                                                   A. System Design
   2.   Through ablation study, we concluded the best format                           We formulated a pipeline which extracts predefined entities
        to provide entity information to finetuned language                        and their relations (from classification), and populates the
        model (BERT) classifier (See Section V.B).                                 searchable, visual and extensive knowledge graph.
   3.   We achieved SOTA results for relationship
        classification task with F1-score of 88.4% and 89.41%
        on the SemEval 2010 Task 8 dataset, outperforming all
        previous results [11]-[18][22][23].
                        II.    RELATED WORK
    There is extensive research ranging from unsupervised to
supervised techniques that attempts to solve for relation
extraction and knowledge mining. Rink et al. [5] used                              Fig. 1. Relation Extraction System Design
handcrafted features that capture the context, semantic role
affiliation, and possible pre-existing relations between entities.                     Figure. 1 depicts 5-step process flow of proposed relation
Research efforts have been made with deep learning methods                         extraction system with various components. Given an English
for learning long term dependency in entity relationships.                         article or document, a sentence tokenizer (step 1) is called and
Zhang et al. [12] and Socher et al. [15] applied RNN and                           then the entity recognizer (step 2) will demarcate possible
MVRNN model respectively for relation classification which                         entities in sentence like location, person or organization. In the
implements variants of recursive neural network.                                   following steps (3 and 4), a BERT based relation classifier is
                                                                                   run and binary entity-relation triplet is generated if relationship
    Deep convolutional neural network models were also                             like acquisition, relative-of, located-in and works-at is found.
employed for extracting lexical and sentence level features                        Once the system has labeled entity-relations triplets, it
using convolution kernels [11]. Dos Santos et al. proposed                         populates the nodes and links in graph database for knowledge
model for relation-classification task using a CNN that                            graph representation (step 5).
performs classification by ranking (CR-CNN) [14]. Research
efforts were made in employing attention levels in deep                            B. Model Architecture- Entity-aware BERT
network models in order to capture specific segment of                             We fine-tuned BERT [21] model in a specific way for
sentence which dictates the relations well [16][17][18]. Wang                      providing input as described in the later sub-sections. Any
et al. proposed CNN model relying on two levels of attention                       language model building has two phases of training: generic
in order to better discern patterns in heterogeneous contexts
                                                                                   pretraining step followed by finetuning on custom dataset
[17]. Lee et al. employed multi-head entity aware self-attention
                                                                                   (mostly limited dataset task). Often the pretraining of these
based Bi-LSTM models [18]. Yu et al. (2014) proposed a
Factor-based Compositional Embedding Model (FCM) by                                models are also extended as an additional step in case of
utilizing sentence-level and substructure embeddings from                          learning specific domain.
word embeddings, employing dependency trees and named
entities recognition (NER) [22].                                                      1) Input Representation
                                                                                       As per original BERT paper [21], a special classification
    Recently, few researchers have made efforts in exploring                       token [CLS] is the first token of the input sequence and end
pretrained language models like BERT for relationship                              token is [SEP]. In order to explicitly provide location
extraction. Yao et al. trained a knowledge graph KG-BERT to                        information, we inserted special symbolic tokens # and $
train triplet of entities and relation description as input to                     without gap to enclose the entities. Hence making it entity-
BERT [24]. Soares et al. presents a method of training relation                    aware BERT classifier. Given a sentence s = {w1, ‚Ä¶‚Ä¶,
representation without any supervision from a knowledge                            <e1>wh</e1>, ‚Ä¶. <e2>wt</e2>, ‚Ä¶wn} with marked entities (h,
graph or human annotators by matching the blanks [25]. Wu et                       t), we convert it to s = {[CLS], w1, ‚Ä¶, #wh#, ‚Ä¶$wt$, ‚Ä¶wn,
al. proposed entity embeddings as well as the sentence                             [SEP]}. For example, an input text sequence is passed to model
encoding from BERT as the input to a multi-layer neural                            in the following manner.
network for classification [23].
                                                                                       [CLS] Louise is a director, audit chair and finance
    Although these models achieve good results, ideally, A                         #committee# $member$ of a public health board and was a
simple yet effective solution would be one which does not                          director of AFAANZ for 3 years [SEP]‚Äù
require handcrafted features, dependency parsing or training
multiple models. In Section 4, through experiments we show                             The above sentence is a training sentence of SemEval
that finetuning a pretrained language model with entity aware                      dataset [28] from Member-Collection (e2, e1) relation class
raw text input simply achieves this, while also obtaining                          with directionality e2 to e1.
considerable improvements in F1 scores. Section 5 writes                              2) Model Architecture
about error analysis and ablation studies to arrive at best format                     We have utilized pre-trained model BERT base from
of providing text input to model. In next section, both the                        Google‚Äôs BERT TensorFlow implementation [27] and
architectures are discussed along with overall system pipeline                     finetuned it for entity-relation classification. The model
design and knowledge graph generation.



                                                                             311
     Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
architecture shown in Figure. 2 depicts the way input sequence
is provided to make it entity-aware.




                                                                                    Fig. 3. 2-Model BERT classifier design

                                                                                        The proposed 2-model architecture is shown in Figure 3.
Fig. 2. Entity-aware Finetuned BERT classifier                                      As shown in the diagram, Directionality is considered only if
                                                                                    relation classifier predicts some relation class, not the artificial
    The final hidden state corresponding to special                                 class ‚ÄúOther‚Äù. We examined the performance of both the
classification token ([CLS]) is used as the aggregated sequence                     model individually. Only relation classification model achieved
representation for classification tasks [21]. The classification                    F1-score of 86.6% whereas binary directional classifier
parameters introduced during fine-tuning are W ‚Ä´ ◊ê‚Ä¨R(K*2 +1) √ó768,                    achieved F1-score of 97% on SemEval 2010 dataset.
where K is the no. of relation classes. We compute a typical                        Moreover, we achieved results better than most of the previous
softmax loss for classification with C and W, i.e.,                                 works and comparable to SOTA models on combining both the
log(softmax(CWT)). The scoring function for a relation                              relation and directionality classification models (See section
classification is                                                                   4.B).
                     F(r) = softmax(C.WT )                                          D. Knowledge Graph
                                                                                        A knowledge graph is developed using graphical method
   The hyperparameters settings                        for   BERT     based         that keeps association as well as hierarchical knowledge of
implementations are as follows:                                                     domain. We employed Neo4J for visualizing and searching
                                                                                    entity-relationships as shown in a sample snippet below (Fig
             TABLE I.         BERT-BASE HYPERPARAMTERS
                                                                                    4).
              Hyperparameters                    Value

              Max Sequence Length                64

              No. of Training Epochs             5

              Train Batch Size                   64

              Warmup Proportion                  0.1

              Learning Rate                      5e-5

              Dropout                            0.1

C. BERT based 2-Model Architecture
    We propose another approach ‚Äú2-model BERT‚Äù for solving
the relationship classification task with directionality. We
trained two BERT based classifier on the same training data in
a similar way as directed in section B. First classifier learns the
relations class whereas second binary classifier learns the                         Fig. 4. Entity-aware Finetuned BERT classifier
directionality of the relationship provided the entity located
with markers.




                                                                              312
      Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                 IV.     EXPERIMENT AND RESULTS                                    Table III. Intuitively, entity marking helps a lot in learning as
                                                                                   BERT is heavily based on multi-head self-attention layers.
A. SemEval 2010 Dataset
    We used SemEval-2010 Task 8 dataset for benchmarking                                      TABLE III.      SEMEVAL-2010 TASK 8 (APPROACH-1)
both the proposed architectures [28]. This dataset consisted of
8,000 examples as training data, and 2717 sentences as testing                                Models                                       F1-Score
set. There are nine types of annotated relations between                                      2-Model BERT with No Entity info.            78.84
entities along with demarcation of entities. Refer to Table IV
for all nine label names of annotated relations. There is an                                  2-model BERT                                 88.44
additional relation type ‚ÄúOther‚Äù (artificial class) which                                     BERT with No Entity Info.                    81.40
indicates that the relation expressed in the text is not among
the nine types. In this dataset, each of the relation types,                                  Entity-aware BERT                            89.41
directionality information is also present which implies that
relationship between entities can be from e1 to e2 or vice
versa. For example, Entity-Origin (e1, e2) and Entity-Origin                       B. Effect of Entity Markers
(e2, e1) can be considered two distinct relations, so the total
number of relationship classes is 19.                                                  The idea behind performing these experiments was to
                                                                                   understand if choosing entity marker also impacts the learning
B. Experimental Results & Comparison                                               of BERT language model. From numerous experiments, it was
   As discussed earlier in the paper, we experimented with                         concluded that symbolic markers like $, # performs better than
two proposed approaches for this dataset. Details about the                        alphabetic marker. One of the possible reasons would be
model architecture are described in section 3.                                     alphabetic markers surrounding entities distorts the language
                                                                                   representation learnt by language models.
    The official scorer was used to evaluate all our model
experiments in terms of the Macro-F1 score over the nine                           Also, entities with symbolic markers without leaving space
relationship pairs taking directionality into account. We also                     marginally performs better than leaving space. Table. 1 shows
compare the results with scores quoted in previous works on                        effect of entity markers in terms of F1-score for each class as
this dataset (shown below).                                                        well as overall macro-averaged score by semval-2010 offline
                                                                                   scorer.
         TABLE II.        SEMEVAL-2010 TASK 8 (APPROACH-1)
                                                                                              TABLE IV.       SEMEVAL-2010 TASK 8 (APPROACH-1)
   Models                                                 F1-Score
                                                                                                                    F1-score (different entity markers)
   SVM [5]                                                82.2                             Classes             E1 start, E1
                                                                                                              end, E2 start,        $,#            $, # (no space)
   RNN [15]                                               77.6                                                   E2 end

   MVRNN [15]                                             82.4                       Cause-Effect           93.53                  94.42               93.74

   FCM [22]                                               83.0                       Component-Whole        84.58                  83.52               86.35

   CNN+ Softmax [11]                                      82.7                       Content-Container      90.16                  87.94               90.82

   CR-CNN [14]                                            84.1                       Entity-Destination     91.76                  93.31               92.97
   Attention CNN [16]                                     85.9                       Entity-Origin          88.68                  88.05               89.27
   DRNNs [13]                                             85.8                       Instrument-Agency      79.01                  81.39               82.96
   Multi-level Att-Pooling-CNN [17]                       88.0                       Member-
                                                                                                            87.12                  88.37               88.37
                                                                                     Collection
   Entity Attention Bi-LSTM [18]                          85.2
                                                                                     Message-Topic          92.05                  91.68               91.71
   R-BERT                                                 89.25
                                                                                     Product-Producer       86.15                  87.90               88.51
   2-Model BERT                                           88.44
                                                                                     _Other                 63.67                  65.31               64.69
   Entity-aware BERT                                      89.41
                                                                                     All Classes            88.12                  88.51               89.41
        V.      ABLATION STUDIES AND ERROR ANALYSIS
A. Effect of Entity Information
                                                                                   C. Effect of Training Epochs
    In order to understand the importance of providing entity
information, we ran the proposed model (Approach-I) without                            Optimal number of epochs for finetuning BERT was found
entity marking. The experimental results are shown in the                          to be 5 for the dataset as shown in Figure.5.




                                                                             313
     Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                                                                                        TABLE VI.        MISSCLASSIFICATION EXAMPLES (ACTUAL-OTHER)

                                                                                      #Danger# is part of the Palestinian             Other     Component-
                                                                                      journalist's daily ÕÑroutine$                              Whole(e2,e1)

                                                                                      The painting shows a historical view of the     Other     Cause-
                                                                                      #damage# caused by the 1693 Catania                       Effect(e2,e1)
                                                                                      earthquake and
                                                                                      the $reconstruction$ activities.

                                                                                                                                                Entity-
                                                                                      The #yeast# is an ingredient for                Other     Origin(e2,e1)
                                                                                      making ÕÑ¬Ñ¬á¬á¬îÕÑ.
Fig. 5. F1-score versus Training epochs (optimal=5)
                                                                                                  VI.     CONCLUSION AND FUTURE WORK
D. Error Analysis: Where it failed ?
    We examined the misclassified examples produced by the                              The objective of the research and experimentation was to
model to understand the possible reasons of failure.                                construct in-domain large scale searchable knowledge graph to
Interestingly, approximately 80% of the misclassifications                          visualize various entities and the way they are related to each
were result of either incorrectly predicting a relation as                          other. In this paper, we utilized the advantage of language
artificial class ‚ÄúOther‚Äù or vice versa.                                             knowledge already learnt by language models and enriched
                                                                                    them by incorporating entity aware information to provide
    Firstly, some of the examples wrongly predicted as ‚ÄúOther‚Äù                      attention for entity relation classification (2*k+1 way). We also
category contains words or context phrases (shown in bold)                          proposed two-model architecture to separately deal with
which were unseen in the training sentences. The model                              relation class as well as directionality of relation. Through
possibly could not get the context and predicted the artificial                     ablation studies, we found that symbolic markers enclosing the
class wrongly. Few examples of such misclassifications are                          entity words without gap is the best way to provide text input
shown in Table V. Another intuition is the generic nature of                        format for relation classification with finetuned BERT. We
text sequences in ‚ÄúOther‚Äù class may confuse model and lead to                       conduct experiments on the SemEval-2010 task 8 benchmark
incorrect prediction for some of such sentences of actual                           dataset. Both the proposed models namely entity-aware BERT
relation classes also.                                                              and 2-model BERT achieve SOTA results of 88.44% and
                                                                                    89.41% F1-score respectively in SemEval-2010 Task 8 without
   TABLE V.        MISSCLASSIFICATION EXAMPLES (PREDICTED-OTHER)                    any explicit embeddings or high-level features from NLP tools.
 #Fish# without the pyloric ceca have                                                   As future directions, we intend to explore multi-label
                                                Component-           Other
 digestive enzyme production in
                                                Whole(e2,e1)
                                                                                    classification task for scenarios where presence of more than
 the $liver$ and pancreas.                                                          two entities in a sentence makes relationship extraction
                                                                                    ambiguous. A limitation of our proposed system in the paper is
 The #body# unleashes its
 extraterrestrial $passenger$, which proceeds
                                                Entity-              Other          that it extracts relation on the sentence level. Relations can
                                                Origin(e2,e1)                       span over sentences also. We intend to modify our systems to
 to infect the student population at a
 breakneck pace.                                                                    capture long range relations. We also look forward to
                                                                                    employing domain specific custom pre-trained model in order
 These #observations# determine the high                                            to improve accuracy of system.
                                                Message-             Other
 spatial resolution stellar $kinematics$
                                                Topic(e1,e2)
 within the nuclei of these galaxies.                                                                        ACKNOWLEDGMENT
 The Postmodernism Generator was written                                                This research was supported by Asset Management Group,
                                                Product-             Other
 by Andrew C. Bulhak using the Dada             Producer(e1,e2)                     Fidelity Investments. We thank colleagues from emerging tech
 Engine, a system for generating random                                             team for providing valuable insight and expertise that assisted
 #text# from recursive $grammars$.                                                  the research.
                                                                                       The views or opinions expressed in this paper are solely
    Secondly, the model may learn relation classes focusing on                      those of the author and do not necessarily represent those of
the prepositional phrases between entities through attention                        Fidelity Investments. This research does not reflect in any way
mechanism e.g. ‚Äúis part of‚Äù phrase mostly shows either                              procedures, processes or policies of operations within Fidelity
Component-Whole or Member-Collection relation class in                              Investments.
training data. But some of the examples from Other class in
test set have such relation defining phrases which confuses the
model (few are shown in Table VI).




                                                                              314
      Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                                REFERENCES                                                     Methods in Natural Language Processing and Computational Natural
                                                                                               Language Learning (EMNLP-CoNLL ‚Äô12).
[1]    Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao,
       Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang.                      [16]   Yatian Shen and Xuanjing Huang. 2016. Attention-based Convolutional
       2014. Knowledge vault: A web-scale approach to probabilistic                            Neural Network for Semantic Relation Extraction. In Proceedings of
       knowledge fusion. International Conference on Knowledge Discovery                       COLING 2016, the 26th International Conference on Computational
       and Data Mining, KDD ‚Äô14, pages 601‚Äì 610. ACM.                                          Linguistics: Technical Papers. 2526‚Äì2536.
[2]    Neo4J Database, [online] https://neo4j.com/                                      [17]   Linlin Wang, Zhu Cao, Gerard de Melo, and Zhiyuan Liu. 2016.
                                                                                               Relation Classification via Multi-Level Attention CNNs. In Proceedings
[3]    Bach, Nguyen, and Sameer Badaskar. ‚ÄúA review of relation                                of the 54th Annual Meeting of the Association for Computational
       extraction.‚Äù Literature review for Language and Statistics II 2 (2007).                 Linguistics.
[4]    Kambhatla, N. (2004). Combining lexical, syntactic, and semantic                 [18]   Joohong Lee, Sangwoo Seo, and Yong Suk Choi. 2019. Semantic
       features with maximum entropy models for extracting relations.                          Relation Classification via Bidirectional LSTM Networks with
       Proceedings of the ACL 2004.                                                            Entityaware Attention using Latent Entity Typing. CoRR (2019).
[5]    GBryan Rink and Sanda Harabagiu. 2010. Utd: Classifying semantic                 [19]   Matthew        E.     Peters, Mark     Neumann, Mohit        Iyyer, Matt
       relations by combining lexical and semantic resources. In Proceedings                   Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, Deep
       of the 5th International Workshop on Semantic Evaluation. 256‚Äì259.                      Contextualized Word Representations, Feb 2018, arXiv pre
[6]    GuoDong, Z., Jian, S., Jie, Z., & Min, Z. (2002). Exploring various                     print arXiv:1802.05365.
       knowledge in relation extraction. Proceedings of the 43rd Annual                 [20]   Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever,
       Meeting on Association for Computational Linguistics (pp. 419‚Äì 444).                    Improving Language Understanding by Generative Pre-Training, 2018.
[7]    Zhao, S., & Grishman, R. (2005). Extracting relations with integrated                   article at openai.
       information using kernel methods. Proceedings of the 43rd Annual                 [21]   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
       Meeting on Association for Computational Linguistics (pp. 419‚Äì426).                     2018. BERT: Pre-training of Deep Bidirectional Transformers for
[8]    Lodhi, H., Saunders, C., Shawe-Taylor, J., & Cristianini, N. (2002).                    Language       Understanding.      CoRR      abs/1810.04805      (2018).
       Text classification using string kernels. Journal of Machine Learning                   arXiv:1810.04805
       Research (pp. 419‚Äì444).                                                          [22]   Mo Yu, Matthew R. Gormley, and Mark Dredze. 2014. Factor-based
[9]    Bunescu, R. C., & Mooney, R. J. (2005b). Subsequence kernels for                        compositional embedding models. In NIPS Workshop on Learning
       relation extraction. Neural Information Processing Systems, NIPS 2005,                  Semantics.
       Vancouver, British Columbia, Canada.                                             [23]   Shanchan Wu, Yifan He, Enriching Pre-trained Language Model with
[10]   Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods for                     Entity Information for Relation Classification, May, 2019. arXiv
       relation extraction. Journal of Machine Learning Research.                              preprint arXiv: 1905.08284.
[11]   Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao.                  [24]   Liang Yao, Chengsheng Mao, Yuan Luo, KG-BERT: BERT for
       2014. Relation Classification via Convolutional Deep Neural Network.                    Knowledge Graph Completion, Sept, 2019, preprint arXiv:1909.03193
       In COLING 2014, 25th International Conference on Computational                   [25]   Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, Tom
       Linguistics, Proceedings of the Conference: Technical Papers, 2014.                     Kwiatkowski, Matching the Blanks: Distributional Similarity for
[12]   Dongxu Zhang, Dong Wang, ‚ÄúRelation Classification via Recurrent                         Relation Learning, July, 2019, Proceedings of the 57th Annual Meeting
       Neural Network‚Äù, Aug 2015, arXiv pre-print arXiv: 1508.01006.                           of the Association for Computational Linguistics.
[13]   Yan Xu, Ran Jia, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, and                [26]   Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
       Zhi Jin. 2016. Improved relation classification by deep recurrent neural                Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, Attention is all
       networks with data augmentation. arXiv preprint arXiv:1601.03651.                       you need, June, 2017, preprint arXiv:1706.03762.
[14]   Cicero Nogueira Dos Santos, Bing Xiang, and Bowen Zhou. 2015.                    [27]   Tensorflow BERT Implementation, [online] https://github.com/google-
       Classifying Relations by Ranking with Convolutional Neural Networks.                    research/bert
       In Proceedings of the 53rd Annual Meeting of the Association for                 [28]   Iris     Hendrickx, Su     Nam      Kim, Zornitsa      Kozareva, Preslav
       Computational Linguistics and the 7th International Joint Conference on                 Nakov, Diarmuid        √ì      S√©aghdha      , Sebastian    Pad√≥, Marco
       Natural Language Processing of the Asian Federation of Natural                          Pennacchiotti, Lorenza Romano, Stan Szpakowicz, ‚ÄúSemEval-2010
       Language Processing, (ACL) 2015.                                                        Task 8: Multi-Way Classification of Semantic Relations Between Pairs
[15]   Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y.                      of Nominals‚Äù, July, 2010, Proceedings of the 5th International
       Ng. 2012. Semantic Compositionality Through Recursive Matrixvector                      Workshop on Semantic Evaluation.
       Spaces. In Proceedings of the 2012 Joint Conference on Empirical




                                                                                  315
        Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON)
Galgotias University, Greater Noida, UP, India. Oct 2-4, 2020




              Building Knowledge Graph using Pre-trained
               Language Model for Learning Entity-aware
                            Relationships
           Abhijeet Kumar                        Abhishek Pandey                               Rohit Gadia                            Mridul Mishra
        Emerging Tech Team                     Emerging Tech Team                         Emerging Tech Team                      Emerging Tech Team
        Fidelity Investments,                  Fidelity Investments,                       Fidelity Investments,                  Fidelity Investments,
          Bangalore, India                        Bangalore, India                           Bangalore, India                        Bangalore, India
      Abhijeet.Kumar@fmr.com                 Abhishek.Pandey@fmr.com                      Rohit.Gadia@fmr.com                    Mridul.Mishra@fmr.com


      Abstract‚Äî Relations exhibited among entities from textual                       knowledge graph aggregates information around entities in a
  content can be a potential source of information for any business                   structural way across multiple content sources and links these
  domain. This paper encompasses a wholesome approach to mine                         entities together. Also, it has the capability to provide entity-
  entity-relation and building knowledge graph from textual                           specific properties such as type, specific relation at the same
  documents. The paper concentrates on two approaches to classify                     time. We created one such financial knowledge graph using
  directional entity relations. We build on extending pretrained                      Neo4J database [2] to visualize the relationships among entities
  language model i.e. BERT for text classification along-side                         like Persons, Organizations and Locations.
  providing entity and directionality information as input making
  it entity-aware BERT classifier. We also did ablation studies of                        There are numerous approaches for extracting relationship
  presented model in terms of various ways of providing entity                        among entities (feature based and kernel-based) which rely on
  information on the learning capabilities of model. We                               NLP stack using POS tagging and dependency parsing [3]-
  demonstrate the end to end pipeline for building an entity-                         [10]. The major concern of these approaches is inability to
  relation extraction system in a business application. The                           capture numerous ways of expressing the similar relationship.
  techniques proposed in the paper are also evaluated against                         The challenging variability in syntactic and semantic nature of
  SemEval-2010 Task 8, a popular relation classification dataset.                     a sentence creates a need for effective solution which can
  The experimental results demonstrate that learning entity-aware                     extract entities as well as context that defines the relationship.
  relations through language models outperforms almost all the
                                                                                      This paper presents a language-model based solution which
  previous state-of-the-art (SOTA) models.
                                                                                      captures relationship between entities contextually and not only
      Keywords‚Äîknowledge graph, entity relations, relationship                        syntactically.
  extraction, deep learning, BERT, language models, graph database                        In recent years, the research has moved towards deep
                                                                                      networks which are effective in contextual learning for a given
                            I.     INTRODUCTION
                                                                                      task. Various architectures of RNN, LSTM and CNNs have
      Entity relationship classification is the task of identifying                   been proposed for sequence modeling or classification task.
  the semantic relation between the entities present in the text.                     These models have been effectively implemented for entity
  For example,                                                                        relation classification also [11]-[15]. More recently, Attention
                                                                                      based models became SOTA techniques for most of NLP tasks.
      ‚ÄúAmazon recently acquired PillPack for $1 billion‚Äù.
                                                                                      A lot of research with attention-based models for learning
  Here, Amazon and PillPack are two entities which has relation                       entity relations had been presented as SOTA models in past
  of ‚Äúacquisition‚Äù. In another complex example,                                       [16]-[18]. In last couple of years, language models have taken
                                                                                      the driving seat in this research direction where a pre-trained
  ‚ÄúHe was chief executive of Worldpay when it was acquired by                         language model (like ELMO [19], GPT [20], BERT [21] etc.)
  Vantiv in a ¬£9.3 billion takeover in 2017‚Äù.                                         has been trained on huge texts in a self-supervised way to learn
  Vantiv and Worldpay are two entities with relation                                  the syntactics and semantics of text sentences.
  ‚Äúacquisition‚Äù. At times, it is also crucial to know the                                 This paper demonstrates two BERT based architectures
  directionality of the relation. In first example, directionality of                 which is effective for relationship classification between
  relation Acquisition was from Amazon (e1) to PillPack (e2)                          entities. Major contributions presented are:
  whereas the same relation is from Vantiv (e2) to Worldpay (e1)
  in second example.                                                                     1.    Two proposed techniques are 1) Training a full
                                                                                               (K*2+1) way classifier where ‚ÄòK‚Äô is number of relation
      This task is indispensable in various NLP applications.                                  classes. We keep an artificial class ‚ÄòOthers‚Äô for
  Imagine with a plethora of news and articles getting generated                               capturing sentences where entities are present but
  every day, there is immense potential of knowledge that can be                               without relation of our interest. 2) Training two
  extracted for any domain. Knowledge graph is a powerful tool                                 classifiers, one binary classifier for directionality
  for supporting a gamut of search applications along with                                     prediction between entities and another K-way
  ranking, recommendation and exploratory search [1]. A



978-1-7281-5070-3/20/$31.00 ¬©2020 IEEE                                          310
        Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
        classifier for relation class prediction and further                                         III.    PROPOSED METHODOLOGY
        combining the results.
                                                                                   A. System Design
   2.   Through ablation study, we concluded the best format                           We formulated a pipeline which extracts predefined entities
        to provide entity information to finetuned language                        and their relations (from classification), and populates the
        model (BERT) classifier (See Section V.B).                                 searchable, visual and extensive knowledge graph.
   3.   We achieved SOTA results for relationship
        classification task with F1-score of 88.4% and 89.41%
        on the SemEval 2010 Task 8 dataset, outperforming all
        previous results [11]-[18][22][23].
                        II.    RELATED WORK
    There is extensive research ranging from unsupervised to
supervised techniques that attempts to solve for relation
extraction and knowledge mining. Rink et al. [5] used                              Fig. 1. Relation Extraction System Design
handcrafted features that capture the context, semantic role
affiliation, and possible pre-existing relations between entities.                     Figure. 1 depicts 5-step process flow of proposed relation
Research efforts have been made with deep learning methods                         extraction system with various components. Given an English
for learning long term dependency in entity relationships.                         article or document, a sentence tokenizer (step 1) is called and
Zhang et al. [12] and Socher et al. [15] applied RNN and                           then the entity recognizer (step 2) will demarcate possible
MVRNN model respectively for relation classification which                         entities in sentence like location, person or organization. In the
implements variants of recursive neural network.                                   following steps (3 and 4), a BERT based relation classifier is
                                                                                   run and binary entity-relation triplet is generated if relationship
    Deep convolutional neural network models were also                             like acquisition, relative-of, located-in and works-at is found.
employed for extracting lexical and sentence level features                        Once the system has labeled entity-relations triplets, it
using convolution kernels [11]. Dos Santos et al. proposed                         populates the nodes and links in graph database for knowledge
model for relation-classification task using a CNN that                            graph representation (step 5).
performs classification by ranking (CR-CNN) [14]. Research
efforts were made in employing attention levels in deep                            B. Model Architecture- Entity-aware BERT
network models in order to capture specific segment of                             We fine-tuned BERT [21] model in a specific way for
sentence which dictates the relations well [16][17][18]. Wang                      providing input as described in the later sub-sections. Any
et al. proposed CNN model relying on two levels of attention                       language model building has two phases of training: generic
in order to better discern patterns in heterogeneous contexts
                                                                                   pretraining step followed by finetuning on custom dataset
[17]. Lee et al. employed multi-head entity aware self-attention
                                                                                   (mostly limited dataset task). Often the pretraining of these
based Bi-LSTM models [18]. Yu et al. (2014) proposed a
Factor-based Compositional Embedding Model (FCM) by                                models are also extended as an additional step in case of
utilizing sentence-level and substructure embeddings from                          learning specific domain.
word embeddings, employing dependency trees and named
entities recognition (NER) [22].                                                      1) Input Representation
                                                                                       As per original BERT paper [21], a special classification
    Recently, few researchers have made efforts in exploring                       token [CLS] is the first token of the input sequence and end
pretrained language models like BERT for relationship                              token is [SEP]. In order to explicitly provide location
extraction. Yao et al. trained a knowledge graph KG-BERT to                        information, we inserted special symbolic tokens # and $
train triplet of entities and relation description as input to                     without gap to enclose the entities. Hence making it entity-
BERT [24]. Soares et al. presents a method of training relation                    aware BERT classifier. Given a sentence s = {w1, ‚Ä¶‚Ä¶,
representation without any supervision from a knowledge                            <e1>wh</e1>, ‚Ä¶. <e2>wt</e2>, ‚Ä¶wn} with marked entities (h,
graph or human annotators by matching the blanks [25]. Wu et                       t), we convert it to s = {[CLS], w1, ‚Ä¶, #wh#, ‚Ä¶$wt$, ‚Ä¶wn,
al. proposed entity embeddings as well as the sentence                             [SEP]}. For example, an input text sequence is passed to model
encoding from BERT as the input to a multi-layer neural                            in the following manner.
network for classification [23].
                                                                                       [CLS] Louise is a director, audit chair and finance
    Although these models achieve good results, ideally, A                         #committee# $member$ of a public health board and was a
simple yet effective solution would be one which does not                          director of AFAANZ for 3 years [SEP]‚Äù
require handcrafted features, dependency parsing or training
multiple models. In Section 4, through experiments we show                             The above sentence is a training sentence of SemEval
that finetuning a pretrained language model with entity aware                      dataset [28] from Member-Collection (e2, e1) relation class
raw text input simply achieves this, while also obtaining                          with directionality e2 to e1.
considerable improvements in F1 scores. Section 5 writes                              2) Model Architecture
about error analysis and ablation studies to arrive at best format                     We have utilized pre-trained model BERT base from
of providing text input to model. In next section, both the                        Google‚Äôs BERT TensorFlow implementation [27] and
architectures are discussed along with overall system pipeline                     finetuned it for entity-relation classification. The model
design and knowledge graph generation.



                                                                             311
     Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
architecture shown in Figure. 2 depicts the way input sequence
is provided to make it entity-aware.




                                                                                    Fig. 3. 2-Model BERT classifier design

                                                                                        The proposed 2-model architecture is shown in Figure 3.
Fig. 2. Entity-aware Finetuned BERT classifier                                      As shown in the diagram, Directionality is considered only if
                                                                                    relation classifier predicts some relation class, not the artificial
    The final hidden state corresponding to special                                 class ‚ÄúOther‚Äù. We examined the performance of both the
classification token ([CLS]) is used as the aggregated sequence                     model individually. Only relation classification model achieved
representation for classification tasks [21]. The classification                    F1-score of 86.6% whereas binary directional classifier
parameters introduced during fine-tuning are W ‚Ä´ ◊ê‚Ä¨R(K*2 +1) √ó768,                    achieved F1-score of 97% on SemEval 2010 dataset.
where K is the no. of relation classes. We compute a typical                        Moreover, we achieved results better than most of the previous
softmax loss for classification with C and W, i.e.,                                 works and comparable to SOTA models on combining both the
log(softmax(CWT)). The scoring function for a relation                              relation and directionality classification models (See section
classification is                                                                   4.B).
                     F(r) = softmax(C.WT )                                          D. Knowledge Graph
                                                                                        A knowledge graph is developed using graphical method
   The hyperparameters settings                        for   BERT     based         that keeps association as well as hierarchical knowledge of
implementations are as follows:                                                     domain. We employed Neo4J for visualizing and searching
                                                                                    entity-relationships as shown in a sample snippet below (Fig
             TABLE I.         BERT-BASE HYPERPARAMTERS
                                                                                    4).
              Hyperparameters                    Value

              Max Sequence Length                64

              No. of Training Epochs             5

              Train Batch Size                   64

              Warmup Proportion                  0.1

              Learning Rate                      5e-5

              Dropout                            0.1

C. BERT based 2-Model Architecture
    We propose another approach ‚Äú2-model BERT‚Äù for solving
the relationship classification task with directionality. We
trained two BERT based classifier on the same training data in
a similar way as directed in section B. First classifier learns the
relations class whereas second binary classifier learns the                         Fig. 4. Entity-aware Finetuned BERT classifier
directionality of the relationship provided the entity located
with markers.




                                                                              312
      Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                 IV.     EXPERIMENT AND RESULTS                                    Table III. Intuitively, entity marking helps a lot in learning as
                                                                                   BERT is heavily based on multi-head self-attention layers.
A. SemEval 2010 Dataset
    We used SemEval-2010 Task 8 dataset for benchmarking                                      TABLE III.      SEMEVAL-2010 TASK 8 (APPROACH-1)
both the proposed architectures [28]. This dataset consisted of
8,000 examples as training data, and 2717 sentences as testing                                Models                                       F1-Score
set. There are nine types of annotated relations between                                      2-Model BERT with No Entity info.            78.84
entities along with demarcation of entities. Refer to Table IV
for all nine label names of annotated relations. There is an                                  2-model BERT                                 88.44
additional relation type ‚ÄúOther‚Äù (artificial class) which                                     BERT with No Entity Info.                    81.40
indicates that the relation expressed in the text is not among
the nine types. In this dataset, each of the relation types,                                  Entity-aware BERT                            89.41
directionality information is also present which implies that
relationship between entities can be from e1 to e2 or vice
versa. For example, Entity-Origin (e1, e2) and Entity-Origin                       B. Effect of Entity Markers
(e2, e1) can be considered two distinct relations, so the total
number of relationship classes is 19.                                                  The idea behind performing these experiments was to
                                                                                   understand if choosing entity marker also impacts the learning
B. Experimental Results & Comparison                                               of BERT language model. From numerous experiments, it was
   As discussed earlier in the paper, we experimented with                         concluded that symbolic markers like $, # performs better than
two proposed approaches for this dataset. Details about the                        alphabetic marker. One of the possible reasons would be
model architecture are described in section 3.                                     alphabetic markers surrounding entities distorts the language
                                                                                   representation learnt by language models.
    The official scorer was used to evaluate all our model
experiments in terms of the Macro-F1 score over the nine                           Also, entities with symbolic markers without leaving space
relationship pairs taking directionality into account. We also                     marginally performs better than leaving space. Table. 1 shows
compare the results with scores quoted in previous works on                        effect of entity markers in terms of F1-score for each class as
this dataset (shown below).                                                        well as overall macro-averaged score by semval-2010 offline
                                                                                   scorer.
         TABLE II.        SEMEVAL-2010 TASK 8 (APPROACH-1)
                                                                                              TABLE IV.       SEMEVAL-2010 TASK 8 (APPROACH-1)
   Models                                                 F1-Score
                                                                                                                    F1-score (different entity markers)
   SVM [5]                                                82.2                             Classes             E1 start, E1
                                                                                                              end, E2 start,        $,#            $, # (no space)
   RNN [15]                                               77.6                                                   E2 end

   MVRNN [15]                                             82.4                       Cause-Effect           93.53                  94.42               93.74

   FCM [22]                                               83.0                       Component-Whole        84.58                  83.52               86.35

   CNN+ Softmax [11]                                      82.7                       Content-Container      90.16                  87.94               90.82

   CR-CNN [14]                                            84.1                       Entity-Destination     91.76                  93.31               92.97
   Attention CNN [16]                                     85.9                       Entity-Origin          88.68                  88.05               89.27
   DRNNs [13]                                             85.8                       Instrument-Agency      79.01                  81.39               82.96
   Multi-level Att-Pooling-CNN [17]                       88.0                       Member-
                                                                                                            87.12                  88.37               88.37
                                                                                     Collection
   Entity Attention Bi-LSTM [18]                          85.2
                                                                                     Message-Topic          92.05                  91.68               91.71
   R-BERT                                                 89.25
                                                                                     Product-Producer       86.15                  87.90               88.51
   2-Model BERT                                           88.44
                                                                                     _Other                 63.67                  65.31               64.69
   Entity-aware BERT                                      89.41
                                                                                     All Classes            88.12                  88.51               89.41
        V.      ABLATION STUDIES AND ERROR ANALYSIS
A. Effect of Entity Information
                                                                                   C. Effect of Training Epochs
    In order to understand the importance of providing entity
information, we ran the proposed model (Approach-I) without                            Optimal number of epochs for finetuning BERT was found
entity marking. The experimental results are shown in the                          to be 5 for the dataset as shown in Figure.5.




                                                                             313
     Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                                                                                        TABLE VI.        MISSCLASSIFICATION EXAMPLES (ACTUAL-OTHER)

                                                                                      #Danger# is part of the Palestinian             Other     Component-
                                                                                      journalist's daily ÕÑroutine$                              Whole(e2,e1)

                                                                                      The painting shows a historical view of the     Other     Cause-
                                                                                      #damage# caused by the 1693 Catania                       Effect(e2,e1)
                                                                                      earthquake and
                                                                                      the $reconstruction$ activities.

                                                                                                                                                Entity-
                                                                                      The #yeast# is an ingredient for                Other     Origin(e2,e1)
                                                                                      making ÕÑ¬Ñ¬á¬á¬îÕÑ.
Fig. 5. F1-score versus Training epochs (optimal=5)
                                                                                                  VI.     CONCLUSION AND FUTURE WORK
D. Error Analysis: Where it failed ?
    We examined the misclassified examples produced by the                              The objective of the research and experimentation was to
model to understand the possible reasons of failure.                                construct in-domain large scale searchable knowledge graph to
Interestingly, approximately 80% of the misclassifications                          visualize various entities and the way they are related to each
were result of either incorrectly predicting a relation as                          other. In this paper, we utilized the advantage of language
artificial class ‚ÄúOther‚Äù or vice versa.                                             knowledge already learnt by language models and enriched
                                                                                    them by incorporating entity aware information to provide
    Firstly, some of the examples wrongly predicted as ‚ÄúOther‚Äù                      attention for entity relation classification (2*k+1 way). We also
category contains words or context phrases (shown in bold)                          proposed two-model architecture to separately deal with
which were unseen in the training sentences. The model                              relation class as well as directionality of relation. Through
possibly could not get the context and predicted the artificial                     ablation studies, we found that symbolic markers enclosing the
class wrongly. Few examples of such misclassifications are                          entity words without gap is the best way to provide text input
shown in Table V. Another intuition is the generic nature of                        format for relation classification with finetuned BERT. We
text sequences in ‚ÄúOther‚Äù class may confuse model and lead to                       conduct experiments on the SemEval-2010 task 8 benchmark
incorrect prediction for some of such sentences of actual                           dataset. Both the proposed models namely entity-aware BERT
relation classes also.                                                              and 2-model BERT achieve SOTA results of 88.44% and
                                                                                    89.41% F1-score respectively in SemEval-2010 Task 8 without
   TABLE V.        MISSCLASSIFICATION EXAMPLES (PREDICTED-OTHER)                    any explicit embeddings or high-level features from NLP tools.
 #Fish# without the pyloric ceca have                                                   As future directions, we intend to explore multi-label
                                                Component-           Other
 digestive enzyme production in
                                                Whole(e2,e1)
                                                                                    classification task for scenarios where presence of more than
 the $liver$ and pancreas.                                                          two entities in a sentence makes relationship extraction
                                                                                    ambiguous. A limitation of our proposed system in the paper is
 The #body# unleashes its
 extraterrestrial $passenger$, which proceeds
                                                Entity-              Other          that it extracts relation on the sentence level. Relations can
                                                Origin(e2,e1)                       span over sentences also. We intend to modify our systems to
 to infect the student population at a
 breakneck pace.                                                                    capture long range relations. We also look forward to
                                                                                    employing domain specific custom pre-trained model in order
 These #observations# determine the high                                            to improve accuracy of system.
                                                Message-             Other
 spatial resolution stellar $kinematics$
                                                Topic(e1,e2)
 within the nuclei of these galaxies.                                                                        ACKNOWLEDGMENT
 The Postmodernism Generator was written                                                This research was supported by Asset Management Group,
                                                Product-             Other
 by Andrew C. Bulhak using the Dada             Producer(e1,e2)                     Fidelity Investments. We thank colleagues from emerging tech
 Engine, a system for generating random                                             team for providing valuable insight and expertise that assisted
 #text# from recursive $grammars$.                                                  the research.
                                                                                       The views or opinions expressed in this paper are solely
    Secondly, the model may learn relation classes focusing on                      those of the author and do not necessarily represent those of
the prepositional phrases between entities through attention                        Fidelity Investments. This research does not reflect in any way
mechanism e.g. ‚Äúis part of‚Äù phrase mostly shows either                              procedures, processes or policies of operations within Fidelity
Component-Whole or Member-Collection relation class in                              Investments.
training data. But some of the examples from Other class in
test set have such relation defining phrases which confuses the
model (few are shown in Table VI).




                                                                              314
      Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
                                REFERENCES                                                     Methods in Natural Language Processing and Computational Natural
                                                                                               Language Learning (EMNLP-CoNLL ‚Äô12).
[1]    Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao,
       Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang.                      [16]   Yatian Shen and Xuanjing Huang. 2016. Attention-based Convolutional
       2014. Knowledge vault: A web-scale approach to probabilistic                            Neural Network for Semantic Relation Extraction. In Proceedings of
       knowledge fusion. International Conference on Knowledge Discovery                       COLING 2016, the 26th International Conference on Computational
       and Data Mining, KDD ‚Äô14, pages 601‚Äì 610. ACM.                                          Linguistics: Technical Papers. 2526‚Äì2536.
[2]    Neo4J Database, [online] https://neo4j.com/                                      [17]   Linlin Wang, Zhu Cao, Gerard de Melo, and Zhiyuan Liu. 2016.
                                                                                               Relation Classification via Multi-Level Attention CNNs. In Proceedings
[3]    Bach, Nguyen, and Sameer Badaskar. ‚ÄúA review of relation                                of the 54th Annual Meeting of the Association for Computational
       extraction.‚Äù Literature review for Language and Statistics II 2 (2007).                 Linguistics.
[4]    Kambhatla, N. (2004). Combining lexical, syntactic, and semantic                 [18]   Joohong Lee, Sangwoo Seo, and Yong Suk Choi. 2019. Semantic
       features with maximum entropy models for extracting relations.                          Relation Classification via Bidirectional LSTM Networks with
       Proceedings of the ACL 2004.                                                            Entityaware Attention using Latent Entity Typing. CoRR (2019).
[5]    GBryan Rink and Sanda Harabagiu. 2010. Utd: Classifying semantic                 [19]   Matthew        E.     Peters, Mark     Neumann, Mohit        Iyyer, Matt
       relations by combining lexical and semantic resources. In Proceedings                   Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, Deep
       of the 5th International Workshop on Semantic Evaluation. 256‚Äì259.                      Contextualized Word Representations, Feb 2018, arXiv pre
[6]    GuoDong, Z., Jian, S., Jie, Z., & Min, Z. (2002). Exploring various                     print arXiv:1802.05365.
       knowledge in relation extraction. Proceedings of the 43rd Annual                 [20]   Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever,
       Meeting on Association for Computational Linguistics (pp. 419‚Äì 444).                    Improving Language Understanding by Generative Pre-Training, 2018.
[7]    Zhao, S., & Grishman, R. (2005). Extracting relations with integrated                   article at openai.
       information using kernel methods. Proceedings of the 43rd Annual                 [21]   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
       Meeting on Association for Computational Linguistics (pp. 419‚Äì426).                     2018. BERT: Pre-training of Deep Bidirectional Transformers for
[8]    Lodhi, H., Saunders, C., Shawe-Taylor, J., & Cristianini, N. (2002).                    Language       Understanding.      CoRR      abs/1810.04805      (2018).
       Text classification using string kernels. Journal of Machine Learning                   arXiv:1810.04805
       Research (pp. 419‚Äì444).                                                          [22]   Mo Yu, Matthew R. Gormley, and Mark Dredze. 2014. Factor-based
[9]    Bunescu, R. C., & Mooney, R. J. (2005b). Subsequence kernels for                        compositional embedding models. In NIPS Workshop on Learning
       relation extraction. Neural Information Processing Systems, NIPS 2005,                  Semantics.
       Vancouver, British Columbia, Canada.                                             [23]   Shanchan Wu, Yifan He, Enriching Pre-trained Language Model with
[10]   Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods for                     Entity Information for Relation Classification, May, 2019. arXiv
       relation extraction. Journal of Machine Learning Research.                              preprint arXiv: 1905.08284.
[11]   Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao.                  [24]   Liang Yao, Chengsheng Mao, Yuan Luo, KG-BERT: BERT for
       2014. Relation Classification via Convolutional Deep Neural Network.                    Knowledge Graph Completion, Sept, 2019, preprint arXiv:1909.03193
       In COLING 2014, 25th International Conference on Computational                   [25]   Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, Tom
       Linguistics, Proceedings of the Conference: Technical Papers, 2014.                     Kwiatkowski, Matching the Blanks: Distributional Similarity for
[12]   Dongxu Zhang, Dong Wang, ‚ÄúRelation Classification via Recurrent                         Relation Learning, July, 2019, Proceedings of the 57th Annual Meeting
       Neural Network‚Äù, Aug 2015, arXiv pre-print arXiv: 1508.01006.                           of the Association for Computational Linguistics.
[13]   Yan Xu, Ran Jia, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, and                [26]   Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
       Zhi Jin. 2016. Improved relation classification by deep recurrent neural                Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, Attention is all
       networks with data augmentation. arXiv preprint arXiv:1601.03651.                       you need, June, 2017, preprint arXiv:1706.03762.
[14]   Cicero Nogueira Dos Santos, Bing Xiang, and Bowen Zhou. 2015.                    [27]   Tensorflow BERT Implementation, [online] https://github.com/google-
       Classifying Relations by Ranking with Convolutional Neural Networks.                    research/bert
       In Proceedings of the 53rd Annual Meeting of the Association for                 [28]   Iris     Hendrickx, Su     Nam      Kim, Zornitsa      Kozareva, Preslav
       Computational Linguistics and the 7th International Joint Conference on                 Nakov, Diarmuid        √ì      S√©aghdha      , Sebastian    Pad√≥, Marco
       Natural Language Processing of the Asian Federation of Natural                          Pennacchiotti, Lorenza Romano, Stan Szpakowicz, ‚ÄúSemEval-2010
       Language Processing, (ACL) 2015.                                                        Task 8: Multi-Way Classification of Semantic Relations Between Pairs
[15]   Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y.                      of Nominals‚Äù, July, 2010, Proceedings of the 5th International
       Ng. 2012. Semantic Compositionality Through Recursive Matrixvector                      Workshop on Semantic Evaluation.
       Spaces. In Proceedings of the 2012 Joint Conference on Empirical




                                                                                  315
        Authorized licensed use limited to: San Jose State University. Downloaded on September 14,2023 at 00:54:26 UTC from IEEE Xplore. Restrictions apply.
Knowledge Graphs for Financial Services   1




  Knowledge Graphs for
  Financial Services
  The path to unlock new insights
  from your data
Knowledge Graphs for Financial Services     2




  ‚ÄúLogic will get you from A to B.
   Imagination will take you everywhere.‚Äù
     Albert Einstein
Knowledge Graphs for Financial Services                             3




Preface‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. 4

What are Knowledge Graphs?‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶. 5

Use Cases

      360¬∞ View of Risk & Value ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶.‚Ä¶.6

      Compliance Management ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶..‚Ä¶‚Ä¶7

      Data Lineage & Metadata Management‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶..‚Ä¶‚Ä¶.8

      Fraud Detection & Financial Crime Analytics‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶.‚Ä¶‚Ä¶..‚Ä¶‚Ä¶‚Ä¶9

      Recommender Systems & Conversational AI‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.10

Three Pillars of our Knowledge Graph Services‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶12

Conclusion‚Ä¶.‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶..‚Ä¶13

Contact‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶14
Knowledge Graphs for Financial Services                                                                   4



Preface
Today, companies are relying more and more on ArtiÔ¨Åcial Intelligence (AI) applications
in their day-to-day decision making. Without context, these AI applications may never
reach their full potential as reliable solutions to address complex business needs.
Knowledge Graphs enable machines to incorporate human expertise for making
meaningful decisions and bring context to AI applications.




The new wave of AI is focused                      This enables users to quickly access two closely
                                                   connected objects and adapt the connection based
on hybrid intelligence that
                                                   on the context, for example both a small enterprise
means learning (data) fused                        and a private individual as customers of the same
with reasoning (knowledge).                        organization may be given the same risk rating due to
                                                   closely matching activities.
Connecting datasets in a meaningful way is
strategic for every business as it enables         Major institutions are commonly faced with
decision makers, users, and (above all)            thousands of isolated ‚Äúdata silos‚Äù, hence facing an
computers gain context on the existing             information overload challenge. Knowledge Graphs
knowledge of an organization. For enterprises      can serve as a hub of integrated knowledge by
to stay competitive in the current knowledge       processing disparate sources and extracting atomic
economy, it is crucial to manage knowledge         units of knowledge from diverse datasets. Moreover,
eÔ¨Éciently and be ready for changes that might      they provide contextual adaptation, and reasoning
serve either as a threat or opportunity to their   capabilities that go beyond the conventional machine
business. That‚Äôs where Knowledge Graphs            learning approaches.
come into play and why tech giants like
Amazon, Facebook, Microsoft and Google
have invested millions of dollars to create        The impact of Knowledge Graphs in Ô¨Ånancial services
their own Knowledge Graphs.                        is just in its inception where the role of knowledge
                                                   scientists to build bridges between business
Knowledge Graphs allow for processing and          requirements, questions and data is becoming more
representation of data and knowledge in a          and more important. In this article, we highlight some
format which is very close to the way a human      example use cases of Knowledge Graphs to
brain processes and stores information.            demonstrate the value of Knowledge Graphs for
                                                   data-driven businesses.
Knowledge Graphs for Financial Services                                                                      5



What are Knowledge Graphs?
A Knowledge Graph is a means to connect and represent knowledge in an area of interest
using a graph-like structure. It is typically built on top of existing databases to link data
together at web-scale, combining both structured and/or unstructured information. As
opposed to the more commonly used relational data models, a graph model is built as a
collection of concepts or entities and the relationships between them.



                                    Thinking, Fast and Slow


   You could see Knowledge Graphs as the brain of a company with two systems of thinking:


   System 1 (Thinking fast)                                                  System 2 (Thinking slow)
   that is intuition-based,                                                  that is logic-based, eÔ¨Äortful
   automatic and error-prone                                                 and capable of making
   to quickly learn from the                                                 complex yet explainable
   past observations.                                                        decisions.

   This system of Knowledge                                                  This system of Knowledge
   Graphs is powered by                                                      Graphs is powered by
   statistical AI approaches                                                 symbolic AI approaches
   such as Machine Learning.                                                 such as Knowledge
                                                                             Representation & Reasoning.
                                                  1   2




                  As an example of system 2, let‚Äôs read the following sentence:
           ‚ÄúA red truck with a siren and a ladder attached to its side rushed in the city‚Äù.
  What do you understand from this sentence? As a human you might already think that the
  vehicle was most likely a fire truck; or there was probably a fire somewhere in the city; and
  many more logical conclusions. However, as a machine it would be very hard to make all those
  connections and come up with the above reasoning due to the lack of background and
  common-sense knowledge.


A Knowledge Graph brings together Machine Learning and Graph technologies to give AI the context it
needs. Knowledge Graphs represent a complex network of information in a meaningful way (in a similar
way to human intelligence) by integrating data from a wide range of data silos and incorporating
learning and reasoning.
Knowledge Graphs for Financial Services                                                                                  6
Use Cases

360¬∞ View of Risk & Value
Knowledge Graphs allow companies to connect the dots in their business and see the
big picture for evaluating risk and value.


The challenge for Ô¨Ånancial            In order to seamlessly integrate
institutions seeking competitive      large enterprise data silos,                    Applications
advantages in the market is not a     companies do not only need to
lack of information. It is an over-   unify various data models and            - Know Your Customer
supply of information from            formats, but also need to                   (KYC)
diverse sources with complex          harmonize data based on its              - Due Diligence
and vast amounts of data.             meaning.                                 - Investment Research
                                                                               - Insurance Underwriting &
                                                                                 Claim Processing
Big Data technologies have            Knowledge Graphs enable
                                                                               - Commercial Real-Estate
empowered companies to ingest         companies to semantically
substantial volumes of data and       integrate diverse data and draw
store it in multiple data silos.      connections at an unprecedented
Bridging these data silos brings      scale. They also allow users to
limitless opportunities for           connect external sources of data
companies to assess risk and          eÔ¨Éciently, regardless of their
value across multiple domains.        underlying data formats and
                                      models.                            Example

                                                                         Imagine an international bank that wants to
                                                                         use their customer data for identification of
                                                                         high-risk customers to avoid sanctions.
                                                                         This would require a deep dive into the
                                                                         customer data, understand the diÔ¨Äerent
                                                                         attributes and create a risk classification
                                                                         while ensuring links to the relevant
                                                                         sources of information such as financial
                                                                         transactions, customer‚Äôs family
                                                                         relationships, as well as regulations.

                                                                         Using a Knowledge Graph, the bank can
                                                                         see all the customers information, risk
                                                                         dimensions, and regulations that are
                                                                         relevant for their specific goal, linked
                                                                         together based on their meaning, in one
                                                                         place for deep analysis.




                  Knowledge Graphs empower business
                     users to see the whole story.
Knowledge Graphs for Financial Services                                                                                  7
Use Cases

Compliance Management
Interlinking company data with various compliance data sources such as internal
policies, legislations, standards and other private contracts in a Knowledge Graph
enables companies to better manage compliance.


                                                                                        Applications
Finding ways to remain compliant         Knowledge Graphs leverage
with ever-changing and growing           the power of semantic
universe of regulations, policies and    technologies to not only unify          - Regulatory Reporting
internal contracts has become one of     and interlink various sources           - Trade Surveillance
the most visible challenges of today‚Äôs   of compliance data, but also            - Insider Trading Surveillance
companies.                               to apply complex rules and
                                         patterns for (semi-)
Financial compliance requires            automated compliance
companies to maintain sophisticated      monitoring.
customer screening and transaction
surveillance systems that pose data      In order to optimize
quality and data availability            compliance check, Knowledge
challenges. Current compliance           Graphs combine contextual
systems are focusing mainly on data      domain knowledge with
collection and data consolidation,       Natural Language Processing
leaving less time for in-depth           (NLP) and Machine Learning.      Example
analysis.
                                                                          Imagine a local company seeking to
                                                                          branch out to other countries and
                                                                          markets. In order to trade abroad and to
                                                                          localize its products and services to other
                                                                          countries, the company needs to take into
                                                                          account the legal barriers applicable to the
                                                                          target market. Dealing with legal and
                                                                          regulatory compliance data is a
                                                                          cumbersome task that needs to access
                                                                          huge volumes of digital compliance
                                                                          documents and integrate them with
                                                                          internal company data.

                                                                          Utilizing a Knowledge Graph allows this
                                                                          company to eÔ¨Éciently identify relevant
                                                                          regulations, link its data to those
                                                                          regulations and to define patterns for
                                                                          automatic compliance check.




  Knowledge Graphs allow companies to bring together diÔ¨Äerent sources of
  compliance in a meaningful way and apply automated compliance checks.
Knowledge Graphs for Financial Services                                                                                     8
Use Cases

Data Lineage & Metadata Management
Knowledge Graphs allow companies to trace their data journey in the right context and
improve the quality of their data Ô¨Çows.


A common issue today‚Äôs data-           The combination of detailed
driven companies face is tracking      metadata and relationships                        Applications
data throughout its lifecycle.         between data lifecycle phases
Whether acquired externally or         results in a semantic data layer.
                                                                                   - Risk Data Aggregation &
generated from internal services,      A semantic data layer (also known
                                                                                     Reporting
data needs to be tracked as it is      as data fabric) enables both data
                                                                                   - Master Data Management
utilized, manipulated, and             experts and business                        - Data Migration for
transformed throughout the             stakeholders to take advantage of             Consolidating Mortgage
organization.                          any data asset to which they have             Systems or On-boarding
                                       access.                                       New Data Feeds

The challenge is that complex
data neither explains itself nor its   Knowledge Graphs provide a
journey. And, data is only             semantic layer with full view of
valuable in the context of what it     the data lifecycle all the way from
means to its stakeholders. Thus,       the business to the most
data must be described with            technical components.
relevant metadata and be                                                     Example
organized in a way that reÔ¨Çects
                                                                             Imagine a company that is in a merger
its meaning and Ô¨Åtness to use.                                               process and needs to migrate all the
                                                                             Customer Relationship Management
                                                                             (CRM) data from the acquired company to
                                                                             its current data lake. To ensure the quality
                                                                             of data, the data managers would like to
                                                                             know the data changes over time and
                                                                             know what manipulations were applied to
                                                                             source data that resulted in its current
                                                                             form.

                                                                             Using a Knowledge Graph solution, the
                                                                             company can get an overview of the data
                                                                             lifecycle together with the sources used
                                                                             and all their dependencies to allow data
                                                                             managers make better decisions for data
                                                                             integration and quality improvement.




                Knowledge Graphs allow to keep track of your data
                 journey meaningful to its different stakeholders.
Knowledge Graphs for Financial Services                                                                                       9
Use Cases

Fraud Detection & Financial Crime Analytics
Augmented analytics provided by Knowledge Graphs & Machine Learning enables
companies to identify fraudulent patterns and investigate speciÔ¨Åc criminal links.


Today‚Äôs Ô¨Ånancial institutions are         Trying to scale these large
contending with measures for Anti-        queries to return real-time data                Applications
Money Laundering (AML), Suspicious        is impossible in most cases as
Activity Reports (SAR), counterfeiting,   the number of connections and            - Spotting fraud, which applies
as well as synthetic, Ô¨Årst-party, and     patterns grow.                             to fraudulent transactions
                                                                                     and applications in banking,
card-not-present fraud.
                                                                                     benefits fraud in
                                          Knowledge Graphs empowered
                                                                                     government, tax fraud,
Frequently, fraud happens relatively      by machine learning and                    applications and claims
quickly and with a convoluted             reasoning capabilities allow               fraud in insurance.
network of transactions that mix and      companies to better identify             - Anti Money Laundering
blend the identity and funds through      fraudulent patterns by
multiple channels that are hard to        traversing many hops on very
detect.                                   large amounts of
                                          interconnected data in
The traditional relational database       real-time.
systems for fraud detection require                                          Example
a lot of complex series of joins that
                                                                             Imagine an insurance company that wants
are often complex to build.
                                                                             to detect fraud schemes. Insurance fraud
                                                                             is usually from complex networks that are
                                                                             diÔ¨Écult to detect for insurance and
                                                                             financial institutions. Fraudsters usually
                                                                             forge fake identities, file several claims and
                                                                             cash the insurance checks. Creating fake
                                                                             identities requires forgery of personal
                                                                             information (social security numbers,
                                                                             addresses, credit cards, etc), to submit to
                                                                             insurance companies to become a
                                                                             customer. Fraudsters often recycle this
                                                                             data to create several fake identities.


                                                                             Using a Knowledge Graph for entity
                                                                             resolution and a visual analytics interface,
                                                                             the company can easily detect clusters of
                                                                             fake claims.



          Knowledge Graphs allow monitoring, categorizing, and
                 predicting potential points of threats.
Knowledge Graphs for Financial Services                                                                              10
Use Cases

Recommender Systems and Conversational AI
Knowledge Graphs enable fact-based recommendations that accumulate contextual
knowledge with each conversation.


The goal of a recommender system      A Knowledge Graph is built as a
is to deal with an overload of        large semantic network of                       Applications
information by Ô¨Åltering vital         entities and their attributes.
information fragments out of a        Therefore, it allows Ô¨Ånding the          -   Conversational Commerce
large amount of information.          best matching entities based on          -   Customer Service Chatbots
                                      semantic similarities between            -   Product Recommendations
                                                                               -   Enterprise Search & Content
In order to provide                   the entities. Knowledge Graphs
                                                                                   Classification
recommendations that match            also allow enriching the context
user‚Äôs intent, preferences and        of data by incorporating
interest, a recommender system        domain-speciÔ¨Åc knowledge
needs to know about the context       vocabularies, taxonomies or
of conversation and must be           ontologies.
capable of not only looking at
structural similarity between items   The personalized experience
but also their semantic similarity.   provided by Knowledge Graphs
                                                                          Example
For example the word ‚Äúbalance‚Äù        enables conversational banking
might convey diÔ¨Äerent meanings        tools to more eÔ¨Äectively interact   Imagine a big retail company that wants to
when used in a Ô¨Ånancial               with customers on their             build a conversational commerce platform
conversation as opposed to a          banking needs.                      where its customers could interact with a
                                                                          bot similar to the way they interact with a
medical context.
                                                                          salesperson in their shop. The company
                                                                          has more than 10,000 product categories
                                                                          and more than 100,000 attributes such as
                                                                          brand, colour, and any other attribute
                                                                          about an object that customers can buy.
                                                                          They failed when they tried a rules-based
                                                                          engine to support such a huge catalog,
                                                                          with more than million items in inventory.


                                                                          Using a Knowledge Graph solution, the
                                                                          company can store relationships between
                                                                          various sources of information such as
                                                                          products, customer interests, and
                                                                          purchase history and quickly query it to
                                                                          make recommendations that are
                                                                           personalized and relevant to customers.

     Knowledge Graphs provide context-driven recommendations.
Knowledge Graphs for Financial Services   11




     A Knowledge Graph is worth
     a thousand words.
Knowledge Graphs for Financial Services                                                                         12



Three Pillars of our Knowledge Graph Services


The eÔ¨Äective design and implementation of Knowledge Graphs requires 3 components:
a) bridging diverse data silos regardless of data formats, serializations,
conceptualizations, and technology ecosystems, b) investigating interconnected data to
Ô¨Ånd out insightful patterns and c) deriving context-relevant knowledge from the large
amounts of integrated data.

This component deals with extracting                              This component deals with diÔ¨Äerent kinds of
knowledge from data.                                              graph analysis to identify patter ns in
Machine reasoning methods supported by                            interconnected data. Methods such as path
semantic technology standards such as RDFS,                       analysis to determine the shortest distance
OWL and SHACL allow our solution to derive                        between nodes, connectivity analysis to
new facts from data. Additionally, advanced AI                    determine weak/strong nodes, community
machine learning techniques such as Graph                         analysis to find groups of related nodes and
Convolutional Networks (GCN) are applied to                       centrality analysis to identify the most
graph data to predict new links and learn                         influential nodes in the graph are applied to the
complex graph patterns.                                           underlying graph.




                      This component deals with data distribution, harmonization,
                      integration and storage at scale. Linked Data standards such as
                      HTTP, URIs and RDF data model are used to represent data in a
                      single interchangeable format that is both understandable by
                      machines and humans.
                      Additionally, multi-model graph databases are incorporated to
                      support multiple data models against a single, integrated backend.
Knowledge Graphs for Financial Services                                                                  13



Conclusion

Knowledge is every company's most valuable asset,      In this report, we shortly touched upon some
however it is scattered across diÔ¨Äerent systems and    example use cases of Knowledge Graphs for
human minds. This decentralized nature of              Ô¨Ånancial services. Knowledge Graphs are already
knowledge makes it hard to grasp and increases the     in use in industries such as public sector,
challenges for organizations. The key to integrating   healthcare & life sciences, energy, resources &
knowledge eÔ¨Éciently among various systems and          industrial sector, technology & media sector, etc.
human users is to provide knowledge representation     Some other prominent use cases can be found in
and reasoning in a machine-readable form.              the following domains:


Creating a Knowledge Graph with semantic               - Personalized health
description of information context allows users to     - Logistics & supply chain management
access a machine-readable representation of            - Industry 4.0 in automation & manufacturing*
complex interdependencies that form a real-world       - IoT data integration & management
model of the knowledge domain.                         - 360¬∞ view of criminals cases
                                                       - Network / IT/ cloud resource optimization and
                                                         maintenance
                                                       - TraÔ¨Éc management
                                                       - Geospatial analytics
                                                       - Performing grid and network quality of service
                                                       - Preventing cyber attacks


                                                       *If you are interested to know more about
                                                       applications of Knowledge Graphs in industry 4.0,
                                                       you can read the following Deloitte article:




                                                                                Wisdom of Enterprise
                                                                                Knowledge Graphs:
                                                                                The path to collective
                                                                                intelligence within
                                                                                your company
Knowledge Graphs for Financial Services                                                                                        14



 Contact
Contact

                  Dr. Ali Khalili                                                               Janvier Jessurun
                  Junior Manager Risk Advisory                                                  Senior Manager Risk Advisory
                  alkhalili@deloitte.nl                                                         jjessurun@deloitte.nl
                  +31650074011                                                                  +31683339436




                  Stuti Oberoi                                                                  Marko van Zwam
                  Senior Consultant Risk Advisory                                               Partner Risk Advisory
                  stoberoi@deloitte.nl                                                          mvanzwam@deloitte.nl
                  +31650055356                                                                  +31621272904




                                                                                                          Stuti Oberoi
       Marco van Zwam
                                                                                                         Eminence Lead
       Sponsoring Partner




                                    Janvier Jessurun
                                     Business Lead
                                                                          Ali Khalili
                                                                        Technical Lead

                                                                                                         Alexander Easton
                                                                                                           Data Scientist
     Ilayda Karatas
                                                                                         Jeroen Bijman
     Business Analyst
                                                                                         Data Engineer
                                                Marit Beerepoot
                                                 Data Scientist




                                                                  Sara Fernandez
                                                                   Data Scientist




                                      The Knowledge Graph Team
Knowledge Graphs for Financial Services   15
Knowledge Graphs for Financial Services                                                                16




   Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited ("DTTL"), its global
   network of member Ô¨Årms and their related entities. DTTL (also referred to as "Deloitte
   Global") and each of its member Ô¨Årms are legally separate and independent entities. DTTL
   does not provide services to clients. Please see www.deloitte.nl/about to learn more.

   Deloitte is a leading global provider of audit and assurance, consulting, Ô¨Ånancial advisory, risk
   advisory, tax and related services. Our network of member Ô¨Årms in more than 150 countries
   and territories serves four out of Ô¨Åve Fortune Global 500¬Æ companies. Learn how Deloitte‚Äôs
   approximately 286,000 people make an impact that matters at www.deloitte.nl.

   This communication contains general information only, and none of Deloitte Touche
   Tohmatsu Limited, its member Ô¨Årms or their related entities (collectively, the ‚ÄúDeloitte
   network‚Äù) is, by means of this communication, rendering professional advice or services.
   Before making any decision or taking any action that may aÔ¨Äect your Ô¨Ånances or your
   business, you should consult a qualiÔ¨Åed professional adviser. No entity in the Deloitte
   network shall be responsible for any loss whatsoever sustained by any person who relies on
   this communication.

   ¬© 2020 Deloitte The Netherlands
                                               Chain-of-Thought Prompting Elicits Reasoning
                                                        in Large Language Models


                                                     Jason Wei           Xuezhi Wang               Dale Schuurmans              Maarten Bosma
                                                      Brian Ichter          Fei Xia        Ed H. Chi         Quoc V. Le            Denny Zhou
arXiv:2201.11903v6 [cs.CL] 10 Jan 2023




                                                                               Google Research, Brain Team
                                                                           {jasonwei,dennyzhou}@google.com



                                                                                             Abstract
                                                  We explore how generating a chain of thought‚Äîa series of intermediate reasoning
                                                  steps‚Äîsignificantly improves the ability of large language models to perform
                                                  complex reasoning. In particular, we show how such reasoning abilities emerge
                                                  naturally in sufficiently large language models via a simple method called chain-of-
                                                  thought prompting, where a few chain of thought demonstrations are provided as
                                                  exemplars in prompting.
                                                  Experiments on three large language models show that chain-of-thought prompting
                                                  improves performance on a range of arithmetic, commonsense, and symbolic
                                                  reasoning tasks. The empirical gains can be striking. For instance, prompting a
                                                  PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art
                                                  accuracy on the GSM8K benchmark of math word problems, surpassing even
                                                  finetuned GPT-3 with a verifier.


                                                              Standard Prompting                                Chain-of-Thought Prompting
                                                Model Input                                               Model Input

                                             Q: Roger has 5 tennis balls. He buys 2 more cans of       Q: Roger has 5 tennis balls. He buys 2 more cans of
                                             tennis balls. Each can has 3 tennis balls. How many       tennis balls. Each can has 3 tennis balls. How many
                                             tennis balls does he have now?                            tennis balls does he have now?

                                             A: The answer is 11.                                      A: Roger started with 5 balls. 2 cans of 3 tennis balls
                                                                                                       each is 6 tennis balls. 5 + 6 = 11. The answer is 11.
                                             Q: The cafeteria had 23 apples. If they used 20 to
                                             make lunch and bought 6 more, how many apples             Q: The cafeteria had 23 apples. If they used 20 to
                                             do they have?                                             make lunch and bought 6 more, how many apples
                                                                                                       do they have?


                                                Model Output                                              Model Output

                                              A: The answer is 27.                                     A: The cafeteria had 23 apples originally. They used
                                                                                                       20 to make lunch. So they had 23 - 20 = 3. They
                                                                                                       bought 6 more apples, so they have 3 + 6 = 9. The
                                                                                                       answer is 9.


                                         Figure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,
                                         commonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.




                                         36th Conference on Neural Information Processing Systems (NeurIPS 2022).
1   Introduction

The NLP landscape has recently been revolutionized by                   Finetuned GPT-3 175B
language models (Peters et al., 2018; Devlin et al., 2019;              Prior best
Brown et al., 2020, inter alia). Scaling up the size of lan-            PaLM 540B: standard prompting
guage models has been shown to confer a range of benefits,              PaLM 540B: chain-of-thought prompting
such as improved performance and sample efficiency (Ka-
plan et al., 2020; Brown et al., 2020, inter alia). However,                       100
scaling up model size alone has not proved sufficient for




                                                                  Solve rate (%)
                                                                                   80
achieving high performance on challenging tasks such as                                           57
                                                                                   60    55
arithmetic, commonsense, and symbolic reasoning (Rae
et al., 2021).                                                     40    33
This work explores how the reasoning ability of large                              18
                                                                   20
language models can be unlocked by a simple method
motivated by two ideas. First, techniques for arithmetic            0
reasoning can benefit from generating natural language              Math Word Problems (GSM8K)
rationales that lead to the final answer. Prior work has
given models the ability to generate natural language inter- Figure 2: PaLM 540B uses chain-of-
mediate steps by training from scratch (Ling et al., 2017) thought prompting to achieve new state-
or finetuning a pretrained model (Cobbe et al., 2021), in of-the-art performance on the GSM8K
addition to neuro-symbolic methods that use formal lan- benchmark of math word problems.
guages instead of natural language (Roy and Roth, 2015; Finetuned GPT-3 and prior best are from
Chiang and Chen, 2019; Amini et al., 2019; Chen et al., Cobbe et al. (2021).
2019). Second, large language models offer the exciting
prospect of in-context few-shot learning via prompting. That is, instead of finetuning a separate
language model checkpoint for each new task, one can simply ‚Äúprompt‚Äù the model with a few
input‚Äìoutput exemplars demonstrating the task. Remarkably, this has been successful for a range of
simple question-answering tasks (Brown et al., 2020).
Both of the above ideas, however, have key limitations. For rationale-augmented training and
finetuning methods, it is costly to create a large set of high quality rationales, which is much more
complicated than simple input‚Äìoutput pairs used in normal machine learning. For the traditional few-
shot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning
abilities, and often does not improve substantially with increasing language model scale (Rae et al.,
2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.
Specifically, we explore the ability of language models to perform few-shot prompting for reasoning
tasks, given a prompt that consists of triples: hinput, chain of thought, outputi. A chain of thought is
a series of intermediate natural language reasoning steps that lead to the final output, and we refer to
this approach as chain-of-thought prompting. An example prompt is shown in Figure 1.
We present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,
showing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking
degree. Figure 2 illustrates one such result‚Äîon the GSM8K benchmark of math word problems
(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting
by a large margin and achieves new state-of-the-art performance. A prompting only approach is
important because it does not require a large training dataset and because a single model checkpoint
can perform many tasks without loss of generality. This work underscores how large language models
can learn via a few examples with natural language data about the task (c.f. automatically learning
the patterns underlying inputs and outputs via a large training dataset).


2   Chain-of-Thought Prompting

Consider one‚Äôs own thought process when solving a complicated reasoning task such as a multi-step
math word problem. It is typical to decompose the problem into intermediate steps and solve each
before giving the final answer: ‚ÄúAfter Jane gives 2 flowers to her mom she has 10 . . . then after she
gives 3 to her dad she will have 7 . . . so the answer is 7.‚Äù The goal of this paper is to endow language
models with the ability to generate a similar chain of thought‚Äîa coherent series of intermediate
reasoning steps that lead to the final answer for a problem. We will show that sufficiently large


                                                   2
language models can generate chains of thought if demonstrations of chain-of-thought reasoning are
provided in the exemplars for few-shot prompting.
Figure 1 shows an example of a model producing a chain of thought to solve a math word problem
that it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution
and can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it
mimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations
typically come after the final answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,
2022, inter alia)).
Chain-of-thought prompting has several attractive properties as an approach for facilitating reasoning
in language models.
      1. First, chain of thought, in principle, allows models to decompose multi-step problems into
         intermediate steps, which means that additional computation can be allocated to problems
         that require more reasoning steps.
      2. Second, a chain of thought provides an interpretable window into the behavior of the model,
         suggesting how it might have arrived at a particular answer and providing opportunities
         to debug where the reasoning path went wrong (although fully characterizing a model‚Äôs
         computations that support an answer remains an open question).
      3. Third, chain-of-thought reasoning can be used for tasks such as math word problems,
         commonsense reasoning, and symbolic manipulation, and is potentially applicable (at least
         in principle) to any task that humans can solve via language.
      4. Finally, chain-of-thought reasoning can be readily elicited in sufficiently large off-the-shelf
         language models simply by including examples of chain of thought sequences into the
         exemplars of few-shot prompting.
In empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic
reasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).

3     Arithmetic Reasoning
We begin by considering math word problems of the form in Figure 1, which measure the arithmetic
reasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where
language models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia). Strikingly, chain-
of-thought prompting when used with the 540B parameter language model performs comparably with
task-specific finetuned models on several tasks, even achieving new state of the art on the challenging
GSM8K benchmark (Cobbe et al., 2021).

3.1   Experimental Setup

We explore chain-of-thought prompting for various language models on multiple benchmarks.
Benchmarks. We consider the following five math word problem benchmarks: (1) the GSM8K
benchmark of math word problems (Cobbe et al., 2021), (2) the SVAMP dataset of math word
problems with varying structures (Patel et al., 2021), (3) the ASDiv dataset of diverse math word
problems (Miao et al., 2020), (4) the AQuA dataset of algebraic word problems, and (5) the MAWPS
benchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.
Standard prompting. For the baseline, we consider standard few-shot prompting, popularized by
Brown et al. (2020), in which a language model is given in-context exemplars of input‚Äìoutput pairs
before outputting a prediction for a test-time example. Exemplars are formatted as questions and
answers. The model gives the answer directly, as shown in Figure 1 (left).
Chain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot
prompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most
of the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars
with chains of thought for prompting‚ÄîFigure 1 (right) shows one chain of thought exemplar, and the
full set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo
prompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether
chain-of-thought prompting in this form can successfully elicit successful reasoning across a range of


                                                     3
      Math Word Problems (free response)        Math Word Problems (multiple choice)                  CSQA (commonsense)

  Q: Roger has 5 tennis balls. He buys         Q: How many keystrokes are needed            Q: Sammy wanted to go to where the
  2 more cans of tennis balls. Each can        to type the numbers from 1 to 500?           people were. Where might he go?
  has 3 tennis balls. How many tennis          Answer Choices: (a) 1156 (b) 1392 (c) 1480   Options: (a) race track (b) populated areas
                                               (d) 1562 (e) 1788                            (c) desert (d) apartment (e) roadblock
  balls does he have now?
                                               A: There are 9 one-digit numbers
  A: Roger started with 5 balls. 2 cans                                                     A: The answer must be a place with a
                                               from 1 to 9. There are 90 two-digit
  of 3 tennis balls each is 6 tennis                                                        lot of people. Race tracks, desert,
                                               numbers from 10 to 99. There are
  balls. 5 + 6 = 11. The answer is 11.         401 three-digit numbers from 100 to          apartments, and roadblocks don't
                                               500. 9 + 90(2) + 401(3) = 1392. The          have a lot of people, but populated
                                                                                            areas do. So the answer is (b).
                                               answer is (b).

                  StrategyQA                              Date Understanding                          Sports Understanding

  Q: Yes or no: Would a pear sink in           Q: The concert was scheduled to be           Q: Is the following sentence
  water?                                       on 06/01/1943, but was delayed by            plausible? "Joao Moutinho caught the
                                               one day to today. What is the date 10        screen pass in the NFC
  A: The density of a pear is about 0.6        days ago in MM/DD/YYYY?                      championship."
  g/cm^3, which is less than water.
  Thus, a pear would float. So the             A: One day after 06/01/1943 is               A: Joao Moutinho is a soccer player.
  answer is no.                                06/02/1943, so today is 06/02/1943.          The NFC championship is part of
                                               10 days before today is 05/23/1943.          American football, not soccer. So the
                                               So the answer is 05/23/1943.                 answer is no.



          SayCan (Instructing a robot)                 Last Letter Concatenation                     Coin Flip (state tracking)
  Human: How would you bring me                Q: Take the last letters of the words        Q: A coin is heads up. Maybelle flips
  something that isn‚Äôt a fruit?                in ‚ÄúLady Gaga‚Äù and concatenate               the coin. Shalonda does not flip the
                                               them.                                        coin. Is the coin still heads up?
  Explanation: the user wants
  something to eat that isn‚Äôt a fruit. An      A: The last letter of ‚ÄúLady‚Äù is ‚Äúy‚Äù. The     A: The coin was flipped by Maybelle.
  energy bar is not a fruit, so I will bring   last letter of ‚ÄúGaga‚Äù is ‚Äúa‚Äù.                So the coin was flipped 1 time, which
  the user an energy bar.                      Concatenating them is ‚Äúya‚Äù. So the           is an odd number. The coin started
  Plan: 1. find(energy bar) 2.                 answer is ya.                                heads up, so after an odd number of
  pick(energy bar) 3. find(user) 4.                                                         flips, it will be tails up. So the answer
  put(energy bar) 5. done().                                                                is no.


Figure 3: Examples of hinput, chain of thought, outputi triples for arithmetic, commonsense, and
symbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.

math word problems, we used this single set of eight chain of thought exemplars for all benchmarks
except AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars
and solutions from the training set, as given in Appendix Table 21.
Language models. We evaluate five large language models. The first is GPT-3 (Brown et al.,
2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which
presumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang
et al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,
68B, and 137B parameters. The third is PaLM, which has models of 8B, 62B, and 540B parameters.
The fourth is UL2 20B (Tay et al., 2022), and the fifth is Codex (Chen et al., 2021, code-davinci-002
in the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows
chain-of-thought prompting can be improved by taking the majority final answer over many sampled
generations (Wang et al., 2022a)). For LaMDA, we report averaged results over five random seeds,
where each seed had a different randomly shuffled order of exemplars. As LaMDA experiments
did not show large variance among different seeds, to save compute we report results for a single
exemplar order for all other models.

3.2     Results

The strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental
outputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.
There are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent
ability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively
impact performance for small models, and only yields performance gains when used with models of
‚àº100B parameters. We qualitatively found that models of smaller scale produced fluent but illogical
chains of thought, leading to lower performance than standard prompting.


                                                                   4
Second, chain-of-thought prompting has larger                                            Standard prompting
performance gains for more-complicated prob-                                             Chain-of-thought prompting
lems. For instance, for GSM8K (the dataset
                                                                                         Prior supervised best
with the lowest baseline performance), perfor-
mance more than doubled for the largest GPT                                      LaMDA        GPT          PaLM
and PaLM models. On the other hand, for Sin-                                60
gleOp, the easiest subset of MAWPS which only




                                                           solve rate (%)
requires a single step to solve, performance im-




                                                              GSM8K
                                                                            40
provements were either negative or very small
(see Appendix Table 3).                                                     20
Third, chain-of-thought prompting via GPT-3                                  0
175B and PaLM 540B compares favorably to
prior state of the art, which typically finetunes a                         80




                                                           solve rate (%)
task-specific model on a labeled training dataset.                          60




                                                              SVAMP
Figure 4 shows how PaLM 540B uses chain-of-
thought prompting to achieve new state of the art                           40
on GSM8K, SVAMP, and MAWPS (though note                                     20
that standard prompting already passed the prior
                                                                             0
best for SVAMP). On the other two datasets,
AQuA and ASDiv, PaLM with chain-of-thought                           100
prompting reaches within 2% of the state of the

                                                          solve rate (%)
                                                                            75
art (Appendix Table 2).                                     MAWPS
                                                           50
To better understand why chain-of-thought
prompting works, we manually examined model-               25
generated chains of thought by LaMDA 137B                   0
for GSM8K. Of 50 random examples where the                    0.4 8 137 0.4 7 175 8 62 540
model returned the correct final answer, all of
the generated chains of thought were also log-                   Model scale (# parameters in billions)
ically and mathematically correct except two
that coincidentally arrived at the correct answer Figure 4: Chain-of-thought prompting enables
(see Appendix D.1, and Table 8 for examples large language models to solve challenging math
of correct model-generated chains of thought). problems. Notably, chain-of-thought reasoning
We also randomly examined 50 random sam- is an emergent ability of increasing model scale.
ples for which the model gave the wrong answer. Prior best numbers are from Cobbe et al. (2021)
The summary of this analysis is that 46% of the for GSM8K, Jie et al. (2022) for SVAMP, and Lan
chains of thought were almost correct, barring et al. (2021) for MAWPS.
minor mistakes (calculator error, symbol map-
ping error, or one reasoning step missing), and that the other 54% of the chains of thought had major
errors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into
why scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors
made by PaLM 62B and whether those errors were fixed by scaling to PaLM 540B. The summary
is that scaling PaLM to 540B fixes a large portion of one-step missing and semantic understanding
errors in the 62B model (see Appendix A.1).


3.3   Ablation Study

The observed benefits of using chain-of-thought prompting raises the natural question of whether the
same performance improvements can be conferred via other types of prompting. Figure 5 shows an
ablation study with three variations of chain of thought described below.
Equation only. One reason for why chain-of-thought prompting might help is that it produces the
mathematical equation to be evaluated, and so we test a variation where the model is prompted
to output only a mathematical equation before giving the answer. Figure 5 shows that equation
only prompting does not help much for GSM8K, which implies that the semantics of the questions
in GSM8K are too challenging to directly translate into an equation without the natural language
reasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we find
that equation only prompting does improve performance, since the equation can be easily derived
from the question (see Appendix Table 6).


                                                      5
Variable compute only. Another intuition is that chain of                                                       Standard prompting
thought allows the model to spend more computation (i.e.,                                                       Equation only
intermediate tokens) on harder problems. To isolate the effect
                                                                                                                Variable compute only
of variable computation from chain-of-thought reasoning, we
                                                                                                                Reasoning after answer
test a configuration where the model is prompted to output a
                                                                                                                Chain-of-thought prompting
only sequence of dots (. . .) equal to the number of characters in




                                                                                        GSM8K solve rate (%)
the equation needed to solve the problem. This variant performs                                                60
about the same as the baseline, which suggests that variable
computation by itself is not the reason for the success of chain-
of-thought prompting, and that there appears to be utility from                                                40
expressing intermediate steps via natural language.
                                                                                                               20
Chain of thought after answer. Another potential benefit of
chain-of-thought prompting could simply be that such prompts
allow the model to better access relevant knowledge acquired                                                    0
during pretraining. Therefore, we test an alternative configura-                                                    LaMDA          PaLM
tion where the chain of thought prompt is only given after the
answer, isolating whether the model actually depends on the                         Figure 5: Ablation study for dif-
produced chain of thought to give the final answer. This variant                    ferent variations of prompting us-
performs about the same as the baseline, which suggests that                        ing LaMDA 137B and PaLM 540B.
the sequential reasoning embodied in the chain of thought is                        Results for other datasets are given
useful for reasons beyond just activating knowledge.                                in Appendix Table 6 and Table 7.


3.4       Robustness of Chain of Thought
                                                                                                                Standard prompting
Sensitivity to exemplars is a key consideration of prompt-                                                      Chain-of-thought prompting
ing approaches‚Äîfor instance, varying the permutation of                                                         ¬∑ different annotator (B)
few-shot exemplars can cause the accuracy of GPT-3 on                                                           ¬∑ different annotator (C)
SST-2 to range from near chance (54.3%) to near state of                                                        ¬∑ intentionally concise style
the art (93.4%) (Zhao et al., 2021). In this final subsec-                                                      ¬∑ exemplars from GSM8K (Œ±)
tion, we evaluate robustness to chains of thought written                                                       ¬∑ exemplars from GSM8K (Œ≤)
by different annotators. In addition to the results above,                                                      ¬∑ exemplars from GSM8K (Œ≥)
which used chains of thought written by an Annotator
A, two other co-authors of this paper (Annotators B and                            20                                       60
C) independently wrote chains of thought for the same
                                                                  Solve rate (%)




few-shot exemplars (shown in Appendix H). Annotator A                              15
also wrote another chain of thought that was more concise                                                                   40
than the original, following the style of solutions given in                       10
Cobbe et al. (2021).1
                                                                                                                            20
Figure 6 shows these results for LaMDA 137B on GSM8K                               5
and MAWPS (ablation results for other datasets are given
in Appendix Table 6 / Table 7). Although there is variance                         0                                         0
among different chain of thought annotations, as would be                                                      GSM8K              MAWPS
expected when using exemplar-based prompting (Le Scao
and Rush, 2021; Reynolds and McDonell, 2021; Zhao                Figure 6: Chain-of-thought prompting
et al., 2021), all sets of chain of thought prompts outper-      has variance for different prompt exam-
form the standard baseline by a large margin. This result        ples (as expected) but outperforms stan-
implies that successful use of chain of thought does not         dard prompting for various annotators as
depend on a particular linguistic style.                         well as for different exemplars.
To confirm that successful chain-of-thought prompting
works for other sets of exemplars, we also run experiments
with three sets of eight exemplars randomly sampled from the GSM8K training set, an independent


      1
     For instance, whereas original chain of thought uses several short sentences (‚Äú‚ÄôThere were originally 9
computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is
29.‚Äù), the concise chain of thought would read ‚Äú5 * 4 = 20 new computers were added. So there are 9 + 20 = 29
new computers in the server room now‚Äù.


                                                     6
source (examples in this dataset already included reasoning steps like a chain of thought).2 Fig-
ure 6 shows that these prompts performed comparably with our manually written exemplars, also
substantially outperforming standard prompting.
In addition to robustness to annotators, independently-written chains of thought, different exemplars,
and various language models, we also find that chain-of-thought prompting for arithmetic reasoning
is robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).

4                    Commonsense Reasoning
Although chain of thought is particularly suitable for math word problems, the language-based nature
of chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,
which involve reasoning about physical and human interactions under the presumption of general
background knowledge. Commonsense reasoning is key for interacting with the world and is still
beyond the reach of current natural language understanding systems (Talmor et al., 2021).
Benchmarks. We consider five datasets covering a diverse range of commonsense reasoning types.
The popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving
complex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires
models to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets
from the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves
inferring a date from a given context, and Sports Understanding, which involves determining whether
a sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,
2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete
set. Figure 3 shows examples with chain of thought annotations for all datasets.
Prompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,
we randomly selected examples from the training set and manually composed chains of thought for
them to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected
the first ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on
the rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.
(2022) and also manually composed chains of thought.
Results. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different
model scales are shown in Table 4). For all tasks, scaling up model size improved the performance
of standard prompting; chain-of-thought prompting led to further gains, with improvements appear-
ing to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong
performance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs
69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).
These results demonstrate that chain-of-thought prompting can also improve performance on tasks
requiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).

                           CSQA        StrategyQA         Date         Sports         SayCan
           100                       90           80             100            100
    Solve rate (%)




                     80              80             60                           80             Standard prompting
                                                                  80                            Chain of thought
                     60              70             40                           60
                                                                                                Prior supervised best
                                                                  60
                     40              60             20                           40             Human
                     20              50               0            40             20
                          8 62 540        8 62 540       8 62 540       8 62 540     8 62 540
                                           Model scale (# parameters in billions)

Figure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of
language models. The language model shown here is PaLM. Prior best numbers are from the
leaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,
as of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown
in Table 4.
         2
    We sample examples ‚â§ 60 tokens to fit into our input context window, and also limit the examples to ‚â§ 2
steps to solve for a fair comparison with the eight exemplars that we composed.


                                                                       7
5       Symbolic Reasoning                                                                           Standard prompting
                                                                                                     Chain-of-thought prompting
Our final experimental evaluation considers symbolic rea-
soning, which is simple for humans but potentially chal-                                         Letter Concat: 2 Letter Concat: 4
lenging for language models. We show that chain-of-                                                (in domain)         (OOD)
thought prompting not only enables language models to                             100




                                                                           Solve rate (%)
perform symbolic reasoning tasks that are challenging in                                    75
the standard prompting setting, but also facilitates length
                                                                                            50
generalization to inference-time inputs longer than those
seen in the few-shot exemplars.                                                             25
                                                                                             0
Tasks. We use the following two toy tasks.
                                                                                                  Coin Flip: 2     Coin Flip: 4
‚Ä¢ Last letter concatenation. This task asks the model                   (in domain)        (OOD)
  to concatenate the last letters of words in a name (e.g.,
                                                                  100
 ‚ÄúAmy Brown‚Äù ‚Üí ‚Äúyn‚Äù). It is a more challenging version




                                                                      Solve rate (%)
  of first letter concatenation, which language models can         80
  already perform without chain of thought.3 We generate
  full names by randomly concatenating names from the              60
  top one-thousand first and last names from name census
  data (https://namecensus.com/).                                  40
‚Ä¢ Coin flip. This task asks the model to answer whether a             8     62 540 8         62 540
  coin is still heads up after people either flip or don‚Äôt flip     Model scale (# parameters in billions)
  the coin (e.g., ‚ÄúA coin is heads up. Phoebe flips the coin.
  Osvaldo does not flip the coin. Is the coin still heads up?‚Äù Figure 8:       Using chain-of-thought
  ‚Üí ‚Äúno‚Äù).                                                      prompting facilitates generalization to
As the construction of these symbolic reasoning tasks is longer sequences in two symbolic rea-
well-defined, for each task we consider an in-domain test soning tasks.
set for which examples had the same number of steps as
the training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation
examples had more steps than those in the exemplars. For last letter concatenation, the model only
sees exemplars of names with two words, and then performs last letter concatenation on names with 3
and 4 words.4 We do the same for the number of potential flips in the coin flip task. Our experimental
setup uses the same methods and models as in the prior two sections. We again manually compose
chains of thought for the few-shot exemplars for each task, which are given in Figure 3.

Results. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,
with results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting
leads to almost 100% solve rates (note that standard prompting already solves coin flip with PaLM
540, though not for LaMDA 137B). Note that these in-domain evaluations are ‚Äútoy tasks‚Äù in the
sense that perfect solution structures are already provided by the chains of thought in the few-shot
exemplars; all the model has to do is repeat the same steps with the new symbols in the test-time
example. And yet, small models still fail‚Äîthe ability to perform abstract manipulations on unseen
symbols for these three tasks only arises at the scale of 100B model parameters.
As for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,
language models achieve upward scaling curves (though performance is lower than in the in-domain
setting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of
thought for language models of sufficient scale.

6       Discussion
We have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-
soning behavior in large language models. We first saw that chain-of-thought prompting improves
performance by a large margin on arithmetic reasoning, yielding improvements that are much stronger
than ablations and robust to different annotators, exemplars, and language models (Section 3). Next,
    3
        We tested 10 common names using GPT-3 davinci and it got all but one correct.
    4
        For names of length longer than 2 words, we concatenate multiple first and last names together.


                                                         8
experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought
reasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,
chain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In
all experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language
model. No language models were finetuned in the process of writing this paper.
The emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme
(Wei et al., 2022b). For many reasoning tasks where standard prompting has a flat scaling curve, chain-
of-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting
appears to expand the set of tasks that large language models can perform successfully‚Äîin other
words, our work underscores that standard prompting only provides a lower bound on the capabilities
of large language models. This observation likely raises more questions than it answers‚Äîfor instance,
how much more can we expect reasoning ability to improve with a further increase in model scale?
What other prompting methods might expand the range of tasks that language models can solve?
As for limitations, we first qualify that although chain of thought emulates the thought processes of
human reasoners, this does not answer whether the neural network is actually ‚Äúreasoning,‚Äù which
we leave as an open question. Second, although the cost of manually augmenting exemplars with
chains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for
finetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot
generalization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct
and incorrect answers; improving factual generations of language models is an open direction for
future work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, inter alia). Finally,
the emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in
real-world applications; further research could explore how to induce reasoning in smaller models.

7   Related Work
This work is inspired by many research areas, which we detail in an extended related work section
(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.
The first relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)
pioneer the idea of using natural language rationales to solve math word problems through a series
of intermediate steps. Their work is a remarkable contrast to the literature using formal languages
to reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe
et al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to finetune a pretrained
language model rather than training a model from scratch. In the domain of program synthesis,
Nye et al. (2021) leverage language models to predict the final outputs of Python programs via
first line-to-line predicting the intermediate computational results, and show that their step-by-step
prediction method performs better than directly predicting the final outputs.
Naturally, this paper also relates closely to the large body of recent work on prompting. Since the
popularization of few-shot prompting as given by Brown et al. (2020), several general approaches
have improved the prompting ability of models, such as automatically learning prompts (Lester et al.,
2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang
et al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,
instructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the
outputs of language models with a chain of thought.

8   Conclusions
We have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-
ing reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense
reasoning, we find that chain-of-thought reasoning is an emergent property of model scale that allows
sufficiently large language models to perform reasoning tasks that otherwise have flat scaling curves.
Broadening the range of reasoning tasks that language models can perform will hopefully inspire
further work on language-based approaches to reasoning.




                                                    9
Acknowledgements
We thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the
paper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,
and Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a
mistake in the manual error analysis in the original manuscript.

References
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea
 Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I
 say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691.
Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh
  Hajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-
  based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and
  Short Papers), Minneapolis, Minnesota. Association for Computational Linguistics.
Daniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding
  operations and arguments with reading comprehension. EMNLP.
Jacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL.
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,
  Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language
  models. arXiv preprint arXiv:2108.07732.
BIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the
  capabilities of language models. In preparation.
Kaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural
  language deductions. EMNLP.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
  Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
  Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,
  Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei. 2020. Language models are few-shot learners. NeurIPS.
Jonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures
  generalize via recursion. ICLR.
Oana-Maria Camburu, Tim Rockt√§schel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:
  Natural language inference with natural language explanations. NeurIPS.
Howard Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization
  improve robustness? NAACL.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
 Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating
 large language models trained on code. arXiv preprint arXiv:2107.03374.
Xinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V. Le. 2019. Neural
  symbolic reader: Scalable integration of distributed and symbolic representations for reading
  comprehension. ICLR.
Ting-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving
  and reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-
  can Chapter of the Association for Computational Linguistics: Human Language Technologies,
  Volume 1 (Long and Short Papers), pages 2656‚Äì2668, Minneapolis, Minnesota. Association for
  Computational Linguistics.


                                                 10
Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over
  language. IJCAI.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher
  Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. arXiv preprint
  arXiv:2110.14168.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of
  deep bidirectional transformers for language understanding. NAACL.
Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural
  logic machines. ICLR.
Dheeru Dua, Sameer Singh, and Matt Gardner. 2020. Benefits of intermediate annotations in reading
  comprehension. ACL.
Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did
 aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL.
Yuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models
  behind language models. NAACL.
Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher
  R√©. 2018. Training classifiers with natural language explanations. ACL.
Peter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework
  for understanding the roles of explanation data. ACL.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,
  and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv
  preprint arXiv:2103.03874.
Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning
 to solve arithmetic word problems with verb categorization. EMNLP.
Zhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem
  solving as complex relation extraction. arXiv preprint arXiv:2203.10316.
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,
  Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language
  models. arXiv preprint arXiv:2001.08361.
Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.
  MAWPS: A math word problem repository. NAACL.
Andrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y. Chan, Kory Matthewson, Michael Henry
 Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language
  models learn from explanations in context? arXiv preprint arXiv:2204.02329.
Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,
  and Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math
  word problem solvers. arXiv preprint arXiv:2109.00799.
Teven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL.
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient
  prompt tuning. EMNLP.
Iddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:
  From robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning
  and Interpretation.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation.
  ACL.


                                               11
Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal
  reasoning through internal monologue. NAACL.
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale
 generation: Learning to solve and explain algebraic word problems. ACL.
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.
  Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language
  processing. arXiv preprint arXiv:2107.13586.
Bodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.
  2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint
  arXiv:2106.13876.
Ana MarasovicÃÅ, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization
  with natural language prompts. NAACL Findings.
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and
  factuality in abstractive summarization. In ACL.
Shen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and
  developing English math word problem solvers. ACL.
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke
  Zettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?
  arXiv preprint arXiv:2202.12837.
Sharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.
  2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint
  arXiv:2004.14546.
Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David
 Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:
 Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong
  Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to
  follow instructions with human feedback. arXiv preprint arXiv:2203.02155.
Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve
  simple math word problems? NAACL.
Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and
 Luke Zettlemoyer. 2018. Deep contextualized word representations. NAACL.
Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and
  Weizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473.
Piotr PiÀõekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving
  BERT‚Äôs mathematical abilities by predicting the order of reasoning. ACL.
Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John
  Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:
  Methods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi
  Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified
  text-to-text transformer. Journal of Machine Learning Research, 21:1‚Äì67.
Dheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:
  A self-explaining architecture for neural text classifiers. EMNLP.
Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain
  yourself! Leveraging language models for commonsense reasoning. ACL.


                                               12
Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading
  comprehension with numerical reasoning. EMNLP.

Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,
  Gaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language
  generation models. arXiv preprint arXiv:2112.12870.

Gabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.
  arXiv preprint arXiv:2109.02102.

Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.
 A recipe for arbitrary text style transfer with large language models. ACL.

Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond
  the few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in
  Computing Systems.

Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP.

Subhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.
  TACL.

Mohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching
 soft rules to pre-trained language models. EMNLP.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,
  Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted
  training enables zero-shot task generalization. ICLR.

Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.
   Generate & rank: A multi-task framework for math word problems. In Findings of the Association
   for Computational Linguistics: EMNLP 2021.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A
  question answering challenge targeting commonsense knowledge. NAACL.

Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-
  thought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS.

Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and
  Jonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamification.
  NeurIPS Track on Datasets and Benchmarks.

Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven
  Zheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv
  preprint arXiv:2205.05131.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
  Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for
  dialog applications. arXiv preprint arXiv:2201.08239.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.
  Self-consistency improves chain of thought reasoning in language models. arXiv preprint
  arXiv:2203.11171.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana
  Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.
  Benchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint
  arXiv:2204.07705.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
  Andrew M. Dai, and Quoc V. Le. 2022a. Finetuned language models are zero-shot learners. ICLR.


                                                13
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
  Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language
  models. Transactions on Machine Learning Research.
Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing
  human-AI collaboration for generating free-text explanations. NAACL.
Sarah Wiegreffe and Ana MarasovicÃÅ. 2021. Teach me to explain: A review of datasets for explainable
  NLP. NeurIPS.
Sarah Wiegreffe, Ana MarasovicÃÅ, and Noah A. Smith. 2021. Measuring association between labels
  and free-text rationales. EMNLP.
Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and
  Carrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual
  programming. CHI Extended Abstracts.
Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable
  human-AI interaction by chaining large language model prompts. CHI.
Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.
  Neural execution engines: Learning to execute subroutines. NeurIPS.
Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Refining language models
 with compositional explanations. NeurIPS.
Xi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.
  arXiv preprint arXiv:2205.03401.
Yordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot
  out-of-domain transfer learning of natural language explanations. arXiv preprint arXiv:2112.06204.
Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using ‚Äúannotator rationales‚Äù to improve
 machine learning for text categorization. NAACL.
Wojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615.
Eric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with
  reasoning. arXiv preprint arXiv:2203.14465.
Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:
  Improving few-shot performance of language models. ICML.
Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and
 Jian Tang. 2020. Towards interpretable natural language understanding with explanations as latent
 variables. NeurIPS.




                                                14
Checklist
    1. For all authors...
        (a) Do the main claims made in the abstract and introduction accurately reflect the paper‚Äôs
            contributions and scope? [Yes]
        (b) Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.
        (c) Did you discuss any potential negative societal impacts of your work? [Yes] We don‚Äôt
            expect negative societal impacts as a direct result of the contributions in our paper. One
            consideration, however, is that generated chain of thought is not always factual, which
            is noted as a limitation in Appendix D.1 (and note that we do not suggest using such
            chains of thought in a factual manner or in any real-world scenario).
        (d) Have you read the ethics review guidelines and ensured that your paper conforms to
            them? [Yes]
    2. If you are including theoretical results...
        (a) Did you state the full set of assumptions of all theoretical results? [N/A]
        (b) Did you include complete proofs of all theoretical results? [N/A]
    3. If you ran experiments...
        (a) Did you include the code, data, and instructions needed to reproduce the main experi-
            mental results (either in the supplemental material or as a URL)? [Yes] We included
            inputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.
            Although we use proprietary models, we GPT-3 results are fully reproducible. Repro-
            ducibility is further discussed in Appendix E.1.
        (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
            were chosen)? [Yes] Data splits were specified, N/A for hyperparams.
        (c) Did you report error bars (e.g., with respect to the random seed after running exper-
            iments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA
            137B, where each seed is a different random order of exemplars, is given in Table 6
            and Table 7.
        (d) Did you include the total amount of compute and the type of resources used (e.g., type
            of GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in
            Appendix E.2, though we did not estimate the total amount of compute.
    4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
        (a) If your work uses existing assets, did you cite the creators? [Yes] We used two models
            that we anonymized based on the recommendation of the NeurIPS chairs. These models
            will be cited in the camera-ready version of the paper.
        (b) Did you mention the license of the assets? [Yes] See Appendix E.3.
        (c) Did you include any new assets either in the supplemental material or as a URL? [Yes]
            The coinflip and last letter concatenation datasets are the only new assets, and they are
            given in the Supplementary Materials.
        (d) Did you discuss whether and how consent was obtained from people whose data you‚Äôre
            using/curating? [N/A] No human data collected.
        (e) Did you discuss whether the data you are using/curating contains personally identifiable
            information or offensive content? [N/A] No human data collected.
    5. If you used crowdsourcing or conducted research with human subjects...
        (a) Did you include the full text of instructions given to participants and screenshots, if
            applicable? [N/A]
        (b) Did you describe any potential participant risks, with links to Institutional Review
            Board (IRB) approvals, if applicable? [N/A]
        (c) Did you include the estimated hourly wage paid to participants and the total amount
            spent on participant compensation? [N/A]




                                                15
A     Frequently Asked Questions

A.1   Why does increasing model scale improve chain-of-thought prompting?

The finding that successful chain-of-thought reasoning predictably emerges only at certain model
scales is intriguing. Scaling up language models has been shown to confer benefits such as improved
performance and sample efficiency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent
in the sense that its success cannot be predicted only by extrapolating the performance of small scale
models, as chain of thought actually hurts performance for most models smaller than 10B parameters.
The question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and
we made a preliminary attempt to shed insight into it via error analysis. This small analysis involved
manually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding
(20 errors), one step missing (18 errors), and other errors (7 errors). The ‚Äúother category‚Äù included
hallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one
borrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were
conceived based on what improvements were needed to make the chain of thought correct.
As shown in Figure 9, scaling PaLM to 540B parameters fixed a substantial portion of errors in all
three categories. Examples of semantic understanding and one-step missing errors that were fixed by
scaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that
language models acquire a range of semantic understanding and logical reasoning skills as a function
of model scale (though note that model scale is often conflated with other factors, such as amount of
training compute).


           Types of errors made by
            a 62B language model:
            Semantic understanding
            (62B made 20 errors of this type,
                 540B xes 6 of them)


                   One step missing
            (62B made 18 errors of this type,
                 540B xes 12 of them)
                                                                             Errors xed by
                         Other                                                scaling from
             (62B made 7 errors of this type,
                  540B xes 4 of them)
                                                                              62B to 540B
              fi    fi




Figure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized
that semantic understanding, one step missing, and other. The other category includes hallucinations,
repetitive outputs, and symbol mapping errors. Scaling PaLM to 540B fixed a substantial portion of
errors in all categories.



There are also three notable points regarding why small language models fail. The first observation
is that small language models fail at even relatively easy symbol mapping tasks. As demonstrated
in Section 5, for even symbolic reasoning tasks that only require generalization to new examples
using the same chain of thought logical structure that was given in the few-shot exemplars, small
language models still failed. The second observation is that small language models seem to have
inherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple
arithmetic operations (without semantic understanding) requires sufficient model scale. Finally, we
noticed qualitatively that small language models often did not generate a final answer that could be
parsed, due to either repetitions or logic that never arrived at a final answer.
In summary, the success of chain-of-thought reasoning as a result of model scale is a complicated
phenomena that likely involves a variety of emergent abilities (semantic understanding, symbol
mapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly
investigate what properties of pretraining data, model architecture, and optimization objective causally
enable such reasoning capabilities.


                                                  16
      Question                         62B Model Output                          540B Model Output
   Tracy used a piece of wire 4     She cut the wire into 6 inch pieces.      The wire was 4 feet long. This
   feet long to support tomato      This means she got 4 * 6 = 24             means it was 4 * 12 = 48 inches
   plants in the garden. The        pieces. The answer is 24.                 long. It was cut into pieces 6 inches
   wire was cut into pieces 6       (Incorrect: semantic                      long. This means she obtained 48 /
   inches long. How many            understanding error)                      6 = 8 pieces. The answer is 8.
   pieces did she obtain?                                                     (Correct)


      Question                         62B Model Output                          540B Model Output

   Tom's ship can travel at 10      He travels from 1 to 4 PM. That           He travels at 10 mph from 1 to 4
   miles per hour. He is sailing    means he travels for 3 hours. He          PM. This means he travels 3 hours.
   from 1 to 4 PM. He then          travels back at 6 mph. That means         3 hours at 10 mph means he travels
   travels back at a rate of 6      he travels for 3 * 6 = 18 miles. The      3 * 10 = 30 miles. He then travels
   mph. How long does it take       answer is 18. (Incorrect: semantic        back at 6 mph. This means he
   him to get back?                 understanding error)                      travels 6 miles per hour. He has to
                                                                              travel 30 miles, so it takes him 30 / 6
                                                                              = 5 hours. The answer is 5.
                                                                              (Correct)


      Question                         62B Model Output                          540B Model Output

   Stephen placed an online         The final price of Stephen's              Stephen's bill was $40.00. The
   order for groceries. His final   groceries was $40.00. The delivery        delivery vendor added 25% to the
   bill came to $40.00.             vendor added 25% to the final total,      bill. This means the bill was
   Because this was through a       so the final total was 125% of            increased by 25% of $40.00. This is
   delivery vendor, they tacked     $40.00. This means the final total        0.25 * $40.00 = $10.00. The delivery
   on a 25% fee to his final        was 125% * $40.00 = $50.00. The           fee was $3.00. The tip was $4.00.
   total and charged him $3.00      delivery vendor also charged $3.00        So the total bill was $40.00 + $10.00
   in delivery fees. Stephen        in delivery fees. So the final price of   + $3.00 + 540b model $4.00 =
   also added a $4.00 tip. After    Stephen's groceries was $50.00 +          $57.00. The answer is 57. (Correct)
   the extra fees, what was the     $3.00 = $53.00. The answer is
   final price of Stephen's         $53.00. (Incorrect: one step
   groceries?                       missing error)


      Question                          62B Model Output                         540B Model Output
  There are four schools            There are 4 schools. Each school          Each school has sent 2 teams, each
  competing at a basketball         has sent a girls‚Äô basketball team and     with 5 players. This means each
  tournament. Each school           a boys‚Äô basketball team. Each team        school has sent 2 * 5 = 10 players.
  has sent a girls‚Äô basketball      has 5 players each. That means            Each school has also sent 2
  team and a boys‚Äô basketball       there are 4 * 2 * 5 = 40 players.         coaches. This means each school
  team and each team has 5          Each team has a coach. That               has sent 10 + 2 = 12 people. There
  players each. Each school         means there are 40 + 4 = 44               are 4 schools, so in total all of the
  has also sent a coach for         coaches. The answer is 44.                schools have sent 4 * 12 = 48
  each team. In total, how          (Incorrect: one step missing              people. The answer is 48. (Correct)
  many people have all of the       error)
  schools sent?


Figure 10: Examples of semantic understanding and one-step missing errors that were fixed by
scaling PaLM from 62B to 540B.


A.2    What is the role of prompt engineering?

One of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage
of work showing that prompts affect language models in unexpected ways (Min et al., 2022). The
general way that we created chain of thought annotations was by taking eight exemplars from the
training set and decomposing the reasoning process into multiple steps leading to the final answer.
Examples of chain of thought annotations are provided in Figure 3, with full prompts given in
Appendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed
robustness experiments with respect to various factors.

‚Ä¢ Different annotators. We first analyze robustness to three different annotators (Section 3.4 and
  Figure 6). Although there is notable variance in performance (which we will discuss later), chain
  of thought performed better than the baseline by a large margin for all three annotators on eight
  datasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the
  annotation process in Cobbe et al. (2021), annotators were not given specific instructions about


                                                           17
  how to write the chain of thought annotations other than to simply write the step-by-step reasoning
  process that led to the final answer. Thus, the annotations were written in each annotator‚Äôs own
  linguistic ‚Äúchain of thought‚Äù writing style.
‚Ä¢ Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)
  conveniently provides a training set with reasoning chains written by crowd compute workers,
  which enables us to investigate whether chain of thought still works with reasoning chains from an
  independent source without a background in machine learning. So we randomly sampled three sets
  of eight exemplars with chains of thought from GSM8K. These chain of thought annotations also
  outperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating
  that chain of thought is not dependent on a particular set of annotators.
‚Ä¢ Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows
  that chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of
  exemplars on all four arithmetic datasets (instead of picking exemplars from the training set for
  each dataset), which suggests that the exemplars do not necessarily have to come from the same
  dataset distribution as the test examples.
‚Ä¢ Different order of exemplars. Prior work has shown that in some cases (e.g., classification) even
  the order of prompts matter‚Äîvarying the permutation of few-shot exemplars can cause the accuracy
  of GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).
  We show the standard deviation of performance from different exemplars in Table 6 and Table 7.
  Standard deviations with respect to prompt order are relatively minimal in almost all cases. The
  one exception is the coin flip task, for which exemplar orders have high standard deviation, likely
  for the reason cited in Zhao et al. (2021)‚Äîfor classification, many exemplars of the same category
  in a row biases the model outputs).
‚Ä¢ Different number of exemplars. We also found that gains from chain-of-thought prompting
  generally still held when there was a varying number of few-shot exemplars. This is shown for five
  datasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in
  preliminary experiments that further increasing the number of exemplars in standard prompting
  did not lead to significant gains (e.g., increasing from 8 to 16 exemplars did not improve the
  performance of standard prompting enough to catch up with chain-of-thought prompting).
‚Ä¢ Different language models. Another interesting question is whether certain prompts that work
  better for one model work better for other large language models. We find that with the same
  prompts, chain-of-thought prompting improves performance across all three models (LaMDA,
  GPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,
  Table 5). The fact that gains from chain of thought did not transfer perfectly among models is
  a limitation; further work could investigate why how different pre-training datasets and model
  architectures affect the performance gain from chain-of-thought prompting.

Prompt engineering still matters, though. Although the results are relatively robust to the prompt
for arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can
improve performance significantly in many cases. Though most chain of thought annotations
outperform standard prompting, there is large variation in many cases. For instance, for the coin
flip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though
both were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt
engineering is a requirement for good performance. In preliminary experiments, we tried using chain
of thought to enable language models to reverse the order of a list of 5 items. While two co-authors
were not able to write chain of thought prompts that solved the task despite their best attempts, a third
co-author was able to write a chain of thought that perfectly solved the task.
How to generate chain of thought annotations in a robust fashion could be an interesting direction
for future work. For instance, an idea here could be to use a large language model to automatically
generate chains of thought via prompting (and potentially optimize this over a validation set).

A.3   Will chain-of-thought prompting improve performance for my task of interest?

While chain-of-thought prompting is in principle applicable for any text-to-text task, it is more
helpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain
of thought helps the most when three conditions are met: (1) the task is challenging and requires


                                                   18
multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively flat.
Conversely, the benefits are smaller when one or more of these conditions are not met.
These intuitions are perhaps supported by the arithmetic reasoning results. The performance gain
from chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step
problems, flat scaling curve), which meets these conditions. The performance gain is small for the
subsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which
PaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is
less headroom for improvement when performance is already strong).
Although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and
symbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a
‚Äúchain of thought‚Äù to solve (at least in principle). We leave the empirical evaluation of chain-of-thought
prompting on such diverse tasks (e.g., machine translation, etc.) to future work.

A.4   Why is prompting with the equation only not enough for some arithmetic reasoning
      datasets?

Prompting with the equation only as an intermediate step does help on many datasets, especially when
the datasets only require a few reasoning steps (SVAMP, ASDiv, MAWPS). For GSM8K, however,
using the equation only did not improve performance substantially. Based on qualitative analysis, we
believe that these questions are too semantically challenging for the model to directly translate them
into a math equation. Consider this example from LaMDA 137B:

         Q UESTION : Mike plays ping pong for 40 minutes. In the first 20 minutes, he scores 4
         points. In the second 20 minutes, he scores 25% more points. How many total points did he
         score?
         E QUATION ONLY ( WRONG ANSWER ): (4 + 20 * 0.25) = 6. The answer is 6.
         C HAIN OF THOUGHT ( CORRECT ): Mike played ping pong for 40 minutes. In the first
         20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So
         he scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the
         second 20 minutes. So he scored 9 points in total. The answer is 9.

It is hard for the model to directly translate all of the semantics into a single equation, but chain of
thought allows it to better reason about each part of the question via intermediate steps in natural
language.




                                                    19
B     All Experimental Results
This section contains tables for experimental results for varying models and model sizes, on all
benchmarks, for standard prompting vs. chain-of-thought prompting.
For the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)
were correct, except the model performed an arithmetic operation incorrectly. A similar observation
was made in Cobbe et al. (2021). Hence, we can further add a Python program as an external
calculator (using the Python eval function) to all the equations in the generated chain of thought.
When there are multiple equations in a chain of thought, we propagate the external calculator results
from one equation to the following equations via string matching. As shown in Table 1, we see that
adding a calculator significantly boosts performance of chain-of-thought prompting on most tasks.

Table 1: Chain of thought prompting outperforms standard prompting for various large language
models on five arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc
external calculator for arithmetic computations only. Prior best numbers are from the following. a:
Cobbe et al. (2021). b & e: Pi et al. (2022), c: Lan et al. (2021), d: PiÀõekos et al. (2021).
                      Prompting           GSM8K SVAMP ASDiv                    AQuA        MAWPS
    Prior best           N/A (finetuning) 55a               57.4b       75.3c       37.9d         88.4e
    UL2 20B              Standard         4.1               10.1        16.0        20.5          16.6
                         Chain of thought 4.4 (+0.3)        12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1)   19.1 (+2.5)
                          + ext. calc        6.9             28.3        34.3         23.6         42.7

    LaMDA 137B           Standard         6.5               29.5        40.1        25.5          43.2
                         Chain of thought 14.3 (+7.8)       37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9)   57.9 (+14.7)
                          + ext. calc        17.8            42.1        53.4         20.6         69.3

    GPT-3 175B           Standard         15.6         65.7        70.3        24.8         72.7
    (text-davinci-002)   Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)
                          + ext. calc        49.6            70.3        71.1         35.8         87.5

    Codex                Standard         19.7         69.9        74.0        29.5         78.7
    (code-davinci-002)   Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)
                          + ext. calc        65.4            77.0        80.0         45.3         93.3

    PaLM 540B            Standard         17.9         69.4        72.1        25.2         79.2
                         Chain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)
                          + ext. calc        58.6            79.8        72.6         35.8         93.5




                                                       20
Table 2: Standard prompting versus chain of thought prompting on five arithmetic reasoning bench-
marks. Note that chain of thought prompting is an emergent ability of model scale‚Äîit does not
positively impact performance until used with a model of sufficient scale.
                        GSM8K         SVAMP          ASDiv            AQuA        MAWPS
   Model            standard CoT standard CoT standard CoT standard CoT standard CoT
   UL2       20B          4.1   4.4   10.1 12.5      16.0 16.9     20.5 23.6      16.6 19.1
   LaMDA 420M             2.6 0.4      2.5 1.6        3.2 0.8      23.5    8.3     3.2 0.9
         2B               3.6 1.9      3.3 2.4        4.1 3.8      22.9   17.7     3.9 3.1
         8B               3.2 1.6      4.3 3.4        5.9 5.0      22.8   18.6     5.3 4.8
         68B              5.7 8.2     13.6 18.8      21.8 23.1     22.3   20.2    21.6 30.6
         137B             6.5 14.3    29.5 37.5      40.1 46.6     25.5   20.6    43.2 57.9
   GPT       350M        2.2 0.5       1.4 0.8        2.1 0.8      18.1 8.7        2.4 1.1
             1.3B        2.4 0.5       1.5 1.7        2.6 1.4      12.6 4.3        3.1 1.7
             6.7B        4.0 2.4       6.1 3.1        8.6 3.6      15.4 13.4       8.8 3.5
             175B       15.6 46.9     65.7 68.9      70.3 71.3     24.8 35.8      72.7 87.1
   Codex     -          19.7 63.1     69.9 76.4      74.0 80.4     29.5 45.3      78.7 92.6
   PaLM      8B          4.9 4.1      15.1 16.8      23.7 25.2     19.3 21.7      26.2 30.5
             62B         9.6 29.9     48.2 46.7      58.7 61.9     25.6 22.4      61.8 80.3
             540B       17.9 56.9     69.4 79.0      72.1 73.9     25.2 35.8      79.2 93.3




Table 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS
benchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are
minimal on easy one-step or two-step problems where large language models already achieve high
performance (e.g., SingleOp, SingleEq, and AddSub).
                              SingleOp       SingleEq      AddSub       MultiArith
           Model            standard CoT standard CoT standard CoT standard CoT
           UL2      20B         24.9 27.2    18.0 20.2      18.5 18.2       5.0 10.7
           LaMDA 420M            2.8 1.0      2.4 0.4        1.9 0.7        5.8 1.5
                 2B              4.6 4.1      2.4 3.3        2.7 3.2        5.8 1.8
                 8B              8.0 7.0      4.5 4.4        3.4 5.2        5.2 2.4
                 68B            36.5 40.8    23.9 26.0      17.3 23.2       8.7 32.4
                 137B           73.2 76.2    48.8 58.7      43.0 51.9       7.6 44.9
           GPT      350M         3.2 1.8      2.0 0.2        2.0 1.5        2.3 0.8
                    1.3B         5.3 3.0      2.4 1.6        2.3 1.5        2.2 0.5
                    6.7B        13.5 3.9      8.7 4.9        8.6 2.5        4.5 2.8
                    175B        90.9 88.8    82.7 86.6      83.3 81.3      33.8 91.7
           Codex    -           93.1 91.8    86.8 93.1      90.9 89.1      44.0 96.2
           PaLM     8B          41.8 46.6    29.5 28.2      29.4 31.4       4.2 15.8
                    62B         87.9 85.6    77.2 83.5      74.7 78.2       7.3 73.7
                    540B        94.1 94.1    86.5 92.3      93.9 91.9      42.2 94.7




                                               21
Table 4: Standard prompting versus chain of thought prompting on five commonsense reasoning
benchmarks. Chain of thought prompting is an emergent ability of model scale‚Äîit does not positively
impact performance until used with a model of sufficient scale.
                       CSQA         StrategyQA         Date         Sports         SayCan
    Model             standard CoT standard CoT standard CoT standard CoT standard CoT
    UL2      20B           34.2 51.4     59.0 53.3       13.5 14.0     57.9 65.3          20.0 41.7
    LaMDA 420M             20.1   19.2   46.4   24.9      1.9 1.6      50.0   49.7         7.5 7.5
          2B               20.2   19.6   52.6   45.2      8.0 6.8      49.3   57.5         8.3 8.3
          8B               19.0   20.3   54.1   46.8      9.5 5.4      50.0   52.1        28.3 33.3
          68B              37.0   44.1   59.6   62.2     15.5 18.6     55.2   77.5        35.0 42.5
          137B             53.6   57.9   62.4   65.4     21.5 26.8     59.5   85.8        43.3 46.6
    GPT      350M          14.7   15.2   20.6 0.9         4.3 0.9      33.8 41.6          12.5 0.8
             1.3B          12.0   19.2   45.8 35.7        4.0 1.4       0.0 26.9          20.8 9.2
             6.7B          19.0   24.0   53.6 50.0        8.9 4.9       0.0 4.4           17.5 35.0
             175B          79.5   73.5   65.9 65.4       43.8 52.1     69.6 82.4          81.7 87.5
    Codex    -             82.3 77.9     67.1 73.2       49.0 64.8     71.7 98.5          85.8 88.3
    PaLM     8B            19.8 24.9     55.6 53.5       12.9 13.1     55.1 75.2          34.2 40.0
             62B           65.4 68.1     58.4 63.4       29.8 44.7     72.1 93.6          65.8 70.0
             540B          78.1 79.9     68.6 77.8       49.0 65.3     80.5 95.4          80.8 91.7




Table 5: Standard prompting versus chain of thought prompting enables length generalization to
longer inference examples on two symbolic manipulation tasks.
                      Last Letter Concatenation               Coin Flip (state tracking)
                       2            OOD: 3      OOD: 4          2           OOD: 3          OOD: 4
 Model            standard CoT standard CoT standard CoT standard    CoT standard CoT standard CoT
 UL2       20B        0.6 18.8       0.0 0.2      0.0 0.0    70.4 67.1        51.6 52.2      48.7 50.4
 LaMDA 420M           0.3 1.6        0.0 0.0      0.0 0.0    52.9    49.6     50.0 50.5      49.5 49.1
       2B             2.3 6.0        0.0 0.0      0.0 0.0    54.9    55.3     47.4 48.7      49.8 50.2
       8B             1.5 11.5       0.0 0.0      0.0 0.0    52.9    55.5     48.2 49.6      51.2 50.6
       68B            4.4 52.0       0.0 0.8      0.0 2.5    56.2    83.2     50.4 69.1      50.9 59.6
       137B           5.8 77.5       0.0 34.4     0.0 13.5   49.0    99.6     50.7 91.0      49.1 74.5
 PaLM      8B         2.6 18.8       0.0 0.0      0.0 0.2    60.0 74.4        47.3 57.1      50.9 51.8
           62B        6.8 85.0       0.0 59.6     0.0 13.4   91.4 96.8        43.9 91.0      38.3 72.4
           540B       7.6 99.4       0.2 94.8     0.0 63.0   98.1 100.0       49.3 98.6      54.8 90.2




                                                  22
Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally
outperforms ablations by a large amount. ‚ÄúEquation only‚Äù performs in between standard prompting
and chain of thought prompting, as it allows for intermediate reasoning steps via equations but does
not leverage natural language. Chain of thought prompting has variance (as expected) when used
with prompts written by different annotators or when using other exemplars, but still outperforms
standard prompting by a large margin. Standard deviation shown is for different order of few-shot
prompting exemplars, with five different random seeds. Results here are shown for LaMDA 137B, as
additional queries for GPT-3 and PaLM are both limited and expensive.
                                             GSM8K SVAMP               ASDiv MAWPS
           Standard prompting                 6.5 ¬±0.4   29.5 ¬±0.6   40.1 ¬±0.6   43.2 ¬±0.9
           Chain of thought prompting        14.3 ¬±0.4   36.7 ¬±0.4   46.6 ¬±0.7   57.9 ¬±1.5
           Ablations
           ¬∑ equation only                    5.4 ¬±0.2   35.1 ¬±0.4   45.9 ¬±0.6   50.1 ¬±1.0
           ¬∑ variable compute only            6.4 ¬±0.3   28.0 ¬±0.6   39.4 ¬±0.4   41.3 ¬±1.1
           ¬∑ reasoning after answer           6.1 ¬±0.4   30.7 ¬±0.9   38.6 ¬±0.6   43.6 ¬±1.0
           Robustness
           ¬∑ different annotator (B)         15.5 ¬±0.6   35.2 ¬±0.4   46.5 ¬±0.4   58.2 ¬±1.0
           ¬∑ different annotator (C)         17.6 ¬±1.0   37.5 ¬±2.0   48.7 ¬±0.7   60.1 ¬±2.0
           ¬∑ intentionally concise style     11.1 ¬±0.3   38.7 ¬±0.8   48.0 ¬±0.3   59.6 ¬±0.7
           ¬∑ exemplars from GSM8K (Œ±)        12.6 ¬±0.6   32.8 ¬±1.1   44.1 ¬±0.9   53.9 ¬±1.1
           ¬∑ exemplars from GSM8K (Œ≤)        12.7 ¬±0.5   34.8 ¬±1.1   46.9 ¬±0.6   60.9 ¬±0.8
           ¬∑ exemplars from GSM8K (Œ≥)        12.6 ¬±0.7   35.6 ¬±0.5   44.4 ¬±2.6   54.2 ¬±4.7


Table 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.
Chain of thought generally outperforms ablations by a large amount. Chain of thought prompting has
variance (as expected) when used with prompts written by different annotators or when using other
exemplars, but still outperforms standard prompting by a large margin. Standard deviation shown
is for different order of few-shot prompting exemplars, with five different random seeds. Results
here are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and
expensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is
only 120 examples and therefore less expensive to run multiple times.
                                              Commonsense                     Symbolic
                                          Date      Sports     SayCan      Concat            Coin
     Standard prompting               21.5 ¬±0.6   59.5 ¬±3.0   80.8 ¬±1.8    5.8 ¬±0.6   49.0 ¬±2.1
     Chain of thought prompting       26.8 ¬±2.1   85.8 ¬±1.8   91.7 ¬±1.4   77.5 ¬±3.8   99.6 ¬±0.3
     Ablations
     ¬∑ variable compute only          21.3 ¬±0.7   61.6 ¬±2.2   74.2 ¬±2.3    7.2 ¬±1.6   50.7 ¬±0.7
     ¬∑ reasoning after answer         20.9 ¬±1.0   63.0 ¬±2.0   83.3 ¬±0.6    0.0 ¬±0.0   50.2 ¬±0.5
     Robustness
     ¬∑ different annotator (B)        27.4 ¬±1.7   75.4 ¬±2.7   88.3 ¬±1.4   76.0 ¬±1.9    77.5 ¬±7.9
     ¬∑ different annotator (C)        25.5 ¬±2.5   81.1 ¬±3.6   85.0 ¬±1.8   68.1 ¬±2.2   71.4 ¬±11.1




                                                  23
C     Extended Related Work
Chain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-
ing, natural language explanations, program synthesis/execution, numeric and logical reasoning, and
intermediate language steps.

C.1   Prompting

The recent success of large-scale language models has led to growing interest in improving their
capability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a
survey). This paper falls in the category of general prompting approaches, whereby input prompts are
optimized to allow a single large language model to better perform a variety of tasks (Li and Liang,
2021; Lester et al., 2021; Reif et al., 2022, inter alia).
One recent line of work aims to improve the ability of language models to perform a task by providing
instructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh
et al., 2022; Wang et al., 2022b). This line of work is related because it also augments input‚Äìoutput
pairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically
prepended to the inputs), chain-of-thought prompting augments the outputs of language models.
Another related direction is sequentially combining the outputs of language models; human‚Äìcomputer
interaction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of
language models improves task outcomes in a 20-person user study.

C.2   Natural language explanations

Another closely related direction uses natural language explanations (NLEs), often with the goal of
improving model interpretability (Zhou et al., 2020; Wiegreffe and MarasovicÃÅ, 2021, inter alia). That
line of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,
2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the final
prediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,
the chain of thought processing considered in this paper occurs before the final answer. And while
NLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of
chain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple
steps‚Äîinterpretability is just a side effect. MarasovicÃÅ et al. (2022) show that prompt-based finetuning
with NLE improves NLI and classification performance, though they largely focus on evaluating
explanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,
and symbolic tasks that require multi-hop reasoning.

C.3   Program synthesis and execution

Using intermediate reasoning steps has a long history in program synthesis and execution (Zaremba
and Sutskever, 2014, inter alia). Recent work along in this direction has included a number of
architectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of
large language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to
ours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit
addition, evaluate polynomials, and execute python programs. Whereas generating a program and
then executing it can be viewed as a type of reasoning, our work generalizes such domain-specific
primitives to natural language, which is open-domain and relevant to any text-to-text NLP task in
principle.

C.4   Numeric and logical reasoning

Numeric and logical reasoning has been a long-studied task in machine learning and natural language
processing (Lev et al., 2004, inter alia). Recent work has also aimed to inject numeric reasoning
abilities in language models in various ways, such as augmenting BERT with a predefined set of
executable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and
using specialized training procedures (PiÀõekos et al., 2021). Another line of work aims to enable
language models to perform logical or formal reasoning, often by verablizing the rules in natural
language formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).


                                                   24
Perhaps the most-related work here is Recchia (2021), which shows that finetuning enables longhand
module operations, which has previously been difficult for performers. Whereas work in this direction
is often task-specific and uses finetuning, we show that chain-of-thought prompting works for a broad
range of tasks without any finetuning.

C.5   Intermediate language steps

Extensive prior work has shown the benefits of endowing neural networks with the ability to produce
intermediate steps via training or finetuning confers various benefits in a range of scenarios. As
examples, it has been shown that natural language intermediate steps can improve performance
(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness
(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and
even help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with
the ability to produce intermediate steps, prior work typically finetunes models on either manually
annotated training datasets (Camburu et al., 2018; Rajani et al., 2019, inter alia) or generates synthetic
datasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or finetuning
methods, our work shows that various natural language reasoning abilities can be elicited in off-the-
shelf language models of sufficient scale simply via prompting. This prompting setup is important
because it allows for intermediate step reasoning without a large number of labeled annotations, and
because a single model can perform a range of reasoning tasks without any gradient updates.

D     Appendix: Additional Analysis
D.1   Correct Chain of Thought Analysis

As mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to
correct answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through
incorrect reasoning (shown in Table 9: ‚Äúcorrect by chance‚Äù). The other 49 had correct logic and
math, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and
understandable logic:
‚Ä¢ One had underspecified statements (shown in Table 9: ‚Äúcorrect but underspecified statements‚Äù).
‚Ä¢ One made an unrelated but correct statement (shown in Table 9: ‚Äúcorrect but unrelated statement‚Äù).
‚Ä¢ Two had the correct logic but omitted specific steps in the equation, though it was still understand-
  able (shown in Table 9: ‚Äúcorrect but imperfect equation‚Äù).
‚Ä¢ One had the correct math but inverted the semantics (shown in Table 9: ‚Äúcorrect but inverted
  semantics‚Äù)

  Table 8: Example of correct chains of thought produced by the model for the GSM8K dataset.

 Q UESTION : James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total
 meters does he run a week?
 M ODEL A NSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each
 sprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. X
 Q UESTION : Brandon‚Äôs iPhone is four times as old as Ben‚Äôs iPhone. Ben‚Äôs iPhone is two times older than Suzy‚Äôs
 iPhone. If Suzy‚Äôs iPhone is 1 year old, how old is Brandon‚Äôs iPhone?
 M ODEL A NSWER (CORRECT): Brandon‚Äôs iPhone is 4 times as old as Ben‚Äôs iPhone. Ben‚Äôs iPhone is 2
 times older than Suzy‚Äôs iPhone. So Brandon‚Äôs iPhone is 4 x 2 = 8 times older than Suzy‚Äôs iPhone. Suzy‚Äôs iPhone
 is 1 year old. So Brandon‚Äôs iPhone is 8 x 1 = 8 years old. The answer is 8. X
 Q UESTION : Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to
 package 2 lollipops in one bag. How many bags can Jean fill?
 M ODEL A NSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops
 left. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. X


Although we find that chain-of-thought reasoning is mostly correct for math questions where the final
answer was correct, this is likely because it is hard to arrive at the correct final answer by coincidence
for free response questions. For multiple choice or binary classification problems, it was much more


                                                    25
likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the
commmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform
an analysis of the factuality of such chains of thought.

Table 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of
thought the model generated was imperfect. We found the other 43 to be equivalent to what a human
would potentially generate as a ground truth.

 Q UESTION : There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.
 Another one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?
 M ODEL A NSWER ( CORRECT BY CHANCE ): There are 36 penguins. One-third of them jump in and swim in
 the ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.
 The answer is 12.
 Q UESTION : John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an
 additional 4 windows in each house not connected to bedrooms. How many total windows are there between the
 houses?
 M ODEL A NSWER ( CORRECT BUT UNDERSPECIFIED STATEMENTS ): There are 2 houses with 3 bedrooms
 each. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional
 4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are
 6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.
 Q UESTION : If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?
 M ODEL A NSWER ( CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her
 age. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The
 answer is 21.
 Q UESTION : A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per
 gallon if you fill up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the
 cashback rewards?
 M ODEL A NSWER ( CORRECT BUT IMPERFECT EQUATION ): The gas is originally 3 dollars per gallon. If
 you buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So
 the total is 30 - 2 = 28 dollars. The answer is 28 dollars.
 Q UESTION : Nissa hires 60 seasonal workers to play elves in her department store‚Äôs Santa village. A third of
 the elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How
 many elves are left?
 M ODEL A NSWER ( CORRECT BUT IMPERFECT EQUATION ): Nissa hires 60 seasonal workers. A third of
 them quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30
 elves.
 Q UESTION : Grandma Jones baked 5 apple pies for the fireman‚Äôs luncheon. She cut each pie into 8 pieces and
 set the five pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the
 guests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were
 taken by the guests?
 M ODEL A NSWER ( CORRECT BUT INVERTED SEMANTICS ): 5 pies were baked and cut into 8 pieces each.
 The 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26
 pieces of pie were left. The answer is 26. X




                                                       26
D.2   Incorrect Chain of Thought Analysis

We also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K
for LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design
of error categorization non-trivial. We decided to categorize errors into what changes are needed to
make the chain of thought correct, with the goal of elucidating how the model can be improved in the
future.
We found that many chains of thought can be made correct with one of the following three classes of
modification.
‚Ä¢ Calculator error only. We found that 8% of the chains of thought were completely correct except
  for a calculator error‚Äîin other words, applying an external calculator to equations, as done in
  Cobbe et al. (2021), would make the chain of thought correct. An example of this type of error is
  shown in Table 10: ‚Äúcalculator error only‚Äù. Indeed, the solve rate of chain-of-thought prompting
  on for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program
  as an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator
  errors in addition to other types of errors. However, we perform the rest of the error categorization
  independently of calculator errors.
‚Ä¢ Symbol mapping error. We next found that 16% percent of the chains of thought were correct
  except for what we call symbol mapping errors. We define a symbol mapping error as when the
  chain of thought is correct except for the number symbols, and it could be made totally correct by
  modifying only the equations and not the words. As one might argue that they could simply place
  the correct final equation in any chain of thought, we constrain this category to chains of thought
  where the chain of thought can be modified to be a completely correct reasoning process (not just
  final answer). An example of this error category is shown in Table 10: ‚Äúsymbol mapping error‚Äù.
‚Ä¢ One step missing error. Our next category of error is chains of thought which were correct except
  that they were missing a single step. In other words, these chains of thoughts could be rewritten to
  be correct by adding in an additional reasoning step that was missed by the model. An example of
  this error category is shown in Table 10: ‚Äúone step missing error‚Äù. We found that 22% percent of
  the errors fell into this category.

  Table 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.

 Q UESTION : Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns
 are there total?
 M ODEL A NSWER ( INCORRECT; CALCULATOR ERROR ONLY ): Dan plants 3 rose bushes. Each rose bush
 has 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. 7
 E XPLANATION FOR E RROR C ATEGORY: The produced chain of thought could be made correct just by
 running the equation through an external calculator, instead of asking the model to do the computation.
 Q UESTION : Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a
 year, 35 hours a week as a teacher and 15 hours a week as a coach, what‚Äôs her annual salary?
 M ODEL A NSWER ( INCORRECT; SYMBOL MAPPING ERROR ): Jill gets paid 20 dollars per hour to teach
 and 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher
 and 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a
 coach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars
 per hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. 7
 E XPLANATION FOR E RROR C ATEGORY: The model incorrectly mapped ‚Äú15 x 30‚Äù instead of ‚Äú15 x 50‚Äù, and
 the chain of thought would be made correct by fixing just that one change (with an external calculator).
 Q UESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having
 twice as many instructions as the first one. How many instructions does Kelian have to read to prepare the two
 dishes?
 M ODEL A NSWER ( INCORRECT; ONE STEP MISSING ERROR ): Kelian has two recipes. One has 20 instruc-
 tions. The other has twice as many instructions as the first one. So the second one has 40 instructions. So Kelian
 has to read 40 instructions to prepare the two dishes. The answer is 40. 7
 E XPLANATION FOR E RROR C ATEGORY: The model answer could be made correct just adding one additional
 step (in this case, adding 20 and 40).



                                                      27
We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make
into a correct chain of thought. Almost all cases here involved some error in semantic understanding
(see Table 11: ‚Äúsemantic understanding error‚Äù), and 8 of the 27 also had incoherent chain of thoughts,
meaning that some statements in the generated chain of thought did not follow from prior ones or
violated basic world knowledge (see Table 11: ‚Äúincoherent chain of thought error‚Äù).

Table 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These
chains of thought had multiple mistakes that could not be fixed with minor edits.

 Q UESTION : Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins
 does Gretchen have?
 M ODEL A NSWER ( INCORRECT; SEMANTIC UNDERSTANDING ERROR ): Gretchen has 110 coins. There
 are 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and
 110 - 80 = 30 gold coins. The answer is 30. 7
 E XPLANATION FOR E RROR C ATEGORY: The model does not understand that 110 coins are in total and that
 it must solve an equation to get the number of gold and silver coins.
 Q UESTION : In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining
 enrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in
 hip-hop dance?
 M ODEL A NSWER ( INCORRECT; INCOHERENT CHAIN OF THOUGHT ERROR ): 20% of the students en-
 rolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop
 dance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students
 enrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the
 percentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop
 dance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. 7
 E XPLANATION FOR E RROR C ATEGORY: This chain of thought is incoherent in that the percent of entire
 students enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another
 term.


Overall, there are no guarantees that the reasoning processes generated by large language models
are coherent or factually correct, as underscored by the recent work evaluating the factuality of
language model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and
Durrett, 2022; MarasovicÃÅ et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead
to both incorrect final answers as well as accidentally correct final answers (with accidentally correct
final answers being more likely for tasks such as binary classification as opposed to free response).
Improving the factuality of language model generations with respect to context and world knowledge
is an important direction open problems in language model research and could also be expected to
potentially improve multi-step reasoning abilities of language models. One potential method for
improving the quality of decoding could involve generating multiple reasoning paths and scoring
each of them with a verifier, though this requires training the verifier (Cobbe et al., 2021; Shen et al.,
2021; Thoppilan et al., 2022).

D.3   Additional Robustness Analysis

As the experiments in the main paper use a fixed number of few-shot exemplars (8; as constrained by
the input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various
numbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought
prompting with standard prompting for the five datasets where standard prompting had a mostly flat
scaling curve (the largest model did not achieve high performance). As shown in Figure 11, the
improvement of chain-of-thought prompting over standard prompting remains robust to varying the
number of few-shot exemplars in the prompt.




                                                       28
                                                                  Standard prompting
                                                               Chain of thought prompting

                                             MultiArith                Sports                                      Last Letter
                       GSM8K                 (MAWPS)                Understanding           Coin Flip             Concatenation
                                       60                    100                    100                     100
                 15
Solve rate (%)




                                                               75                    75                      75
                 10                    40
                                                               50                    50                      50
                  5                    20
                                                               25                    25                      25
                  0                    0                      0                    0                          0
                      12   4   6   8        12   4   6    8     12 4 6 8             12         4   6   8         1   2    3   4
                                                          Number of few-shot exemplars

Figure 11: The improvement of chain of thought prompting over standard prompting appears robust
to varying the number of few-shot exemplars in the prompt.




Table 12: Summary of math word problem benchmarks we use in this paper with examples. N :
number of evaluation examples.
 Dataset                N Example problem
GSM8K                                  1,319 Josh decides to try flipping a house. He buys a house for $80,000 and then puts
                                                 in $50,000 in repairs. This increased the value of the house by 150%. How
                                                 much profit did he make?
SVAMP                                  1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each
                                                 pack. How much do you have to pay to buy each pack?
ASDiv                                  2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does
                                                 Ellen have?
AQuA                                    254      A car is being driven, in a straight line and at a uniform speed, towards the base
                                                 of a vertical tower. The top of the tower is observed from the car and, in the
                                                 process, it takes 10 minutes for the angle of elevation to change from 45‚ó¶ to 60‚ó¶ .
                                                 After how much  ‚àö more time‚àöwill ‚àö this car reach
                                                                                              ‚àö the base   ‚àö of the tower? Answer
                                                 Choices: (a) 5 3 + 1 (b) 6 3 + 2 (c) 7 3 - 1 (d) 8 3 - 2 (e) None of these
MAWPS: SingleOp                         562      If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how
                                                 many bottle caps are in the box?
MAWPS: SingleEq                         508      Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27
                                                 dollars. How much did each candy bar cost?
MAWPS: AddSub                           395      There were 6 roses in the vase. Mary cut some roses from her flower garden.
                                                 There are now 16 roses in the vase. How many roses did she cut?
MAWPS: MultiArith                       600      The school cafeteria ordered 42 red apples and 7 green apples for students
                                                 lunches. But, if only 9 students wanted fruit, how many extra did the cafeteria
                                                 end up with?




                                                                      29
E       Additional Details

Version Control
V5 ‚Üí V6. Fixed minor typo in Figure 3.
V4 ‚Üí V5. Added Codex and UL2 results. Small changes to writing and style of paper.
V3 ‚Üí V4. Fixed typo in Figure 3 and added a couple citations.
V2 ‚Üí V3. Added GPT-3 results. Added SVAMP and AQuA eval datasets for math. Added SayCan
eval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for
Commonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw
results in Appendix B.
V1 ‚Üí V2. Added PaLM results (V1 only had LaMDA).

E.1      Reproducibility Statement

As our results make use of two sets of large language models that is not publicly available, we take
the following actions to facilitate reproducibility. First, we provide the exact input prompts for all
tasks in Table 20‚ÄìTable 27 in Appendix G (and emphasize that we do not perform any finetuning and
only apply prompting to off-the-shelf language models). Second, we conduct experiments using the
publicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,
text-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each
task available as a zip file in the supplementary material.

E.2      Computational Resources

For all three language models we evaluated, we did prompting-based inference only. No finetuning
was done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 configuration, 64 chips
/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 configuration, 192 chips / 384
cores). GPT-3 experiments were done using the public API.5

E.3      Dataset Details and Licenses

We list the details and licenses for all arithmetic and commonsense datasets used in this paper. The
symbolic reasoning datasets were created synthetically, as described in Section 4.

Arithmetic reasoning

          ‚Ä¢ Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini
            et al., 2014): https://www.cs.washington.edu/nlp/arithmetic; MultiArith (Roy
            and Roth, 2015), license: CC BY 4.0.
          ‚Ä¢ ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset.
          ‚Ä¢ AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA, license: https://
            github.com/deepmind/AQuA/blob/master/LICENSE.
          ‚Ä¢ GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math,
            MIT license: https://github.com/openai/grade-school-math/blob/master/
            LICENSE.
          ‚Ä¢ SVAMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP, MIT license:
            https://github.com/arkilpatel/SVAMP/blob/main/LICENSE.

Commonsense reasoning

          ‚Ä¢ CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa, https://
            github.com/jonathanherzig/commonsenseqa.
    5
        https://beta.openai.com/docs/api-reference/making-requests


                                                 30
‚Ä¢ StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)
  from BIG-bench collaboration (2021): https://github.com/google/BIG-bench/
  tree/main/bigbench/benchmark_tasks/strategyqa. The original dataset is from
  https://github.com/eladsegal/strategyqa, MIT license: https://github.com/
  eladsegal/strategyqa/blob/main/LICENSE.
‚Ä¢ Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,
  2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/
  LICENSE.
‚Ä¢ SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.
  io/ under CC BY 4.0 license.




                                      31
F   Appendix: Input/Output Examples

Table 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the
letter concatenation task.

 Q UESTION : Take the last letters of the words in ‚ÄúWaldo Schmidt‚Äù and concatenate them.
 M ODEL A NSWER (CORRECT): The last letter of ‚ÄúWaldo‚Äù is ‚Äúo‚Äù. The last letter of ‚ÄúSchmidt‚Äù is ‚Äút‚Äù.
 Concatenating them is ‚Äúot‚Äù. So the answer is ot. X
 Q UESTION : Take the last letters of the words in ‚ÄúDaniel Friedman‚Äù and concatenate them.
 M ODEL A NSWER (INCORRECT): The last letter of ‚ÄúDaniel‚Äù is ‚Äúl‚Äù. The last letter of ‚ÄúFriedman‚Äù is ‚Äúm‚Äù.
 Concatenating them is ‚Äúlm‚Äù. So the answer is lm. 7


Table 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the
coinflip task.

 Q UESTION : A coin is heads up. Andree flips the coin. Audrie does not flip the coin. Is the coin still heads up?
 M ODEL A NSWER (CORRECT): The coin was flipped by Andree. So the coin was flipped 1 time, which is
 an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is no.
 X
 Q UESTION : A coin is heads up. Kristian does not flip the coin. Dallas does not flip the coin. Is the coin still
 heads up?
 M ODEL A NSWER (INCORRECT): The coin was flipped by Kristian. So the coin was flipped 1 time, which
 is an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is
 no. 7



Table 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.

 Q UESTION : When a person is beginning work, what are they building?
 Answer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness
 M ODEL A NSWER (CORRECT): The answer must be something that is built. Of the above choices, only
 momentum is built. So the answer is (d). X
 Q UESTION : Where are you likely to find a hamburger?
 Answer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus
 M ODEL A NSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above
 choices, only fast food restaurants serve hamburgers. So the answer is (a). X
 Q UESTION : Aside from water and nourishment what does your dog need?
 Answer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked
 M ODEL A NSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,
 only bone is something that a dog needs. So the answer is (a). 7 (Ground truth is (d).)
 Q UESTION : What are you waiting alongside with when you‚Äôre in a reception area?
 Answer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels
 M ODEL A NSWER (INCORRECT): The answer must be something that is waiting with you in a reception
 area. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). 7 (Ground
 truth is (d).)




                                                       32
Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on
StrategyQA.

 Q UESTION : Will The Exorcist stimulate limbic system?
 M ODEL A NSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system
 is involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. X
 Q UESTION : Was Jackson Pollock trained by Leonardo da Vinci?
 M ODEL A NSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the
 20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. X
 Q UESTION : Can Harry Potter book a flight on Asiana Airlines?
 M ODEL A NSWER (INCORRECT): Harry Potter is a fictional character. Thus, Harry Potter can do anything.
 So the answer is yes. 7 (Ground truth is ‚Äúno‚Äù.)
 Q UESTION : Would a sophist use an √©p√©e?
 M ODEL A NSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An √©p√©e is
 a type of sword. Thus, a sophist could use an √©p√©e. So the answer is yes. 7 (Ground truth is ‚Äúno‚Äù.)


Table 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date
Understanding.

 Q UESTION : May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month
 ago in MM/DD/YYYY?
 M ODEL A NSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will
 be April 6, 2002. So the answer is 04/06/2002. X
 Q UESTION : This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?
 M ODEL A NSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is
 01/01/1900. X
 Q UESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one
 week ago from today in MM/DD/YYYY?
 M ODEL A NSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the
 answer is 7/2/1972. 7 (Ground truth is 07/01/1972.)
 Q UESTION : Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same
 backwards as forwards. What is the date tomorrow in MM/DD/YYYY?
 M ODEL A NSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is
 03/01/2020. 7 (Ground truth is ‚Äú02/03/2020‚Äù.)


Table 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports
Understanding.

 Q UESTION : Is the following sentence plausible? ‚ÄúJoao Moutinho was out at third.‚Äù
 M ODEL A NSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not
 soccer. So the answer is no. X
 Q UESTION : Is the following sentence plausible? ‚ÄúMalcolm Brogdon eurostepped to the basket in the NBA
 Championship.‚Äù
 M ODEL A NSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part
 of basketball. So the answer is yes. X
 Q UESTION : Is the following sentence plausible? ‚ÄúDerrick White backhanded a shot.‚Äù
 M ODEL A NSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of
 basketball. So the answer is yes. 7 (Ground truth is ‚Äúno‚Äù, backhanding a shot is part of hockey.)
 Q UESTION : Is the following sentence plausible? ‚ÄúNazem Kadri was out at home.‚Äù
 M ODEL A NSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.
 So the answer is yes. 7 (Ground truth is ‚Äúno‚Äù, being out at home is part of baseball.)



                                                     33
Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan
robot planning tasks.

 Q UESTION : I spilled my coke on the table, could you throw it away and then bring me something to help clean?
 M ODEL A NSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away
 the coke and then bring the user a sponge. Plan: find(coke), pick(coke), find(trash), put(coke), find(sponge),
 pick(sponge), find(table), put(sponge). X
 Q UESTION : Could you compost that apple for me?
 M ODEL A NSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the
 apple to the compost. Plan: find(apple), pick(apple), find(trash), put(apple). X
 Q UESTION : Can you bring me a drink that is not coke?
 M ODEL A NSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will
 bring a sprite. Plan: find(sprite), pick(sprite), find(user), put(sprite). 7 (Feasible answers including finding lime
 soda, pepsi, grapefruit soda or water, because there is no sprite in the scene as defined in Table 28.)
 Q UESTION : Can you bring me something salty?
 M ODEL A NSWER (INCORRECT): Explanation: The user would like something salty. There are several
 options in the objects list, so I will bring the user a lime soda. Plan: find(lime soda), pick(lime soda), find(user),
 put(lime soda). 7 (Feasible answers including finding chips. The model misidentify lime soda as salty.)




                                                        34
G    Appendix: Full Prompts




Table 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of
exemplars was used for all math word problem datasets except AQuA.

 P ROMPT FOR M ATH W ORD P ROBLEMS
 Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there
 will be 21 trees. How many trees did the grove workers plant today?
 A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have
 been 21 - 15 = 6. The answer is 6.
 Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
 A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.
 Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
 A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they
 had 74 - 35 = 39. The answer is 39.
 Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did
 Jason give to Denny?
 A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.
 The answer is 8.
 Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he
 have now?
 A: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.
 The answer is 9.
 Q: There were nine computers in the server room. Five more computers were installed each day, from monday
 to thursday. How many computers are now in the server room?
 A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20
 computers were added. 9 + 20 is 29. The answer is 29.
 Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf
 balls did he have at the end of wednesday?
 A: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he
 had 35 - 2 = 33 golf balls. The answer is 33.
 Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
 A: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23
 - 15 is 8. The answer is 8.



                                                        35
             Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.

 P ROMPT FOR AQ UA ALGEBRAIC WORD PROBLEMS
 Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers
 is?
 Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64
 A: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be
 50. The answer is (a).
 Q: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.
 Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2
 A: If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simplifies to 8a + 20a / 3 = 22, which means 44a / 3
 = 22. So a is equal to 3/2. The answer is (b).
 Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance?
 Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km
 A: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).
 Q: How many keystrokes are needed to type the numbers from 1 to 500?
 Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788
 A: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401
 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).




Table 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.

 P ROMPT FOR L AST L ETTER C ONCATENATION
 Q: Take the last letters of the words in "Elon Musk" and concatenate them.
 A: The last letter of "Elon" is "n". The last letter of "Musk" is "k". Concatenating them is "nk". The answer is nk.
 Q: Take the last letters of the words in "Larry Page" and concatenate them.
 A: The last letter of "Larry" is "y". The last letter of "Page" is "e". Concatenating them is "ye". The answer is ye.
 Q: Take the last letters of the words in "Sergey Brin" and concatenate them.
 A: The last letter of "Sergey" is "y". The last letter of "Brin" is "n". Concatenating them is "yn". The answer is
 yn.
 Q: Take the last letters of the words in "Bill Gates" and concatenate them.
 A: The last letter of "Bill" is "l". The last letter of "Gates" is "s". Concatenating them is "ls". The answer is ls.



                                                        36
      Table 23: Few-shot exemplars for full chain of thought prompt for the coinflip task.

P ROMPT FOR C OIN F LIP
Q: Q: A coin is heads up. Ka flips the coin. Sherrie flips the coin. Is the coin still heads up?
A: The coin was flipped by Ka and Sherrie. So the coin was flipped 2 times, which is an even number. The coin
started heads up, so after an even number of flips, it will still be heads up. So the answer is yes.
Q: A coin is heads up. Jamey flips the coin. Teressa flips the coin. Is the coin still heads up?
A: The coin was flipped by Jamey and Teressa. So the coin was flipped 2 times, which is an even number. The
coin started heads up, so after an even number of flips, it will still be heads up. So the answer is yes.
Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up?
A: The coin was flipped by Maybelle. So the coin was flipped 1 time, which is an odd number. The coin started
heads up, so after an odd number of flips, it will be tails up. So the answer is no.
Q: A coin is heads up. Millicent does not flip the coin. Conception flips the coin. Is the coin still heads up?
A: The coin was flipped by Conception. So the coin was flipped 1 time, which is an odd number. The coin
started heads up, so after an odd number of flips, it will be tails up. So the answer is no.
Q: A coin is heads up. Sal flips the coin. Raymond does not flip the coin. Is the coin still heads up?
A: The coin was flipped by Sal. So the coin was flipped 1 time, which is an odd number. The coin started heads
up, so after an odd number of flips, it will be tails up. So the answer is no.
Q: A coin is heads up. Conception flips the coin. Kristian does not flip the coin. Is the coin still heads up?
A: The coin was flipped by Conception. So the coin was flipped 1 time, which is an odd number. The coin
started heads up, so after an odd number of flips, it will be tails up. So the answer is no.
Q: A coin is heads up. Inga does not flip the coin. Elanor does not flip the coin. Is the coin still heads up?
A: The coin was flipped by no one. So the coin was flipped 0 times. The coin started heads up, and it was not
flipped, so it is still heads up. So the answer is yes.
Q: A coin is heads up. Ryan flips the coin. Shaunda flips the coin. Is the coin still heads up?
A: The coin was flipped by Ryan and Shaunda. So the coin was flipped 2 times, which is an even number. The
coin started heads up, so after an even number of flips, it will still be heads up. So the answer is yes.




                                                      37
Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines
between the answer choices that are omitted in the table for space reasons.

 P ROMPT FOR CSQA
 Q: What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)
 calligrapher‚Äôs hand (c) inkwell (d) desk drawer (e) blotter
 A: The answer must be an item that can absorb ink. Of the above choices, only blotters are used to absorb ink.
 So the answer is (e).
 Q: What home entertainment equipment requires cable?
 Answer Choices: (a) radio shack (b) substation (c) television (d) cabinet
 A: The answer must require cable. Of the above choices, only television requires cable. So the answer is (c).
 Q: The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty flowers (b)
 hen house (c) natural habitat (d) storybook
 A: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the
 answer is (b).
 Q: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas
 (b) race track (c) desert (d) apartment (e) roadblock
 A: The answer must be a place with a lot of people. Of the above choices, only populated areas have a lot of
 people. So the answer is (a).
 Q: Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super
 market (d) fruit basket (e) fruit market
 A: The answer should be the place where grocery items are placed before checking out. Of the above choices,
 grocery cart makes the most sense for holding grocery items. So the answer is (b).
 Q: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united
 states (b) mexico (c) countryside (d) atlas
 A: The answer must be something that used to do what Google Maps and GPS services do, which is to give
 directions. Of the above choices, only atlases are used to give directions. So the answer is (d).
 Q: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)
 anguish (c) bitterness (d) tears (e) sadness
 A: The answer should be the feeling of someone getting divorced who was doing all the work. Of the above
 choices, the closest feeling is bitterness. So the answer is (c).




                                                      38
        Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.

P ROMPT FOR S TRATEGY QA
Q: Do hamsters provide food for any animals?
A: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. So
the answer is yes.
Q: Could Brooke Shields succeed at University of Pennsylvania?
A: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the
University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the
answer is yes.
Q: Yes or no: Hydrogen‚Äôs atomic number squared exceeds number of Spice Girls?
A: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen‚Äôs atomic
number squared is less than 5. So the answer is no.
Q: Yes or no: Is it common to see frost during some college commencements?
A: College commencement ceremonies can happen in December, May, and June. December is in the winter, so
there can be frost. Thus, there could be frost at some commencements. So the answer is yes.
Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?
A: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6
months. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no.
Q: Yes or no: Would a pear sink in water?
A: The density of a pear is about 0.6g/cm3 , which is less than water. Objects less dense than water float. Thus,
a pear would float. So the answer is no.




    Table 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.

P ROMPT FOR DATE U NDERSTANDING
Q: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?
A: If 2015 is coming in 36 hours, then it is coming in 2 days. 2 days before 01/01/2015 is 12/30/2014, so today
is 12/30/2014. So one week from today will be 01/05/2015. So the answer is 01/05/2015.
Q: The first day of 2019 is a Tuesday, and today is the first Monday of 2019. What is the date today in
MM/DD/YYYY?
A: If the first day of 2019 was Tuesday, then 01/01/2019 was a Tuesday. Today is the first monday, would be six
days later. So today is 01/07/2019. So the answer is 01/07/2019.
Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10
days ago in MM/DD/YYYY?
A: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the
answer is 05/23/1943.
Q: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?
A: Today is 04/19/1969. 24 hours later is one day after today, which would be 04/20/1969. So the answer is
04/20/1969.
Q: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours
later in MM/DD/YYYY?
A: Today is 03/12/2002. So the date 24 hours later will be 03/13/2002. So the answer is 03/13/2002.
Q: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date
yesterday in MM/DD/YYYY?
A: The last day of February is the 28th, so Jane was born on 02/28/2001. Today is her 16-year old birthday, so
today is 02/28/2017. So yesterday was 02/27/2017. So the answer is 02/27/2017.



                                                     39
   Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.

P ROMPT FOR S PORTS U NDERSTANDING
Q: Is the following sentence plausible? ‚ÄúKyle Palmieri was called for slashing.‚Äù
A: Kyle Palmieri is a hockey player. Being called for slashing is part of hockey. So the answer is yes.
Q: Is the following sentence plausible? ‚ÄúJoao Moutinho caught the screen pass in the NFC championship.‚Äù
A: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the
answer is no.
Q: Is the following sentence plausible? ‚ÄúCarson Wentz set the pick and roll.‚Äù
A: Carson Wentz is an American football player. Pick and roll is part of basketball, not football. So the answer
is no.
Q: Is the following sentence plausible? ‚ÄúJonas Valanciunas beat the buzzer.‚Äù
A: Jonas Valanciunas is a basketball player. Beating the buzzer is part of basketball. So the answer is yes.
Q: Is the following sentence plausible? ‚ÄúJamel Murray was perfect from the line.‚Äù
A: Jamal Murray is a basketball player. Being perfect from the line is part of basketball. So the answer is yes.
Q: Is the following sentence plausible? ‚ÄúSam Darnold passed the puck.‚Äù
A: Sam Darnold is a American football player. Passing the puck is part of hockey, not American football. So the
answer is no.
Q: Is the following sentence plausible? ‚ÄúDraymond Green threw a touchdown.‚Äù
A: Draymond Green is an basketball player. Throwing a touchdown is part of football, not basketball. So the
answer is no.
Q: Is the following sentence plausible? ‚ÄúMalcolm Brogdon banked the shot in.‚Äù
A: Malcolm Brogdon is a basketball player. Banking the shot in is part of basketball. So the answer is yes.




                                                     40
Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.

P ROMPT FOR S AY C AN ROBOT P LANNING
Locations = [counter, table, user, trash, bowl].
Objects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,
grapefruit soda, pepsi, redbull, energy bar, sponge, water].
The robot can pick up items with pick(object) and put down items with put(object) as well as find objects or
locations with find(). The robot can only understand the explicit locations and objects listed.
Human: I‚Äôm hungry, can you bring me some chips.
Explanation: The user is hungry and has asked for chips. There are several types of chips available, I will bring
the user the kettle chips.
Plan: 1. find(kettle chips), 2. pick(kettle chips), 3. find(user), 4. put(kettle chips), 5. done().
Human: How would you move the grapefruit drink from the table to the counter?
Explanation: The user has asked me to move the grapefruit drink to the counter.
Plan: 1. find(grapefruit soda), 2. pick(grapefruit soda), 3. find(counter), 4. put(grapefruit soda), 5. done().
Human: How would you bring me some snacks?
Explanation: The user has asked for snacks, I will choose two items and bring them. I will bring jalapeno chips
and an apple.
Plan: 1. find(jalapeno chips), 2. pick(jalapeno chips), 3. find(user), 4. put(jalapeno chips), 5. find(apple), 6.
pick(apple), 7. find(user), 8. put(apple), 9. done().
Human: How would you bring me something to eat that isn‚Äôt a fruit?
Explanation: The user has asked for a food that isn‚Äôt a fruit, I will bring an energy bar to them.
Plan: 1. find(energy bar), 2. pick(energy bar), 3. find(user), 4. put(energy bar), 5. done().
Human: How would you put the rice chips in the bowl and then move the tea to the table?
Explanation: The user has asked me to do two tasks, I will do one and then the other.
Plan: 1. find(rice chips), 2. pick(rice chips), 3. find(bowl), 4. put(rice chips), 5. find(tea), 6. pick(tea), 7.
find(table), 8. put(tea), 9. done().
Human: How would you throw away a redbull?
Explanation: The user has asked me to throw away the redbull, I will move it to the trash.
Plan: 1. find(redbull), 2. pick(redbull), 3. find(trash), 4. put(redbull), 5. done().
Human: Bring me a drink.
Explanation: The user has asked for a drink and there are many options. I will bring them a water.
Plan: 1. find(water), 2. pick(water), 3. find(user), 4. put(water), 5. done().




                                                      41
H    Appendix: Alternate Annotators for MWP

Table 29: Few-shot exemplars for full chain of thought prompt for math word problems. These
exemplars are the same as in Table 20, except that the chains of thought were written by a different
annotator (‚ÄúAnnotator B‚Äù instead of ‚ÄúAnnotator A‚Äù). Annotators were co-authors and familiar with
the goal of chain of thought prompting.

 P ROMPT FOR M ATH W ORD P ROBLEMS
 Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there
 will be 21 trees. How many trees did the grove workers plant today?
 A: There are 21 trees now and there are 15 trees in the beginning, so the workers plant 21 - 15 = 6 trees. The
 answer is 6.
 Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
 A: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.
 Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
 A: Leah had 32 chocolates and her sister had 42, in total they have 32 + 42 = 74 chocolates. After they ate 35,
 now there are 74 - 35 = 39 chocolates. The answer is 39.
 Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did
 Jason give to Denny?
 A: Jason started with 20 lollipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lollipops. The answer
 is 8.
 Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he
 have now?
 A: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The
 answer is 9.
 Q: There were nine computers in the server room. Five more computers were installed each day, from monday
 to thursday. How many computers are now in the server room?
 A: 5 computers were installed from monday to thursday, so in total 5 * 4 = 20 computers are installed. 9
 computers are there in the beginning, so now there are 20 + 9 = 29 computers. The answer is 29.
 Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf
 balls did he have at the end of wednesday?
 A: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. After he lost 2 more, he has 35 - 2 = 33
 balls now. The answer is 33.
 Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
 A: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 =
 8 dollars left. The answer is 8.




                                                       42
Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These
exemplars are the same as in Table 20, except that the chains of thought were written by a different
annotator (‚ÄúAnnotator C‚Äù instead of ‚ÄúAnnotator A‚Äù).

 P ROMPT FOR M ATH W ORD P ROBLEMS
 Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there
 will be 21 trees. How many trees did the grove workers plant today?
 A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So,
 they must have planted 21 - 15 = 6 trees. The answer is 6.
 Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
 A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.
 Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
 A: Leah had 32 chocolates and Leah‚Äôs sister had 42. That means there were originally 32 + 42 = 74 chocolates.
 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.
 Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did
 Jason give to Denny?
 A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of
 lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.
 Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he
 have now?
 A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in
 total he has 7 + 2 = 9 toys. The answer is 9.
 Q: There were nine computers in the server room. Five more computers were installed each day, from monday
 to thursday. How many computers are now in the server room?
 A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20
 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The
 answer is 29.
 Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf
 balls did he have at the end of wednesday?
 A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday
 he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.
 Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
 A: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning,
 so now she has $23 - $15 = $8. The answer is 8.




                                                      43
                                      The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)




  Document-Level Relation Extraction with Adaptive Thresholding and Localized
                               Context Pooling
                              Wenxuan Zhou,1 * Kevin Huang,2 Tengyu Ma,3‚Ä† Jing Huang 2
                      1
                          Department of Computer Science, University of Southern California, Los Angeles, CA
                                                 2
                                                   JD AI Research, Mountain View, CA
                                 3
                                   Department of Computer Science, Stanford University, Stanford, CA
                           zhouwenx@usc.edu, {kevin.huang, jing.huang}@jd.com, tengyuma@stanford.edu




                              Abstract                                          John Stanistreet was an Australian politician. He was
  Document-level relation extraction (RE) poses new challenges                  born in Bendigo to legal manager John Jepson
  compared to its sentence-level counterpart. One document                      Stanistreet and Maud McIlroy. (‚Ä¶4 sentences‚Ä¶) In 1955
  commonly contains multiple entity pairs, and one entity pair
  occurs multiple times in the document associated with multiple                John Stanistreet was elected to the Victorian Legislative
  possible relations. In this paper, we propose two novel tech-
                                                                                Assembly as the Liberal and Country Party member for
  niques, adaptive thresholding and localized context pooling, to
  solve the multi-label and multi-entity problems. The adaptive                 Bendigo. Stanistreet died in Bendigo in 1971.
  thresholding replaces the global threshold for multi-label clas-
  sification in the prior work with a learnable entities-dependent              Subject: John Stanistreet     Object: Bendigo
  threshold. The localized context pooling directly transfers at-
  tention from pre-trained language models to locate relevant                   Relation: place of birth; place of death
  context that is useful to decide the relation. We experiment on
  three document-level RE benchmark datasets: DocRED, a re-                  Figure 1: An example of multi-entity and multi-label
  cently released large-scale RE dataset, and two datasets CDR               problems from the DocRED dataset. Subject entity John
  and GDA in the biomedical domain. Our ATLOP (Adaptive                      Stanistreet (in orange) and object entity Bendigo (in green)
  Thresholding and Localized cOntext Pooling) model achieves                 express relations place of birth and place of death. The re-
  an F1 score of 63.4, and also significantly outperforms ex-                lated entity mentions are connected by lines. Other entities
  isting models on both CDR and GDA. We have released our                    in the document are highlighted in grey.
  code at https://github.com/wzhouad/ATLOP.


                           Introduction                                         Compared to sentence-level RE, document-level RE poses
Relation extraction (RE) aims to identify the relationship                   unique challenges. For sentence-level RE datasets such as
between two entities in a given text and plays an impor-                     TACRED (Zhang et al. 2017) and SemEval 2010 Task 8 (Hen-
tant role in information extraction. Existing work mainly                    drickx et al. 2009), a sentence only contains one entity pair
focuses on sentence-level relation extraction, i.e., predicting              to classify. On the other hand, for document-level RE, one
the relationship between entities in a single sentence (Zeng                 document contains multiple entity pairs, and we need to clas-
et al. 2014; Miwa and Bansal 2016; Zhang, Qi, and Man-                       sify the relations of them all at once. It requires the RE model
ning 2018). However, large amounts of relationships, such                    to identify and focus on the part of the document with rel-
as relational facts from Wikipedia articles and biomedical                   evant context for a particular entity pair. In addition, one
literature, are expressed by multiple sentences in real-world                entity pair can occur many times in the document associated
applications (Verga, Strubell, and McCallum 2018; Yao et al.                 with distinct relations for document-level RE, in contrast
2019). This problem, commonly referred to as document-                       to one relation per entity pair for sentence-level RE. This
level relation extraction, necessitates models that can capture              multi-entity (multiple entity pairs to classify in a document)
complex interactions among entities in the whole document.                   and multi-label (multiple relation types for a particular entity
   * This
                                                                             pair) properties of document-level relation extraction make
          work was conducted while the first author was doing an
                                                                             it harder than its sentence-level counterpart. Figure 1 shows
internship at JD AI Research.
    ‚Ä†
      TM is also partially supported by the Google Faculty Award,
                                                                             an example from the DocRED dataset (Yao et al. 2019). The
JD.com, Stanford Data Science Initiative, and the Stanford Artificial        task is to classify the relation types of pairs of entities (high-
Intelligence Laboratory.                                                     lighted in color). For a particular entity pair (John Stanistreet,
Copyright ¬© 2021, Association for the Advancement of Artificial              Bendigo), it expresses two relations place of birth and place
Intelligence (www.aaai.org). All rights reserved.                            of death by the first two sentences and the last sentence. Other


                                                                     14612
sentences contain irrelevant information to this entity pair.          model significantly outperforms the state-of-the-art methods.
    To tackle the multi-entity problem, most current ap-               The contributions of our work are summarized as follows:
proaches construct a document graph with dependency struc-             ‚Ä¢ We propose adaptive-thresholding loss, which enables the
tures, heuristics, or structured attention (Peng et al. 2017;            learning of an adaptive threshold that is dependent on entity
Liu and Lapata 2018; Christopoulou, Miwa, and Ananiadou                  pairs and reduces the decision errors caused by using a
2019; Nan et al. 2020), and then perform inference with graph            global threshold.
neural models (Liang et al. 2016; Guo, Zhang, and Lu 2019).
The constructed graphs bridge entities that spread far apart in        ‚Ä¢ We propose localized context pooling, which transfers pre-
the document and thus alleviate the deficiency of RNN-based              trained attention to grab related context for entity pairs to
encoders (Hochreiter and Schmidhuber 1997; Chung et al.                  get better entity representations.
2014) in capturing long-distance information (Khandelwal               ‚Ä¢ We conduct experiments on three public document-level
et al. 2018). However, as transformer-based models (Vaswani              relation extraction datasets. Experimental results demon-
et al. 2017) can implicitly model long-distance dependen-                strate the effectiveness of our ATLOP model that achieves
cies (Clark et al. 2019; Tenney, Das, and Pavlick 2019), it              state-of-the-art performance on three benchmark datasets.
is unclear whether graph structures still help on top of pre-
trained language models such as BERT (Devlin et al. 2019).                               Problem Formulation
There have also been approaches to directly apply pre-trained          Given a document d and a set of entities {ei }ni=1 , the task
language models without introducing graph structures (Wang             of document-level relation extraction is to predict a sub-
et al. 2019a; Tang et al. 2020a). They simply average the em-          set of relations from R ‚à™ {NA} between the entity pairs
bedding of entity tokens to obtain the entity embeddings and           (es , eo )s, o=1...n; s6=o , where R is a pre-defined set of rela-
feed them into the classifier to get relation labels. However,         tions of interest, es , eo are identified as subject and object
each entity has the same representation in different entity            entities, respectively. An entity ei can occur multiple times in
pairs, which can bring noise from irrelevant context.                                                                Ne
                                                                       the document by entity mentions {mij }j=1i . A relation exists
    In this paper, instead of introducing graph structures, we
propose a localized context pooling technique. This technique          between entities (es , eo ) if it is expressed by any pair of their
solves the problem of using the same entity embedding for all          mentions. The entity pairs that do not express any relation are
entity pairs. It enhances the entity embedding with additional         labeled NA. At the test time, the model needs to predict the
context that is relevant to the current entity pair. Instead           labels of all entity pairs (es , eo )s, o=1...n; s6=o in document d.
of training a new context attention layer from scratch, we
directly transfer the attention heads from pre-trained language                       Enhanced BERT Baseline
models to get entity-level attention. Then, for two entities in        In this section, we present our base model for document-level
a pair, we merge their attentions by multiplication to find the        relation extraction. We build our model based on existing
context that is important to both of them.                             BERT baselines (Yao et al. 2019; Wang et al. 2019a) and in-
    For the multi-label problem, existing approaches reduce            tegrate other techniques to further improve the performance.
it to a binary classification problem. After training, a global
threshold is applied to the class probabilities to get relation        Encoder
labels. This method involves heuristic threshold tuning and            Given a document d = [xt ]lt=1 , we mark the position of
introduces decision errors when the tuned threshold from               entity mentions by inserting a special symbol ‚Äú*‚Äù at the start
development data may not be optimal for all instances.                 and end of mentions. It is adapted from the entity marker
    In this paper, we propose the adaptive thresholding tech-          technique (Zhang et al. 2017; Shi and Lin 2019; Soares et al.
nique, which replaces the global threshold with a learn-               2019). We then feed the document into a pre-trained language
able threshold class. The threshold class is learned with              model to obtain the contextual embeddings:
our adaptive-threshold loss, which is a rank-based loss that                  H = [h1 , h2 , ..., hl ] = BERT([x1 , x2 , ..., xl ]).   (1)
pushes the logits of positive classes above the threshold and
pulls the logits of negative classes below in model training.          Following previous work (Verga, Strubell, and McCallum
At the test time, we return classes that have higher logits than       2018; Wang et al. 2019b), the document is encoded once by
the threshold class as the predicted labels or return NA if such       the encoder, and the classification of all entity pairs is based
class does not exist. This technique eliminates the need for           on the same contextual embedding. We take the embedding
threshold tuning, and also makes the threshold adjustable to           of ‚Äú*‚Äù at the start of mentions as the mention embeddings. For
                                                                                                            Ne
different entity pairs, which leads to much better results.            an entity ei with mentions {mij }j=1i , we apply logsumexp
    By combining the proposed two techniques, we propose a             pooling (Jia, Wong, and Poon 2019), a smooth version of
simple yet effective relation extraction model, named ATLOP            max pooling, to get the entity embedding hei .
(Adaptive Thresholding and Localized cOntext Pooling), to                                            Nei
fully utilize the power of pre-trained language models (De-                                          X            
vlin et al. 2019; Liu et al. 2019). This model tackles the                               hei = log         exp hmij .                  (2)
                                                                                                     j=1
multi-label and multi-entity problems in document-level RE.
Experiments on three document-level relation extraction                This pooling accumulates signals from mentions in the docu-
datasets, DocRED (Yao et al. 2019), CDR (Li et al. 2016),              ment. It shows better performance compared to mean pooling
and GDA (Wu et al. 2019b), demonstrate that our ATLOP                  in experiments.


                                                               14613
Binary Classifier
Given the embedding (hes , heo ) of an entity pair es , eo com-
puted by equation (2), we map the entities to hidden states
z with a linear layer followed by non-linear activation, then
calculate the probability of relation r by bilinear function and
sigmoid activation. This process is formulated as:
                        zs = tanh (Ws hes ) ,               (3)
                        zo = tanh (Wo heo ) ,               (4)           Figure 2: An artificial illustration of our proposed adaptive-
                                                                          thresholding loss. A TH class is introduced to separate posi-
             P (r|es , eo ) = œÉ (zs| Wr zo + br ) ,                       tive classes and negative classes: positive classes would have
where Ws ‚àà Rd√ód , Wo ‚àà Rd√ód , Wr ‚àà Rd√ód , br ‚àà R                          higher probabilities than TH, and negative classes would
are model parameters. The representation of one entity is                 have lower probabilities than TH.
the same among different entity pairs. To reduce the number
of parameters in the bilinear classifier, we use the group
bilinear (Zheng et al. 2019; Tang et al. 2020b), which splits              ‚Ä¢ negative classes NT ‚äÜ R are the relations that do not exist
the embedding dimensions into k equal-sized groups and                       between the entities. If T does not express any relation,
applies bilinear within the groups:                                          NT = R.
           1                                                             If an entity pair is classified correctly, the logits of positive
           zs ; ...; zsk = zs ,
                        
           1                                                             classes should be higher than the threshold while those of neg-
           zo ; ...; zok = zo ,
                        
                                                                          ative classes should be lower. Here we introduce a threshold
                                k
                                                 !                        class TH, which is automatically learned in the same way as
                                                                          other classes (see Eq.(5)). At the test time, we return classes
                                X
                                   i|   i i
          P (r|es , eo ) = œÉ      zs Wr zo + br ,        (5)
                              i=1
                                                                          with higher logits than the TH class as positive classes or
                                                                          return NA if such classes do not exist. This threshold class
where Wri ‚àà Rd/k√ód/k for i = 1...k are model parameters,                  learns an entities-dependent threshold value. It is a substi-
P (r|es , eo ) is the probability that relation r is associated           tute for the global threshold and thus eliminates the need for
with the entity pair (es , eo ). In this way, we can reduce the           tuning threshold on the development set.
number of parameters from d2 to d2 /k. We use the binary                     To learn the new model, we need a special loss func-
cross entropy loss for training. During inference, we tune                tion that considers the TH class. We design our adaptive-
a global threshold Œ∏ that maximizes evaluation metrics (F1                thresholding loss based on the standard categorical cross
score for RE) on the development set and return r as an                   entropy loss. The loss function is broken down to two parts
associated relation if P (r|es , eo ) > Œ∏ or return NA if no              as shown below:
relation exists.                                                                                                                       !
   Our enhanced base model achieves near state-of-the-art
                                                                                         X                      exp (logitr )
                                                                               L1 = ‚àí         log P                                      ,
performance in our experiments, significantly outperforms                               r‚ààPT             r 0 ‚ààPT ‚à™{TH} exp (logitr 0 )
existing BERT baselines.                                                                                                        !
                                                                                                        exp (logitTH )
                                                                               L2 = ‚àí log P                                       ,
                Adaptive Thresholding                                                             r 0 ‚ààNT ‚à™{TH} exp (logitr 0 )
The RE classifier outputs the probability P (r|es , eo ) within
                                                                               L = L1 + L2 .
the range [0, 1], which needs thresholding to be converted to
relation labels. As the threshold neither has a closed-form               The first part L1 involves positive classes and the TH class.
solution nor is differentiable, a common practice for deciding            Since there may be multiple positive classes, the total loss
threshold is enumerating several values in the range (0, 1)               is calculated as the sum of categorical cross entropy losses
and picking the one that maximizes the evaluation metrics                 on all positive classes (Menon et al. 2019; Reddi et al. 2019).
(F1 score for RE). However, the model may have different                  L1 pushes the logits of all positive classes to be higher than
confidence for different entity pairs or classes in which one             the TH class. It is not used if there is no positive label. The
global threshold does not suffice. The number of relations                second part L2 involves the negative classes and threshold
varies (multi-label problem) and the models may not be glob-              class. It is a categorical cross entropy loss with TH class
ally calibrated so that the same probability does not mean                being the true label. It pulls the logits of negative classes to
the same for all entity pairs. This problem motivates us to               be lower than the TH class. Two parts are simply summed
replace the global threshold with a learnable, adaptive one,              for the total loss.
which can reduce decision errors during inference.                           The proposed adaptive-thresholding loss is illustrated in
   For the convenience of explanation, we split the labels of             Figure 2. It obtains a large performance gain to the global
entity pair T = (es , eo ) into two subsets: positive classes PT          threshold in our experiments.
and negative classes NT , which are defined as follows:
 ‚Ä¢ positive classes PT ‚äÜ R are the relations that exist be-                             Localized Context Pooling
   tween the entities in T . If T does not express any relation,          The logsumexp pooling (see Eq. (2)) accumulates the em-
   PT is empty.                                                           bedding of all mentions for an entity across the whole docu-


                                                                  14614
                                               ùë†,ùëú
      Context                              ùíÑ                                    Statistics                   DocRED       CDR     GDA
      Pooling                                                                  # Train                           3053      500    23353
                                                                               # Dev                             1000      500     5839
                                                                               # Test                            1000      500     1000
       BERT                                                                    # Relations                        97        2        2
      Layer ùêø            ‚Ä¶
                                                                               Avg.# entities per Doc.           19.5      7.6      5.4
                    ùëíùë†       ùëíùë†                           ùëíùëú
       BERT                                                                      Table 1: Statistics of the datasets in experiments.
                               ‚Ä¶                        ‚Ä¶
    Layer ùêø ‚àí 1
                                                                              Hyperparam             DocRED           CDR          GDA
Figure 3: Illustration of localized context pooling. Tokens                                       BERT RoBERTa      SciBERT      SciBERT
are weighted averaged to form the localized context c(s,o) of                 Batch size           4       4             4         16
the entity pair (es , eo ). The weights of tokens are derived by              # Epoch              30      30            30        10
multiplying the attention weights of the subject entity es and                lr for encoder      5e-5    3e-5          2e-5      2e-5
the object entity eo from the last transformer layer so that                  lr for classifier   1e-4    1e-4          1e-4      1e-4
only the tokens that are important to both entities (highlighted
in light yellow) receive higher weights.                                                Table 2: Hyper-parameters in training.

ment and generates one embedding for this entity. The entity               entity embedding to obtain entity representations that are
embedding from this document-level global pooling is then                  different for different entity pairs, by modifying the original
used in the classification of all entity pairs. However, for               linear layer in Eq. (3) and Eq. (4) as follows:
an entity pair, some context of the entities may not be rele-
vant. For example, in Figure 1, the second mention of John
                                                                                                                           
                                                                                      zs(s,o) = tanh Ws hes + Wc1 c(s,o) ,             (6)
Stanistreet and its context are irrelevant to the entity pair
(John Stanistreet, Bendigo). Therefore, it is better to have
                                                                                                                           
                                                                                      zo(s,o) = tanh Wo heo + Wc2 c(s,o) ,             (7)
a localized representation that only attends to the relevant
context in the document that is useful to decide the relation
for this entity pair.                                                      where Wc1 , Wc2 ‚àà Rd√ód are model parameters. The pro-
   Therefore we propose the localized context pooling, where               posed localized context pooling is illustrated in Figure 3.
we enhance the embedding of an entity pair with an additional              In experiments, we use the attention matrix from the last
local context embedding that is related to both entities. In               transformer layer.
this work, since we use pre-trained transformer-based models
as the encoder, which has already learned token-level depen-                                        Experiments
dencies by multi-head self-attention (Vaswani et al. 2017),                Datasets
we consider directly using their attention heads for local-
ized context pooling. This method transfers the well-learned               We evaluate our ATLOP model on three public document-
dependencies from the pre-trained language model without                   level relation extraction datasets. The dataset statistics are
learning new attention layers from scratch.                                shown in Table 1.
   Specifically, given a pre-trained multi-head attention ma-              ‚Ä¢ DocRED (Yao et al. 2019) is a large-scale crowdsourced
trix A ‚àà RH√ól√ól , where Aijk represents attention from                       dataset for document-level RE. It is constructed from
token j to token k in the ith attention head, we first take the              Wikipedia articles. DocRED consists of 3053 documents
attention from the ‚Äú*‚Äù symbol as the mention-level attention,                for training. For entity pairs that express relation(s), about
then average the attention over mentions of the same entity                  7% of them have more than one relation label.
to obtain entity-level attention AE    i ‚ààR
                                              H√ól
                                                  , which denotes          ‚Ä¢ CDR (Li et al. 2016) is a human-annotated dataset in the
                        th
attention from the i entity to all tokens. Then given an en-                 biomedical domain. It consists of 500 documents for train-
tity pair (es , eo ), we locate the local context that is important          ing. The task is to predict the binary interactions between
to both es and eo by multiplying their entity-level attention,               Chemical and Disease concepts.
and obtain the localized context embedding c(s,o) by:
                                                                           ‚Ä¢ GDA (Wu et al. 2019b) is a large-scale dataset in the
                   A(s,o) = AE    E
                             s ¬∑ Ao ,                                        biomedical domain. It consists of 29192 articles for train-
                               H                                             ing. The task is to predict the binary interactions between
                                        (s,o)
                               X
                   q (s,o) =       Ai           ,                            Gene and Disease concepts. We follow Christopoulou,
                               i=1                                           Miwa, and Ananiadou (2019) to split the training set into
                                                                             an 80/20 split as training and development sets.
                   a(s,o) = q   (s,o)
                                        /1| q (s,o) ,
                 c(s,o) = H | a(s,o) ,                                     Experiment Settings
where H is the contextual embedding in Eq. (1). The local-                 Our model is implemented based on Huggingface‚Äôs Trans-
ized context embedding is then fused into the globally pooled              formers (Wolf et al. 2019). We use cased BERT-base (Devlin


                                                                   14615
                       Model                                                       Dev                    Test
                                                                          Ign F1          F1         Ign F1    F1
                       Sequence-based Models
                       CNN (Yao et al. 2019)                               41.58         43.45       40.33   42.26
                       BiLSTM (Yao et al. 2019)                            48.87         50.94       48.78   51.06
                       Graph-based Models
                       BiLSTM-AGGCN (Guo, Zhang, and Lu 2019)              46.29         52.47       48.89   51.45
                       BiLSTM-LSR (Nan et al. 2020)                        48.82         55.17       52.15   54.18
                       BERT-LSRBASE (Nan et al. 2020)                      52.43         59.00       56.97   59.05
                       Transformer-based Models
                       BERTBASE (Wang et al. 2019a)                          -           54.16         -     53.20
                       BERT-TSBASE (Wang et al. 2019a)                       -           54.42         -     53.92
                       HIN-BERTBASE (Tang et al. 2020a)                    54.29         56.31       53.70   55.60
                       CorefBERTBASE (Ye et al. 2020)                      55.32         57.51       54.54   56.96
                       CorefRoBERTaLARGE (Ye et al. 2020)                  57.35         59.43       57.90   60.25
                       Our Methods
                       BERTBASE (our implementation)                 54.27 ¬± 0.28     56.39 ¬± 0.18     -       -
                       BERT-EBASE                                    56.51 ¬± 0.16     58.52 ¬± 0.19     -       -
                       BERT-ATLOPBASE                                59.22 ¬± 0.15     61.09 ¬± 0.16   59.31   61.30
                       RoBERTa-ATLOPLARGE                            61.32 ¬± 0.14     63.18 ¬± 0.19   61.39   63.40

Table 3: Main results (%) on the development and test set of DocRED. We report the mean and standard deviation of F1 on
the development set by conducting 5 runs of training using different random seeds. We report the official test score of the best
checkpoint on the development set.


  Model                                   CDR          GDA                For the DocRED dataset, the training takes about 1 hour 45
  BRAN (Verga, Strubell, and McCal-       62.1           -                minutes with BERT-base encoder and 3 hours 30 minutes
  lum 2018)                                                               with RoBERTa-large encoder. For CDR and GDA datasets,
  CNN (Nguyen and Verspoor 2018)          62.3          -                 the training takes 20 minutes and 3 hours 30 minutes with
  EoG (Christopoulou, Miwa, and           63.6         81.5               SciBERT encoder, respectively.
  Ananiadou 2019)
  LSR (Nan et al. 2020)                   64.8         82.2               Main Results
  SciBERT (our implementation)          65.1 ¬± 0.6   82.5 ¬± 0.3           We compare ATLOP with sequence-based models, graph-
  SciBERT-E                             65.9 ¬± 0.5   83.3 ¬± 0.3           based models, and transformer-based models on the DocRED
  SciBERT-ATLOP                         69.4 ¬± 1.1   83.9 ¬± 0.2           dataset. The experiment results are shown in Table 3. Follow-
                                                                          ing Yao et al. (2019), we use F1 and Ign F1 in evaluation.
Table 4: Test F1 score (%) on CDR and GDA dataset. Our                    The Ign F1 denotes the F1 score excluding the relational facts
ATLOP model with the SciBERT encoder outperforms the                      that are shared by the training and dev/test sets.
current SOTA results.
                                                                          Sequence-based Models. These models use neural architec-
                                                                          tures such as CNN (Goodfellow et al. 2016) and bidirectional
                                                                          LSTM (Schuster and Paliwal 1997) to encode the entire doc-
et al. 2019) or RoBERTa-large (Liu et al. 2019) as the en-                ument, then obtain entity embeddings and predict relations
coder on DocRED, and cased SciBERT (Beltagy, Lo, and                      for each entity pair with bilinear function.
Cohan 2019) on CDR and GDA. We use mixed-precision
training (Micikevicius et al. 2018) based on the Apex library1 .          Graph-based Models. These models construct document
Our model is optimized with AdamW (Loshchilov and Hut-                    graphs by learning latent graph structures of the docu-
ter 2019) using learning rates ‚àà {2e‚àí5, 3e‚àí5, 5e‚àí5, 1e‚àí4},                ment and perform inference with graph convolutional net-
with a linear warmup (Goyal et al. 2017) for the first 6% steps           work (Kipf and Welling 2017). We include two state-of-the-
followed by a linear decay to 0. We apply dropout (Srivastava             art graph-based models, AGGCN (Guo, Zhang, and Lu 2019)
et al. 2014) between layers with rate 0.1, and clip the gradi-            and LSR (Nan et al. 2020), for comparison. The result of
ents of model parameters to a max norm of 1.0. We perform                 AGGCN is from the re-implementation by Nan et al. (2020).
early stopping based on the F1 score on the development set.              Transformer-based Models. These models directly adapt
All hyper-parameters are tuned on the development set. We                 pre-trained language models to document-level RE with-
list some of the hyper-parameters in Table 2.                             out using graph structures. They can be further divided into
   For models that use a global threshold, we search threshold            pipeline models (BERT-TS (Wang et al. 2019a)), hierarchical
values from {0.1, 0.2, ..., 0.9} and pick the one that maxi-              models (HIN-BERT (Tang et al. 2020a)), and pre-training
mizes dev F1 . All models are trained with 1 Tesla V100 GPU.              methods (CorefBERT and CorefRoBERTa (Ye et al. 2020)).
                                                                          We also include the BERT baseline (Wang et al. 2019a) and
   1
       https://github.com/NVIDIA/apex                                     our re-implemented BERT baseline in comparison.


                                                                  14616
       Model                            Ign F1     F1                                            Strategy                    Dev F1   Test F1
       BERT-ATLOPBASE                    59.22   61.09                                           Global Thresholding         60.14    60.62
       ‚àí Adaptive Thresholding           58.32   60.20                                           Per-class Thresholding      61.73    60.35
       ‚àí Localized Context Pooling       58.19   60.12                                           Adaptive Thresholding       61.27    61.30
       ‚àí Adaptive-Thresholding Loss      39.52   41.74
       BERT-EBASE                        56.51   58.52                   Table 6: Result of different thresholding strategies on Do-
       ‚àí Entity Marker                   56.22   58.28                   cRED. Our adaptive thresholding consistently outperforms
       ‚àí Group Bilinear                  55.51   57.54                   other strategies on the test set.
       ‚àí Logsumexp Pooling               55.35   57.40
                                                                                            75
Table 5: Ablation study of ATLOP on DocRED. We turn                                                                                     w/ LOP
off different components of the model one at a time. These                                  70




                                                                            dev F1 (in %)
                                                                                                                                        w/o LOP
ablation results show that both adaptive thresholding and                                   65
localized context pooling are effective. Logsumexp pooling
                                                                                            60
and group bilinear both bring noticeable gain to the baseline.
                                                                                            55

                                                                                            50
                                                                                                   1-5      6-10 11-15 16-20 21-25 26-30 31-35
   We find that our re-implemented BERT baseline gets sig-                                                      # of Entities per Document
nificantly better results than Wang et al. (2019a), and outper-
forms the state-of-the-art RNN-based model BiLSTM-LSR                    Figure 4: Dev F1 score of documents with the different num-
by 1.2%. It demonstrates that pre-trained language models                ber of entities on DocRED. Our localized context pooling
can capture long-distance dependencies among entities with-              achieves better results when the number of entities is larger
out explicitly using graph structures. After integrating other           than 5. The improvement becomes more significant when the
techniques, our enhanced baseline BERT-EBASE achieves an                 number of entities increases.
F1 score of 58.52%, which is close to the current state-of-the-
art model BERT-LSRBASE . Our BERT-ATLOPBASE model
further improves the performance of BERT-EBASE by 2.6%,
demonstrating the efficacy of the proposed two novel tech-               and 0.97% in dev F1 score respectively when removed from
niques. Using RoBERTa-large as the encoder, our ALTOP                    ATLOP. Note that the adaptive thresholding only works when
model achieves an F1 score of 63.40%, which is a new state-              the model is optimized with the adaptive-thresholding loss.
of-the-art result on DocRED.                                             Applying adaptive thresholding to models trained with binary
                                                                         cross entropy results in dev F1 of 41.74%.
Results on Biomedical Datasets                                              For our enhanced baseline model BERT-EBASE , both group
Experiment results on two biomedical datasets are shown in               bilinear and logsumexp pooling lead to about 1% increase
Table 4. Verga, Strubell, and McCallum (2018) and Nguyen                 in dev F1 . We find the improvement from entity markers is
and Verspoor (2018) are both sequence-based models that                  minor (0.24% in dev F1 ) but still use the technique in the
use self-attention network and CNN as the encoders, respec-              model as it makes the derivation of mention embedding and
tively. Christopoulou, Miwa, and Ananiadou (2019) and Nan                mention-level attention easier.
et al. (2020) use graph-based models that construct document
graphs by heuristics or structured attention, and perform in-            Analysis of Thresholding
ference with graph neural network. To our best knowledge,
transformer-based pre-trained language models have not been
                                                                         Global thresholding does not consider the variations of model
applied to document-level RE datasets in the biomedical do-
                                                                         confidence in different classes or instances, and thus yields
main. In experiments, we replace the encoder with SciBERT,
                                                                         suboptimal performance. One interesting question is whether
which is pre-trained on multi-domain corpora of scientific
                                                                         we can improve global thresholding by tuning different
publications. The SciBERT baseline already outperforms all
                                                                         thresholds for different classes. To answer this question, We
existing methods. Our SciBERT-ATLOP model further im-
                                                                         try to tune different thresholds on different classes to max-
proves the F1 score by 4.3% and 1.4% on CDR and GDA,
                                                                         imize the dev F1 score on DocRED using the cyclic opti-
respectively, yielding new state-of-the-art results on these
                                                                         mization algorithm (Fan and Lin 2007). Results are shown
two datasets.
                                                                         in Table 6. We find that using per-class thresholding signifi-
                                                                         cantly improves the dev F1 score to 61.73%, which is even
Ablation Study                                                           higher than the result of adaptive thresholding. However, this
To show the efficacy of our proposed techniques, we conduct              gain does not transfer to the test set. The result of per-class
two sets of ablation studies on ATLOP and enhanced base-                 thresholding is even worse than global thresholding. It indi-
line, by turning off one component at a time. We observe that            cates that tuning per-class thresholding after training can lead
all components contribute to model performance. The adap-                to severe over-fitting to the development set. While our adap-
tive thresholding and localized context pooling are equally              tive thresholding technique learns the threshold in training,
important to model performance, leading to a drop of 0.89%               which can generalize to the test set.


                                                                 14617
 John Stanistreet was an Australian politician. He wa                     However, as large amounts of relationships are expressed
 s born in Bendigo to legal manager John Jepson Stan                   by multiple sentences (Verga, Strubell, and McCallum 2018;
 istreet and Maud McIlroy. (‚Ä¶ 4 sentences ‚Ä¶) In 195                    Yao et al. 2019), recent work starts to explore document-
 5 John Stanistreet was elected to the Victorian Legisl                level relation extraction. Most approaches on document-level
 ative Assembly as the Liberal and Country Party mem                   RE are based on document graphs, which were introduced
 ber for Bendigo, but he was defeated in 1958. Stanistr                by Quirk and Poon (2017). Specifically, they use words as
 eet died in Bendigo in 1971.                                          nodes and inner and inter-sentential dependencies (depen-
                                                                       dency structures, coreferences, etc.) as edges. This document
 Subject: John Stanistreet Object: Bendigo                             graph provides a unified way of extracting the features for
 Relation: place of birth; place of death                              entity pairs. Later work extends the idea by improving neural
                                                                       architectures (Peng et al. 2017; Verga, Strubell, and McCal-
Figure 5: Context weights of an example from DocRED. We                lum 2018; Song et al. 2018; Jia, Wong, and Poon 2019; Gupta
visualize the weight of context tokens a(s,o) in localized con-        et al. 2019) or adding more types of edges (Christopoulou,
text pooling. The model attends to the most relevant context           Miwa, and Ananiadou 2019; Nan et al. 2020). In particu-
born and died for entity pair (John Stanistreet, Bendigo).             lar, Christopoulou, Miwa, and Ananiadou (2019) constructs
                                                                       nodes of different granularities (sentence, mention, entity),
                                                                       connects them with heuristically generated edges, and infers
Analysis of Context Pooling                                            the relations with an edge-oriented model (Christopoulou,
                                                                       Miwa, and Ananiadou 2018). Nan et al. (2020) treats the doc-
To show that our localized context pooling (LOP) technique             ument graph as a latent variable and induces it by structured
mitigates the multi-entity issue, we divide the documents              attention (Liu and Lapata 2018). This work also proposes
in the development set of DocRED into different groups by              a refinement mechanism to enable multi-hop information
the number of entities, and evaluate models trained with or            aggregation from the whole document. Their LSR model
without localized context pooling on each group. Experi-               achieved state-of-the-art performance on document-level RE.
ment results are shown in Figure 4. We observe that for both              There have also been models that directly apply pre-trained
models, their performance gets worse when the document                 language models without introducing document graphs, since
contains more entities. The model w/ LOP consistently out-             edges such as dependency structures and coreferences can be
performs the model w/o LOP except when the document                    automatically learned by pre-trained language models (Clark
contains very few entities (1 to 5), and the improvement gets          et al. 2019; Tenney, Das, and Pavlick 2019; Vig and Belinkov
larger when the number of entities increases. However, the             2019; Hewitt and Manning 2019). In particular, Wang et al.
number of documents that only contain 1 to 5 entities is very          (2019a) proposes a pipeline model that first predicts whether
small (4 in the dev set), and the documents in DocRED con-             a relationship exists in an entity pair and then predicts the
tain 19 entities on average. Therefore our localized context           specific relation types. Tang et al. (2020a) proposes a hierar-
pooling still improves the overall F1 score significantly. This        chical model that aggregates entity information from the en-
indicates that the localized context pooling technique can             tity level, sentence level, and document level. Ye et al. (2020)
capture related context for entity pairs and thus alleviates the       introduces a copy-based training objective to pre-training,
multi-entity problem.                                                  which enhances the model‚Äôs ability in capturing coreferential
   We also visualize the context weights of the example in             information and brings noticeable gain on various NLP tasks
Figure 1. As shown in Figure 5, our localized context pooling          that require coreferential reasoning.
gives high weights to born and died, which are most relevant              However, none of the models focus on the multi-entity and
to both entities (John Stanistreet, Bendigo). These two tokens         multi-label problems, which are among the key differences of
are also evidence for the two ground truth relationships place         document-level RE to its sentence-level RE counterpart. Our
of birth and place of death, respectively. Tokens like elected         ATLOP model deals with the two problems by two novel tech-
and politician get much smaller weights because they are               niques: adaptive thresholding and localized context pooling,
only related to the subject entity John Stanistreet. The visual-       and significantly outperforms existing models.
ization demonstrates that the localized context can locate the
context that is related to both entities.                                                      Conclusion
                                                                       In this work, we propose the ATLOP model for document-
                      Related Work                                     level relation extraction, which features two novel techniques:
Early research efforts on relation extraction concentrate on           adaptive thresholding and localized context pooling. The
predicting the relationship between two entities within a sen-         adaptive thresholding technique replaces the global threshold
tence. Various approaches including sequence-based meth-               in multi-label classification with a learnable threshold class
ods (Zeng et al. 2014; Wang et al. 2016; Zhang et al. 2017),           that can decide the best threshold for each entity pair. The lo-
graph-based methods (Miwa and Bansal 2016; Zhang, Qi,                  calized context pooling utilizes pre-trained attention heads to
and Manning 2018; Guo, Zhang, and Lu 2019; Wu et al.                   locate relevant context for entity pairs and thus helps in alle-
2019a), transformer-based methods (Alt, HuÃàbner, and Hennig            viating the multi-entity problem. Experiments on three public
2019; Shi and Lin 2019), and pre-training methods (Zhang               document-level relation extraction datasets demonstrate that
et al. 2019; Soares et al. 2019) have been shown effective in          our ATLOP model significantly outperforms existing models
tackling this problem.                                                 and yields the new state-of-the-art results on all datasets.


                                                               14618
                       References                                      Kipf, T.; and Welling, M. 2017. Semi-Supervised Classifica-
Alt, C.; HuÃàbner, M.; and Hennig, L. 2019. Improving Rela-             tion with Graph Convolutional Networks. In ICLR.
tion Extraction by Pre-trained Language Representations. In            Li, J.; Sun, Y.; Johnson, R. J.; Sciaky, D.; Wei, C.-H.; Leaman,
AKBC.                                                                  R.; Davis, A. P.; Mattingly, C. J.; Wiegers, T. C.; and Lu,
Beltagy, I.; Lo, K.; and Cohan, A. 2019. SciBERT: A Pre-               Z. 2016. BioCreative V CDR task corpus: a resource for
trained Language Model for Scientific Text. In EMNLP-                  chemical disease relation extraction. In Database.
IJCNLP.                                                                Liang, X.; Shen, X.; Feng, J.; Lin, L.; and Yan, S. 2016.
Christopoulou, F.; Miwa, M.; and Ananiadou, S. 2018. A                 Semantic Object Parsing with Graph LSTM. In ECCV.
Walk-based Model on Entity Graphs for Relation Extraction.             Liu, Y.; and Lapata, M. 2018. Learning Structured Text
In ACL.                                                                Representations. Transactions of the Association for Compu-
                                                                       tational Linguistics 6: 63‚Äì75.
Christopoulou, F.; Miwa, M.; and Ananiadou, S. 2019. Con-
necting the Dots: Document-level Neural Relation Extraction            Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;
with Edge-oriented Graphs. In EMNLP-IJCNLP.                            Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V. 2019.
                                                                       RoBERTa: A Robustly Optimized BERT Pretraining Ap-
Chung, J.; CÃßaglar GuÃàlcÃßehre; Cho, K.; and Bengio, Y. 2014.           proach. ArXiv abs/1907.11692.
Empirical Evaluation of Gated Recurrent Neural Networks
on Sequence Modeling. ArXiv abs/1412.3555.                             Loshchilov, I.; and Hutter, F. 2019. Decoupled Weight Decay
                                                                       Regularization. In ICLR.
Clark, K.; Khandelwal, U.; Levy, O.; and Manning, C. D.
2019. What Does BERT Look at? An Analysis of BERT‚Äôs                    Menon, A.; Rawat, A.; Reddi, S.; and Kumar, S. 2019. Mul-
Attention. In BlackboxNLP workshop.                                    tilabel reductions: what is my loss optimising? In NeurIPS.
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.             Micikevicius, P.; Narang, S.; Alben, J.; Diamos, G.; Elsen,
BERT: Pre-training of Deep Bidirectional Transformers for              E.; Garcƒ±ÃÅa, D.; Ginsburg, B.; Houston, M.; Kuchaiev, O.;
Language Understanding. In NAACL-HLT.                                  Venkatesh, G.; and Wu, H. 2018. Mixed Precision Training.
                                                                       In ICLR.
Fan, R.-E.; and Lin, C.-J. 2007. A study on threshold selec-
tion for multi-label classification. Department of Computer            Miwa, M.; and Bansal, M. 2016. End-to-End Relation Ex-
Science, National Taiwan University 1‚Äì23.                              traction using LSTMs on Sequences and Tree Structures. In
                                                                       ACL.
Goodfellow, I.; Bengio, Y.; Courville, A.; and Bengio, Y.
2016. Deep learning, volume 1. MIT press Cambridge.                    Nan, G.; Guo, Z.; Sekulic, I.; and Lu, W. 2020. Reason-
                                                                       ing with Latent Structure Refinement for Document-Level
Goyal, P.; DollaÃÅr, P.; Girshick, R. B.; Noordhuis, P.;                Relation Extraction. In ACL.
Wesolowski, L.; Kyrola, A.; Tulloch, A.; Jia, Y.; and He, K.
                                                                       Nguyen, D. Q.; and Verspoor, K. 2018. Convolutional neural
2017. Accurate, Large Minibatch SGD: Training ImageNet
                                                                       networks for chemical-disease relation extraction are im-
in 1 Hour. ArXiv abs/1706.02677.
                                                                       proved with character-based word embeddings. In BioNLP
Guo, Z.; Zhang, Y.; and Lu, W. 2019. Attention Guided                  workshop.
Graph Convolutional Networks for Relation Extraction. In
                                                                       Peng, N.; Poon, H.; Quirk, C.; Toutanova, K.; and Yih, W.-t.
ACL.
                                                                       2017. Cross-Sentence N-ary Relation Extraction with Graph
Gupta, P.; Rajaram, S.; SchuÃàtze, H.; and Runkler, T. 2019.            LSTMs. Transactions of the Association for Computational
Neural Relation Extraction Within and Across Sentence                  Linguistics 5: 101‚Äì115.
Boundaries. In AAAI.                                                   Quirk, C.; and Poon, H. 2017. Distant Supervision for Rela-
Hendrickx, I.; Kim, S.; Kozareva, Z.; Nakov, P.; SeÃÅaghdha,            tion Extraction beyond the Sentence Boundary. In EACL.
D. OÃÅ.; Pennacchiotti, M.; Romano, L.; and Szpakowicz, S.              Reddi, S. J.; Kale, S.; Yu, F.; Holtmann-Rice, D.; Chen, J.;
2009. SemEval-2010 Task 8: Multi-Way Classification of                 and Kumar, S. 2019. Stochastic Negative Mining for Learn-
Semantic Relations Between Pairs of Nominals. In HLT-                  ing with Large Output Spaces. In AISTATS.
NAACL.
                                                                       Schuster, M.; and Paliwal, K. 1997. Bidirectional recurrent
Hewitt, J.; and Manning, C. D. 2019. A Structural Probe for            neural networks. IEEE Trans. Signal Process. 45: 2673‚Äì
Finding Syntax in Word Representations. In NAACL-HLT.                  2681.
Hochreiter, S.; and Schmidhuber, J. 1997. Long Short-Term              Shi, P.; and Lin, J. 2019. Simple BERT Models for Re-
Memory. Neural Computation 9: 1735‚Äì1780.                               lation Extraction and Semantic Role Labeling. ArXiv
Jia, R.; Wong, C.; and Poon, H. 2019. Document-Level N-ary             abs/1904.05255.
Relation Extraction with Multiscale Representation Learning.           Soares, L. B.; FitzGerald, N.; Ling, J.; and Kwiatkowski, T.
In NAACL-HLT.                                                          2019. Matching the Blanks: Distributional Similarity for
Khandelwal, U.; He, H.; Qi, P.; and Jurafsky, D. 2018. Sharp           Relation Learning. In ACL.
Nearby, Fuzzy Far Away: How Neural Language Models Use                 Song, L.; Zhang, Y.; Wang, Z.; and Gildea, D. 2018. N-ary
Context. In ACL.                                                       Relation Extraction using Graph-State LSTM. In EMNLP.


                                                               14619
Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; and        Zhang, Z.; Han, X.; Liu, Z.; Jiang, X.; Sun, M.; and Liu,
Salakhutdinov, R. 2014. Dropout: A Simple Way to Pre-                 Q. 2019. ERNIE: Enhanced Language Representation with
vent Neural Networks from Overfitting. Journal of Machine             Informative Entities. In ACL.
Learning Research 15: 1929‚Äì1958.                                      Zheng, H.; Fu, J.; Zha, Z.-J.; and Luo, J. 2019. Learning
Tang, H.; Cao, Y.; Zhang, Z.; Cao, J.; Fang, F.; Wang, S.;            Deep Bilinear Transformation for Fine-grained Image Repre-
and Yin, P. 2020a. HIN: Hierarchical Inference Network for            sentation. In NeurIPS.
Document-Level Relation Extraction. In PAKDD.
Tang, Y.; Huang, J.; Wang, G.; He, X.; and Zhou, B. 2020b.
Orthogonal Relation Transforms with Graph Context Model-
ing for Knowledge Graph Embedding. In ACL.
Tenney, I.; Das, D.; and Pavlick, E. 2019. BERT Rediscovers
the Classical NLP Pipeline. In ACL.
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;
Gomez, A. N.; Kaiser, ≈Å.; and Polosukhin, I. 2017. Attention
is All you Need. In NeurIPS.
Verga, P.; Strubell, E.; and McCallum, A. 2018. Simulta-
neously Self-Attending to All Mentions for Full-Abstract
Biological Relation Extraction. In NAACL-HLT.
Vig, J.; and Belinkov, Y. 2019. Analyzing the Structure of At-
tention in a Transformer Language Model. In BlackboxNLP
workshop.
Wang, H.; Focke, C.; Sylvester, R.; Mishra, N.; and Wang,
W. W. J. 2019a. Fine-tune Bert for DocRED with Two-step
Process. ArXiv abs/1909.11898.
Wang, H.; Tan, M.; Yu, M.; Chang, S.; Wang, D.; Xu, K.;
Guo, X.; and Potdar, S. 2019b. Extracting Multiple-Relations
in One-Pass with Pre-Trained Transformers. In ACL.
Wang, L.; Cao, Z.; De Melo, G.; and Liu, Z. 2016. Relation
Classification via Multi-Level Attention CNNs. In ACL.
Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.;
Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; et al.
2019. HuggingFace‚Äôs Transformers: State-of-the-art Natural
Language Processing. ArXiv arXiv‚Äì1910.
Wu, F.; Zhang, T.; Souza, A.; Fifty, C.; Yu, T.; and Wein-
berger, K. Q. 2019a. Simplifying Graph Convolutional Net-
works. In ICML.
Wu, Y.; Luo, R.; Leung, H. C.; Ting, H.-F.; and Lam, T.-W.
2019b. RENET: A Deep Learning Approach for Extracting
Gene-Disease Associations from Literature. In RECOMB.
Yao, Y.; Ye, D.; Li, P.; Han, X.; Lin, Y.; Liu, Z.; Liu, Z.;
Huang, L.; Zhou, J.; and Sun, M. 2019. DocRED: A Large-
Scale Document-Level Relation Extraction Dataset. In ACL.
Ye, D.; Lin, Y.; Du, J.; Liu, Z.; Sun, M.; and Liu, Z. 2020.
Coreferential Reasoning Learning for Language Representa-
tion. In EMNLP.
Zeng, D.; Liu, K.; Lai, S.; Zhou, G.; and Zhao, J. 2014. Rela-
tion Classification via Convolutional Deep Neural Network.
In COLING.
Zhang, Y.; Qi, P.; and Manning, C. D. 2018. Graph Con-
volution over Pruned Dependency Trees Improves Relation
Extraction. In EMNLP.
Zhang, Y.; Zhong, V.; Chen, D.; Angeli, G.; and Manning,
C. D. 2017. Position-aware Attention and Supervised Data
Improve Slot Filling. In EMNLP.


                                                              14620
      Collective Multi-type Entity Alignment Between Knowledge
                                 Graphs

                            Qi Zhu1‚àó , Hao Wei2 , Bunyamin Sisman2 , Da Zheng2 , Christos Faloutsos3 ,
                                                   Xin Luna Dong2 , Jiawei Han1
                        1 University of Illinois at Urbana-Champaign 2 Amazon.com, Inc. 3 Carnegie Mellon University
               1 {qiz3,   hanj}@illinois.edu      2 {wehao,bunyamis,dzzhen,lunadong}@amazon.com 3 christos@cs.cmu.edu


ABSTRACT                                                                                                                                                                                                                  Komedi-
                                                                                                                           comedy                           drama
                                                                                                                                                                                                                           drama
                                                                                                                e
                                                                                                           genr                       gen             nre                                                           re
Knowledge graph (e.g. Freebase, YAGO) is a multi-relational graph                                                                           re      ge                             Don‚Äôt stop                    gen
representing rich factual information among entities of various                                                                                  Don‚Äôt stop                        Dreaming
                                                                                                 Gawaahi
                                                                                                                                                 Dreaming
types. Entity alignment is the key step towards knowledge graph                                                     edi




                                                                                                                                                                                    pr o
                                                                                                                       t




                                                                                                                                                                                         wri
                                                                                                                                            e
                                                                                                                                     writ




                                                                                                 write




                                                                                                                                                                                           duc
integration from multiple sources. It aims to identify entities across




                                                                                                                                                                                             te
                                                                                                                                                                                                e
different knowledge graphs that refer to the same real world entity.                            Anant                  Aditya Raj                                                        Aditya Raj
However, current entity alignment systems overlook the sparsity                                 Balani                                                                                    Kapoor




                                                                                                                       ite
                                                                                                                                                                                        ite                  e




                                                                                                                                 wr
of different knowledge graphs and can not align multi-type enti-                                                                                                                                        uc




                                                                                                                     wr
                                                                                                                                                                                   wr




                                                                                                                                     ite
                                                                                                                                                                                                   od
ties by one single model. In this paper, we present a Collective                                                                                                                              pr
                                                                                                          Shamaal:                 Sambar                                     Sambar
Graph neural network for Multi-type entity Alignment, called CG-                                            The                      Salsa                                     Salsa
MuAlign. Different from previous work, CG-MuAlign jointly aligns                                         Sandstorm                  ce     edi                                                edi
                                                                                                                                d u           t                           c   e                  t
                                                                                                                                 o                                     du
multiple types of entities, collectively leverages the neighborhood                                                           pr                                    pro
                                                                                                                                                    Ashish                Vasanti                                Ashish
                                                                                                                           Vasanti
information and generalizes to unlabeled entity types. Specifically,                                                                                 Redij                Balani                                  Redij
                                                                                                                           Balani
we propose novel collective aggregation function tailored for this
task, that (1) relieves the incompleteness of knowledge graphs via                                                               IMDB                                             Freebase
both cross-graph and self attentions, (2) scales up efficiently with
mini-batch training paradigm and effective neighborhood sampling
strategy. We conduct experiments on real world knowledge graphs                               Figure 1: An example of Entity Alignment on person called ‚ÄúAditya
with millions of entities and observe the superior performance                                Raj‚Äù across IMDB and Freebase. Different edge types indicates dif-
                                                                                              ferent relations(e.g. ‚Äúdirect‚Äù and ‚Äúwrite‚Äù). We use different color and
beyond existing methods. In addition, the running time of our ap-
                                                                                              shape indicates node types and different arrow types indicates dif-
proach is much less than the current state-of-the-art deep learning
                                                                                              ferent relations.
methods.

ACM Reference Format:
Qi Zhu, Hao Wei, Bunyamin Sisman, Da Zheng, Christos Faloutsos, Xin Luna
Dong, Jiawei Han. 2020. Collective Multi-type Entity Alignment Between
                                                                                              of structured and semi-structured online data, numerous knowl-
Knowledge Graphs. In Proceedings of The Web Conference 2020 (WWW
                                                                                              edge graphs are extracted on the same domain [25]. Different KGs,
‚Äô20), April 20‚Äì24, 2020, Taipei, Taiwan. ACM, New York, NY, USA, 11 pages.
                                                                                              though subject to the incompleteness in varying degrees, usually
https://doi.org/10.1145/3366423.3380289
                                                                                              contain complementary information. Entity alignment (EA) aims
                                                                                              to identify entities across different knowledge graphs that refer
1     INTRODUCTION                                                                            to the same real world entity. This problem also known as entity
Knowledge Graphs (KGs) contain large volumn of relation tuples                                matching/resolution [12, 14, 16, 27] that matches records in the
in the form of ‚ü®subject, relation, object‚ü©, such as ‚ü®Aditya Raj, write,                       multi-relational databases.
Don‚Äôt stop Dreaming‚ü© in Figure 1. These relation tuples have a                                   In a knowledge graph, there are different entity types (e.g., movie,
variety of downstream applications including Question Answer-                                 actor, characters) and relation types (e.g., direct by, act by, release
ing [19], Search, and Recommendation [42]. With the booming                                   date, etc.). Given the nature of entity types, the alignment strategy
                                                                                              for different entity types could be different. For example, we observe
* Work performed while at Amazon.
                                                                                              much more characters than films, that share the same name in
                                                                                              the IMDB-Freebase dataset. One obvious solution is to develop
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed         different models for different entity types; however, the solution
for profit or commercial advantage and that copies bear this notice and the full citation     falls short for two reasons. First, collecting annotations and training
on the first page. Copyrights for components of this work owned by others than ACM            hundreds or even more models for different entity types can be very
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a   complex and expensive. Second, an entity may belong to multiple
fee. Request permissions from permissions@acm.org.                                            overlapping types (e.g. a person can be both a movie director and a
WWW ‚Äô20, April 20‚Äì24, 2020, Taipei, Taiwan                                                    novel writer), making it hard to decide which model to apply for
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7023-3/20/04.                                                             each entity. Thus, a multi-type entity alignment algorithm becomes
https://doi.org/10.1145/3366423.3380289                                                       critical for effective knowledge integration [11].
   However, previous entity alignment methods [4, 7, 8, 37, 45, 46,        Table 1: Comparison of methods for entity alignment. Inductive:
                                                                           Making use of node features and generalize to new nodes. Predi-
51] suffer from the following challenges presented in the multi-type
                                                                           cate: Modeling semantics of different relations. Collective: Collect-
entity alignment problem.
                                                                           ing evidence from neighborhood. Multi-type: Handling multiple en-
Transductive ‚Üí Inductive. Previous methods [7, 8, 37, 51] adopt            tity types in one model. Scalable: Scaling up to millions of nodes.
knowledge graph embeddings to jointly perform the KG completion
and entity alignment tasks, thus may not be tuned perfectly for                             CG-MuAlign   MuGNN [4]   GCN-Align [45]   DeepMatcher [27]
alignment purpose. In particular, they focus only on related enti-             Inductive        ‚úî                          ‚úî                 ‚úî
                                                                               Predicate        ‚úî           ‚úî                                ‚úî
ties, i.e. transductive setting, ignoring the potentially rich attribute       Collective       ‚úî
information such as the name and the released date. In addition,               Multi-type       ‚úî           ‚úî              ‚úî
when new entities are added into the graphs, these methods require              Scalable        ‚úî                                            ‚úî

complete retraining to predict alignment for new entities.
Labeled Type ‚Üí Unlabeled Type. Traditional methods[27, 39]                     We note that although collectively linking entities is not a new
can often perform well for entity types with rich training data,           idea [2, 12, 31, 34], our method is the first scalable solution that
but often fail for the types where training data are sparse or even        does not require any manually defined rules (like [31]) or logic
lacking. Intuitively, the rich connections between different types         (like [34]) for evidence propagation. Similarly, although GNN has
of entities shall help boost performance for the types with small          been widely adopted for iteratively capturing the neighborhood
training data, but the connections are not yet effectively leveraged       information, our model, to the best of our knowledge, is the first
on a large scale.                                                          that allows collective decisions in a GNN. Besides, we develop a
    Inspired by the recent success of Graph Neural Networks (GNN)          scalable GNN framework to support large-scale entity alignment
on various tasks such as node classification [21], link prediction [5,     in the experiments. In Table. 1, we compare our method with most
48] and graph classification [23], we propose to apply GNN to              recent entity alignment algorithm from five different perspectives.
generate structure-aware representations for each entity, and align        In particular, we made the following contributions.
entities by comparing their representations. The GNN mechanism                 ‚Ä¢ We propose a GNN-based knowledge graph entity alignment
allows us to incorporate neighborhood information recursively and                framework called CG-MuAlign, that collectively align entities
make inductive predictions on unseen entities, thus addressing both              of different types. We carefully design the attention mecha-
of the afore-mentioned challenges. Unfortunately, as we show in                  nisms that can both effectively accumulate positive evidence
our experiments (Section. 4.4), a vanilla application of GNN failed              from the neighborhood, and remain sensitive to strong nega-
terribly, obtaining only 0.33 F1 score (27% precision and 43% recall)            tive evidence to distinguish similar but different entities.
for alignment. The key reason is that the GNN models will generate             ‚Ä¢ We scale up our model to large-scale knowledge graphs by
similar embeddings for the same entity from two different KGs                    avoiding expensive computation in each layer of the deep
only if both KGs contain fairly complete information about the                   neural network and by relation-aware neighborhood sampling.
entity. In reality, most KGs are sparse in different ways, making the          ‚Ä¢ Through extensive experiments on two different datasets, we
embeddings often very different. For example, for the same movie,                show that our methods obtain high quality linkage (80.5% F1
IMDB may contain editor, director and actor information, while                   and 60% recall when precision is 95%) on knowledge graphs
Freebase contains only director and producer information.                        with size of two and half millions of nodes. In particular, with
    This paper presents a novel GNN model that makes collective de-              the help of labeled film data, we show that CG-MuAlign trained
cisions [2, 36] (i.e. related entities alignment are determined jointly)         on 2,000 person pairs can reach comparable performance with
on entity alignment for multple different types. The key of our                  model trained on ‚àº24,000 person pairs.
solution is a carefully designed attention mechanism that effec-
                                                                               The rest of the paper is organized as follows. We first provide
tively leverages shared neighborhoods as positive evidence without
                                                                           the preliminary knowledge and problem definition in Section 2.
ignoring strong negative evidence. First, to be robust on incomplete
                                                                           Our method is presented in Section 3 and we demonstrate the
knowledge graphs, we design the cross-graph attention that allows
                                                                           experimental results as well as analysis in Section 4. We review the
focusing more on the similar neighborhoods across two graphs. To
                                                                           literature and summarize the differences of our methods in Section
illustrate the intuition, consider our motivating example in Figure 1.
                                                                           5. At last, we conclude the whole paper in Section 6.
‚ÄúAditya Raj‚Äù participates in four movies in IMDB, whereas ‚ÄúAditya
Raj Kapoor‚Äù writes/produces two movies in Freebase; a vanilla ver-
sion of GNN will generate different representations for them. Our
                                                                           2    PROBLEM DEFINITION
cross-graph attention gives higher weight to shared neighbors such         A knowledge graph G is defined as a graph with multi-typed nodes
as ‚ÄúSambar Salsa‚Äù, and thus generate similar representations for           and edges. We denote nodes V as entities and edges E as relations.
the two nodes. Second, to be sensitive towards strong negative             Formally we have G = (V, E, T , R) with a node type mapping
evidence, we employ relation-aware self-attention on edges that            œï : V ‚Üí T and edge type mapping œà : E ‚Üí R.
prevents blindly aligning nodes with similar neighborhoods. For               Given two different knowledge graphs G and G ‚Ä≤ on same domain,
example, two movies in the same series are likely to share directors,      the node type and edge type are {T , T ‚Ä≤ } and {R, R ‚Ä≤ } , respectively.
writers, and some actors; our edge-level attention allows us to pick       Assuming node and edge types are aligned in advance: T ‚àó {(t, t ‚Ä≤ ) ‚àà
up key differences in release year and length to distinguish them.         T √ó T ‚Ä≤ |t ‚áî t ‚Ä≤ }, R ‚àó {(r , r ‚Ä≤ ) ‚àà R √ó R ‚Ä≤ |r ‚áî r ‚Ä≤ }, certain amount
                                                                           of ground truth node pairs S{(vit , vit‚Ä≤ )|t ‚àó ‚àà T ‚àó } are available.
                                                                                                                   ‚àó    ‚àó
Indeed, our experiments show that the two attention mechanisms
collectively improve linkage quality by 10% F1 score in average.           Normally, there are only a few aligned seed pairs for some of the
                                                                           aligned node type T ‚àó , i.e. |S| ‚â™ |V |.
    Formally, we define the problem of entity alignment as follows.             encoders as (hiK , hiK‚Ä≤ ) and apply a marginal hinge loss on distance
                                                                                between output vector of two nodes,
   Definition 2.1 (KG Entity Alignment). Given two knowledge
graphs G = (V, E, T , R) and G ‚Ä≤ = (V ‚Ä≤, E ‚Ä≤, T , R), entity align-                                        max 0, d(hiK , hiK‚Ä≤ ) ‚àí d(hi‚àí
                                                                                                                                      K     K
                                                                                           √ï √ï                                                      
                                                                                     L=                                                  , hi‚àí‚Ä≤) + Œ≥
ment aims to find a set of entity pairs {(vi , vi ‚Ä≤ ) ‚àà V √ó V ‚Ä≤ } with                     (i,i ‚Ä≤ ) (i‚àí,i ‚Ä≤ ‚àí)
high precision and recall, such that each pair refers to the same real
world entity.                                                                   In the experiments, we use d(x, y) = ||x ‚àí y||2 as the distance func-
                                                                                tion. The overall architecture of our solution is shown in Figure 3.
3     METHOD
                                                                                3.2    Collective Graph Neural Networks
CG-MuAlign features a collective GNN framework to address the
KG Entity Alignment problem. Our model not only bridges the                     In CG-MuAlign, we first group the neighbor nodes by edge type r
gap between single-type and multi-type alignment model, but also                as Ni,r and apply different Transform, i.e. Wr . In Figure 1, for ex-
generalize to unlabeled types. In Section 3.1, we describe the over-            ample, the target node ‚ÄúAditya Raj‚Äù in the left IMDB sub-graph
all picture of our alignment model. Then we discuss two proposed                have Ni,write = {Don‚Äôt stop Dreaming, Shamaal: The Sandstorm,
attention mechanisms and explain how they contribute to the collec-             Sambar Salsa} and Ni,edit = {Gawaahi}. At each layer, we trans-
tive setting in Sections 3.3 and 3.4, respectively. At last, we present         form the neighborhood (j ‚àà Ni,r ) information regarding the rela-
our model specifications and reason about scalability concerns.                 tion between node i and j as follows,
                                                                                                           zi,k j = Wrk hkj ‚àí1 , j ‚àà Ni,r                     (3)
                                   GNN encoder
                                                                                As one entity can belong to multiple overlapping types, the above
                                       Combine
                      Aggregate                                                 transformation explicitly differentiate the same person‚Äôs represen-
                                                                                tations as editor and writer in the aggregation.
Graph A                                                                            We calculate node-level attention Œ± (details in Section 3.3), edge-
                                                                                level attention Œ≤ (details in Section 3.4) and Aggregate neighbor-
                                                            Align               hood as,
                                                            Model                                  zik =             Œ± i j Œ≤i j zi,k j , Œ£ j Œ± i j Œ≤i j = 1
                                                                                                       √ï
                                     shared parameters                                                                                                        (4)
                       Aggregate                                                                            ‚à™N i,r
                                        Combine

Graph B
                                                                                Then we proposes the following Combine function:
                                                                                                              k
                                                                                                  hki = œÉ [Wsel    k ‚àí1 k
                                                                                                                              
                                                         self representation                                     h
                                                                                                                f i    ||z i ]                                (5)
                                                         neighborhood

                                                         final representation
                                                                                Intuitively, we concatenate the self information and neighborhood
                                                                                information to make the alignment decision on self information
                                                                                and neighborhood information independently. And we name this
                 Figure 3: CG-MuAlign architecture                              layer as CollectiveAgg.
                                                                                   In CG-MuAlign, we stack multiple layers in each GNN encoder,
                                                                                where the inputs at layer k is the output representation of layer k-1.
3.1     Solution Overview                                                       The layer-0 representation is the input node features and we allow
We model the entity alignment problem as a classification problem,              entities of different types to have different length of features. Let
where we predict whether two nodes v ‚àà V and v ‚Ä≤ ‚àà V ‚Ä≤ represent                the hidden dimension of the model be m, we have the first layer
                                                                                of relation matrices Wr1 ‚àà Rdr √ó 2 , where dr is the feature length
                                                                                                                   m
the same real-world entity.
   The model includes two GNN encoders and an entity alignment                  of entity in neighbor group Nr . After concatenation as depicted in
loss layer. The GNN encoder takes an K-hop sub-graph derived                    Equation 5, the hidden representation is then m      m
                                                                                                                                 2 + 2 = m. For the
from target node v, aggregates the neighborhood information and                 layer k = 2, 3, ..., K, we have Wrk ‚àà Rm√ó  m
                                                                                                                           2 Then we describe how
outputs representation hvk for node v. In its k-th layer, for node i,           we compute the two attentions Œ± and Œ≤.
the GNN encoder aggregates neighbor information from k-1 layer,
                                                                                3.3    Node-level Cross-graph Attention
        zik = Aggregate ‚ó¶ Transform(k ) {hk‚àí1
                                                             
                                               j  , j ‚àà N i }    (1)
                                                                                Existing GNN-based entity alignment methods reconcile structural
where hk ‚àí1 is the hidden representation of the previous layers and             difference across two knowledge graphs by implicit means, such
Ni is the neighborhood of node i in the knowledge graph. The                    as graph matching objective [46] and rule grounding [4]. As we
output representation hki is the combination of hk‚àí1
                                                  i   and zik ,                 discussed in the introduction, the structural differences are mainly
                                                                                raised by the nature of incompleteness in a knowledge graph. In
                  hki = Combine(k) {hk‚àí1      k
                                               
                                                                                CG-MuAlign, we address this problem by collective aggregation of
                                       i , zi }                  (2)
                                                                                confident neighborhood information. Namely, we explicitly assign
    For two KGs, we have two K-layer models GNN1 and GNN2 with                  higher weights for those neighbors that are likely to have the corre-
identical structure and shared parameters. For each pair of entities            sponding ones in the other graph. We achieve this by employing a
(i, i ‚Ä≤ ) in the training data, we sample N negative entities from KG 1         cross-graph attention mechanism that attends over the neighbor‚Äôs
and KG 2 . Then we obtain the final representations from two GNN                feature vectors.
                                              h i2                                                                           h i2                                                                                  h i2

 Layer k+1                           CollectiveAgg                                                                   CollectiveAgg                                                                     CollectiveAgg                               Layer k+1
                                                                                                                                                                                                                             self attention Œ≤
                                                                     cross attention Œ±

                 zj0        zj1         zj2           zj3            zi                        zj0            zj1          zj2          zj3          zi                                                                                       zi


                        Wwrite                                                                                                                                                     zj0          zj1          zj2            zj3
           Wproduce                Wproduce                                           Wwrite         Wwrite         Wwrite       Wedit
                                                                     Wself-loop                                                                           Wself-loop
                                                     Wwrite

 Layer k         hj11                 hj21                                            hj01           hj11           hj21                                                   hj01          hj11         hj21
                                                            h i1                                                                 hj31         h i1                                                                   hj31              h i1        Layer k
                                                                                                                                    Person:
                    Film:                 Film:                Person:                   Film:           Film:      Film:   Film:                                             Film:         Film:      Film:   Film:                    Person:
                                                                                                                                  Aditya Raj
                 Sambar Salsa          Don‚Äôt stop             Aditya Raj              Don‚Äôt stop        Sambar Shamaal: Gawaahi                                            Don‚Äôt stop      Sambar Shamaal: Gawaahi                    Aditya Raj
                                        dreaming               Kapoor                  dreaming          Salsa The Sandstorm                                                dreaming        Salsa The Sandstorm

                                                       (a) Cross-graph Attention                                                                                                         (b) Relation-aware Self-Attention

                                                                   Figure 2: Illustration of node-level and edge-level attention in CG-MuAlign


  Given the candidate node pair (i, i ‚Ä≤ ), we have Ni and Ni ‚Ä≤ as                                                                             Table 2: Alignment Example for song Radioactive. Neighbor nodes
                                                                                                                                              are grouped by relations as described in Section 3.2. Bold font indi-
neighborhood of node i and node i ‚Ä≤ , respectively. We make soft
                                                                                                                                              cates the neighbor node with large cross-attention weights.
decisions by calculating similarity of pairs (p, q) ‚àà Ni √ó Ni ‚Ä≤ ,

                exp‚àí | |zp ‚àízq | |2                exp‚àí | |zq ‚àízp | |2
           √ç                                  √ç
                                                                                                                                                                                         Amazon Music                                 Wikipedia
              q ‚ààNi ‚Ä≤                                                             p ‚ààNi
 Œ±p =                                                              , Œ±q =                                                                                 Attributes
                                  exp‚àí | |zp ‚àízq | |2                                          exp‚àí| |zq ‚àízp | |2
             √ç          √ç                                                         √ç    √ç
           p ‚ààNi q ‚ààNi ‚Ä≤                                                     q ‚ààNi ‚Ä≤ p ‚ààNi                                                                      Title                     Radioactive                                 Radioactive
                                                                                                                                                               Duration                     2M19S                                       2M19S
The hidden representation zp and zq are calculated in Equation 3.
                                                                                                                                                          Neighbors
For p1 , p2 ‚àà Ni , Œ±p1 > Œ±p2 if the accumulated similarity between
p1 and neighbors Ni ‚Ä≤ in Graph G ‚Ä≤ is larger than p2 . In computation,                                                                                                               Wayne Sermon                                 Wayne Sermon
weight Œ±p and Œ±q are the row-wise and column-wise normalized                                                                                                                            A. Grant                                  Alexander Grant
                                                                                                                                                             Song writer
                                                                                                                                                                                     Dan Reynolds                                  Dan Reynolds
vector for the cross-graph attention matrix Ai,i ‚Ä≤ ‚àà R |Ni |√ó|Ni ‚Ä≤ | .                                                                                                                Josh Mosser                                   Josh Mosser
In Figure 2a, we turn the 1-hop neighbor in Figure 1 into actual
                                                                                                                                                          Song producer                   Alex Da Kid
computation graph in our CollectiveAgg layer. The neighborhood
for ‚ÄúAditya Raj‚Äù two knowledge graphs are {Gawaahi:edit, Don‚Äôs                                                                                                   Album            Night Visions (Deluxe)                            Night Visions
stop Dreaming:write , The Sandstorm:write, Sambar Salsa:write } and                                                                                                                Imagine Dragons
                                                                                                                                                          Main performer                                                          Imagine Dragons
{Don‚Äôs stop Dreaming:write, Don‚Äôs stop Dreaming:produce, Sambar                                                                                                                     Kendrick Lamar
Salsa:write, Sambar Salsa:produce }. The cross-graph attention will
give high weights to neighbor nodes {Sambar Salsa:write, Don‚Äôs
stop Dreaming Salsa:write} as their hidden representation is similar.                                                                         Networks [41], we adjust the cross-graph attention with an edge-
Thus, the proposed cross-graph attention leverages the positive                                                                               level self-attention that considers the edge(tuple) information, i.e.
evidence to the collective decisions.                                                                                                         ‚ü®Radioactive, perform by, Kendrick Lamar‚ü© we calculate an edge-
                                                                                                                                              level self-attention by a weight vector a¬Ær to estimate the importance
3.4        Edge-level Relation-aware Self-attention                                                                                           of an edge composed of subject, object and relation.
Yet, cross-graph attention neglects the negative evidence across                                                                                                                                 aTr [zi ||z j ]))
                                                                                                                                                                                          exp(œÉ (¬Æ
the graphs. If the neighborhood aggregation only relies on the                                                                                                             Œ≤i j =
                                                                                                                                                                                                     aTr [zi ||zk ]))
                                                                                                                                                                                         √ç
cross-attention, it fails to predict ‚Äúnegative‚Äù when only unimpor-                                                                                                                          exp(œÉ (¬Æ
                                                                                                                                                                                     k ‚ààNi
tant nodes are softly aligned. In our music data set at Figure 2, when
aligning song ‚ÄúRadioactive‚Äù by American rock band Imagine Drag-                                                                               We use œÉ (¬∑) as LeakyReLU suggested in [41]. As depicted in Fig-
ons between Amazon Music and Wikipedia, cross-graph attention                                                                                 ure 2b, self-attention measures the importance of a relation tuple
produce positive evidence on most of the neighbors such as song                                                                               with the relation aware linear layer ar . In the previous example,
writer, producer and one performer. However, it is an unmatched                                                                               the attention score of ‚ü®Radioactive, perform by, Kendrick Lamar‚ü© is
pair since the one in Amazon is a deluxe version collaborated with                                                                            similar with ‚ü®Radioactive, perform by, Imagine Dragons‚ü© and much
‚ÄúKendrick Lamar‚Äù. In other words, different relations shall play dif-                                                                         larger than grouped neighbors such as writer and producer.
ferent roles in alignment prediction. For example, performed by is
more informative than written by.                                                                                                             3.5             Scaling up
   In fact, the computation of cross-graph attention focuses on                                                                               Despite the effectiveness of the proposed GNN model, training
the neighbor nodes similarity and considers each relation equally                                                                             and applying it is very expensive. We scale it up in three ways:
important. In light of this issue, similar with Graph Attention                                                                               by carefully removing unnecessary computation, by strategically
sampling the neighborhood, and by selectively considering the                          training data and construct a K-hop sub-graph from G and G ‚Ä≤ . To
matching candidates.                                                                   further speed up the training, we adopt neighborhood sampling to
                                                                                       control the size of the computation graph.
Simplifying Computation: We now analyze the effectiveness of
CollectiveAgg under the Open World Assumption1 , that is, no                              Lemma 3.2. Let the maximum neighborhood size as N and batch
knowledge graph has complete knowledge. We assume graph G and                          size as B, the space complexity of CG-MuAlign is O(BN K ). Without
G ‚Ä≤ observes p portion and q portion from the underlying complete                      batch training or sampling, the space complexity is O(|V | ¬∑ K). For
knowledge Gu . In our example in Figure 1, both IMDB and Freebase                      training data of size S, the expected running time is O(S ¬∑ N K ).
contains only partial information of ‚ÄúAditya‚Äù. Given a ground truth
pair (i, i ‚Ä≤ ), that both refers to the real world entity e, the number
of neighborhood of e in the real world is Ne . We now quantify                            Additionally, we adopt a relation-aware neighborhood sampling
the Collective Power by counting numer of shared (same) nodes                          to leverage the maximal collective power, which samples those ‚Äúone-
regarding order of the neighbors.                                                      to-one‚Äù relation first. The probability of sampling possibly matched
                                                                                       neighbor node is greater than those ‚Äúone-to-many‚Äù relations. For
   Theorem 3.1. If G and G ‚Ä≤ have the same number of nodes, i.e.                       example, one movie usually has only one director but many actors,
|V1 | = |V2 | and there exists a injective function F : V1 ‚Üí V2 . Let K                knowing whether the director is same is more informative than
denote the order of the neighborhood, |E | is the total number of edges                knowing one actor is same. For each type of entity v t , we calculate
in the underlying graph Gu , the expected Collective Power decays                      the average number av–¥_Nrt of neighbors connected by relation r .
geometrically as K increases.                                                          During the neighborhood sampling process for node i of type t, we
                                                        K   K                          sample from the neighborhood group Ni,r with probability
                    E(v, F(v))‚àºG 1 CP(K) ‚â§ |E | ¬∑ p 2 q     2
                                                                                                                         av–¥_Nrt
                                                                                                                                     ‚àí1
   Proof. According to the definition of p and q. Let pi and qi be                                            Pr(n) ‚àù √ç            t
                                                                                                                         r av–¥_Nr
the actual observed ratio for node vi and F (vi ) in graph G and G ‚Ä≤ ,
we have,                                                                               Therefore, director neighbors are more likely to be sampled com-
                     |V
                      √ç1 |                 |V
                                            √ç2 |                                       pared with characters and actors due to their large population. It
                           |Ni | ¬∑ pi             |Ni | ¬∑ qi                           helps make the collective decisions when we sample a small number
                     i=1                   i=1
                p=                    ,q =                                             of neighborhoods.
                            |E |                   |E |
For a specific node i, the expected number of same neighborhood                        Candidate Generation. Though the training cost is controlled by
from a uniform distribution in two graphs is |Ne |pi qi . Thus, when                   number of GNN layers and number of sampled neighbors, the infer-
K = 1,                                                                                 ence cost remains as a problem. Naive one-versus-all comparison
                                           √ï                                           leads to time complexity up to O(|V |!). To scale up to millions
                 E(v, F(v))‚àºG 1 CP(1) =          |Ne |pi qi       (6)                  of entities, we employ candidate generation during the inference
                                                    i                                  stage, also known as blocking. For each test node, we use several
                          s
                           √ï p        2√ï p        2                                    strong keys(e.g. name and date of birth for person) to collect possi-
                        ‚â§   ( Ne pi )   ( Ne qi )                               (7)
                                                                                       ble match entities and use CG-MuAlign to predict alignment score
                               i                i
                        s√ï                                                             within candidate pairs.
                                       √ï                 ‚àö
                    ‚â§          Ne pi       Ne qi = |E | ¬∑ pq                    (8)
                           i           i
                                                                                       3.6    Relations with other GNN variants
                                                                                       Now we summarize the key differences of proposed CollectiveAgg
Recursively, we repeat the same calculation on shared neighbor
                                                          ‚àö                            with previous popular GNN framework.
nodes in previous step, that is, E[CP(K + 1)] = E[CP(K)] ¬∑ pq ‚ñ°
                                                                                          Similar with RGCN [32], we adopt multi-relational matrices to
   The above theorem can be explained as jaccard similarity of                         model the semantics of different relations when aggregating the
neighborhood follows a long-tail distribution as K grows, because                      neighbors. Our self-attention modules shares similar motivation
only same first-order neighbor nodes may contain the same second-                      with GAT [41]. Both GraphSage and CollectiveAgg characterize
order neighbor nodes in principle. According to this, we employ the                    with concatenating self representation and neighborhood repre-
CollectiveAgg as the Aggregate only at the last layer to reduce                        sentations. The GraphSage GNN layer includes concatenation and
the computation cost as the collective power decrease. That is,                        aggregate function, like average

                                                                                           hki = œÉ W1 hk‚àí1   ||œÉ W2 ¬∑ MEAN{hkj ‚àí1 , j ‚àà Ni,r }
                                                                                                  h                                        i
       Ô£≤ CollectiveAgg {hkj ‚àí1 , j ‚àà Ni ‚à™ {i}} , k = K ‚àí 1                                                                                         ,
       Ô£±
                                                                                                         i                                           (10)
       Ô£¥
   k
  hi =
       Ô£¥
                                                               (9)
       Ô£¥ AverageAgg {hk‚àí1
       Ô£¥
                           j , j ‚àà Ni ‚à™ {i}}          k <K ‚àí1                          There are two differences between CollectiveAgg and GraphSage.
                                                                                       First, we have multi-relational projection matrix Wr in the hidden
       Ô£≥
where the AverageAgg replaces the Œ± i j Œ≤i j in Equation 4 as |N1 | .                  layer. Second, we use weighted average (attention) Œõ instead of
                                                                                i

Mini-batch Training and Neighborhood Sampling. Traditional                             averaging or max pooling.

                                                                                                  hki = œÉ W1 hki ‚àí1 ||Œõ(Wr ¬∑ {hkj ‚àí1 , j ‚àà Ni })
                                                                                                           h                                    i
graph neural nets are trained globally, which is infeasible when the                                                                                  (11)
graph is large. Instead, we sample a batch of positive pairs from
1 the assumption that the truth value of a statement may be true irrespective of
                                                                                          In the toy example below, all kinds of previous aggregation
whether or not it is known to be true, from wikipedia:https://en.wikipedia.org/wiki/   function, e.g. MEAN/MAX/SUM, fail to fit the label if node id is the
Open-world_assumption                                                                  only input feature. A learnable mask Œõ on neighborhood, instead,
                     Table 3: Overall Dataset Statistics                                                          Table 5: Music Dataset


 Dataset       # Nodes          # Edges          # Node Types          # Edge Types              Dataset        # Songs    # Albums        # Artists     # Train/Test
    Movie      2,684,233        6,851,166                8                     8/8           Wikipedia          104,179     188,602        71,409
                                                                                                                                                         57,062/23,485
    Music      1,768,983       10,723,141                6                     4/5          Amazon-Music        999,900     200,911        201,550

                             Table 4: Movie Dataset
                                                                                                                     1
                                                                                                     song            2                          1
    Dataset    # Films       # People     # Characters       # Genres       # Train/Test                                          person            isComposedby
                                                                                                                     3                          2    isWrittenby
    Freebase   273,526       314,869          859,289           599
                                                                           53,405/53,405                             4
     IMDB      423,118       600,909          211,895           28                                                                              3   isProducedby
                                                                                                            5                 3                 4
                                                                                                                                  4                  isPerformedby
                         1                                                                                                                      5   hasTrackon
       movie             2
                                        person                                                                     album
                         3                          1   isDirectedby   5   isActedby
                         4                          2   isEditedby     6   inFilmGenre
         6                                7
                 8       5                          3   isProducedby   7   isPerformedby                Figure 5: The schema of the Music Graph
       genre                        character       4   isWrittedby    8   isCharacterIn


                                                                                           In Table 4, we report the distribution of entity types and the size of
               Figure 4: The schema of the Movie Graph                                     the training/testing data.
                                                                                           Music Dataset contains two music knowledge graph from Amazon
can fit the label by masking out node c and d. To some extent,                             Music and wikipedia. There are three major types in this dataset:
CollectiveAgg has a greater representation power for the task of                           song, album and artist. The five relations among them can be found
entity alignment when data is sparse.                                                      in Figure 5. The positive pairs on songs and albums are generated
   Example 3.3. For node a ‚àà G and a ‚Ä≤ ‚àà G ‚Ä≤ , we have first-order                         with noise and we ask annotators to label testing pairs among a
neighbors {b, c, d} in graph G and {b} in graph G ‚Ä≤ , the training                         candidate pool for two types. Detailed number of entities can be
label is 1.                                                                                found in Table 5.

4     EXPERIMENTS                                                                          4.2    Baselines
We compare CG-MuAlign with other knowledge graph alignment                                 We consider methods from three families: (1) link prediction (2)
algorithms to examine our three major claims one by one in Sec-                            entity alignment between graphs (3) entity matching in multi-
tion 4.4.                                                                                  relational database.
   ‚Ä¢ CG-MuAlign outperforms existing methods on real-world                                 Link prediction. Between two knowledge graphs G and G ‚Ä≤ , we can
     large-scale dataset.                                                                  add equivalent edges between ground truth node pairs {(vit , v tj ‚Ä≤ )}.
   ‚Ä¢ Collective alignment is not sensitive to the amount of training
                                                                                           We then run advanced graph embedding algorithm with node fea-
     data.
                                                                                           tures to embed nodes from different graphs in the same unified
   ‚Ä¢ CG-MuAlign generalizes to unlabeled type effectively with
                                                                                           space. Later, we train a two-layer perceptron on the labeled equiv-
     limited labels.
                                                                                           alent edges. Specifically, we consider the following method that
                                                                                           consider the node attributes:
4.1      Datasets
In our experiments, we use two different knowledge graph align-                              ‚Ä¢ GraphSage [18] is the first large-scale inductive representation
ment data sets and evaluate the performance under inductive set-                               learning algorithm.
tings. Both (i.e. Movie and Music domain) contain abundant node                            We denote this method as GraphSage+NN along with another
attributes and feature with millions of nodes and tens of millions                         baseline named Feature+NN to verify the feature effectiveness
edges of different types. We report basic graph statistics in Table 3                      and inspect how different methods gain improvement over its per-
and then introduce them in more details. The number of nodes and                           formance.
number of edges are summed over two knowledge graphs.
                                                                                           Knowledge Graph Alignment. Most of the previous work focus
Movie Dataset contains a subset of IMDB (an online database of                             on the transductive setting. Some recent work [4, 45, 46] based on
information related to films) and Freebase (a large knowledge base                         Graph Neural Networks, start to extend graph alignment problem
on general domains). The latter originally has a large number of                           under inductive setting. We group these methods into transductive
edge types compared with IMDB. We sample a subset of Freebase                              only: MuGNN [4] and BootEA [37] that both models knowledge
that is related to the movie domain. It has ground truth links to the                      graph embedding and entity alignment simultaneously and induc-
IMDB ID for some of the films and people. We split the ground truth                        tive: MultiKE [49] and AttrE [39] further incorporate attribute in-
pairs into training and testing data. It has four different entity types                   formation into embedding-based entity alignment. GCN-Align [45]
and eight different relations, the schema can be found in Figure 4.                        models both structure and attribute features with same relation
matrices for different relations. As we found embedding-based meth-      similarities are computed as features, such as jaccard similarity,
ods fail to scale up to graphs with millions of entities, we carefully   levenshtein edit distance between attributes of entity pairs.
verify the effectiveness of proposed GNN model with following
                                                                         Evaluation Metrics. We evaluate different methods on both la-
recent GNN variants.
                                                                         beled and unlabeled settings and report their Recall@Precision=0.95,
  ‚Ä¢ GCN-Align [45] models both structure and attribute features          F1, PRAUC (precision-recall area under curve) and hit@1 on three
    with the original graph convolutional network [21].                  data sets. Typically, previous research mainly use hit@1 since the
  ‚Ä¢ GraphSage [18] concatenates the self feature vector and neigh-       evaluation data set is small. It is infeasible to conduct one-versus-all
    borhood aggregation vector.                                          comparison when there are millions of candidate nodes. Thus, we
  ‚Ä¢ GAT [41] aggregates neighborhood information with multi-             use candidate generation introduced in Section. 3.5 in the test-
    head attention.                                                      ing stage and report hit@1 based on the candidate set. We re-
  ‚Ä¢ RGCN [32] differs GCN with multi-relational linear transfor-         port the precision and recall curve while tuning the alignment
    mation matrices.                                                     threshold. PRAUC and best F1 provide more insights how differ-
  ‚Ä¢ R-GraphSage is a variant of GraphSage with multi-relational          ent methods perform without knowing all positive pairs. We will
    linear transformation matrices.                                      later show in Table 6, methods have similar hit@1 result could
                                                                         produce rather different PRAUC and F1. Besides, we propose metric
    To address the scalability issue, we re-implement all of them in     Recall@Precision=0.95 to evaluate model performance when high
PyTorch [28] under DGL framework [43]. CG-MuAlign and above              precision is required.
GNN variants adopt same mini-batch paradigm training described
in Section. 3.5 with the batch size of 32. We sample 10 negative en-     Evaluation Settings. The ground truth links between person and
tities from each graph and have total 20 negative samples for every      movie serve as positive data in training and testing. During training,
positive pair. We use Adam [20] as our optimizer with learning rate      we adopt the same random sampling to construct negative samples
as 0.003. We set the max neighborhood size as 10 in the neighbor         for different methods as we assume no prior knowledge of the target
sampler function. The number of layers for all GNN methods are           domain. We construct the testing data by joining output of candidate
set as two. And we set hidden dimension as 100 for link prediction       generation and the test split of ground truth links. Specifically, we
and graph alignment baselines.                                           use blocking function in Magellan [22] to generate candidates. For
                                                                         example, we use person‚Äôs name and date of birth(allow missing) as
Entity Matching. We refer methods that finds all tuple pairs (a, b)      the blocking key. Note that on the music domain, the ground truth
across different multi-relational databases into this category. We       links are also noisy. We annotate a subset of the candidates, thus,
explore the performance of two representative methods:                   hit@1 metric is not included for music data. For unlabeled type
  ‚Ä¢ Magellan [22] is end-to-end entity matching framework that           evaluation, we use the same way to generate the evaluation data.
    supports different matching functions like linear regression,
    SVM, random forest, etc. We choose random forest as the              4.4    Experiments and Performance Study
    matching function.
  ‚Ä¢ DeepMatcher [27] is a recent deep learning entity matching           Alignment Result on labeled types. We train a unified model
    algorithm, we use its ‚Äúhybrid‚Äù mode in our experiments.              for multiple entity types and report all of baselines including GNN
  ‚Ä¢ PARIS [36] is an unsupervised RDF ontologies alignment model,        variants. From Table 6, we can conclude CG-MuAlign outperforms
    which makes collective decisions based on iterative probability      all other method. On the movie dataset, it yields a large margin
    estimates.                                                           over the second best method - DeepMatcher. It is mainly because
                                                                         IMDB and Freebase have rather different relation distributions and
                                                                         they suffer from data incompleteness differently. DeepMatcher con-
4.3    Experimental Settings                                             siders the difference between attribute sets from two graphs, thus,
                                                                         it performs better than the remaining ones. It is quite surprising
Now we describe how we conduct the experiments and evaluate
                                                                         that Feature+NN outperforms most of the GNN variants, which
the performance.
                                                                         indicates the neighborhood information affects the performance
Data Processing. For all of the GNN-based methods, we pre-compute        negatively in those methods. Although other GNN algorithms suf-
the feature vector of different entities. There are two major types      fer from the sparsity of knowledge graphs while our collective
of features: string and numerical. We use fastText [26] to encode        aggregation layer avoid performance drop by aggregating mostly
string features. For numerical features, we preserve the original        aligned neighborhood via cross-graph attention. Specifically, among
value except time values. For time values, like duration, date of        three GNN variants that do not consider multi-relational structure
birth, we use periodical function sin(¬∑) to encode each periodical       (GCN, GrageSage, GAT) perform worse than those includes multi-
segment, e.g. seconds, minutes. Finally, we concatenate all of the       relational transformation as expected. We find the concatenation
features into a unified vector as the node feature.                      mechanism first introduced in GraphSage benefit the task. The rea-
   For entity matching baselines, we convert one-hop neighbor            son could be self-information is critical to the alignment task and
node in the knowledge graph into the format relation@attribute,          mixing it with neighborhoods confuses the model predictions. On
e.g. for a movie record, we have the field isDirectedby@Name             the music data set, CG-MuAlign gain a smaller margin over other
indicating movie director‚Äôs name. Thus, we can turn the first order      baselines as we observe the music graphs are much denser. The
information in the knowledge graph into a multi-relational table in      performance difference is similar with the movie dataset, vanilla
a lossless way. In Magellan [22], the features used in the random        GNN perform badly while GraphSage and R-GraphSage obtain
forest are automatically generated by the model. Different string        reasonable results compared with Feature+NN. We notice the link
Table 6: Alignment Result on labeled types for inductive setting. For simplicity, transductive only methods are not included in this table. We
report the standard deviation by 5-runs of each method except DeepMatcher, which takes long time for one run.


                                                                                                    Movie Dataset                                                                  Music Dataset
                                  Method
                                                           Rec@Prec=.95                          PRAUC            F1                                  hit@1       Rec@Prec=.95       PRAUC                     F1
                                 Feature+NN                       0                         0.3672 ¬± 0.053          0.6380 ¬± 0.000    0.7197 ¬± 0.001              0.0025 ¬± 0.002     0.7251 ¬± 0.027     0.6795 ¬± 0.009
                                 GraphSage+NN               0.0155 ¬± 0.001                  0.3229 ¬± 0.003          0.3557 ¬± 0.001    0.4503 ¬± 0.003              0.0002 ¬± 0.000     0.2468 ¬± 0.018     0.3134 ¬± 0.012
                                 Magellan                   0.4387 ¬± 0.000                  0.7067 ¬± 0.000          0.6945 ¬± 0.000    0.7974 ¬± 0.000              0.1071 ¬± 0.000     0.7461 ¬± 0.000     0.6760 ¬± 0.000
                                 DeepMatcher                      0                         0.5829 ¬± 0.000          0.7549 ¬± 0.000    0.8468 ¬± 0.000                     0           0.1748 ¬± 0.000     0.3559 ¬± 0.000
                                 PARIS                      0.5840 ¬± 0.000                  0.7759 ¬± 0.000          0.7661 ¬± 0.000    0.7725 ¬± 0.000                  0.2333         0.4175 ¬± 0.000     0.4640 ¬± 0.000
                                                            0.0098 ¬± 0.001                  0.2831 ¬± 0.006          0.3313 ¬± 0.004    0.4896 ¬± 0.003              0.0020 ¬± 0.002     0.3829 ¬± 0.009     0.4190 ¬± 0.003
            GNN variants




                                 GCN
                                 GraphSage                  0.1900 ¬± 0.007                  0.5589 ¬± 0.004          0.5251 ¬± 0.003    0.6605 ¬± 0.009              0.2868 ¬± 0.029     0.8252 ¬± 0.003     0.7637 ¬± 0.001
                                 GAT                        0.0147 ¬± 0.002                  0.3448 ¬± 0.006          0.3793 ¬± 0.004    0.5483 ¬± 0.003              0.0004 ¬± 0.001     0.4485 ¬± 0.014     0.4819 ¬± 0.007
                                 RGCN                       0.0106 ¬± 0.002                  0.4247 ¬± 0.003          0.4435 ¬± 0.001    0.5450 ¬± 0.002              0.0025 ¬± 0.004     0.4419 ¬± 0.024     0.4625 ¬± 0.020
                                 R-GraphSage                0.2829 ¬± 0.009                  0.6573 ¬± 0.003          0.6110 ¬± 0.004    0.7125 ¬± 0.003              0.4081 ¬± 0.029     0.8335 ¬± 0.004     0.7646 ¬± 0.003
                                 CG-MuAlign                0.6010 ¬± 0.004                  0.8548 ¬± 0.004           0.8050 ¬± 0.006   0.8869 ¬± 0.002               0.4437 ¬± 0.023   0.8400 ¬± 0.008       0.7762 ¬± 0.004


                                                                                                                                     Table 7: Alignment Result on unlabeled types for few-shot setting.
           0.8                                                                      0.8
           0.7                                                                                                                       We mark the best and second-best result. Column person stands for
           0.6                                                                      0.7                                              unlabeled type in the evaluation.
F1 score




                                                                         F1 score




           0.5
           0.4                                                                      0.6
           0.3                                  No film supervision                 0.5                No person supervision                                                  Person                      Film
           0.2                                  Full film supervision                                  Full person supervision                           Method
                                                                                                                                                                           PRAUC     F1               PRAUC    F1
                           0.0     0.2    0.4       0.6    0.8     1.0                    0.0    0.2   0.4    0.6    0.8    1.0
                                   percentage of supervision                                    percentage of supervision
                                                                                                                                                       Node features        0.8285      0.8563        0.4231    0.4780
                                 (a) Test on Person                                             (b) Test on Film                                       PARIS                0.7303      0.7489        0.8392    0.7961
                                                                                                                                       GNN variants



                                                                                                                                                       GCN                  0.3492      0.4659        0.2589    0.3223
Figure 6: Sensitivity to the amount of training data. The orange                                                                                       GraphSage            0.5495      0.6069        0.4269    0.4158
curve indicates the collective setting, i.e. supervision of other types                                                                                GAT                  0.3518      0.3791        0.4926    0.4818
are provided. The blue curve indicates the non-collective setting.                                                                                     RGCN                 0.3130      0.3518        0.4288    0.4369
                                                                                                                                                       R-GraphSage          0.8065      0.7582        0.5008    0.4705
                                                                                                                                                       Few-shot             0.8403      0.8033        0.8505    0.8136
prediction baseline - GraphSage+NN achieves worse results than
                                                                                                                                                       Fully-supervised     0.8543      0.8214        0.9101    0.8794
Feature+NN. GraphSage embedding models every edges of differ-
ent types in the objective and the ‚Äúequivalent‚Äù edges contributes
than 1% in total. The ‚Äúequivalent‚Äù relation may be biased by other
links, therefore, predicts unsatisfactory results. Three entity match-                                                               When we do not have any labeled data for person type, the model
ing baselines reports competitive performance on movie dataset but                                                                   can achieve 0.53 F1 already and adding 10% of training data make
DeepMatcher performs much worse on the music dataset. Moreover,                                                                      the performance quickly converge to the final model in Figure 6a.
it achieves almost zero on the metric Rec@Prec.95. It may be caused                                                                  Note that 10% of training data in our setting is about 2K samples
by overfitting the noisy training data with huge amount of param-                                                                    only. When we have about 40% of training data, both settings are
eters(20 million). PARIS, though unsupervised, yield second-best                                                                     on a par with full supervision model. On the film type, the trends
F1 on the movie dataset, which proves the collective design works                                                                    are similar but result is not that satisfactory when supervision is
very nice on incomplete knowledge graphs. However, it can not tell                                                                   limited. We explain it as film alignment is more tricky since different
the subtle difference between songs with slightly different names                                                                    films could have partially overlapped titles and same movies across
and duration due to lack of supervisions. Overall, Magellan and                                                                      different graphs could have multi-lingual names. Both figure shows
CG-MuAlign are the most robust methods under different datasets                                                                      that CG-MuAlign does not rely on large amount of training data.
and metrics. As we know, the feature importance of random forest
                                                                                                                                     Few-shot alignment on unlabeled types. In order to investigate
depends on the training data. So Magellan produces more false
                                                                                                                                     the generalization capability of different methods, we design few-
positives than ours, while CG-MuAlign reports above 50% recall
                                                                                                                                     shot alignment experiments, that first train a model on type A and
when precision is at 95% across two datasets.
                                                                                                                                     fine-tune the model with only a few (i.e. 2,000) training pairs of type
Sensitivity to the amount of training data. Then we investigate                                                                      B. The model is evaluated on the test data of new type. We train and
how much supervision needed in CG-MuAlign, since label scarcity                                                                      test on person and film alternatively. Magellan and DeepMatcher
is quite normal in the real applications. Also, we are interested in                                                                 are trained on one type is not compatible with the new type, so
how collective alignment benefits from different types in this case.                                                                 we do not report their performance in Table 7. In addition, we add
Therefore, we range ratio of supervision from 0 to 1.0 on type A and                                                                 cosine similarity of node features as an unsupervised benchmark in
test it on type A on two conditions: (1) 100% training type of type                                                                  the table. When tested on person, we observe the cosine similarity
B (2) 0% training type of type B. The result is plotted in Figure. 6.                                                                of feature vector is a very competitive method, since people who
 Table 8: Effectiveness of proposed attention mechanism. We report                                                                                    Parameter Study. To measure the parameter sensitivity of CG-
 the averaged metrics on movie and music data set.
                                                                                                                                                      MuAlign, we evaluate the performance on movie dataset varying
                                                                                                                                                      one of the following parameters while fixing the others to the de-
                                          Method                    Averaged-PRAUC                                         Averaged-F1                fault values mentioned above: (1) number of neighbor sampled for
                                                                                                                                                      each node (2) hidden dimension size of each GNN layer (3) number
                             w.o. cross attention                             0.7654                                         0.7034
                                                                                                                                                      of negative samples for each positive pair (4) number of GNN lay-
                             w.o. self attention                              0.8342                                         0.7880
                                                                                                                                                      ers. The result is shown at Figure 7, where PRAUC, F1 and Hit@1
                                CG-MuAlign                                    0.8474                                         0.7906
                                                                                                                                                      are reported under different parameters. First, the performance on
                                                                                                                                                      three metrics improves when number of sampled neighbors, i.e.
                     0.90                                                                              0.90                                           2,4,6. It is mainly because many useful neighborhood information
                     0.85                                                                                                                             is dropped, when number of neighborhood size is small. When the
Evaluation Metrics




                                                                                  Evaluation Metrics

                                                                                                       0.85
                     0.80                                                                                                                             neighbor window size is reasonably large, the performance tends to
                     0.75                                                                              0.80                                           be similar. Then in Figure 7b, we observe the performance is similar
                     0.70                                                                                                                             under different hidden dimensions, which reveals that CG-MuAlign
                                                                  PRAUC                                0.75                                  PRAUC
                     0.65                                         F1                                                                         F1       neither overfits nor relies on huge amount of parameters. Since we
                     0.60                                         Hit@1                                                                      Hit@1
                                                                                                       0.70                                           have the similar positive ratio in training and testing (10:1), we are
                                  2       4       6       8           10                                      50     100     150       200      250
                                                                                                                                                      also interested whether CG-MuAlign achieves good performance
   (a) Varying #sampled neighbors                                                   (b) Varying #hidden dimensions                                    under different positive ratio. Result presented in Figure 7c shows
                           0.90                                                                  0.90                                                 the positive ratio does not affect the model performance. At last, we
                                                                                                 0.85                                                 notice our model performs best with 2 alignment layers. More lay-
      Evaluation Metrics




                                                                            Evaluation Metrics




                           0.85
                                                                                                 0.80                                                 ers negatively affects the model performance, besides the running
                           0.80                                                                  0.75                                                 time increases as number of layers grows. The results shows that
                                                                  PRAUC                          0.70              PRAUC                              1-hop neighborhood information is not sufficient for the task of
                           0.75
                                                                  F1                             0.65              F1                                 entity alignment, while higher (> 2) order information deteriorates
                                                                  Hit@1                                            Hit@1
                           0.70                                                                  0.60                                                 the performance as lots of asymmetric information appears. It is
                                      2       4       6       8        10                                     1        2           3            4
                                                                                                                                                      consistent with our scaling up analysis in Section 3.5.
                 (c) Varying #negative samples                                                                (d) Varying #layers
                                                                                                                                                      Efficiency Study. We compare the training time, number of param-
 Figure 7: Parameter sensitivity of CG-MuAlign on movie dataset.
                                                                                                                                                      eters and the average F1 score on two large-scale entity alignment
 Each figure shows the result of varying the x-axis parameter.                                                                                        datasets with two existing systems, i.e. Magellan [22] and Deep-
                                                                                                                                                      Matcher [27]. As shown in Table 9, CG-MuAlign achieves the best
                                                                                                                                                      performance with the least training time. Compared with the other
                                                                                                                                                      Deep Learning solution, i.e. DeepMatcher, we yield better perfor-
 have the same names are likely to be the same person. Another
                                                                                                                                                      mance with 100 times fewer parameters and 20X speed up. All of
 unsupervised baseline PARIS reports promising results thanks to
                                                                                                                                                      our experiments run on AWS EC2 instance with one 16G NVIDIA
 the collective probabilistic alignment. Most of the GNN variants
                                                                                                                                                      V100 Tensor Core GPU.
 report poor performance except CG-MuAlign and R-GraphSage
                                                                                                                                                              Table 9: Efficiency study of three different methods
 that consider the self information (person name) separately. On
 type of film, few-shot CG-MuAlign achieves 81.4% F1 when feature
 similarity only obtains 47.8%. All other methods perform worse                                                                                             Method       Training Time     # Parameters     Averaged-F1
 or slightly better than node feature similarity. The result clearly                                                                                       Magellan          7m13s            9,300            0.6641
 demonstrates the effectiveness of collective design, especially when                                                                                     DeepMatcher       13h40m          17,757,810         0.6014
 the training data is limited. We want to note that alignment result                                                                                      CG-MuAlign        30m47s           175,134           0.7925
 reported in Table 6 are for multi-type alignment, but here the result
 is evaluated for each type separately. Our fully supervised model
 achieves better results than the reported figures in Table 6, because                                                                                   The running time of CG-MuAlign is affected by number of sam-
 multi-type alignment is more challenging. Overall, our few-shot                                                                                      pled neighbors and number of the GNN layers as discussed in
 results are quite close to the fully-supervised version.                                                                                             Lemma 3.2. Thus, we report the training time for single epoch by
                                                                                                                                                      varying these two parameters. In Figure 8a, we change the number
                                                                                                                                                      of sampled neighbors while fixing #layers=2. The training time
 4.5                                  Analysis of CG-MuAlign
                                                                                                                                                      increases slowly from 80 seconds to 200 seconds, because only a
 Effectiveness of Collective Aggregation. Overall, CG-MuAlign                                                                                         few nodes have many neighbors. In Figure 8b, we set the number
 outperforms baselines by 10% F1 in average. We report the quan-                                                                                      of neighbors as 4 and increase the number of layers in GNN. Al-
 titative improvement by two different mechanism in Table 8. It                                                                                       though the running time grows exponentially, our discussion in
 shows the cross attention boost the performance by 7% in averaged-                                                                                   Figure 7d supports that the 2-hop model works best in terms of the
 PRAUC and by 5% in averaged-F1. The self-attention further im-                                                                                       performance-efficiency trade-offs.
 proves 1% PRAUC and F1. The cross attention contributes the major
 part of the performance boost. But when the training data is not                                                                                     5     RELATED WORK
 that sparse, i.e. the music dataset, self-attention help identify the                                                                                In this section, we review the literature of entity alignment from
 strong negative evidence.                                                                                                                            four different perspectives.
                        250                                                                  1200                                remove obviously non-matched pairs between two tables and (2)




                                                                     Training time(second)
Training time(second)




                        200                                                                  1000                                matching [22] predicts the match score for the remaining pairs.
                        150                                                                   800
                                                                                                                                 Megellan [22] is an open-source and scalable entity matching frame-
                                                                                              600
                        100                                                                                                      work that uses handcraft features and various machine learning
                                                                                              400
                         50                                                                   200                                algorithms as the matching function such as SVM, random forest,
                          0                                                                                                      etc.. Later, DeepMatcher [27] computes the pairwise similarity from
                              2        4       6       8        10                                  1    2       3       4   5
                                  Number of sampled neighbors                                             Number of layers       the attribute embeddings and adopts deep neural network as the
                                                                                                                                 matching function. DeepER [14] is the first to consider sequence
    (a) Varying #sampled neighbors                                                                  (b) Varying #layers
                                                                                                                                 model like LSTM to model the textual attributes automatically. En-
                                                                                                                                 tity matching methods mostly use 1-hop neighbor information, but
  Figure 8: Running time per epoch varying # neighbors and # layers.
                                                                                                                                 CG-MuAlign can easily absorb multiple hops of neighbor entities.

  Link Prediction. Entity Alignment problem can be formulated as                                                                 Collective Entity Resolution. Researchers have noticed the cor-
  predicting ‚Äúequivalent‚Äù links among two graphs. For large-scale                                                                relations between labeled entities and unlabeled neighbor entities in
  graph structured data, network embeddings [17, 29, 38] tranform                                                                multi-relational database and network structured data [2, 12]. Col-
  nodes in networks into dense vectors that helps predict missing                                                                lective entity resolution considers that the decisions made on related
  links conveniently. methods [3, 24, 35, 47] capture the first-order                                                            entities are affected by each other. An unsupervised method [52]
  information and facilitate logical inference with explicit relation                                                            is proposed to reduce the entity resolution problem into a graph
  embeddings. To capture higher order information, previous work                                                                 summarization problem by clustering the co-referenced entities
  models the heterogenous types of nodes and edges with pre-defined                                                              across different knowledge graphs into a super node. People design
  meta-structures [6, 9, 13, 15, 33]. HetG [48] proposes a random walk                                                           collective features upon human-curated entity resolution rules [31].
  based sampling strategy and models each type of neighborhood                                                                   PARIS is an unsupervised probabilistic model for ontologies align-
  nodes differently. GATNE [5] studies the attributed multiplex het-                                                             ment. HolisticEM [30] builds a graph where each node represents
  erogenous network embedding under transductive and inductive                                                                   similarity of a pair of entities, and propagates similarity by Per-
  settings. HAN [44] aggregates neighbor nodes along meta-path via                                                               sonalized Random Walk to make collective decisions. We carefully
  hierarchical attention mechanism.                                                                                              consider collective decisions between sub-graphs sampled around
                                                                                                                                 candidate pairs and boost the performance of GNN greatly.
 Graph Alignment. Previous efforts on graph alignment mainly
 span on the transductive setting, where the entity attribute is not
 available. Traditional network alignment methods [40, 50] focus
 on graphs with a small number of relation types and optimize the
                                                                                                                                 6   CONCLUSION
 alignment objective based on the topology. Taking the advantage                                                                 In this paper, we propose CG-MuAlign to align entities of different
 of knowledge graph representation learning [3], embedding based                                                                 types between two knowledge graphs. CG-MuAlign leverages both
 methods [7, 8, 37, 51] embed entities from different space along with                                                           attribute information and neighborhood information during the
 an alignment objective on the training data. Starting with limited                                                              alignment and a novel cross-graph attention mechanism is designed
 alignment seeds, people propose to use either bootstrapping [37]                                                                to deal with the data incompleteness of knowledge graphs. Our
 or iteratively [51] align the entities.                                                                                         experiments show CG-MuAlign outperforms the baselines by 10%
    Recently, graph convolutional neural network [21] sheds light                                                                on PRAUC and F1 measure. CG-MuAlign can be generalized to
 on inductive graph representation learning. GAT [41] aggregates                                                                 entity types of low supervision/few-shot and more than 20% boost.
 neighborhood information via multi-head attention mechanism.                                                                    CG-MuAlign training is highly efficient, 20 times faster than the
 RGCN [32] applies multi-relational Graph Convolutional Networks                                                                 state-of-the-art deep learning methods. The collective mechanisms
 and improves the performance of link prediction and node classifi-                                                              shows great potential in pairwise prediction tasks. Interesting fu-
 cation on knowledge graphs. GraphSage [18] introduces inductive                                                                 ture work can be (1) extend CG-MuAlign to the transductive setting,
 representation learning on large scale graph data with neighbor-                                                                where collective decisions need be to carefully carried out upon
 hood sampling. Besides, graph neural network methods designed                                                                   structural information. (2) handle multiple (> 2) knowledge graphs
 for entity alignment [4, 45, 46] demonstrate great performance im-                                                              alignment simultaneously. We are also seeking to align entity and
 provement for multi-lingual KG alignment. Although studies [4, 46]                                                              relation jointly in a unified GNN framework.
 already observe the structural heterogeneity, our proposed frame-
 work is the first to leverage the collective alignment on two KGs
 directly.                                                                                                                       7   ACKNOWLEDGEMENTS
    This task is also related with the problem of graph matching.
                                                                                                                                 Research was sponsored in part by DARPA under Agreements
 Two most recent works [1, 23] introduce cross-attention mechanism
                                                                                                                                 No. W911NF-17-C-0099 and FA8750-19-2-1004, National Science
 while criterion of graph matching is much more rigorous than entity
                                                                                                                                 Foundation IIS 16-18481, IIS 17-04532, and IIS-17-41317, and DTRA
 alignment. Same entities in two KGs can have rather different k-
                                                                                                                                 HDTRA11810026. Any opinions, findings, and conclusions or rec-
 hop neighborhood sub-graph, whereas it is more likely to be an
                                                                                                                                 ommendations expressed in this document are those of the author(s)
 unmatched case in graph matching.
                                                                                                                                 and should not be interpreted as the views of any U.S. Government.
  Entity Matching. Entity Matching (EM) techniques [14, 22, 27]                                                                  The U.S. Government is authorized to reproduce and distribute
  find all tuple pairs between two relational tables. It is composed                                                             reprints for Government purposes notwithstanding any copyright
  by two major components: (1) blocking [10] utilizes heuristics to                                                              notation hereon.
REFERENCES                                                                                      Conference on Language Resources and Evaluation (LREC 2018), 2018.
 [1] R. Al-Rfou, B. Perozzi, and D. Zelle. Ddgk: Learning graph representations for        [27] S. Mudgal, H. Li, T. Rekatsinas, A. Doan, Y. Park, G. Krishnan, R. Deep, E. Ar-
     deep divergence graph kernels. In The World Wide Web Conference, pages 37‚Äì48.              caute, and V. Raghavendra. Deep learning for entity matching: A design space
     ACM, 2019.                                                                                 exploration. In Proceedings of the 2018 International Conference on Management
 [2] I. Bhattacharya and L. Getoor. Collective entity resolution in relational data.            of Data, pages 19‚Äì34. ACM, 2018.
     ACM Transactions on Knowledge Discovery from Data (TKDD), 1(1):5, 2007.               [28] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Des-
 [3] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating           maison, L. Antiga, and A. Lerer. Automatic differentiation in PyTorch. In NIPS
     embeddings for modeling multi-relational data. In Advances in neural information           Autodiff Workshop, 2017.
     processing systems, pages 2787‚Äì2795, 2013.                                            [29] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of social repre-
 [4] Y. Cao, Z. Liu, C. Li, J. Li, and T.-S. Chua. Multi-channel graph neural network           sentations. In Proceedings of the 20th ACM SIGKDD international conference on
     for entity alignment. arXiv preprint arXiv:1908.09898, 2019.                               Knowledge discovery and data mining, pages 701‚Äì710. ACM, 2014.
 [5] Y. Cen, X. Zou, J. Zhang, H. Yang, J. Zhou, and J. Tang. Representation learning      [30] M. Pershina, M. Yakout, and K. Chakrabarti. Holistic entity matching across
     for attributed multiplex heterogeneous network. arXiv preprint arXiv:1905.01669,           knowledge graphs. In 2015 IEEE International Conference on Big Data (Big Data),
     2019.                                                                                      pages 1585‚Äì1590. IEEE, 2015.
 [6] S. Chang, W. Han, J. Tang, G.-J. Qi, C. C. Aggarwal, and T. S. Huang. Hetero-         [31] J. Pujara and L. Getoor. Generic statistical relational entity resolution in knowl-
     geneous network embedding via deep architectures. In Proceedings of the 21th               edge graphs. arXiv preprint arXiv:1607.00992, 2016.
     ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,           [32] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov, and M. Welling.
     pages 119‚Äì128. ACM, 2015.                                                                  Modeling relational data with graph convolutional networks. In European Se-
 [7] M. Chen, Y. Tian, K.-W. Chang, S. Skiena, and C. Zaniolo. Co-training embeddings           mantic Web Conference, pages 593‚Äì607. Springer, 2018.
     of knowledge graphs and entity descriptions for cross-lingual entity alignment.       [33] J. Shang, M. Qu, J. Liu, L. M. Kaplan, J. Han, and J. Peng. Meta-path guided em-
     arXiv preprint arXiv:1806.06478, 2018.                                                     bedding for similarity search in large-scale heterogeneous information networks.
 [8] M. Chen, Y. Tian, M. Yang, and C. Zaniolo. Multilingual knowledge graph                    arXiv preprint arXiv:1610.09769, 2016.
     embeddings for cross-lingual knowledge alignment. In Proceedings of the 26th          [34] P. Singla and P. Domingos. Entity resolution with markov logic. In Sixth Interna-
     International Joint Conference on Artificial Intelligence, pages 1511‚Äì1517. AAAI           tional Conference on Data Mining (ICDM‚Äô06), pages 572‚Äì582. IEEE, 2006.
     Press, 2017.                                                                          [35] R. Socher, D. Chen, C. D. Manning, and A. Ng. Reasoning with neural tensor
 [9] T. Chen and Y. Sun. Task-guided and path-augmented heterogeneous network                   networks for knowledge base completion. In Advances in neural information
     embedding for author identification. In Proceedings of the Tenth ACM International         processing systems, pages 926‚Äì934, 2013.
     Conference on Web Search and Data Mining, pages 295‚Äì304. ACM, 2017.                   [36] F. M. Suchanek, S. Abiteboul, and P. Senellart. Paris: Probabilistic alignment of
[10] X. Chu, I. F. Ilyas, and P. Koutris. Distributed data deduplication. Proceedings of        relations, instances, and schema. arXiv preprint arXiv:1111.7164, 2011.
     the VLDB Endowment, 9(11):864‚Äì875, 2016.                                              [37] Z. Sun, W. Hu, Q. Zhang, and Y. Qu. Bootstrapping entity alignment with
[11] X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann,               knowledge graph embedding. In IJCAI, pages 4396‚Äì4402, 2018.
     S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic          [38] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. Line: Large-scale infor-
     knowledge fusion. In Proceedings of the 20th ACM SIGKDD international conference           mation network embedding. In Proceedings of the 24th international conference
     on Knowledge discovery and data mining, pages 601‚Äì610. ACM, 2014.                          on world wide web, pages 1067‚Äì1077. International World Wide Web Conferences
[12] X. Dong, A. Halevy, and J. Madhavan. Reference reconciliation in complex infor-            Steering Committee, 2015.
     mation spaces. In Proceedings of the 2005 ACM SIGMOD international conference         [39] B. D. Trisedya, J. Qi, and R. Zhang. Entity alignment between knowledge graphs
     on Management of data, pages 85‚Äì96. ACM, 2005.                                             using attribute embeddings. In Proceedings of the AAAI Conference on Artificial
[13] Y. Dong, N. V. Chawla, and A. Swami. metapath2vec: Scalable representation                 Intelligence, volume 33, pages 297‚Äì304, 2019.
     learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD            [40] H. T. Trung, N. T. Toan, T. Van Vinh, H. T. Dat, D. C. Thang, N. Q. V. Hung, and
     international conference on knowledge discovery and data mining, pages 135‚Äì144.            A. Sattar. A comparative study on network alignment techniques. Expert Systems
     ACM, 2017.                                                                                 with Applications, 140:112883, 2020.
[14] M. Ebraheem, S. Thirumuruganathan, S. Joty, M. Ouzzani, and N. Tang. Deeper‚Äì          [41] P. Velivckoviƒá, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. Graph
     deep entity resolution. arXiv preprint arXiv:1710.00597, 2017.                             attention networks. arXiv preprint arXiv:1710.10903, 2017.
[15] T.-y. Fu, W.-C. Lee, and Z. Lei. Hin2vec: Explore meta-paths in heterogeneous         [42] H. Wang, F. Zhang, X. Xie, and M. Guo. Dkn: Deep knowledge-aware network
     information networks for representation learning. In Proceedings of the 2017               for news recommendation. In Proceedings of the 2018 World Wide Web Confer-
     ACM on Conference on Information and Knowledge Management, pages 1797‚Äì1806.                ence, pages 1835‚Äì1844. International World Wide Web Conferences Steering
     ACM, 2017.                                                                                 Committee, 2018.
[16] L. Getoor and A. Machanavajjhala. Entity resolution: theory, practice & open          [43] M. Wang, L. Yu, D. Zheng, Q. Gan, Y. Gai, Z. Ye, M. Li, J. Zhou, Q. Huang, C. Ma,
     challenges. Proceedings of the VLDB Endowment, 5(12):2018‚Äì2019, 2012.                      Z. Huang, Q. Guo, H. Zhang, H. Lin, J. Zhao, J. Li, A. J. Smola, and Z. Zhang.
[17] A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks.               Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR
     In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge                Workshop on Representation Learning on Graphs and Manifolds, 2019.
     discovery and data mining, pages 855‚Äì864. ACM, 2016.                                  [44] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, and P. S. Yu. Heterogeneous graph
[18] W. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large          attention network. In The World Wide Web Conference, WWW 2019, San Francisco,
     graphs. In Advances in Neural Information Processing Systems, pages 1024‚Äì1034,             CA, USA, May 13-17, 2019, pages 2022‚Äì2032, 2019.
     2017.                                                                                 [45] Z. Wang, Q. Lv, X. Lan, and Y. Zhang. Cross-lingual knowledge graph alignment
[19] D. Khashabi, T. Khot, A. Sabharwal, P. Clark, O. Etzioni, and D. Roth. Question            via graph convolutional networks. In Proceedings of the 2018 Conference on
     answering via integer programming over semi-structured knowledge. arXiv                    Empirical Methods in Natural Language Processing, pages 349‚Äì357, 2018.
     preprint arXiv:1604.06076, 2016.                                                      [46] K. Xu, L. Wang, M. Yu, Y. Feng, Y. Song, Z. Wang, and D. Yu. Cross-lingual
[20] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv                  knowledge graph alignment via graph matching neural network. arXiv preprint
     preprint arXiv:1412.6980, 2014.                                                            arXiv:1905.11605, 2019.
[21] T. N. Kipf and M. Welling. Semi-supervised classification with graph convolu-         [47] B. Yang, W.-t. Yih, X. He, J. Gao, and L. Deng. Embedding entities and relations
     tional networks. arXiv preprint arXiv:1609.02907, 2016.                                    for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575,
[22] P. Konda, S. Das, P. Suganthan GC, A. Doan, A. Ardalan, J. R. Ballard, H. Li,              2014.
     F. Panahi, H. Zhang, J. Naughton, et al. Magellan: Toward building entity matching    [48] C. Zhang, D. Song, C. Huang, A. Swami, and N. V. Chawla. Heterogeneous Graph
     management systems. Proceedings of the VLDB Endowment, 9(12):1197‚Äì1208,                    Neural Network. In Proceedings of the 25th ACM SIGKDD International Conference
     2016.                                                                                      on Knowledge Discovery & Data Mining - KDD ‚Äô19, pages 793‚Äì803. ACM Press,
[23] Y. Li, C. Gu, T. Dullien, O. Vinyals, and P. Kohli. Graph matching networks for            2019.
     learning the similarity of graph structured objects. In Proceedings of the 36th       [49] Q. Zhang, Z. Sun, W. Hu, M. Chen, L. Guo, and Y. Qu. Multi-view knowledge
     International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long              graph embedding for entity alignment. arXiv preprint arXiv:1906.02390, 2019.
     Beach, California, USA, pages 3835‚Äì3845, 2019.                                        [50] S. Zhang and H. Tong. Attributed network alignment: Problem definitions and
[24] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation embeddings        fast solutions. IEEE Transactions on Knowledge and Data Engineering, 2018.
     for knowledge graph completion. In Twenty-ninth AAAI conference on artificial         [51] H. Zhu, R. Xie, Z. Liu, and M. Sun. Iterative entity alignment via joint knowledge
     intelligence, 2015.                                                                        embeddings. In IJCAI, pages 4258‚Äì4264, 2017.
[25] C. Lockard, P. Shiralkar, and X. L. Dong. Openceres: When open information            [52] L. Zhu, M. Ghasemi-Gol, P. Szekely, A. Galstyan, and C. A. Knoblock. Unsu-
     extraction meets the semi-structured web. In Proceedings of the 2019 Conference            pervised entity resolution on multi-type graphs. In International semantic web
     of the North American Chapter of the Association for Computational Linguistics:            conference, pages 649‚Äì667. Springer, 2016.
     Human Language Technologies, Volume 1 (Long and Short Papers), pages 3047‚Äì3056,
     2019.
[26] T. Mikolov, E. Grave, P. Bojanowski, C. Puhrsch, and A. Joulin. Advances in
     pre-training distributed word representations. In Proceedings of the International
                                                      Journal of Network and Computer Applications 185 (2021) 103076


                                                                    Contents lists available at ScienceDirect


                                        Journal of Network and Computer Applications
                                                            journal homepage: www.elsevier.com/locate/jnca




Domain-specific knowledge graphs: A survey
Bilal Abu-Salih
King Abdullah II School of Information Technology, The University of Jordan, Jordan




A R T I C L E I N F O                                      A B S T R A C T

Keywords:                                                  Knowledge Graphs (KGs) have made a qualitative leap and effected a real revolution in knowledge represen¬≠
Knowledge graph                                            tation. This is leveraged by the underlying structure of the KG which underpins a better comprehension,
Domain-specific knowledge graph                            reasoning and interpretation of knowledge for both human and machine. Therefore, KGs continue to be used as
Knowledge graph construction
                                                           the main means of tackling a plethora of real-life problems in various domains. However, there is no consensus in
Knowledge graph embeddings
Knowledge graph evaluation
                                                           regard to a plausible and inclusive definition of a domain-specific KG. Further, in conjunction with several
Domain ontology                                            limitations and deficiencies, various domain-specific KG construction approaches are far from perfect. This
Survey                                                     survey is the first to offer a comprehensive definition of a domain-specific KG. Also, the paper presents a thor¬≠
                                                           ough review of the state-of-the-art approaches drawn from academic works relevant to seven domains of
                                                           knowledge. An examination of current approaches reveals a range of limitations and deficiencies. At the same
                                                           time, uncharted territories on the research map are highlighted to tackle extant issues in the literature and point
                                                           to directions for future research.




1. Introduction                                                                             knowledge (Kejriwal, 2019). However, this ongoing interest in
                                                                                            domain-specific KGs raises questions about their quality and robustness,
    KGs, one of the key trends which are driving the next wave of                           and whether adequate evaluation measures have been applied, partic¬≠
technologies (Bellomarini et al., 2020), have now become a new form of                      ularly to those KGs derived from data sources of inconsistent quality.
knowledge representation, and the cornerstone of several applications                       Also, the dynamic nature of domain knowledge is highly correlated to
ranging from generic to specific industrial usage cases (Hubauer et al.,                    contextual situations, and various facts that describe entities might
2018). The ever-increasing interest in this technology is due to its un¬≠                    change over time. Neglecting the dynamic nature of knowledge di¬≠
derlying abstract structure which effectively facilitates domain                            minishes the quality and correctness of facts represented by KGs, and
conceptualization and data management, and its usage as the main                            could lead to poor decision making that is based merely on such data
driver of several Artificial Intelligence applications. In particular, the KG               sources. Therefore, it is important that a comprehensive review be
depicts an integrated collection of real-world entities which are con¬≠                      conducted of the current state-of-the-art approaches for domain-specific
nected by semantically-interrelated relations. In this respect, data are                    KG construction so as to highlight such issues and address them with
given formal semantics via data annotation and manipulation in a                            viable solutions.
machine-readable format, thereby reducing ambiguity and deriving                                In this survey, we provide an inclusive definition to domain-specific
meaningful information that is specific to an application‚Äôs domain.                         KGs. Further, we discuss various notable KG construction approaches in
Therefore, the incorporation of KGs has extended the existing data                          seven domains of knowledge. These approaches are reviewed and a
models depicted by domain ontologies and established a new form of                          summary is provided for each domain showing how the KG in each case
data analytics that is able to capture semantically-interconnected,                         has been constructed, the resources used to construct the KG, whether
large-scale data sets.                                                                      any of the KG embedding techniques have been incorporated, the
    Beyond the generic and open-world KGs such as Google KG (Singhal,                       measures used to evaluate the KG construction approach, and the limi¬≠
2012), most of the current KGs are domain-specific, with certain un¬≠                        tations and shortcomings of each approach. This survey paper is
derlying ontologies in their design (Li et al., 2020a). Because of the lack                 different from other similar researches that tend to either focus on
of a ‚Äòone-size fits all‚Äô schema or ontology that can be applied to address                  generic and domain-independent KGs such as (Ji et al., 2020; Paulheim,
real-life problems, efforts to establish, polish, and augment                               2017; Wang et al., 2017a), or only briefly discuss domain-specific KGs
domain-specific KGs are continuing to be made in several domains of                         (Kejriwal, 2019; Zou, 2020). To the best of our knowledge, this is the


    E-mail address: b.abusalih@ju.edu.jo.

https://doi.org/10.1016/j.jnca.2021.103076
Received 27 November 2020; Received in revised form 15 March 2021; Accepted 5 April 2021
Available online 20 April 2021
1084-8045/¬© 2021 Elsevier Ltd. All rights reserved.
B. Abu-Salih                                                                                          Journal of Network and Computer Applications 185 (2021) 103076


first attempt to provide both an inclusive definition of a domain-specific
KG as well as a thorough analysis of various domain-based KG con¬≠
struction approaches. Further, this paper provides a summary of the
main issues derived from the conducted analysis. At the same time,
several improvements, recommendations, and opportunities are sug¬≠
gested to address these limitations which point to directions for future
research. The contributions of this paper are:

 ‚Ä¢ To the best of our knowledge, this is the first paper to provide an
   inclusive definition of a domain-specific KG and the first compre¬≠
   hensive survey of domain-specific KGs.
 ‚Ä¢ We conduct a thorough analysis of more than 140 papers on KG
   construction approaches, covering seven domains.
 ‚Ä¢ The review reveals the shortcomings of current approaches and
   proposes solutions to address them.                                                             Fig. 1. Number of studied papers per year.
 ‚Ä¢ The paper highlights research gaps in the area of domain-specific KG
   construction and suggests venues for future research.
                                                                                 since the invention of the Semantic Web, generic KGs have been asso¬≠
                                                                                 ciated with linked data, being natural representations of the interlinking
   The rest of this paper is organised as follows: Section 2 discusses the
                                                                                 of entities (Ehrlinger and WoÃà√ü, 2016). Nevertheless, the term has gained
methodology adopted in this study. Section 3 establishes the necessary
                                                                                 much momentum recently as it has given rise to new computing para¬≠
ground for this work by including important preliminaries and relevant
                                                                                 digms by shifting from traditional databases to knowledge databases
terminologies. Section 4 analyses the KG construction approaches in
                                                                                 (Menon et al., 2019). Ironically, there is no consensus on the definition
seven domains. Section 5 presents an in-depth discussion of the findings
                                                                                 of the term despite the few attempts to provide a reasonable description.
as well as the identified research gaps. Section 6 concludes the paper.
                                                                                 For example, Ehrlinger and WoÃà√ü (2016) perceive the KG as the process of
                                                                                 acquiring and correlating knowledge to an ontology and applying a
2. Methodology                                                                   reasoner to infer knowledge. A further technical depiction of the term is
                                                                                 provided by Wang et al. (2017a) who conceive the KG as a multidi¬≠
    As the first step, seven domains were chosen and the articles for            mensional graph comprising entities/nodes and relations/edges.
review were collected accordingly. The domains are: healthcare, edu¬≠                 A KG is commonly described as a directed graph (G), where G = (V,
cation, ICT, science and engineering, finance, society and politics, and         E). This notation depicts the relationship between vertices (V) of the
travel. Articles relevant to any of these domains were obtained by               graph and edges (E) between these vertices. The vertices represent the
searching recent volumes of both conference proceedings of relevant              set of real-world entities and the edges represent the relationships be¬≠
series (such as ACM SIGKDD, ACM WSC, WWW, ICWE, ISWC, etc.) and                  tween these entities. Vertices/entities/nodes are interconnected using
high-quality journals (such as Knowledge-based Systems, Expert Sys¬≠              relations which are the edges of the graph, and facts are commonly
tems with Applications, IEEE Access, Journal of Web Semantic, etc.).             represented as an RDF1 triple (subjects, predicate, object) or (head, rela¬≠
Furthermore, we used keywords such as ‚Äúknowledge graph for engi¬≠                 tion, tail), and denoted as < h, r, t >. Intuitively, two entities connected
neering‚Äù, ‚Äúknowledge graph for healthcare‚Äù, etc. to search for articles in       by a relation form a fact in the KG. For example, Fig. 2 gives an example
Google Scholar. Although the articles chosen for each domain intuitively         of a KG representation in terms of entities and relations.
depict the KG construction approaches to the domain of interest, it was              Several facts (triples) can be inferred from this KG. For example, the
noted that some papers were concerned with more than one high-level              facts ‚ÄúTim Berners-Lee has invented WWW‚Äù comprises two entities/nodes,
domain of knowledge. Those papers dealing with interrelated domains              namely ‚ÄúTim Berners-Lee‚Äù and ‚ÄúWWW‚Äù, and the relation ‚Äúhas invented‚Äù
are positioned under the domain umbrella that is explicitly indicated by         forms the triple ‚ÄúTim Berners-Lee, hasInvented, WWW‚Äù.
the papers‚Äô authors.                                                                 Examples of various steadily evolving open-world KGs include:
    We examined more than 140 research articles that appeared between            BabelNet,2 YAGO,3 Cyc,4 NELL,5 CliGraph6 and DBPedia7 knowledge
2016 and 2020 in high-quality computer science and information sys¬≠              base. In fact, several of these massive publicly-available data islands
tems publication venues. Fig. 1 indicates the number of papers collected         have been harvested from the Web as key sources of knowledge to
for the review. As seen in the figure, the interest in domain-specific KGs       benefit numerous Artificial Intelligence and smart systems (Wang et al.,
has increased dramatically over recent years.                                    2019a), such as recommender systems (Catherine and Cohen, 2016),
    Our study is different from other similar works. For example, the            decision support systems (DSSs) (Elnagar and Weistroffer, 2019), and
current important researches in this arena, such as (Ji et al., 2020;            intelligent QA systems (Yang et al., 2019a). Table 1 presents statistics for
Paulheim, 2017; Wang et al., 2017a), either focus on generic and                 popular generic KGs. The statistics include #instances, #facts, #types
domain-independent KGs, or only touch upon and do not discuss in                 (indicating the number of classes in the designated schema), and
depth domain-specific KGs (Kejriwal, 2019; Zou, 2020). To the best of            #relations.
our knowledge, this is the first attempt to provide both an inclusive
definition of the term ‚Äòdomain-specific KG‚Äô as well as a thorough analysis
                                                                                 3.2. Domain-specific knowledge graphs
of various domain-based KG construction approaches. Furthermore, the
review reveals the shortcomings of current approaches and proposes
                                                                                      Despite the extensive use of the generic and open-world KGs to tackle
solutions to address them.

3. Preliminaries                                                                  1
                                                                                      https://www.w3.org/TR/rdf11-concepts/.
                                                                                  2
                                                                                      https://babelnet.org/.
3.1. Generic knowledge graphs                                                     3
                                                                                      http://www.foaf-project.org/.
                                                                                  4
                                                                                      https://www.cyc.com/.
   Generic KGs (a.k.a. open-world, cross-domain, or domain-                       5
                                                                                      http://rtw.ml.cmu.edu/rtw/kbbrowser/.
independent) were constructed long before the term ‚Äúknowledge                     6
                                                                                      http://caligraph.org/ontology/Scientist.
graph‚Äù was coined, and such constructions have been ongoing. In fact,             7
                                                                                      https://wiki.dbpedia.org/.

                                                                             2
B. Abu-Salih                                                                                              Journal of Network and Computer Applications 185 (2021) 103076




                                                        Fig. 2. An example of entities and relations in a KG.


                                                                                      3.3. Knowledge graph construction
Table 1
Statistics for some of the open world KGs (Heist et al., 2020).
                                                                                          KG was introduced as an efficient and smart approach to tackle the
                Instances/entities   Facts           Types/classes   Relations        continuous propagation of various forms of unstructured text (e.g. Web
  DBpedia       5,044,223            400             760             1355             data) and other structured or semi-structured sources (Ji et al., 2020).
  YAGO          6,349,359            479,392,870     819,292         77               The construction of a KG can be perceived as a paradigm which com¬≠
  Wikidata      52,252,549           732,420,508     2,356,259       6236
                                                                                      prises different perspectives. We have examined the literature on KG
  BabelNet      7,735,436            178,982,397     6,044,564       22
  Cyc           122,441              2,229,266       116,821         148              construction approaches and we design a taxonomy to highlight the key
  NELL          5,120,688            60,594,443      1187            440              aspects of KG construction. Fig. 3 illustrates the taxonomy for KG con¬≠
  CaLiGraph     7,315,918            517,099,124     755,963         271              struction which is mainly categorised based on the level of knowledge
  Voldemort     55,861               693,428         621             294              extraction, the type of knowledge base, and the incorporated construc¬≠
                                                                                      tion method.
a wide variety of domain-independent tasks, constructing KGs from                         In terms of knowledge extraction, KG construction is the process of
domain corpora to address domain-specific problems is greatly impor¬≠                  extracting entities and relationships between these entities. Entity
tant (Kejriwal et al., 2019). This is because domain-specific KGs have                extraction comprises three key tasks (Al-Moslmi et al., 2020), namely: i)
relevant and semantically interlinked applications with domain-specific               Named Entity Recognition (NER) which involves the process of finding
problems. Moreover, domain-specific KGs also lack a well-established,                 individuals, organisation, locations, events, and other entities from (un)
consensual and comprehensive definition, which is not surprising                      (semi-)structured data sources; ii) Named Entity Disambiguation (NED)
given that this is still a comparatively new territory and an                         which aims to eliminate the ambiguity of an inferred entity by mapping
under-explored frontier (Shen et al., 2019). Nevertheless, some studies               it to the factual real-world entity; and iii) Named Entity Linking (NEL)
perceive the domain-specific KG as a special type of KG that is used to               which assigns a unique IRI identified to the disambiguated entity. The
represent a specific and complex domain (Li et al., 2020a; Yuan et al.,               purpose of relation extraction is to discover the semantic relationships
2020; Fan et al., 2017). Others reported that domain-specific KGs are the             between the identified and disambiguated entities. Relation extraction
result of the process of enriching an underlying domain ontology (Kej¬≠                can be done by either local-based or global-based relation extraction
riwal, 2019). This inability to provide an inclusive definition to the                methods. The former indicates the mention-level relation which is
domain-specific KG has driven us to frame the following definition of                 commonly inferred form short textual contents, and the latter aims to
this term:                                                                            infer those relations that span several local-based relations. The reader
                                                                                      can obtain further details on these tasks in relevant literature such as
    ‚ÄúDomain Knowledge Graph is an explicit conceptualisation to a high-               (Kim et al., 2020; Smirnova and CudreÃÅ-Mauroux, 2018).
    level subject-matter domain and its specific subdomains represented                   Another perspective conceives that the KG construction depends on
    in terms of semantically interrelated entities and relations‚Äù.                    whether a predefined ontology schema is used (schema-based), or the
                                                                                      KG is constructed with no predefined schema (schema-free) (Nickel
    This comprehensive definition addresses three core aspects, namely:
                                                                                      et al., 2015), or if the construction comprises a hybrid of schema-based
(i) formal conceptualization: which indicates the logical design of the
                                                                                      and schema-free approaches. The first methodology (schema-based) can
KG depicted by a specific and predefined domain ontology established to
                                                                                      be categorised according to two groups based on the selection of data
capture the domain of interest either in its generic (high-level) sense or
                                                                                      sources and ontology (Dong et al., 2014; Heist, 2018) namely: (i) the
in its specific subdomains; (ii) subject-matter domain: this frames the
                                                                                      bottom-up method whereby the structural nature of an ontology is
domain-specific KG to be firmly contextualised to address a particular
                                                                                      incorporated to build the KG (e.g. Wikipedia is established by using the
subject-matter knowledge; and (iii) semantically interrelated entities
                                                                                      predefined ontology model, i.e. DBpedia (Kuhn et al., 2016)); and (ii)
and relations, which indicate the physical design of the domain-specific
                                                                                      the top-down method where the ontology schema is inferred from the
KG depicted as a labelled graph in which the semantics of data is
                                                                                      underlying structured data (e.g. YAGO) (Suchanek et al., 2007)) or build
enriched with a specific conceptual representation of entities and re¬≠
                                                                                      taxonomies (hierarchy) are constructed based on information from the
lationships between these entities.
                                                                                      Web (Wu et al., 2012). Schema-free approaches are open information
                                                                                      extraction techniques which rely on the openness of the Web; hence, the
                                                                                      information is collected using various knowledge extraction techniques
                                                                                      with no consideration given to creating a unified ontology design (e.g.

                                                                                  3
B. Abu-Salih                                                                                            Journal of Network and Computer Applications 185 (2021) 103076




                                                           Fig. 3. A taxonomy for KG construction.


OpenIE (Fader et al., 2011)). Hybrid knowledge-based approaches: are                3.4. Knowledge graph embedding
the techniques whereby the knowledge is obtained based on a pre¬≠
determined ontology, as well as facts gathered from the Web (e.g.                       KG Embedding (KGE) is the process of creating propositional feature
KnowledgeVault (Dong et al., 2014), NELL (Carlson et al., 2010)).                   vector representations of the constituents of a KG (entities and re¬≠
    The third thread of research sees the KG construction as being based            lationships) (Wang et al., 2017a) so as to apply numeric techniques that
on the technical solutions and methods used to mine the Web and other               produce scalable and effective results (Bonatti et al., 2019). KGE tech¬≠
data silos and repositories to deduce entities and relations, thereby               niques can simplify the resolution of various complex real-life graph
constructing the KG. Various approaches were proposed in the literature             problems for which conventional graph presentation (i.e., adjacency
to address this issue. These fall under four key categories (Ji et al., 2020;       matrix) is inadequate and inferior. Hence, currently, KGE is being used
Al-Moslmi et al., 2020; Smirnova and CudreÃÅ-Mauroux, 2018): (1)                     extensively to tackle problems such as KG completion, entity recogni¬≠
Knowledge-based approaches: these methods mainly involve domain                     tion, and link-based clustering (Nickel et al., 2015; Kipf and Welling,
experts to establish human-crafted rules (Association Rules) by incor¬≠              2016; Wang et al., 2017b).
porating domain-knowledge and lexicon resources. (2) Learning-based                     The core idea underlying KGE is to create a vector for each entity and
methods: these methods encompass (un)(semi-)supervised techniques.                  each relation in the KG, then define a set of score functions that are used
Examples of these methods that are employed for entities recognition                to measure the space distance of two entities relative to the type of the
and relations extraction are Conditional Random Field (CRF), Hidden                 relation in the low-dimensional embedding vector space. The aim is to
Markov Models (HMM), Support Victor Machine (SVM), Na√Øve Bayes                      capture latent properties of the semantics in the KG so that like entities
(NB), Logistic Regression (LR), and Decision Trees, and bootstrapped                and like relations will be represented with similar vectors, and those not
methods. (3) Neural network models: these methods incorporate neural                semantically connected are detached. The embedding of a KG is learned
networks and deep learning to infer features. These methods require                 via training a neural architecture over a KG, and usually includes three
neither domain ontologies nor domain-specific corpora, thereby making               main steps (Bianchi et al., 2020), namely: (i) encoding entities into
them suitable for domain-independent KGs. Examples of these methods                 dispersed points in the semantic space, and encoding relations as vec¬≠
Convolutional Neural Network (CNN), Recurrent Neural Network                        tors; (ii) scoring function or model-specific function that is used to
(RNN), Bidirectional Long Short-Term Memory (BiLSTM). (4)                           assemble the information combing from a triple; and (iii) applying an
Off-the-shelf NLP tools: those are commonly commercial/open source                  optimization procedure represented by the loss function in which the
ready-to-use tools which might embed one or more of the aforemen¬≠                   objective is defined and minimised during the KG embedding process.
tioned approaches to analyse textual content and extract entities and               Table 2 shows the most popular of the many models which are
relations. Examples of these tools are spaCy,8 Stanford CoreNLP,9                   commonly used for KG embeddings.
AllenNLP 10, and IBM Watson NLU.11

                                                                                    3.5. Knowledge graph evaluation

                                                                                        The proliferation of massive KGs poses a question regarding the
                                                                                    quality of the embedded knowledge (i.e., entities and relations), and
 8
     https://spacy.io/.                                                             whether these facts precisely convey the intended real-world concepts
 9
     http://corenlp.run/.                                                           interlinked via their relationships. Therefore, ascertaining the
10
     https://allennlp.org/.                                                         completeness and correctness of the constructed KG is crucial to deter¬≠
11
     https://www.ibm.com/cloud/watson-natural-language-understanding.               mine its ‚Äúfitness of purposes‚Äù (Chen et al., 2019a) for various

                                                                                4
B. Abu-Salih                                                                                                                  Journal of Network and Computer Applications 185 (2021) 103076


Table 2
Examples of well-known KG embedding models.
  Model                        Description                                                                                                                      Scoring Function
                                                                                                                                                                             ‚Éí‚Éí             ‚Éí
  TransE (Bordes et al.,       learns the representation of both the entities and relations as vectors in the same low dimensional semantic space.              f TransE = ‚àí ‚Éí‚Éíeh + er ‚àí et ‚Éí|n
    2013)                      Hence, for a golden triple (h,r,t), TransE treats the relation r as a translation in the embedding space so that h + r ‚âà t ,
                               when (h, r, t) holds (t should be the closest to h + r), otherwise h + r should be away in distance from t.
  DistMult (Yang et al.,       is an extension and a simplification to RESCAL (Nickel et al., 2011) and is based on the bilinear model. In this model,          f DistMult = rŒ§ (h ‚äôt)
    2014)                      the relation is encoded as diagonal (single vector) using the trilinear dot product.
  ComplEx (Trouillon           this is an extension to DistMult model by introducing complex-valued embeddings, where the scoring function is based             f ComplEx = Re(er , eh , et )
    et al., 2016)              on the trilinear Hermitian dot product in C.
  HolE (Nickel et al.,         a compositional vector space model that learns compositional vector space representations of entities and relations              f HolE = wr ‚ãÖ(eh ‚äó et ) =
   2016)                       through incorporating the strength of RESCAL as well as the simplicity of DistMult.                                              1
                                                                                                                                                                   F(wr )‚ãÖ(F(eh ) ‚äôF(et ))
                                                                                                                                                                k
  ConvE (Dettmers et al.,      is a neural link prediction model that uses deep, multi-layer, conventional and fully connected layers of nonlinear              f ConvE =
    2018)                      features to tackle the interactions between input entities and relations.                                                         ‚å©œÉ(vec(g([eh ; er ] *Œ©))W))et ‚å™
  ConvKB (Nguyen et al.,       incorporates conventional neural networks to represent the concatenation of entities and relations, which increases the          f ConvKB = concat(g([eh , er ,
    2017)                      learning ability of latent features.                                                                                             et ] *Œ©))‚ãÖW



downstream applications, and to deal with the uncertainty in the data                                and Engineering, Finance, Society and Politics, and Travel. Appendix A
quality (Gao et al.).                                                                                includes seven tables, each with a summary of the literature for each
   In a domain-specific KG, the absence of a complete and accurate KG                                designated domain. These tables demonstrate the specific KG usage, KG
poses a challenge to the evaluation process. This is because collecting all                          construction algorithm(s), the resources used to feed the KG, whether
true facts about a certain domain of interest is not a trivial task (if not                          KG embedding techniques were incorporated, the evaluation approach,
impossible). Therefore, various attempts, commonly known as KG                                       and the limitations of each designated work.
Augmentation/Completion techniques, have been undertaken to
augment the KG with new facts presented by new potential entities and/                               4.1. Healthcare
or new relations. To ensure data quality, these efforts are subject to
correctness and completeness evaluation measures. In particular, ac¬≠                                     Recently, the Healthcare sector has gained much attention, particu¬≠
cording to the new and known true facts, the evaluation can be carried                               larly with coronavirus 2019 (COVID-19) pandemic continues to rattle
out by using classification accuracy and ranking metrics such as Hits@N                              the world. Therefore, there is a notable consensus in both industry and
and Mean Reciprocal Rank (MRR), Accuracy, Precision, Recall, and F-                                  academia to consolidate efforts to overcome the challenges of this vital
score (Kejriwal, 2019; Pezeshkpour et al., 2020). These metrics are                                  sector (Cui et al., 2020). KGs offer the healthcare sector technical means
amongst various other measures that are currently being incorporated to                              to derive meaningful insights from voluminous and heterogeneous
evaluate the KG construction and completion in terms of the factuality of                            healthcare data (Zhang et al., 2020a; Malik et al., 2020). The examined
the embedded entities as well as their relations. Table 3 lists some of the                          papers in Healthcare domain can be categorised into the following
well-known evaluation metrics.                                                                       subdomains.
   Evaluations of KG constructions have also been carried out by means
of case studies and domain experts (Zaveri et al., 2016; Mohammad¬≠                                   4.1.1. Generic healthcare
hassanzadeh et al., 2018).                                                                               Health data mining by means of a KG approach was followed in the
                                                                                                     literature. Gatta et al. (2017) presented a library in R that was developed
4. Domain-specific KGs                                                                               for process mining in the medical domain. The library is designed to
                                                                                                     encode the extracted processes in the form of directed graphs, which can
    This section reviews various domain-based KGs that were discussed                                be then interpreted and visualised by domain experts. Another impor¬≠
in the literature. These domains are Healthcare, Education, ICT, Science                             tant effort that integrated plausible reasoning with fine-grained

Table 3
Examples of well-known KG Evaluation metrics.
  Metric                 Description                                                     Formal definition
                                                                                                                               ‚é´
  Hits@N                 indicates the number of elements in the ranking vector                ‚éß |Q|                                where rank(s, p, o)i refers to the rank of a positive element
                                                                                               ‚é®‚àë                              ‚é™
                                                                                                                               ‚é¨
                         retrieved from the model is positioned in the top (N)                        1, if rank(s, p, o)i ‚â§ N      i against a list of negative elements, T is a set of test triples
                                                                                         Hits@N
                         locations.                                                            ‚é© i=1                           ‚é™
                                                                                                                               ‚é≠    and (s, p, o) is a triple ‚àà T.
                                                                                                 0, otherwise
  MRR                    is a function that computes the mean of the reciprocal of               1 ‚àë
                                                                                                     |Q|
                                                                                                               1
                         elements embodied in a vector of rankings. It is used as a      MRR =                          ,
                                                                                                |T| i=1 rank(s, p, o)i
                         measure to evaluate the system performance against the
                         retrieved elements.
  MR                     refers to the mean rank of the correct test facts/triples                1 ‚àë
                                                                                                      |Q|

                         embodied in a vector of rankings (i.e., the average of the      MR =
                                                                                                 |T| i=1
                                                                                                          rank(s, p, o)i
                         predicted ranks).
  Accuracy               specifies the accuracy of the incorporated embedding                              TP + TN                  True-Positives (TP): refer to the true facts that are
                                                                                         Accuracy =
                         model in making a correct prediction. Accuracy is the ratio                   FN + TP + FP + TN            classified by the model as true statements. False-Positives
                         obtained between the accurate predictions (i.e., TP + TN)                                                  (FP): refer to the false facts that are classified incorrectly
                         and the overall inferred predictions (FN + TP + FP + TN).                                                  as true statements. True-Negatives (TN): refer to the false
  Precision              refers to the proportion of those facts that were classified                  TP                           facts that are classified correctly as false statements.
                         accurately as positive and they are actually positive.
                                                                                         Precision =
                                                                                                     TP + FP                        False-Negatives (FN): refer to the true facts that are
  Recall                 recall indicates the proportion of true positive facts were                 TP                             classified incorrectly as false statements.
                                                                                         Recall =
                         correctly classified as positives facts.                                 TP + FN
  F- measure             (a.k.a. f-measure/f-score) is a harmonic measure used to                     Precision‚ãÖRecall
                                                                                         F ‚àí score =
                         provide a trade-off between precision and recall                            Precision + Recall




                                                                                                 5
B. Abu-Salih                                                                                          Journal of Network and Computer Applications 185 (2021) 103076


biomedical ontologies to tackle data incompleteness problem in generic            direction, an inclusive healthy diet KG was also constructed by Chi et al.
health data was undertaken by Mohammadhassanzadeh et al. (2018).                  (2018a). The reported KG integrated five key concepts that included
The authors proposed Semantics-based Data analytics (SeDan) frame¬≠                food material, dish, nutritional element, symptom, and the crowd.
work that performs an exploratory and plausible analysis of the KG using          Through semi-automatically extraction approach, the proposed model
plausible OWL extension and query rewriting algorithm. The framework              was capable to collect and import entities captured from a set of online
incorporates various knowledge bases including the DrugBank, Disease              resources using various NLP and machine learning algorithms. Modeling
Ontology, and the large-scale semantic MEDLINE database (Sem¬≠                     food domain-specific KGs were also implemented in Yu et al. (2020);
MedDB). Rastogi et al. (Rastogi and Zaki, 2020) framed the personal               Zeng and Nakano (2020); Salehian et al. (2019). Further, tackling
health KG as a combination of context, personalization, and integration           challenges in healthcare systems leveraging KGs technologies was dis¬≠
with other knowledge-bases. Their study indicated that the literature on          cussed in Wang et al. (2020a); Tao et al. (2020a); Goodwin and Har¬≠
personalized health-related KGs is inadequate and lacks a unified stan¬≠           abagiu (2017).
dard representation to depict the designated domain. Incorporating
health KGs for Query Answering (QA) system was discussed by Sahu                  4.2. Education
et al. (2018). The authors offered a system that can be used to search for
various health-based KGs to obtain a set of healthcare-related response               The construction and usage of educational KGs have been extended
sub-graphs. Incorporating KG in the medical domain to benefit QA ap¬≠              recently due to the significance of KGs application to the learning sys¬≠
plications was also discussed in Sheng et al. (2020).                             tems as well as the abundance of pedagogical data (Shi et al., 2020). The
                                                                                  following subdomains are inferred from the collected education-related
4.1.2. Diseases                                                                   papers.
    The advances of constructing KGs to conceptualise health-related
problems and diseases were discussed in the literature. Rotmensch                 4.2.1. Teaching and classroom resources
et al. (2017) constructed a KG that captures diseases and symptoms                    KGs have proven ability to foster learning (Cui and Yu, 2019) and
related entities form 273,174 electronic medical records. The authors             been used in popular massive open online course (MOOC) platforms
incorporate Google Health Knowledge Graph (GHKG) and created a KG                 (Chen et al., 2018a; Zheng et al., 2017). For example, Chen et al. (2018b)
that embodies diseases and symptoms and relationships between them.               presented K12EduKG, a KG constructed based on K-12 educational
Constructing KGs that can describe depression was provided by Huang               subjects. Domain-specific educational data (Chinese curriculum standards
et al. (2017a). In particular, they attempted to generate a sub-graph, that       of mathematics) was the source of knowledge that was used in
describes depression disorder, obtained by parsing a variety of large             K12EduKG. Concepts and relations are identified and imported into
knowledge sources such as PubMed, Medical Guidelines, DrugBank,                   K12EduKG using CRF model and probabilistic association rule mining.
Unified Medical Language System (UMLS) etc. Evaluating the robustness             Su and Zhang (2020) designed a KG schema that can accommodate
of a constructed KG in healthcare is of utmost significance to ensure the         educational Big data. Their KG was enriched by using two large datasets,
quality of the inferred knowledge in this sensitive domain. In this               namely subject teaching resources and an online encyclopedia resource.
context, Chen et al. (2020a) presented a methodology to measure and               Another attempt has been undertaken to build a KG (MathGraph) that
evaluate the robustness of knowledge in terms of diseases and symptoms            can be used to solve high school mathematical exercises including
captured from existing health knowledge graphs as well as records of              mathematical derivation and calculation (Zhao et al., 2019). The au¬≠
patient visits to the Beth Israel Deaconess Medical Center (BIDMC).               thors of Zhao et al. (2019) used MathGraph, that was initially con¬≠
Addressing the temporal dimension in KG creation is an important                  structed with the help of crowdsource, to embody dissimilar
dimension in healthcare. Ma et al. (2019) established a temporal KG that          mathematical objects, operations and constraints. KnowEdu (Chen et al.,
can be used for cognitive episodic memory. This temporal KG was                   2018a) is one of the important efforts in educational KG design and
initially derived from the Integrated Conflict Early Warning System               construction. By using standard curriculum and learning assessment
(ICEWS) dataset as well as Global Database of Events, Language and                data as data sources, and by using neural network models for concepts
Tone (GDELT). Their work was different from other seminal works by                and relations identification, KnowEdu is created to facilitate learner‚Äôs
generalizing four significant static KGs embedding to 4-dimensional               cognitive and educational process.
temporal/episodic KGs. Also, two novel generalizations of RESCAL
were proposed and discussed. Application of KGs in healthcare and                 4.2.2. Education management
medical domains was demonstrated in other relevant tasks such as                      Aliyu et al. (2020) presented an approach for implementing a KG to
fraud, waste, and abuse Detection (Sun et al., 2020), drugs similarity            be used for course allocation scheduling and management. Although the
(Shen et al., 2019), drug repurposing (Zhu et al., 2020), clinical decision       evaluation of the constructed KG was inadequate, the work is promising
support systems (Li et al., 2020b), and medical recommender systems               toward this important research direction. Liu et al. (2016) and Lian et al.
(Sadeghi and Lehmann, 2019; Lin et al., 2020).                                    (Liang et al., 2018) provided approaches that adopted graph-based
                                                                                  relational learning for concept prerequisite learning in education
4.1.3. Healthcare management                                                      domain. The former introduced an automatic technique for prerequisites
    Constructing a KG to benefit health management and to address                 prediction by inferring directed graph at the course and concept levels.
current health-related problems and chronic diseases were proposed in             The latter incorporated active learning to the concept prerequisite
the literature (Huang et al., 2019; Haussmann et al., 2019; Chi et al.,           learning problem. Modelling internal control in higher education using
2018a; Zhang et al., 2019a). For example, Huang et al. (2019) suggested           KG technology was discussed in Wang (2020). The author proposed a KG
a KG construction model that benefits people seeking knowledge                    that can conceptualise the internal control policy in the higher educa¬≠
regarding a healthy diet. The authors proposed a domain ontology as an            tional institutions. Despite the author‚Äôs attempt to demonstrate the
underlying structure of a diet KG. The KG was then enriched with en¬≠              utility in a visualisation task, the overall mechanism to construct and
tities extracted from a set of healthcare websites using Conditional              evaluate the designated KG is inadequate and inferior. Applying KGs to
Random Fields (CRF), Support Vector Machine (SVM) and Decision Tree               benefit education management was also outlined in Zhang and Zhang
(DT) algorithms. Another effort was carried out by Haussmann et al.               (2020).
(2019) who proposed an integrated KG (FoodKG) that embodies
knowledge on healthy food, recipes, and nutrition. The authors ensured            4.2.3. Educational technologies
the credibility of the obtained knowledge by adopting RDF Nano¬≠                       Designing a KG that can be used to depict academic networks was
publication specification (Groth et al., 2010). On the same research              discussed in Chi et al. (2018b). The authors proposed a model of

                                                                              6
B. Abu-Salih                                                                                          Journal of Network and Computer Applications 185 (2021) 103076


scientific publication management that can integrate scientific metadata          scenarios. Fu et al. (2019) made use of IT crowdsourcing services to
in terms of academic entities. The model embodies a KG which conveys              construct a KG (ITServiceKG) to improve existing IT services IR system.
the relationship between research entities and research topics. Incor¬≠            The authors implemented a learning-to-rank model (Gradient Decision
porating KG embedding techniques in the process of constructing the               Tree) that was leveraged to re-rank the obtained results, thereby
educational KGs is inadequate, particularly those leverage the rich lit¬≠          attaining much relative search results. Constructing KGs to improve
erals of the designated KGs, thus Yao et al. (2020) attempted to tackle           software engineering practices and internal processes were also
this issue by reporting on a model for embedding learning of educational          addressed in Wang et al. (2019b); Xiao et al. (2019); Zhang et al.
KGs. With the use of three experimental KGs in the education domain,              (2020b); Xie et al. (2019).
the authors demonstrated the significance of the proposed model when
processing educational KGs. In particular, authors of Yao et al. (2020)           4.3.3. Telecommunication
presented a method that can jointly learn embeddings built on                         Defining and conceptualizing the structure of telecommunication
pre-trained structural (i.e. TransE) and literal embedding vectors (i.e.          networks can be explicitly delivered through incorporating KGs.
BERT). Evaluating the utility of the educational KG by means of visu¬≠             Aumayr et al. (2019) benefited from the unique structure of KG to build
alisation analysis was rarely discussed in the literature. An attempt in          a graph that can be used to solving issues that confront telecom opera¬≠
this direction was undertaken by Sun et al. (2016) who integrated an              tors. The authors populated the KG with entities captured form com¬≠
education KG and demonstrated its utility by carrying out visual analysis         munity knowledge in forms of telecom and products documentations,
so as to provide a better understanding to its topological structure.             online sites, engineering reports, etc. The aim was to build an automated
                                                                                  system to improve network incident management processes and to
4.3. ICT                                                                          provide better customer service. Krinkin et al. (2020) proposed a tele¬≠
                                                                                  communication network monitoring model by means of incorporating a
    KGs have been widely used to improve several subdomains related to            domain-specific KG at the top of the telecommunications service domain
Information and Communication Technology as follows:                              ontology. In particular, the authors encompass an array of components
                                                                                  that are integrated into monitoring cable television operator networks.
4.3.1. Cybersecurity                                                              These components are: the billing model, user access rights, network
    Detecting and preventing cyberattack is inevitable to ensure                  topology and application hierarchy, and the cable television operator
providing continuous and uninterrupted services. Interestingly, various           network service model.
cybersecurity-related KGs have been introduced and developed. For
example (Jia et al., 2018), presented a practical approach for cyberse¬≠           4.3.4. Internet of things (IoT)
curity. They first developed a domain ontology that put forward a                    In IoT integrating heterogeneous access of electronic devices poses a
technique to construct the cybersecurity KG. Then they proposed a                 momentous challenge. Hence, the underlying structure of the KG offers a
quintuple model that was used to obtain new knowledge using the                   promising solution to bridge the gap between IoT devices. For example,
path-ranking algorithm. Deng et al. (2019a) discussed another                     Xie et al. (2020) proposed an IoT KG that was used in a new layer to map
cybersecurity-related KG that was constructed to serve students who               IoT devices, thereby unifying the communications of all devices. Many
seek concepts in this domain. Despite the Adhoc mechanism to construct            studies further elaborated on KGs and their advantages to the IoT
their KG and the absence of a benchmark comparison for utility evalu¬≠             ecosystem (Le-Phuoc et al., 2016; Zhang et al., 2016; Chen et al., 2019b).
ation, the line of research is important per se; providing KGs that facil¬≠
itate personalized learning and benefit education is highly                       4.4. Sciences and engineering
recommended (Meissner and KoÃàbis, 2020). Kiesling et al. (2019) fol¬≠
lowed a bottom-up approach to build their cybersecurity KG using Na¬≠                 Applying semantic web technologies and ontologies in natural sci¬≠
tional U.S. Vulnerability Database (NVD) and set of security online               ences has proven successful leveraging the formal knowledge repre¬≠
references. The authors demonstrated the effectiveness of the developed           sentation and the semantic web languages that can model rich and
KG by means of two case studies in vulnerability assessment and                   complex knowledge of natural sciences (Hastings et al., 2012; Taylor
intrusion detection systems. Cybersecurity KGs were also reported in              et al., 2006; Collins and Clark, 2014; Dupre, 2014; Raskin and Pan,
Pingle et al. (2019); Tao et al. (2020b); Hooi et al. (2019).                     2005). Examples of subdomains that benefited from the KG technology
                                                                                  are reviewed as follows:
4.3.2. Software development
    Software development is a sophisticated process that encompasses an           4.4.1. Chemistry
array of challenges and decisions to be made in a timely manner                       The utility of semantic analytics has been validated in providing a
(Abu-Salih et al., 2021a). Hence, the software engineering domain has             formal representation to chemical data, thereby increasing the sharing
also benefited from the propagational use of domain-specific KGs due to           and interoperability of such data (Farazi et al., 2020a). Incorporating KG
their efficacy to store and manage relevant entities and relations of high        has extended these endeavours and provided a platform where infor¬≠
complexity. For example, Nayak et al. (2020) developed a KG that was              mation can be integrated from multiple chemical kinetic systems, and
used to extract test cases that would assist in the functional requirements       offered an automatic method to comprehend chemical mechanisms to
gathering process. As a backbone schema, the authors designed an                  perform complex chemical-related semantic queries (Farazi et al.,
ontology for software testing and applied a series of NLP tools including         2020b). For example (Farazi et al., 2020c), proposed an integrated
Constituency Parse Tree (CPT) to mine and populate the KG with test               system that used KG to demonstrate interoperability in cross-domain
cases. Schindler et al. (2020) introduced a KG (SoftwareKG) that em¬≠              applications that compass combustion as well as to address the prob¬≠
bodies information pertaining to the software mentioned in academic               lem of data inconsistencies in chemical reaction mechanisms. Krdzavac
articles of social science. SotwareKG depicts various aspects of the              et al. (2019) designed a domain ontology (OntoCompChem) as an un¬≠
software including its availability, source and links with other knowl¬≠           derlying structure of a KG that was used to demonstrate quantum
edge repositories. Designing a framework to industrial software design            chemistry calculations.
and development processes was proposed by Li et al. (2019). The au¬≠
thors applied a knowledge-driven QA system for parameters searching               4.4.2. Biology
and can be also used for carrying out variable calculation and ontology              The continuous propagation of the throughput data in molecular
reasoning. The proposed model integrated the constructed KG with an               biology has necessitated the introduction of formal representation of this
SQL database and efficiency is demonstrated in certain industrial                 knowledge domain. For example, Humayun et al. (2020) developed a

                                                                              7
B. Abu-Salih                                                                                           Journal of Network and Computer Applications 185 (2021) 103076


mechanistic KG to depict the heme‚Äôs interactome, an important factor of           heterogeneous knowledge base that contains power transmission and
diverse biological processes. Choi et al. (Choi and Lee, 2019) carried out        transformation assets. Engineering is a wide spectrum of domains that
benchmark comparison amongst a selection of KG embedding models in                have found KGs advantageous in several important applications. This is
a relational discovery task. Prior to the implementation of the incor¬≠            evident in various other engineering fields such as, nuclear engineering
porated KG embeddings, the authors constructed a domain-specific KG               (Zhao and Smidts, 2019), marine engineering (Fujun et al., 2017),
that was populated with entities and relations captured from heteroge¬≠            Photonics engineering (Li et al., 2020d), Nanotechnology Engineering
neous public data sources. These bio-related data sources are PubMed              (Erkimbaev et al., 2019), Ceramics engineering (Gao et al., 2019), and
database,12 Comparative Toxicogenomics database (CTD),13 The Bio¬≠                 Geomatics engineering (Jiang et al., 2019).
logical General Repository For Interaction datasets(BioGRID),14 and the
human disease database: (MalaCards).15                                            4.5. Finance

4.4.3. Geology                                                                        The finance sector is a pillar of any successful business. It is the driver
    Incorporating KGs on geological data has proven effectiveness and             for businesses to take opportunities and make revenue. Accordingly,
enhanced the interconnectivity between such data sets. Zhu et al. (2017)          researchers commonly draw great attention to this domain by discov¬≠
showcased the use of KG in an intelligent system for deep mining of               ering new venues for continuous improvements. Intuitively, KGs, as
geological data. The authors constructed the KG using Baike.com and               being a powerful tool for various applications, have been constructed to
local geological documents. Constructing a KG from geoscience docu¬≠               enrich several subdomains of Finance (TONG et al., 2016). The
ments was discussed in Wang et al. (2018a). The authors made use of an            following discussion sheds the light on recent works pertaining to two
integrated corpus composed of a geology dictionary and the Terminol¬≠              important subdomains of Finance, namely financial investments and
ogies and Classification Codes of Geology and Mineral Resources (TCCGMR)          fraud detection.
(Xinqing et al., 1999) to enrich the KG incorporating CRF-base geolog¬≠
ical word segmentation model. The utilization of KG to conceptualise              4.5.1. Financial investments
geosciences were further detailed in (ZHANG et al., 2020; Bucher et al.,              Liu et al. (2019a) leverage a domain-specific KG to carry out stock
2020; Fan et al., 2020a).                                                         market forecasting on the renowned companies. Their work also
                                                                                  comprised a deep learning approach and proven effectiveness when
4.4.4. Engineering                                                                integrated with the constructed KG on the prediction task. Another
    More advanced technical solutions have been also importing KGs to             attempt was commenced by Fu et al. (2018). The authors introduced a
build sophisticated systems in various fields of engineering (Fan et al.,         stochastic optimization algorithm, genetic programming, and general¬≠
2019). For example, Myklebust et al. (2019) demonstrated the impli¬≠               ised crowding which are all integrated into a model for market return
cation of using a domain-specific KG and KG embeddings to improve the             prediction using financial KG. Cheng et al. (2020) proposed KG-based
ecotoxicological effect prediction in the Norwegian Institute for Water           event embedding framework that is designed for event-driven quanti¬≠
Research (NIVA). In particular, the authors designed TERA KG to inte¬≠             tative investment. In particular, the constructed KG (named FinKG) and
grate information captured from dissimilar resources relevant to eco¬≠             the implemented embeddings performs learn informative representa¬≠
toxicology and risk assessment domain (e.g. ECOTOXicology database                tions based on both the relations of event argument and the lead-lag
(ECOTOX)16 and NCBI taxonomy17). The construction of TERA KG was                  relations amongst the entire KG. Liu et al. (2019b) demonstrated the
carried out by using LogMap ontology alignment system (JimeÃÅnez-Ruiz              use of a KG embedding framework to predict stock prices using news
and Grau, 2011) to index and align the ECOTOX and NCBI vocabularies.              sentiment analysis. Although the authors did not provide much discus¬≠
Yan et al. (2020) designed KnowIME (KG‚Äôs Intelligent Manufacturing                sion on the validity of the mechanism followed to construct the KG, the
Equipment), a knowledge-based integration system for manufacturing                utility was demonstrated in the prediction task. In the same line of
equipment such as lathes, conveyors and robots. A domain-specific KG              research, Long et al. (2020) integrated trading data, public market in¬≠
was constructed and augmented using CRF method from heterogeneous                 formation and investor‚Äôs records to construct a KG that is incorporated
equipment-related data. Industrial adoption to KGs to enhance customer            to model the market and its features. The KG was then embedded using
satisfaction and user experience was undertaken by Li et al. (2020c). The         node2vector approach and used in a deep neural network model for
authors designed two KGs for evolutionary Smart Product‚Äì Service                  forecasting trends in stock prices. Authors of Ding et al. (2016) depicted
System (Smart PSS) development. The constructed KGs resulted from                 the relevance of using a knowledge-empowered model on event repre¬≠
data obtained from open-source knowledge, prototype specifications,               sentation and stock prediction. Zhang et al. (2018a) supported the
and user-generated textual data. The KGs were then used to bringing               aforementioned endeavours by proposing an approach to detect
expert knowledge, thereby solving issues related to cost-effectiveness            short-term stock price movement. The authors developed an enterprise
that exist in the current knowledge supply for Smart PSS.                         KG and designed a top-up power vector model and influence propaga¬≠
    Electric power artificial intelligence systems have also contributed to       tion model. The aim was to compute the effect of a specific relationship
the KGs construction and augmentation. For example, Fan et al. (2020b)            from the relevant enterprise. The construction of the KG involved
proposed an approach to construct the dispatch KG for the power grid to           incorporating Named Entities Recognition (NER) and Neural Relation
semantically describing behavior of dispatchers. They follow                      Extraction (NRE) for entities extraction and Convolutional Neural
semi-automated labelling to construct a power corpus, then                        Network (CNN) for relation inference. Stock management and stock
BiLSTM-CRF model was used to extract entities and indicate the dis¬≠               prediction tasks have been also discussed in (Wang et al., 2019c, 2020b;
patching behavior relationship patterns. Yang et al. (2019b) also                 Deng et al., 2019b; Matsunaga et al., 2019; Zhang et al., 2018b).
leveraged the KG schema to collect and integrate data from various
power assets. They aimed to deliver a unified multi-source                        4.5.2. Fraud detection
                                                                                      Financial fraud detection is an important area of financial risk
                                                                                  management. KGs have been leveraged to establish approaches that can
12                                                                                be used to stop such criminal activity. For example, Wang et al. (2020c)
     http://www.ncbi.nlm.nih.gov/PubMed/.
13
     http://ctdbase.org/.                                                         used a finance KG as a basis for label propagation algorithm to detect
14
     https://thebiogrid.org/.                                                     online fraud. Their model embodies a partition algorithm that is used to
15
     https://www.malacards.org/.                                                  distinguish fraudulent groups of users. They argued that fraudulent
16
     https://cfpub.epa.gov/ecotox/.                                               users tend to position a close distance, whereas normal users commonly
17
     https://www.ncbi.nlm.nih.gov/taxonomy.                                       exist in isolated tense or firmly connected groups. Zhan et al. (Zhan and

                                                                              8
B. Abu-Salih                                                                                           Journal of Network and Computer Applications 185 (2021) 103076


Yin, 2018) also proposed a model that was applied in the fraud detection         efforts emphasized the significance of adding trust aspect in the process
domain. In particular, the authors designed a call network KG that is            of designing and constructed a KG. In particular, the authors presented
enriched with call historical data and loan transactional data. Although         POLARE, an ontology that conceptualised the political system, and built
the mechanism followed to construct the KG and the evaluation metrics            a KG based on the provided ontology schema so as to be used for a better
are inadequate and inferior, the research topic is important and em¬≠             understanding the existing relations between agents in the political
phasises the significance of combining KGs with machine learning                 system in Brazil. Another attempt to detect and infer Political ideology
techniques to detect fraud in finance (Wang and Zhu, 2020; Kunlin,               was proposed by Chen et al. (2017) whereby the authors introduced an
2018).                                                                           opinion-aware KG that was used for conducting political ideology
                                                                                 forecasting. The model integrated knowledge captured from social
4.6. Society and politics                                                        media, DBpedia and ideological books corpus. Rudnik et al. (2019)
                                                                                 made use of Wikidata to semantically annotating news articles. The
   Societies were initially formed men who have intuitively established          annotated articles were then fed into a predefined event-oriented KG
political systems by making formal and informal decisions concerning             that was used for semantic-based search engine. News recommendation
the production, distribution, and the use of various resources (Sahlins,         by means of a KG was also examined in Liu et al. (2019c). The authors
1960). Thus, entities in terms of people, organizations, and resources           applied a filtering method to eliminate irrelevant relations from the
have been involved to establish various forms of relations which exist           currently incorporated and propagated KG. Microsoft Satori KG was
among them (Schwabe et al., 2019). The formal representation of KGs              used as a backbone knowledge-based and enriched with entities
provides an excellent mean to conceptualise relationships in social sci¬≠         captured from MSN news corpus. Also, the authors introduced article
ences and politics.                                                              topic entities and the collaborative edges as two new categories of in¬≠
                                                                                 formation to be embedded in the original graph. Mehdi et al. (Ali et al.,
4.6.1. Social science                                                            2019) designed a KG embedding approach based on socio-scholarly KG
    The current advances in information and communication technolo¬≠              which embodies scientific artifacts on social good. The developed sys¬≠
gies have made a qualitative leap and have created new venues where              tem incorporated various KG embedding approaches so as to retrieve,
people can exchange thought, ideas and interest (Abu-Salih et al., 2018,         for a given entity (i.e., publication, author, domain and venue), all
2020a, 2021a; Meneghello et al., 2020). This ICT revolution is embodied          related and semantically-matched entities. Other studies were further
into various electronic means depicted by the emergence of social                established systems over KGs to benefit news and journalism domain
media. The data created by such platforms are propagating posing                 (Berven et al., 2020; Wang et al., 2018b; Sheu and Li, 2020).
questions on the quality of the data being generated by these platforms
(Abu-Salih et al., 2019; Wongthongtham et al., 2018; Wongthongtham               4.6.3. Culture
and Salih, 2018; Nabipourshiri et al., 2018). Hence, there is a vital need          Modelling culture and history of societies have been also con¬≠
to study these platforms and provide ground truth of trustworthy data            ceptualised using domain-specific KGs. For example, Liu et al. (2020)
sets (Wongthongtham and Salih, 2018; Chan et al., 2018; Abu-Salih                developed a KG that depicts ancient Chinese history and culture. The
et al., 2021b; Wongthongtham and Abu-Salih, 2015). Tchechmedjiev                 author constructed the KG employing Baidu Encyclopedia18 as the
et al. (2019) introduced ClaimsKG, a knowledge graph of fact-checked             knowledge source, BiLSTM-CRF for entity recognition, and DeepKE
claims originated from International Fact-Checking Network (IFCN).               (developed by Zhejiang University) for relation inference. Constructing
The purpose of ClaimsKG is to enable users searching for true facts of a         cultural knowledge bases that benefit from domain ontology and cul¬≠
certain entity. Similarly, it can be used to infer false facts of people,        tural KGs was elaborated further in Wei and Liu (2019); Marchand et al.
organizations, etc. Nguyen et al. (Nguyen and Jung, 2019) created a KG           (2020); Carriero et al. (2019).
that embodied social events decomposed from social media using In¬≠
dependent Component Analysis (ICA) and the SocioScope Knowledge                  4.7. Travel
Graph (SKG) model. ICA is used to cluster social events obtained from a
matrix of collected hashtags. This was followed by using the SKG model              Travel is one of the key domains which availed from the growing use
do automatically construct event-driven KGs from Twitter data. Huang             of KGs. In particular, Tourism and Trafic/Transportation are amongst
et al. (2017b) reported a KG that can be used in social media to detect          the subdomains that have largely employed KGs.
entity morphs (aliases that are commonly used to conceal the identity of
a certain entity). The developed KG includes the real entity linked with         4.7.1. Tourism
all identified morphs mansions. A topic modelling algorithm(i.e.                     KGs have been constructed and used in touristic QA systems (Yang
CorrLDA2), as well as SVM models, were used in the KG construction               et al., 2020) or in tourism recommender systems to recommend
process. Various comparative studies were undertaken to demonstrate              personalized attractions (Lu et al., 2016) and the best accommodation
the effectiveness of the proposed approach.                                      prices (KaÃàrle et al., 2018). For example, KaÃàrle et al. (2018) gathered data
                                                                                 about Tirol region at Austria and constructed ‚ÄúTirol Tourism‚Äù KG to
4.6.2. Politics                                                                  benefit applications such as eCommerce. The constructed KG was fed by
    Processing social data to infer domain knowledge that can be used to         entities and relations extracted from Destination Management Organi¬≠
design a political KG was also discussed in the literature. For example,         zations (DMOs) and Geographical Information Systems (GIS) and other
our previous work (Abu-Salih et al., 2020b) developed a                          tourism and accommodation-related websites. Establishing a touristic
credibility-based Politics and applied various KG embedding techniques           KG for China was introduced in Zhang et al. (2019b). The authors
to validate the KG‚Äôs utility. In particular, BBC politics ontology was           designed the domain-specific KG by using data obtained from Chinese
incorporated and extended as a backbone schema for the Politics KG.              encyclopedia KG and unstructured web pages. For entity alignment, the
Then, various domain knowledge inference tools were used to enrich the           authors made use of Skip-Gram Model to fitch relative entities during
KG with political entities captured from the collected datasets. Finally,        the knowledge acquisition phase. Another attempt to construct a KG for
several KG embedding models were implemented and tested over a set of            Chinese tourism was undertaken by Yang et al. (2020). The aim was to
link prediction, clustering, and visualisation tasks. The work proposed          build a QA system based on the implemented KG of tourism. The authors
by Laufer and Schwabe (2017) crossed with the former model as both               followed a proposed entity recognition algorithm for entity extraction


                                                                                 18
                                                                                      https://baike.baidu.com/.

                                                                             9
B. Abu-Salih                                                                                            Journal of Network and Computer Applications 185 (2021) 103076


and utilised CNN model for relation inference. In a different context,            detect fraud in finance (Zhan and Yin, 2018), and to discover and
Calleja et al. (2018) created ‚ÄúDBtravel‚Äù KG over the Spanish entries of           visualise political relationships (Abu-Salih et al., 2020b; Chen et al.,
Wikitravel.19 The authors followed GATE20 pipeline that encompasses               2017). These attempts demonstrate how knowledge can be obtained
three internal processes, namely: (1) tokenizer, (2) sentence splitter and        from different sources, which perhaps exist in different formats, and can
(3) named entity recognition. Employing KGs in the tourism domain has             be then fed into one coherent schema to be formally used to conceptu¬≠
been highly active recently and used in various applications (Feng,               alise the designated domain. At the same time, we observe that several
2020; Liang et al., 2020; Wu et al., 2020).                                       other works, particularly in the sciences and engineering domain, have
                                                                                  not taken advantage of this important feature of KGs, but have employed
4.7.2. Transportation and traffic                                                 limited data sources to feed their constructed KGs. Further observations
    Applying KGs in transportation and traffic has also obtained much             and findings from this study are discussed in the next section.
attention recently due to the population growth, air pollution, and other
sophisticated embedded issues that require intelligent systems to resolve         5. Findings from the survey
them efficiently (D√≠az et al., 2020). For example, Zhou et al. (Zhou and
Chen, 2019) introduced a model to predict urban traffic congestion. In                The review of KG construction approaches which are drawn from
this model urban KG was constructed from miscellanies static and dy¬≠              academic works in seven domains reveals a correlated array of limita¬≠
namic raw urban data. The authors applied CNN to model                            tions and deficiencies related to the following summarised points:
spatio-temporal correlation between each indicated region. One of the
well-known KGs that was applied to the US transportation system is                5.1. KG data quality, privacy, and credibility
ATMGRAPH (M. Keller, 2019) which was built at the top of the NASA
ATM Ontology (ATMONTO) (Keller, 2018). M. Keller (M. Keller, 2019)                    The reviewed articles have not consistently used standardized and
in ATMGRAPH combined an array of structured aviation data obtained                appropriate data quality measures, particularly with the construction of
from the large part by US federal agencies. The developed KG concep¬≠              large-scale KGs. Various approaches imported data collected from noisy
tualises the US National Airspace System by incorporating entities                and low-quality data sources (such as social media) with little consid¬≠
describing, airspace infrastructure, flights, and flight operating condi¬≠         eration given to the credibility or privacy of generated information. This
tions. Detecting traffic events by employing KG was proposed in Mup¬≠              is also seen in electronic medical records from which it is difficult to
palla et al. (2017). The authors built a KG named ITSKG (Imagery-based            collect data due to privacy and confidentiality constraints. This raises a
Traffic Sensing Knowledge Graph) that was used to comprehend traffic              question regarding the quality and robustness of KGs that are con¬≠
patterns based on stationary traffic camera imagery data. Further, Wang           structed from such data repositories. Despite some attempt to tackle data
et al. (2019d) followed a semi-automated KG construction approach                 quality issues (Chen et al., 2019a; Zaveri et al., 2016), the endeavours in
based on China railway electrical accidents data. The purpose of the              this direction have been inadequate. Blockchain technology presents a
work is to analyse and identify the faulty equipment of railway electrical        promising breakthrough in this regard as it provides continuous verifi¬≠
accidents in China as well to infer patterns and trends from such data. In        cation and advanced audit trails of all transactions. Blockchain tech¬≠
a different context, Zhang et al. (2020c) have expanded the exertions in          nology does not only provide a complete mechanism to ensure data
the maritime transportation by applying KG to build a knowledge rep¬≠              quality, integrity, and accuracy; it also has a secure and tamper-proof
resentation of the regulations depicted by International Maritime                 architecture for data storage, which would be extremely beneficial for
Dangerous Goods Code (IMDG Code). They aimed to facilitate the access             healthcare information. Future research should be steered toward
and retrieval of detailed guidelines embedded in IMDG.                            designing methodologies that establish best practices to construct
Knowledge-based models in transportation domain were also bench¬≠                  immutable domain-specific KGs leveraging both KG and blockchain
marked (Chaves-Fraga et al., 2020) and others were used in                        technologies.
travel-related intelligent systems to facilitate information sharing and
interoperability (Sandberg et al., 2020; Ramnani et al., 2018).                   5.2. Knowledge resources and semantic expansion

4.8. Summary                                                                          Semantic Web technologies and Linked Open Data (LOD) have
                                                                                  opened the door wide to improving several domain applications
    The aim of this study was to review the latest publications concerned         (HyvoÃànen, 2012). KGs are extensions to these efforts and are commonly
with KG construction approaches in seven domains of knowledge,                    associated with LOD projects as they enrich the semantics of data by
namely: healthcare, education, ICT, science and engineering, finance,             providing conceptual representations of concepts and entities (Ehrlinger
society and politics, and travel. A close examination of these interesting        and WoÃà√ü, 2016). Therefore, the interoperability of information is facil¬≠
domains reveals important areas of research that can greatly benefit              itated by relevant entity interlinking obtained from other KG re¬≠
from KG technology. This study not only demonstrates the popularity of            positories, thereby constructing multi-modal KGs. However, the
incorporating KGs to arrive at solutions for real-life problems, but also         approaches examined in the designated domains have demonstrated
illustrates how KGs have proven to be an effective overall solution to            limitations in achieving interoperability of information. In particular,
mitigate complexity, ensure flexibility, and establish a common-ground            semantic expansion/broadening techniques were insufficiently incor¬≠
topology whereby data can be integrated from different sources. This is           porated to benefit from the openly available vocabularies and curated
clearly articulated in the selected articles in which there is a consensus        semantic repositories. Essentially, the underlying structure of KGs is
that KG technology facilitates the integration of information captured            designed to pave the way for data integration, unification, and infor¬≠
from various sources. For example, we observe several efforts where KGs           mation sharing and usability. Research in this direction should be
have been constructed using heterogenous resources to build consoli¬≠              reinforced to ensure that the essence of KGs adheres to FAIR (Findable,
dated QA and recommender systems in healthcare (Mohammadhas¬≠                      Accessible, Interoperable, Reusable) principles.21
sanzadeh et al., 2018; Huang et al., 2017a; Haussmann et al., 2019), to
discover relations in biodata (Choi and Lee, 2019), to predict ecotoxi¬≠           5.3. KG construction algorithms
cological effects in environment engineering (Myklebust et al., 2019), to
                                                                                       Deriving meaningful knowledge from a diversity of data formats is

19
     https://wikitravel.org/.
20                                                                                21
     https://gate.ac.uk/.                                                              https://www.go-fair.org/fair-principles/.

                                                                             10
B. Abu-Salih                                                                                           Journal of Network and Computer Applications 185 (2021) 103076


not a trivial task; it involves extracting facts about entities and their         the conventional technologies used to process and analyse the contin¬≠
potential relationships, which requires a correlated array of various             uous propagation large-scale datasets are no longer adequate (Marz and
Information Extraction (IE) techniques and sophisticated Natural Lan¬≠             Warren, 2015). Machine Learning and Artificial Intelligence have
guage Processing (NLP) approaches. The review of the selected articles            become the preferred methods for the processing and analysis of Big
revealed only limited discussions on techniques used for entity recog¬≠            data, by means of which the hoped-for added value is obtained.
nition and/or relation extraction. Most of these studies either neglected         Large-scale KGs (i.e., those with trillions of triples) adhere to various Big
to specify the algorithm(s) used in the KG construction including tech¬≠           data features. Volume is not the only feature of Big KGs; they can be
niques for entity and relation extraction (e.g. (Yang et al., 2019b; Fu           described by the variety in data sources, the velocity of data generation,
et al., 2018; Wang et al., 2020c)) or presented few details and poor              veracity of data quality, volatility of data currency and availability, etc.
rationale for using such techniques (e.g. (Gatta et al., 2017; Jia et al.,        Despite some growing efforts to integrate large-scale KGs in Big Data
2018; Krinkin et al., 2020; Cheng et al., 2020)). From the analysis, we           processing (Wang and Luo, 2018), there is a need for a deeper and
also identified an existing research gap - there were no consolidated             congruent integration of Big Data technology infrastructures and so¬≠
methodologies for automating the process of constructing a                        phisticated statistical models required for reasoning over
domain-specific KG that facilitates the selection of suitable algorithms          domain-specific KGs, and this remains an open research venue.
for the designated techniques (involving both NLP methods and
data-driven approaches (Hunter, 2017)). Such methodologies would not              5.7. Domain-specific KG reasoning
only improve KG construction practices; they could also make the
knowledge broadly available for access by both humans and machines.                   KG reasoning aims to provide new interpretations and conclusions
                                                                                  from constructed KGs. It is a mechanism whereby new facts can be
5.4. Time-aware KGs                                                               inferred from an existing KG (Tari, 2013). KG embedding-based ap¬≠
                                                                                  proaches (including tensor decomposition, distance, and semantic
    The dynamic nature of knowledge is highly correlated to contextual            matching models) have gained considerable attention in the literature
situations; hence, various facts that describe entities might change over         due to their scalability and efficiency in accommodating large-scale KGs
time. Therefore, the temporal dimension should be integrated into KGs.            so as to deduce a generalizable context about the KG that can be applied
Various currently propagated KGs are static but temporary, and do not             to infer new relations (Wang et al., 2017a; Chen et al., 2020b). This
consider the time factor (Jiang et al., 2016). This applies to both               study discloses a lack of incorporating KG embedding techniques into
open-world and domain-specific KGs. Neglecting the dynamic nature of              the examined approaches. Applying KG embeddings extends these ef¬≠
knowledge harms the quality and correctness of facts contained in the             forts and tackles the deficiencies that might occur in the KG construction
KGs and might lead to poor decision making that is based merely on such           process, which subsequently leads to incomplete graphs. To address this
data sources. Consequently, despite some exceptions such as Wikidata              issue and to establish a technical ground for conducting relational
and YAGO in which certain facts are already endowed with the time                 reasoning in AI systems, KG embeddings should be integrated and
information, the construction of KGs should consider the validity period          implemented in domain-specific KG construction models.
of facts (Leblay and Chekol, 2018).
                                                                                  5.8. Availability of domain-specific KGs
5.5. KG evaluation
                                                                                      Unlike open-world and generic KGs, most of the constructed and
    During the process of constructing KGs, incorrect facts in terms of           populated domain-specific KGs are not published on the Web and thus
entities and/or relations could be captured. This process is prone to             are not accessible to other researchers. The paucity of such annotated
errors, particularly in regard to the information derived from mix-               and enriched data silos makes the process of benchmark comparison
quality data sources. As mentioned previously, it is vital to consider            more difficult, as well as limiting reusability, interlinking and interop¬≠
the credibility of the data source, as is the evaluation of the overall           erability. At the same time, there is a scarcity of relevant experts who
construction process. In fact, among the reviewed articles, the evalua¬≠           can perform data annotation. For example, in the healthcare domain,
tion of KGs was the predominant weakness. For example, some studies               there is a lack of detailed clinical entities and relations. This is due to the
carried out a superficial and subjective evaluation of the KG construc¬≠           shortage of both clinical repositories (Malik et al., 2020) and clinicians
tion with no incorporation of concrete evaluation metrics (Fan et al.,            to conduct data annotation (Xue and Chuah, 2019). This issue has also
2020b; Fu et al., 2018; Muppalla et al., 2017). Another thread of efforts         been highlighted by researchers in Cybersecurity (Piplai et al., 2020),
attempted to involve theoretically-proven evaluation metrics to sys¬≠              Finance (Bi et al., 2020), and Social Science (Feng and Chen, 2021), to
tematically measure KG completion and KG correctness approaches. The              name a few.
former approaches were commonly measured using recall, precision,
and f-measure (Huang et al., 2019; Chi et al., 2018a; Su and Zhang,               5.9. Room for further research on domain-specific KGs
2020; Jia et al., 2018). The latter incorporated accuracy and/or area
under the ROC curve (AUC) (Paulheim, 2017; Chen et al., 2020a; Long                   This study attempts to capture a snapshot of recent advances in KGs
et al., 2020). Nevertheless, our study endorses the work conducted by             in certain domains of knowledge. Due to limitations of space, not all KGs
Paulheim (2017) in that, providing holistic techniques which simulta¬≠             construction attempts in every domain and its subdomains could be
neously improve the quality of KGs in dissimilar domains, is still an open        considered. Hence, there are still various specific areas of the selected
research problem. Further, the absence of testbeds and benchmark                  high-level domains that can exploit KG technology. For example, there is
datasets has prevented the community from undertaking an appropriate              a need for technical solutions to respond to COVID-19 as a critical cat¬≠
and fair evaluation of techniques used for KG creation (Chaves-Fraga              alyser of various technological applications. KG technology can provide
et al., 2019). Lastly, in their evaluation methodologies, researchers             a shared conceptualised structure which can be used to map all
should consider various other data quality indicators including                   dispersed facts stored in various data silos which are relevant to this
completeness, believability, relevance, objectivity, consistency, under¬≠          pandemic. Integrating information from various available resources
standability, etc. (Wang and Strong, 1996).                                       pertaining to COVID-19 can help to bridge the knowledge gap and
                                                                                  provide a better understanding of this disease. COVID-19 has also given
5.6. Computing performance in big KGs                                             impetus to the adoption of new technologies for remote and online ed¬≠
                                                                                  ucation. The propagation of online learning resources has established a
    There is a notable consensus amongst the research community that              space where domain-specific KGs can be employed to alleviate the

                                                                             11
B. Abu-Salih                                                                                           Journal of Network and Computer Applications 185 (2021) 103076


problem of selecting relevant resources to benefit both teachers and               been constructed and used to tackle several real-life problems in dis¬≠
learners. KG technology can be applied to solve an array of problems in            similar domains. Yet, to date, there has been no consensual definition of
any domain where the data is collected from different sources. In these            a domain-specific KG. Moreover, the current methods used to construct
applications, KG technology is an excellent means of achieving inter¬≠              and evaluate domain knowledge graphs are far from perfect.
operability, unification, interlinking, and data integration.                          This paper is the first to present an inclusive definition of domain-
                                                                                   specific KG. Further, it provides an in-depth analysis of the current
6. Conclusion                                                                      state-of-the-art knowledge graph construction research in seven do¬≠
                                                                                   mains of knowledge. The efforts undertaken in each research domain are
    The widespread use and the prevalence of the Internet have led to the          discussed, and the shortcomings and limitations of these efforts are
rapid increase in data volume which has necessitated the development               considered, along with future research opportunities which we hope will
of advanced data analytics that are capable of handling the propagation            motivate researchers in this specific area.
and the heterogeneity of such data. Knowledge graphs continue to
dominate as a distinctive form of data representation and knowledge                Declaration of competing interest
inference, and are core activity of several industrial applications. The
great amount of interest in this technology is due to its underlying                   The authors declare that they have no known competing financial
structure that is built on a formal conceptual representation that is              interests or personal relationships that could have appeared to influence
depicted by a domain ontology. Therefore, domain-specific KGs have                 the work reported in this paper.



Appendix A. Tables
Table A.1
Overview of KG approaches in Healthcare domain.

  Ref.                      Sub-domain   KG Usage              Construction        KG Resource(s)   Embedding         Evaluation           Limitation(s)
                                                               Algorithm(s)                         Technique(s)      Measure(s)

  Gatta et al. (2017)       Generic      Medical process       Markov Models       Event logs       N/A               Case study           ‚Ä¢Inadequate evaluation,
                                         mining                and Careflow                                                                ‚Ä¢inadequate discussion on
                                                               Mining,                                                                     the KG construction
                                                                                                                                           approach
  Mohammadhassanzadeh       Generic      QA                    Plausible           BioASQ,          N/A               Domain expert‚Äôs      ‚Ä¢Insufficient evaluation,
   et al. (2018)                                               reasoning           DrugBank,                          verification         ‚Ä¢evaluating the
                                                                                   Disease                                                 performance of query
                                                                                   Ontology, and                                           rewriting algorithm does
                                                                                   SemMedDB                                                not exist
  Rotmensch et al. (2017)   Diseases     Identification of     LR, NB and          Custom, GHKG     N/A               Precision and        ‚Ä¢Inadequate to infer
                                         diseases and          Bayesian                                               Recall               correct causal relations,
                                         symptoms across the   network                                                                     ‚Ä¢concept extraction
                                         collected medical     modeling                                                                    requires further
                                         records                                                                                           elaboration
  Huang et al. (2017a)      Diseases     QA - Depression       NLP tools           PubMed,          N/A               Use cases            ‚Ä¢Lack of proper
                                         disorder                                  DrugBank,                                               evaluation,
                                                                                   DrugBook,                                               ‚Ä¢ insufficient use of other
                                                                                   andUMLS                                                    important medical
                                                                                                                                              repositories
  Chen et al. (2020a)       Diseases     Benchmark             LR, NB, and         BIDMC, GHKG      N/A               AUC, F1 score,       ‚Ä¢ Limited data sources,
                                         comparison-Diseases   (noisy OR)                                             and AUPRC            ‚Ä¢ poor causal inference
                                         and symptoms                                                                                         methods
  Ma et al. (2019)          Diseases     Episodic memory -     Manual              GDELT and        Tucker,           MRR, and             ‚Ä¢ Poor generalization
                                         Inductive learning    integration         ICEWS            RESCAL, HolE,     AUPRC                   due to the timestamps
                                                                                                    ComplEx,                                  not observed in the
                                                                                                    DistMult, ConT                            training dataset,
                                                                                                    and Tree                               ‚Ä¢ KG embeddings are
                                                                                                                                              prone to overfitting
                                                                                                                                              (too many parameters)
  Huang et al. (2019)       Healthcare   Healthy diet          CRF, SVM and        Healthcare       N/A               Precision,           ‚Ä¢ Limited to food and
                            management   recommendation        DT                  websites                           Recall, and F1-         dietary,
                                                                                                                      score                ‚Ä¢ Chinese language only,
                                                                                                                                           ‚Ä¢ inadequacy to prove
                                                                                                                                              utility in link
                                                                                                                                              prediction and other
                                                                                                                                              knowledge discovery
                                                                                                                                              tasks
  Haussmann et al. (2019)   Healthcare   Food                  Lexical             DBpedia, USDA,   word2vec, and     Case study and       ‚Ä¢ Lack of evaluation on
                            management   recommendation, and   similarity and      Recipe1M and     FastText          F1-score                both KG constructions
                                         QA systems            string matching     FoodOn KG                                                  and incorporated
                                                                                                                                              embeddings
                                                                                                                                              techniques,
                                                                                                                                           ‚Ä¢ inadequate meaningful
                                                                                                                                              representations for
                                                                                                                                              food recommendation
  Chi et al. (2018a)        Healthcare   Food recommendation   NLP tools, CRF,     China Food       N/A               Precision, recall,   ‚Ä¢ Limited data sources,
                            management                         SVM, NB,            Composition                        F1-measure, and      ‚Ä¢ lack of proper
                                                                                                                      Questionnaire           recommendations,
                                                                                                                                             (continued on next page)


                                                                              12
B. Abu-Salih                                                                                                               Journal of Network and Computer Applications 185 (2021) 103076

Table A.1 (continued )
  Ref.                            Sub-domain        KG Usage                   Construction        KG Resource(s)      Embedding           Evaluation         Limitation(s)
                                                                               Algorithm(s)                            Technique(s)        Measure(s)

                                                                               LSTM, and           and Online                                                  ‚Ä¢ directed solely for the
                                                                               KNN                 health websites,                                              Chinese context




Table A.2
Overview of KG approaches in Education domain.

  Ref.                         Sub-domain           KG Usage                   Construction           KG Resource(s)          Embedding       Evaluation        Limitation(s)
                                                                               Algorithm(s)                                   Technique       Measure(s)
                                                                                                                              (s)

  Chen et al. (2018b)          Teaching and         K-12 Education             CRF and                Chinese curriculum      N/A             AUC               ‚Ä¢ Insufficient
                               classroom                                       probabilistic          standards of                                                evaluation,
                               resources                                       association rule       mathematics                                               ‚Ä¢ narrow scope of the
                                                                               mining                                                                             proposed KG and its
                                                                                                                                                                  applications
  Su and Zhang (2020)          Teaching and         Learning assessment        Bootstrapping          Subject teaching        N/A             Precision,        ‚Ä¢ Limited
                               classroom            and recommendation         construction           resources, Baidu                        Recall and F1       demonstration on the
                               resources                                       strategy and           Encyclopedia, and                       measure             utility of the
                                                                               BERT-BiLSTM-           DBPedia                                                     constructed KG
                                                                               CRF                                                                                including assessment
                                                                                                                                                                  of student learning,
                                                                                                                                                                  etc.
  Zhao et al. (2019)           Teaching and         Solving high school        Complex,               Crowdsourcing and       N/A             Accuracy,         ‚Ä¢ Limited resources
                               classroom            mathematical exercises     Triangle, Conic        domain experts                          Precision,          used for KG
                               resources                                       and Solid                                                      Recall and F1       construction,
                                                                                                                                              measure           ‚Ä¢ limited targeted
                                                                                                                                                                  audience
  Chen et al. (2018a)          Teaching and         Learning assessment        RNN and                Pedagogical data        N/A             AUC,              ‚Ä¢ Lack of elucidating
                               classroom                                       probabilistic          and learning                            Precision,          the effects of KG in
                               resources                                       association rule       assessment data                         Recall and F1       other settings,
                                                                               mining                                                         measure           ‚Ä¢ their schema is
                                                                                                                                                                  relatively hard to be
                                                                                                                                                                  provided for
                                                                                                                                                                  conducting
                                                                                                                                                                  benchmark
                                                                                                                                                                  comparison
  Aliyu et al. (2020)          Education            QA and course              Adhoc                  Structural              N/A             Case study        ‚Ä¢ Poor evaluation
                               management           allocation scheduling                             educational                                                 measures, limited KG
                                                                                                      information system                                          resources,
                                                                                                                                                                narrow scope
  Wang (2020)                  Education            Internal policy control    Adhoc                  CNKI database           pTransE         mean              ‚Ä¢ Limited data sources,
                               management           conceptualization and                                                                     Silhouette        ‚Ä¢ limited application
                                                    visualisation in higher                                                                                       scope, poor
                                                    education                                                                                                     evaluation metrics,
                                                                                                                                                                ‚Ä¢ KG embedding was
                                                                                                                                                                  not properly
                                                                                                                                                                  demonstrated and
                                                                                                                                                                  evaluated
  Yao et al. (2020)            Educational          Link Prediction            Adhoc                  Knowledge Forest,       TransE and      Mean Rank         ‚Ä¢ Insufficient structural
                               Technologies                                                           Wikipedia               BERT            and Hits@10         and literal embedding
                                                                                                                                                                  models were used
  Chi et al. (2018b)           Educational          Decision-making in         NLP tools, SVM,        Web of Science,         N/A             F-score           ‚Ä¢ The limited scope of
                               Technologies         academia                   NB, and LR             Engineering                                                 KG (can be expanded
                                                                                                      Village, and EBSCO                                          to include instructors
                                                                                                                                                                  and their metadata),
                                                                                                                                                                ‚Ä¢ no domain ontology is
                                                                                                                                                                  provided as a base for
                                                                                                                                                                  the proposed KG,
                                                                                                                                                                ‚Ä¢ limited evaluation
                                                                                                                                                                  measures




Table A.3
Overview of KG approaches in ICT domain.

  Ref.            Sub-domain          KG Usage                  Construction        KG Resource(s)             Embedding         Evaluation             Limitation(s)
                                                                Algorithm(s)                                   Technique(s)      Measure(s)

  Jia et al.      Cybersecurity       Cyberattack               Stanford NER        Enterprise data and        N/A               Precision, Recall,     ‚Ä¢ Narrow KG construction
    (2018)                            detection                                     security websites                            and F1                   approaches,
                                                                                                                                                                 (continued on next page)




                                                                                              13
B. Abu-Salih                                                                                                     Journal of Network and Computer Applications 185 (2021) 103076

Table A.3 (continued )
  Ref.            Sub-domain      KG Usage                 Construction        KG Resource(s)        Embedding         Evaluation            Limitation(s)
                                                           Algorithm(s)                              Technique(s)      Measure(s)

                                                                                                                                             ‚Ä¢ limited evaluation with
                                                                                                                                               current state-of-the-art KGs in
                                                                                                                                               the designated domain
  Deng et al.     Cybersecurity   QA and RS for            Adhoc and NLP       Wikipedia             N/A               Case study and        ‚Ä¢ Limited data sources,
   (2019a)                        education                tools                                                       survey                ‚Ä¢ no benchmark comparison,
                                                                                                                                             ‚Ä¢ no backbone ontology schema
  Kiesling        Cybersecurity   Vulnerability            Adhoc and           NVD and security      N/A               Case studies          ‚Ä¢ No benchmark comparison,
    et al.                        Assessment and           RML Rules1          online sites                                                  ‚Ä¢ inadequate rationale on the
    (2019)                        Intrusion Detection                                                                                          construction approach
  Nayak et al.    Software        Test cases extraction    CPT and CRF         Software documents,   FastText          Accuracy,             ‚Ä¢ Transfer learning can replace
    (2020)        development                                                  requirement           algorithm         Precision, Recall,      the incorporated NER model,
                                                                               statements and test                     F1                      thereby using pre-trained
                                                                               reports                                                         datasets instead,
                                                                                                                                             ‚Ä¢ Inadequate validation to the
                                                                                                                                               collected requirement
                                                                                                                                               statements and past test
                                                                                                                                               reports
  Schindler       Software        Investigating            bi-LSTM and         DBpedia and PLoS      N/A               Case study            ‚Ä¢ Narrow to PLoS which affected
    et al.        development     Software Usage in the    bi-LSTM-CRF                                                                         the target domain,
    (2020)                        Social Sciences                                                                                            ‚Ä¢ evaluation is inadequate as no
                                                                                                                                               benchmark comparison was
                                                                                                                                               undertaken,
                                                                                                                                             ‚Ä¢ the automatic linking process
                                                                                                                                               with DBpedia requires a
                                                                                                                                               further scrutiny
  Fu et al.       Software        Info. Retrieval (IT      Adhoc               StackOverflow,        N/A               MRR, P@K, Recall      ‚Ä¢ Ranking modeling system can
    (2019)        development     Crowdsourcing                                Wikipedia and                                                   be enhanced with
                                  services)                                    crowdsourcing                                                   incorporating neural networks
                                                                               platforms
  Li et al.       Software        Industrial software      Adhoc               Generic(public        N/A               Case study            ‚Ä¢ Limited domain-based data
    (2019)        development     design and                                   databases and                                                   sources,
                                  development                                  unstructured data                                             ‚Ä¢ unable to provide
                                  processes                                    sources)                                                        recommendation in complex
                                                                                                                                               and domain-specific
                                                                                                                                               situations,
                                                                                                                                             ‚Ä¢ poor retrieval performance
  Aumayr          Telecom         Telecom incidents        NLP tools           Network incident      N/A               Case study on         ‚Ä¢ No discussion on the
   et al.                         managements                                  documents                               information             effectiveness of the
   (2019)                                                                                                              reduction and           incorporated algorithms/tools
                                                                                                                       discovery               for KG construction,
                                                                                                                                             ‚Ä¢ no benchmark comparison
                                                                                                                                               with similar state-of-the-art
  Krinkin         Telcom          Television operator      Adhoc               Data obtained by      N/A               Case study            ‚Ä¢ Limited discussion on KG
    et al.                        network monitoring                           monitoring systems                                              construction and propagation,
    (2020)                                                                                                                                   ‚Ä¢ no rationale on using the
                                                                                                                                               designated ontology schema,
                                                                                                                                               inadequate evaluation method
  Xie et al.      IoT             Bridging gaps            Adhoc               oneM2M2               N/A               Case study            ‚Ä¢ Inadequate discussion on
    (2020)                        between e-devices in                                                                                         concept and relation
                                  IoT                                                                                                          extraction approaches,
                                                                                                                                             ‚Ä¢ limited in data sources and
                                                                                                                                               application scope
 1
     https://github.com/carml/carml.
 2
     https://www.onem2m.org/component/rsfiles.


Table A.4
Overview of KG approaches in Science and Engineering domain.

  Ref.            Sub-domain        KG Usage                Construction         KG Resource(s)      Embedding           Evaluation           Limitation(s)
                                                            Algorithm(s)                             Technique(s)        Measure(s)

  Farazi et al.   Chemistry         Combustion              J-Park               Linked open data    N/A                 Query and            ‚Ä¢ Limited data sources,
    (2020c)                         chemistry modelling     Simulator                                                    simulation           ‚Ä¢ lack of human and
                                                                                                                         systems                machine‚àí interaction tools
  Choi and        Biology           Biodata relational      Manually             PubMed, CTD,        TransE,             Hits@10              ‚Ä¢ Poor KG construction
    Lee                             discovery                                    BioGRID, and        PTransE,                                   approach,
    (2019)                                                                       MalaCards           TransR and                               ‚Ä¢ unsatisfactory evaluation of
                                                                                                     TransH                                     the incorporated KG
                                                                                                                                                embedding models
  Zhu et al.      Geology           Geological IR system    HanLP1 and           Baike.com           N/A                 Case study           ‚Ä¢ Limited data sources.,
    (2017)                                                  association rule                                                                    undefined underlying
                                                            analysis                                                                            structure,
                                                                                                                                              ‚Ä¢ inadequate evaluation to the
                                                                                                                                                utility of KG.
                                                                                                                                                      (continued on next page)


                                                                                       14
B. Abu-Salih                                                                                                               Journal of Network and Computer Applications 185 (2021) 103076

Table A.4 (continued )
  Ref.             Sub-domain         KG Usage                    Construction        KG Resource(s)            Embedding             Evaluation             Limitation(s)
                                                                  Algorithm(s)                                  Technique(s)          Measure(s)

  Wang et al.      Geology            Chinese geology             CRF                 Geology dictionary        N/A                   Case study             ‚Ä¢ Limited data sources,
   (2018a)                            Knowledgebase                                   and TCCGMR                                                               inadequate concept and
                                                                                                                                                               relation extraction,
                                                                                                                                                             ‚Ä¢ no benchmark comparison
                                                                                                                                                               with similar state-of-the-art
  Yan et al.       Manufacturing      Intelligent                 CRF                 Equipment-related         N/A                   Case study             ‚Ä¢ Limited to level of stand-alone
    (2020)         engineering        manufacturing                                   data (e.g. Baidu                                (Information             equipment,
                                      equipment                                       Encyclopedia, etc.)                             richness and           ‚Ä¢ scattered manufacturing data
                                      recommendation                                                                                  effectiveness)           that harden data acquisition,
                                                                                                                                                               poor accuracy
  Li et al.        Design             Evolutionary Smart          Domain experts      Smart PSS prototype,      N/A                   Showcase               ‚Ä¢ Proposed solutions for the
    (2020c)        engineering        Product‚Äì Service            and NLP             user generated                                                           personalized requirements
                                      System Development          toolkits            textual data, misc.                                                      are someway generic and
                                                                                      medical websites                                                         oversimplified,
                                                                                                                                                             ‚Ä¢ unoptimized incorporated
                                                                                                                                                               algorithms that led to poor
                                                                                                                                                               complexity in terms of time
                                                                                                                                                               and space
  Myklebust        Environment        Ecotoxicological            LogMap              ECOTOX, NCBI and          TransE,               Accuracy,              ‚Ä¢ Limited data sources; can be
    et al.         engineering        effect prediction                               Wikidata                  DistMult, and         Precision, Recall,       enhanced with information
    (2019)                                                                                                      HolE                  and F-score              about species and compounds
  Fan et al.       Electrical         Improving power             BiLSTM-CRF          Power dispatching         N/A                   Subjective             ‚Ä¢ Small, static and non-
    (2020b)        engineering        dispatching process.                            texts                                           evaluation               diversified dataset,
                                                                                                                                                             ‚Ä¢ poor evaluation mechanism
  Yang et al.      Electrical         Improving utilization       Adhoc               PMS and ERP               N/A                   Case study             ‚Ä¢ Limited evaluation measures,
    (2019b)        engineering        of power assets                                                                                                        ‚Ä¢ limited data sources,
                                      information                                                                                                            ‚Ä¢ limited KG structure and
                                                                                                                                                               application
  Huang et al.     Oil and gas        Intelligent earch           BiLSTM-CRF          Center of Oil and Gas     N/A                   Precision and          ‚Ä¢ Limited data sources,
   (2020)                             engine for oil and gas                                                                          Recall                 ‚Ä¢ lack of optimization to the
                                                                                                                                                               embedded search engine.
 1
     https://javalibs.com/artifact/com.hankcs/hanlp.


Table A.5
Overview of KG approaches in Finance domain.

  Ref.           Sub-domain        KG Usage               Construction           KG Resource(s)           Embedding             Evaluation Measure         Limitation(s)
                                                          Algorithm(s)                                    Technique(s)          (s)

  Liu et al.     Investment        Stock market           Adhoc                  Tomson Reuters,          word2vec,             Accuracy and F1-           ‚Ä¢ Limited resources led to
    (2019a)                        prediction                                    CNN                      TransE, Neural        score                        insignificant scale of the trained
                                                                                                          network                                            dataset,
                                                                                                                                                           ‚Ä¢ vague KG construction approach
                                                                                                                                                             (no algorithm is indicated),
                                                                                                                                                           ‚Ä¢ reporting the utility of the KG
                                                                                                                                                             embedding was inadequate
  Fu et al.      Investment        Market return          Adhoc                  Shanghai Stock           N/A                   Subjective                 ‚Ä¢ KG construction in terms of
    (2018)                         prediction                                    Exchange and                                   evaluation based on          entities and relations was not
                                                                                 WIND Financial                                 29 component                 properly addressed,
                                                                                 Terminal                                       stocks                     ‚Ä¢ missing KG schema,
                                                                                                                                                           ‚Ä¢ poor evaluation to the resultant
                                                                                                                                                             KG
  Cheng          Investment        Event-driven           OpenIE v5.1            Financial news           N/A                   Micro ‚àí F1,                ‚Ä¢ Poor discussion on KG
    et al.                         quantitative                                  websites                                       Weighed ‚àí F1                 construction mechanism/
    (2020)                         investments                                                                                                               algorithm,
                                                                                                                                                           ‚Ä¢ lack of justification on the use of
                                                                                                                                                             customized evaluation metric
  Liu et al.     Investment        Stock price            Rule-based             Financial news           TransR                Accuracy                   ‚Ä¢ Large scale KG that can affect
    (2019b)                        volatility             named entity           websites and UQER                              (prediction task)            the performance of TransR
                                   prediction             recognition                                                                                        embedding model,
                                                                                                                                                           ‚Ä¢ the KG construction validity was
                                                                                                                                                             not scrutinized prior using it in
                                                                                                                                                             the prediction task
  Long et al.    Investment        Stock price trend      Adhoc                  Chinese securities       node2vec              AUC                        ‚Ä¢ KG modelling was neither
    (2020)                         prediction                                    companies                                                                   illustrated nor validated,
                                                                                                                                                           ‚Ä¢ sentiment analysis can be
                                                                                                                                                             integrated to obtain better
                                                                                                                                                             performance results
  Zhang          Investment        Stock price            NER, NRE, and          Online financial         N/A                   Acc, MCC, and FM           ‚Ä¢ Lack of temporal dimension,
    et al.                         movement               CNN                    news                                                                      ‚Ä¢ limited data sources,
    (2018a)                        direction                                                                                                               ‚Ä¢ discussion on KG construction is
                                   prediction                                                                                                                inadequate
                 Financial risk    Fraud Detection        N/A                    Orange Finance           N/A                                              ‚Ä¢ Unindicated KG construction
                 management                                                                                                                                  mechanism/algorithm,
                                                                                                                                                                      (continued on next page)


                                                                                            15
B. Abu-Salih                                                                                                                Journal of Network and Computer Applications 185 (2021) 103076

Table A.5 (continued )
  Ref.            Sub-domain        KG Usage                Construction           KG Resource(s)            Embedding           Evaluation Measure      Limitation(s)
                                                            Algorithm(s)                                     Technique(s)        (s)

  Wang                                                                                                                           AUC, Precision,         ‚Ä¢ inadequate demonstration to the
    et al.                                                                                                                       Recall and F1             KG schema
    (2020c)                                                                                                                      measure
  Zhan and        Financial risk    Fraud Detection         Adhoc                  Loan transaction          word2vec            Precision               ‚Ä¢ Challenging data acquisition
    Yin           management                                                       data and call                                 Acceleration-Recall       and might lead to poor KG
    (2018)                                                                         history                                       curve                     construction and prediction
                                                                                                                                                           performance accordingly,
                                                                                                                                                         ‚Ä¢ poor evaluation to the
                                                                                                                                                           implemented KG




Table A.6
Overview of KG approaches in the Society and Politics domain.

  Ref.                   Sub-       KG Usage                   Construction            KG Resource(s)             Embedding              Evaluation            Limitation(s)
                         domain                                Algorithm(s)                                       Technique(s)           Measure(s)

  Tchechmedjiev          Social     QA (fact-checked           TagMe tool              International Fact-        N/A                    Case study            ‚Ä¢ Limited data sources,
    et al. (2019)        science    claims)                                            Checking                                                                ‚Ä¢ poor KG construction
                                                                                       Network websites                                                          algorithm, limited
                                                                                                                                                                 evaluation metrics
  Nguyen and Jung        Social     Detecting and tracing      SKG model               Social media               N/A                    Precision, Recall,    ‚Ä¢ Complexity can be
   (2019)                science    social events.                                     (Twitter)                                         and F-measure           improved by increasing
                                                                                                                                                                 periods and applying ICA
                                                                                                                                                                 on other cases,
                                                                                                                                                               ‚Ä¢ limited data sources,
                                                                                                                                                               ‚Ä¢ schema of the KG is
                                                                                                                                                                 inadequate to properly
                                                                                                                                                                 representing the
                                                                                                                                                                 relationships
  Huang et al.           Social     Identify Entity            CorrLDA2 and            DBpedia, Yago, and         N/A                    Precision, recall,    ‚Ä¢ Too many useless
   (2017b)               science    Morphs                     SVM                     Freebase                                          and F-measure           generate morphs can be
                                                                                                                                                                 avoided by adopting
                                                                                                                                                                 certain heuristic
                                                                                                                                                                 algorithms,
                                                                                                                                                               ‚Ä¢ morphs can be also
                                                                                                                                                                 extended to cover not only
                                                                                                                                                                 people but events and
                                                                                                                                                                 other entities
  Ali et al. (2019)      Social     Social good                Adhoc                   Academic research          TransE, ComplEx,       Mean rank and         ‚Ä¢ Limited conceptual
                         science    recommender system                                 papers                     TransH, TransR,        hits@k                  presentation of the KG in
                                                                                                                  TransD, DistMult                               terms of entities and
                                                                                                                  and RESCAL                                     relations,
                                                                                                                                                               ‚Ä¢ results can be improved
                                                                                                                                                                 by using reinforcement
                                                                                                                                                                 learning
  Abu-Salih et al.       Politics   Link prediction,           Adhoc using IBM         BBC Politics               TransE, DistMult.      Hits@N, MMR,          ‚Ä¢ Limited discussion on the
   (2020b)                          clustering, and            Watson NLU              ontology, Wordnet,         ComplEx, HolE,         Accuracy,               utility of the KG in a
                                    visualisation                                      Google KG and light-       ConvE, and             Precision, Recall       practical real-life
                                                                                       wight ontologies.          ConvKB,                and F-score             example,
                                                                                                                                                               ‚Ä¢ limited discussion on the
                                                                                                                                                                 KG construction
                                                                                                                                                                 algorithms.
  Laufer and             Politics   Trustworthy claims         Adhoc/                  Se Liga na Politica        N/A                    Case Study            ‚Ä¢ Limited direct relations
    Schwabe                         fact in the political      nanopublication         (SLNP)                                                                    between political
    (2017)                          system                     model1                                                                                            organizations,
                                                                                                                                                               ‚Ä¢ lack of fine-grained pat¬≠
                                                                                                                                                                 terns in the political agent
                                                                                                                                                                 domain,
                                                                                                                                                               ‚Ä¢ the utility of the
                                                                                                                                                                 incorporated provenance
                                                                                                                                                                 dimension was not
                                                                                                                                                                 properly validated
  Chen et al.            Politics   Political ideology         Holistic lexicon-       DBpedia, Twitter and       N/A                    Accuracy              ‚Ä¢ Imperfect use of
    (2017)                          detection                  based approach          ideological books                                                         evaluation strategy and
                                                                                       corpus                                                                    metrics,
                                                                                                                                                               ‚Ä¢ no KG Embedding was
                                                                                                                                                                 undertaken, thus, no
                                                                                                                                                                 rationale provided on the
                                                                                                                                                                 benchmark comparison,
                                                                                                                                                               ‚Ä¢ limited data sources
  Rudnik et al.          Politics   News articles              SpaCy                   Wikidata                   N/A                    N/A                   ‚Ä¢ Limited data sources,
    (2019)                          retrieval
                                                                                                                                                                    (continued on next page)



                                                                                             16
B. Abu-Salih                                                                                                         Journal of Network and Computer Applications 185 (2021) 103076

Table A.6 (continued )
  Ref.                 Sub-         KG Usage                 Construction      KG Resource(s)             Embedding               Evaluation           Limitation(s)
                       domain                                Algorithm(s)                                 Technique(s)            Measure(s)

                                                                                                                                                       ‚Ä¢ evaluation metrics were
                                                                                                                                                         not provided
  Liu et al. (2019c)   Politics     Politics news            Adhoc             MSN News corpus            TransE                  AUC, NDCG            ‚Ä¢ Sophisticated model
                                    recommendation                             and Microsoft Satori                               @10, and F1-           construction that hardens
                                                                                                                                  Score                  the process of usability
                                                                                                                                                         and interoperability
  Liu et al. (2020)    Culture      QA and RS for            BiLSTM-CNN-       Baidu Encyclopedia         N/A                     Precision, recall,   ‚Ä¢ Inadequate use of named
                                    Chinese ancient          CRF2 and DeepKE                                                      and F1-score           entity extraction
                                    history and culture.                                                                                                 techniques,
                                                                                                                                                       ‚Ä¢ limited data sources
 1
     http://nanopub.org/wordpress/.
 2
     BiLSTM-CNN-CRF: Short-Term Memory-Convolutional Neural Networks-Conditions Random Field.


Table A.7
Overview of KG approaches in Travel domain

  Ref.             Sub-domain          KG Usage              Construction      KG Resource(s)                      Embedding        Evaluation         Limitation(s)
                                                             Algorithm(s)                                          Technique(s)     Measure(s)

  KaÃàrle et al.    Tourism             Touristic IR          Adhoc wrapper     DMOs, GISs, Feratel1,               N/A              Case Study         ‚Ä¢ Scalability; hard to
    (2018)                             system for Tirol at   software          Infomax2, web maps3,                                                      provide a wrapper for each
                                       Austria                                 Outdooractive4 and                                                        source when it maps to
                                                                               waldhart5                                                                 Schema.org,
                                                                                                                                                       ‚Ä¢ data collection is subject
                                                                                                                                                         to error- prone,
                                                                                                                                                       ‚Ä¢ poor KG construction
                                                                                                                                                         evaluation
  Zhang et al.     Tourism             Chinese tourism-      NLP -Skip-Gram    Sogou-T6, Chinese                   N/A              Accuracy           ‚Ä¢ Inadequate evaluation
    (2019b)                            domain                Model             Wikipedia dump7, and                                                      measures,
                                       knowledge service                       Zhishi.me8                                                              ‚Ä¢ lack of benchmark
                                                                                                                                                         comparisons with other
                                                                                                                                                         related KGs
  Yang et al.      Tourism             KG-QA in tourism      Adhoc entity      Manual collection and               N/A              Accuracy           ‚Ä¢ Inadequate discussion on
    (2020)                                                   recognition       NLPCC2016KBQA dataset9                                                    rationale on entity and
                                                             algorithm and                                                                               relation extraction,
                                                             CNN                                                                                       ‚Ä¢ limited evaluation metrics
  Calleja et al.   Tourism             Spanish tourism-      Adhoc based on    Wikitravel                          N/A              Precision,         ‚Ä¢ Construction of the KG led
    (2018)                             oriented              GATE pipeline                                                          recall and F-        to import noisy data,
                                       knowledge service                                                                            measure            ‚Ä¢ limited data sources.
  Zhou and         Transportation      Urban traffic         Adhoc             Beijing traffic data and            N/A              Accuracy, and      ‚Ä¢ Limited discussion on KG
    Chen           and traffic         congestion                              meteorological data.                                 F1                   construction including
    (2019)                                                                                                                                               entity and relation
                                                                                                                                                         extraction approaches
  Muppalla         Transportation      Traffic image         Adhoc             Imagery data                        N/A              Subjective         ‚Ä¢ Poor evaluation approach,
   et al.          and traffic         feature extraction                                                                           evaluation         ‚Ä¢ traffic cameras are prone
   (2017)                                                                                                                                                to errors (weather,
                                                                                                                                                         lighting, maintenance,
                                                                                                                                                         etc.)
  Wang et al.      Transportation      Railway Electrical    Adhoc and         China Railway electrical            N/A              Precision,         ‚Ä¢ Limited data sources,
   (2019d)         and traffic         Accident Analysis     BiLSTM-CRF        accidents data                                       Recall and F1      ‚Ä¢ inadequate discussion on
                                                                                                                                                         utility of the constructed
                                                                                                                                                         KG,
                                                                                                                                                       ‚Ä¢ lack of benchmark
                                                                                                                                                         comparison
  Zhang et al.     Transportation      Knowledge             Adhoc             IMDG Code                           N/A              Case study         ‚Ä¢ Poor discussion on entity
    (2020c)        and traffic         integration of                                                                                                    and relation extraction
                                       maritime                                                                                                          algorithms,
                                       dangerous goods.                                                                                                ‚Ä¢ lack of proper evaluation
                                                                                                                                                         metrics to validate the
                                                                                                                                                         utility of the proposed KG
 1
     https://www.feratel.com/.
 2
     https://www.infomax.de/.
 3
     https://general-solutions.eu.
 4
     https://www.outdooractive.com.
 5
     https://www.waldhart.at/.
 6
     https://www.sogou.com/labs/resource/t.php.
 7
     https://dumps.wikimedia.org/zhwiki/.
 8
     http://openkg.cn/dataset/zhishi-me-dump.
 9
     https://github.com/huangxiangzhou/NLPCC2016KBQA.




                                                                                     17
B. Abu-Salih                                                                                                                Journal of Network and Computer Applications 185 (2021) 103076


References                                                                                          Collins, J.B., Clark, D., 2014. Towards an Ontology of Physics. NAVAL RESEARCH LAB
                                                                                                        WASHINGTON DC.
                                                                                                    Cui, J., Yu, S., 2019. Fostering deeper learning in a flipped classroom: effects of
Abu-Salih, B., Wongthongtham, P., Chan, K.Y., 2018. Twitter mining for ontology-based
                                                                                                        knowledge graphs versus concept maps. Br. J. Educ. Technol. 50 (5), 2308‚Äì2328.
     domain discovery incorporating machine learning. J. Knowl. Manag. 22 (5),
                                                                                                    Cui, L., et al., 2020. DETERRENT: knowledge guided graph attention network for
     949‚Äì981.
                                                                                                        detecting healthcare misinformation. In: Proceedings of the 26th ACM SIGKDD
Abu-Salih, B., et al., 2019. Social Credibility Incorporating Semantic Analysis and
                                                                                                        International Conference on Knowledge Discovery & Data Mining.
     Machine Learning: A Survey of the State-Of-The-Art and Future Research Directions.
                                                                                                    Deng, Y., et al., 2019a. Knowledge graph based learning guidance for cybersecurity
     Springer International Publishing, Cham.
                                                                                                        hands-on labs. In: Proceedings of the ACM Conference on Global Computing
Abu-Salih, B., et al., 2020a. Time-aware domain-based social influence prediction. J. Big
                                                                                                        Education.
     Data 7 (1), 10.
                                                                                                    Deng, S., et al., 2019b. Knowledge-driven stock trend prediction and explanation via
Abu-Salih, B., et al., 2020b. Relational Learning Analysis of Social Politics Using
                                                                                                        temporal convolutional network. In: Companion Proceedings of the 2019 World
     Knowledge Graph Embedding arXiv preprint arXiv:2006.01626.
                                                                                                        Wide Web Conference.
Abu-Salih, B., et al., 2021a. Toward a knowledge-based personalised recommender
                                                                                                    Dettmers, T., et al., 2018. Convolutional 2d knowledge graph embeddings. In: Thirty-
     system for mobile app development. J. Univers. Comput. Sci. 27 (2), 208‚Äì229.
                                                                                                        Second AAAI Conference on Artificial Intelligence.
Abu-Salih, B., Wongthongtham, P., Zhu, D., Chan, K.Y., Rudra, A., 2021b. Social Big Data
                                                                                                    D√≠az, G., et al., 2020. An Intelligent Transportation System to control air pollution and
     Analytics: Practices, Techniques, and Applications. Springer, Singapore.
                                                                                                        road traffic in cities integrating CEP and Colored Petri Nets. Neural Comput. Appl.
Al-Moslmi, T., et al., 2020. Named entity extraction for knowledge graphs: a literature
                                                                                                        32 (2), 405‚Äì426.
     overview. IEEE Access 8, 32862‚Äì32881.
                                                                                                    Ding, X., et al., 2016. Knowledge-driven event embedding for stock prediction. In:
Ali, M., et al., 2019. Improving access to science for social good. In: Joint European
                                                                                                        Proceedings of Coling 2016, the 26th International Conference on Computational
     Conference on Machine Learning and Knowledge Discovery in Databases. Springer.
                                                                                                        Linguistics: Technical Papers.
Aliyu, I., Kana, A., Aliyu, S., 2020. Development of knowledge graph for university
                                                                                                    Dong, X., et al., 2014. Knowledge vault: a web-scale approach to probabilistic knowledge
     courses management. Int. J. Educ. Manag. Eng. 10 (2), 1.
                                                                                                        fusion. In: Proceedings of the 20th ACM SIGKDD International Conference on
Aumayr, E., Wang, M., Bosneag, A.-M., 2019. Probabilistic knowledge-graph based
                                                                                                        Knowledge Discovery and Data Mining.
     workflow recommender for network management automation. In: 2019 IEEE 20th
                                                                                                    Dupre, J., 2014. A process ontology for biology. Philosopher‚Äôs Mag. (67), 81‚Äì88.
     International Symposium on" A World of Wireless, Mobile and Multimedia
                                                                                                    Ehrlinger, L., WoÃà√ü, W., 2016. Towards a definition of knowledge graphs. SEMANTiCS
     Networks"(WoWMoM). IEEE.
                                                                                                        (Posters, Demos, SuCCESS) 48, 1‚Äì4.
Bellomarini, L., Sallinger, E., Vahdati, S., 2020. Knowledge graphs: the layered
                                                                                                    Elnagar, S., Weistroffer, H.R., 2019. Introducing knowledge graphs to decision support
     perspective. In: Knowledge Graphs and Big Data Processing. Springer, Cham,
                                                                                                        systems design. In: EuroSymposium on Systems Analysis and Design. Springer.
     pp. 20‚Äì34.
                                                                                                    Erkimbaev, A.O., et al., 2019. Ontological concepts and taxonomies for nano world. J.
Berven, A., et al., 2020. A knowledge-graph platform for newsrooms. Comput. Ind. 123,
                                                                                                        Inf. Knowl. Manag. 18, 1950014, 02.
     103321.
                                                                                                    Fader, A., Soderland, S., Etzioni, O., 2011. Identifying relations for open information
Bi, Y., et al., 2020. DCDIR: a deep cross-domain recommendation system for cold start
                                                                                                        extraction. In: Proceedings of the 2011 Conference on Empirical Methods in Natural
     users in insurance domain. In: Proceedings of the 43rd International ACM SIGIR
                                                                                                        Language Processing.
     Conference on Research and Development in Information Retrieval.
                                                                                                    Fan, Y., et al., 2017. Dkgbuilder: an architecture for building a domain knowledge graph
Bianchi, F., et al., 2020. Knowledge Graph Embeddings and Explainable AI arXiv preprint
                                                                                                        from scratch. In: International Conference on Database Systems for Advanced
     arXiv:2004.14843.
                                                                                                        Applications. Springer.
Bonatti, P.A., et al., 2019. Knowledge graphs: new directions for knowledge
                                                                                                    Fan, C., et al., 2019. Disaster City Digital Twin: a vision for integrating artificial and
     representation on the semantic web (dagstuhl seminar 18371). In: Dagstuhl Report.
                                                                                                        human intelligence for disaster management. Int. J. Inf. Manag. 102049.
     Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.
                                                                                                    Fan, R., et al., 2020a. Deep learning-based named entity recognition and knowledge
Bordes, A., et al., 2013. Translating embeddings for modeling multi-relational data. In:
                                                                                                        graph construction for geological hazards. ISPRS Int. J. Geo-Inf. 9 (1), 15.
     Advances in Neural Information Processing Systems.
                                                                                                    Fan, S., et al., 2020b. How to Construct a Power Knowledge Graph with Dispatching
Bucher, B., et al., 2020. Conciliating perspectives from mapping agencies and Web of
                                                                                                        Data? Scientific Programming, p. 2020.
     data on successful European SDIs: toward a European geographic knowledge graph.
                                                                                                    Farazi, F., et al., 2020a. Linking reaction mechanisms and quantum chemistry: an
     ISPRS Int. J. Geo-Inf. 9 (2), 62.
                                                                                                        ontological approach. Comput. Chem. Eng. 106813.
Calleja, P., et al., 2018. DBtravel: a tourism-oriented semantic graph. In: International
                                                                                                    Farazi, F., et al., 2020b. OntoKin: an ontology for chemical kinetic reaction mechanisms.
     Conference on Web Engineering. Springer.
                                                                                                        J. Chem. Inf. Model. 60 (1), 108‚Äì120.
Carlson, A., et al., 2010. In: Toward an Architecture for Never-Ending Language
                                                                                                    Farazi, F., et al., 2020c. Knowledge graph approach to combustion chemistry and
     Learning. Aaai, Atlanta.
                                                                                                        interoperability. ACS Omega 5 (29), 18342‚Äì18348.
Carriero, V.A., et al., 2019. ArCo: the Italian cultural heritage knowledge graph. In:
                                                                                                    Feng, L., 2020. Design of tourism intelligent recommendation model of mount tai scenic
     International Semantic Web Conference. Springer.
                                                                                                        area based on knowledge graph. In: 2020 International Conference on E-Commerce
Catherine, R., Cohen, W., 2016. Personalized recommendations using knowledge graphs:
                                                                                                        and Internet Technology (ECIT). IEEE.
     a probabilistic logic programming approach. In: Proceedings of the 10th ACM
                                                                                                    Feng, D., Chen, H., 2021. A small samples training framework for deep Learning-based
     Conference on Recommender Systems.
                                                                                                        automatic information extraction: case study of construction accident news reports
Chan, K.Y., et al., 2018. Affective design using machine learning: a survey and its
                                                                                                        analysis. Adv. Eng. Inf. 47, 101256.
     prospect of conjoining big data. Int. J. Comput. Integrated Manuf. 33 (7), 645‚Äì669.
                                                                                                    Fu, X., et al., 2018. Stochastic optimization for market return prediction using financial
Chaves-Fraga, D., et al., 2019. What are the parameters that affect the construction of a
                                                                                                        knowledge graph. In: 2018 IEEE International Conference on Big Knowledge (ICBK).
     knowledge graph?. In: OTM Confederated International Conferences" on the Move to
                                                                                                        IEEE.
     Meaningful Internet Systems. Springer.
                                                                                                    Fu, D., et al., 2019. In: Enhancing Semantic Search of Crowdsourcing IT Services Using
Chaves-Fraga, D., et al., 2020. GTFS-Madrid-Bench: a benchmark for virtual knowledge
                                                                                                        Knowledge Graph. SEKE.
     graph access in the transport domain. J. Web Semant. 65, 100596.
                                                                                                    Fujun, Z., Quanhui, Y., Luyun, Y., 2017. Analysis of technical opportunity in marine
Chen, W., et al., 2017. In: Opinion-aware Knowledge Graph for Political Ideology
                                                                                                        science field based on knowledge graph. Sci. Technol. Manag. Res. 2017 (24), 25.
     Detection. IJCAI.
                                                                                                    Gao, J., et al., reportEfficient Knowledge Graph Accuracy Evaluation (Technical Report
Chen, P., et al., 2018a. KnowEdu: a system to construct knowledge graph for education.
                                                                                                        Version).
     Ieee Access 6, 31553‚Äì31563.
                                                                                                    Gao, X., et al., 2019. Construction of knowledge map of continuous fiber reinforced
Chen, P., et al., 2018b. An automatic knowledge graph construction system for K-12
                                                                                                        ceramic matrix composites. In: Proceedings of the 2019 8th International Conference
     education. In: Proceedings of the Fifth Annual ACM Conference on Learning at Scale.
                                                                                                        on Computing and Pattern Recognition.
Chen, H., et al., 2019a. A practical framework for evaluating the quality of knowledge
                                                                                                    Gatta, R., et al., 2017. Generating and comparing knowledge graphs of medical processes
     graph. In: China Conference on Knowledge Graph and Semantic Computing.
                                                                                                        using pMineR. In: Proceedings of the Knowledge Capture Conference.
     Springer.
                                                                                                    Goodwin, T.R., Harabagiu, S.M., 2017. Knowledge representations and inference
Chen, Y., et al., 2019b. Time-aware smart object recommendation in social Internet of
                                                                                                        techniques for medical question answering. ACM Trans. Intell. Syst. Technol. (TIST)
     things. IEEE Internet Things J. 7 (3), 2014‚Äì2027.
                                                                                                        9 (2), 1‚Äì26.
Chen, I.Y., et al., 2020a. Robustly extracting medical knowledge from EHRs: a case study
                                                                                                    Groth, P., Gibson, A., Velterop, J., 2010. The anatomy of a nanopublication. Inf. Serv.
     of learning a health knowledge graph. In: Pac Symp Biocomput. World Scientific.
                                                                                                        Use 30 (1‚Äì2), 51‚Äì56.
Chen, X., Jia, S., Xiang, Y., 2020b. A review: knowledge reasoning over knowledge
                                                                                                    Hastings, J., et al., 2012. Structure-based classification and ontology in chemistry. J.
     graph. Expert Syst. Appl. 141, 112948.
                                                                                                        Cheminf. 4 (1), 8.
Cheng, D., et al., 2020. Knowledge graph-based event embedding framework for
                                                                                                    Haussmann, S., et al., 2019. FoodKG: a semantics-driven knowledge graph for food
     financial quantitative investments. In: Proceedings of the 43rd International ACM
                                                                                                        recommendation. In: International Semantic Web Conference. Springer.
     SIGIR Conference on Research and Development in Information Retrieval.
                                                                                                    Heist, N., 2018. Towards knowledge graph construction from entity Co-occurrence.
Chi, Y., et al., 2018a. Knowledge management in healthcare sustainability: a smart
                                                                                                        EKAW (Doctoral Consortium).
     healthy diet assistant in traditional Chinese medicine culture. Sustainability 10 (11),
                                                                                                    Heist, N., et al., 2020. Knowledge Graphs on the Web-An Overview.
     4197.
                                                                                                    Hooi, E.K.J., et al., 2019. TAGraph: knowledge graph of threat actor. In: 2019
Chi, Y., et al., 2018b. Knowledge graph in smart education: a case study of
                                                                                                        International Conference on Cybersecurity (ICoCSec). IEEE.
     entrepreneurship scientific publication management. Sustainability 10 (4), 995.
                                                                                                    Huang, Z., et al., 2017a. Constructing knowledge graphs of depression. In: International
Choi, W., Lee, H., 2019. Inference of biomedical relations among chemicals, genes,
                                                                                                        Conference on Health Information Science. Springer.
     diseases, and symptoms using knowledge representation learning. IEEE Access 7,
     179373‚Äì179384.


                                                                                               18
B. Abu-Salih                                                                                                                Journal of Network and Computer Applications 185 (2021) 103076

Huang, L., et al., 2017b. KIEM: a knowledge graph based method to identify entity                  Liu, D., et al., 2019c. News graph: an enhanced knowledge graph for news
     morphs. In: Proceedings of the 2017 ACM on Conference on Information and                           recommendation. In: KaRS@ CIKM.
     Knowledge Management.                                                                         Liu, S., et al., 2020. Preliminary study on the knowledge graph construction of Chinese
Huang, L., et al., 2019. Towards smart healthcare management based on knowledge                         ancient history and culture. Information 11 (4), 186.
     graph technology. In: Proceedings of the 2019 8th International Conference on                 Long, J., et al., 2020. An integrated framework of deep learning and knowledge graph for
     Software and Computer Applications.                                                                prediction of stock price trend: an application in Chinese stock exchange market.
Huang, S., Wang, Y., Yu, X., 2020. Design and implementation of oil and gas information                 Appl. Soft Comput. 106205.
     on intelligent search engine based on knowledge graph. In: Journal of Physics:                Lu, C., Laublet, P., Stankovic, M., 2016. Travel attractions recommendation with
     Conference Series. IOP Publishing.                                                                 knowledge graphs. In: European Knowledge Acquisition Workshop. Springer.
Hubauer, T., et al., 2018. Use cases of the industrial knowledge graph at siemens. In:             M Keller, R., 2019. Building a knowledge graph for the air traffic management
     International Semantic Web Conference (P&D/Industry/BlueSky).                                      community. In: Companion Proceedings of the 2019 World Wide Web Conference.
Humayun, F., et al., 2020. A computational approach for mapping heme biology in the                Ma, Y., Tresp, V., Daxberger, E.A., 2019. Embedding models for episodic knowledge
     context of hemolytic disorders. Front Bioeng. Biotechnol. 8, 74.                                   graphs. J. Web Semant. 59, 100490.
Hunter, L.E., 2017. Knowledge-based biomedical data science. EPJ Data Sci 1 (1‚Äì2),                 Malik, K.M., et al., 2020. Automated domain-specific healthcare knowledge graph
     19‚Äì25.                                                                                             curation framework: subarachnoid hemorrhage as phenotype. Expert Syst. Appl.
HyvoÃànen, E., 2012. Publishing and using cultural heritage linked data on the semantic                  145, 113120.
     web. Synth. Lect. Semant. Web: Theor. Technol. 2 (1), 1‚Äì159.                                  Marchand, E., Gagnon, M., Zouaq, A., 2020. Extraction of a knowledge graph from
Ji, S., et al., 2020. A Survey on Knowledge Graphs: Representation, Acquisition and                     French cultural heritage documents. In: ADBIS, TPDL and EDA 2020 Common
     Applications arXiv preprint arXiv:2002.00388.                                                      Workshops and Doctoral Consortium. Springer.
Jia, Y., et al., 2018. A practical approach to constructing a knowledge graph for                  Marz, N., Warren, J., 2015. Big Data: Principles and Best Practices of Scalable Realtime
     cybersecurity. Engineering 4 (1), 53‚Äì60.                                                           Data Systems. Manning Publications Co.
Jiang, T., et al., 2016. Towards time-aware knowledge graph completion. In: Proceedings            Matsunaga, D., Suzumura, T., Takahashi, T., 2019. Exploring Graph Neural Networks for
     of COLING 2016, the 26th International Conference on Computational Linguistics:                    Stock Market Predictions with Rolling Window Analysis arXiv preprint arXiv:
     Technical Papers.                                                                                  1909.10660.
Jiang, B., et al., 2019. Intelligent interaction with virtual geographical environments            Meissner, R., KoÃàbis, L., 2020. Annotated knowledge graphs for teaching in higher
     based on geographic knowledge graph. ISPRS Int. J. Geo-Inf. 8 (10), 428.                           education. In: International Conference on Web Engineering. Springer.
JimeÃÅnez-Ruiz, E., Grau, B.C., 2011. Logmap: logic-based and scalable ontology matching.           Meneghello, J., et al., 2020. Unlocking social media and user generated content as a data
     In: International Semantic Web Conference. Springer.                                               source for knowledge management. Int. J. Knowl. Manag. 16 (1), 101‚Äì122.
KaÃàrle, E., et al., 2018. Building an ecosystem for the tyrolean tourism knowledge graph.          Menon, A., Krdzavac, N.B., Kraft, M., 2019. From database to knowledge graph‚Äîusing
     In: International Conference on Web Engineering. Springer.                                         data in chemistry. Curr. Opin. Chem. Eng. 26, 33‚Äì37.
Kejriwal, M., 2019. Domain-Specific Knowledge Graph Construction. Springer.                        Mohammadhassanzadeh, H., et al., 2018. Investigating plausible reasoning over
Kejriwal, M., Shao, R., Szekely, P., 2019. Expert-guided entity extraction using expressive             knowledge graphs for semantics-based health data analytics. In: 2018 IEEE 27th
     rules. In: Proceedings of the 42nd International ACM SIGIR Conference on Research                  International Conference on Enabling Technologies: Infrastructure for Collaborative
     and Development in Information Retrieval.                                                          Enterprises (WETICE). IEEE.
Keller, R., 2018. The NASA Air Traffic Management Ontology (Atmonto)‚Äìrelease Dated                 Muppalla, R., et al., 2017. A knowledge graph framework for detecting traffic events
     March 2018. 2019, Technical Report. URL ‚Ä¶. National Aeronautics and Space                          using stationary cameras. In: Proceedings of the 2017 ACM on Web Science
     Administration.                                                                                    Conference.
Kiesling, E., et al., 2019. The SEPSES knowledge graph: an integrated resource for                 Myklebust, E.B., et al., 2019. Knowledge graph embedding for ecotoxicological effect
     cybersecurity. In: International Semantic Web Conference. Springer.                                prediction. In: International Semantic Web Conference. Springer.
Kim, K., et al., 2020. GREG: a global level relation extraction with knowledge graph               Nabipourshiri, R., Abu-Salih, B., Wongthongtham, P., 2018. Tree-based classification to
     embedding. Appl. Sci. 10 (3), 1181.                                                                users‚Äô trustworthiness in OSNs. In: Proceedings of the 2018 10th International
Kipf, T.N., Welling, M., 2016. Semi-supervised Classification with Graph Convolutional                  Conference on Computer and Automation Engineering. ACM, Brisbane, Australia,
     Networks arXiv preprint arXiv:1609.02907.                                                          pp. 190‚Äì194.
Krdzavac, N., et al., 2019. An ontology and semantic web service for quantum chemistry             Nayak, A., Kesri, V., Dubey, R.K., 2020. Knowledge graph based automated generation of
     calculations. J. Chem. Inf. Model. 59 (7), 3154‚Äì3165.                                              test cases in software engineering. In: Proceedings of the 7th ACM IKDD CoDS and
Krinkin, K., et al., 2020. Models of telecommunications network monitoring based on                     25th COMAD, pp. 289‚Äì295.
     knowledge graphs. In: 2020 9th Mediterranean Conference on Embedded Computing                 Nguyen, H.L., Jung, J.J., 2019. Social event decomposition for constructing knowledge
     (MECO). IEEE.                                                                                      graph. Future Generat. Comput. Syst. 100, 10‚Äì18.
Kuhn, P., et al., 2016. Type inference on Wikipedia list pages. Informatik 2016.                   Nguyen, D.Q., et al., 2017. A Novel Embedding Model for Knowledge Base Completion
Kunlin, Y., 2018. A memory-enhanced framework for financial fraud detection. In: 2018                   Based on Convolutional Neural Network arXiv preprint arXiv:1712.02121.
     17th IEEE International Conference on Machine Learning and Applications (ICMLA).              Nickel, M., Tresp, V., Kriegel, H.-P., 2011. In: A Three-Way Model for Collective Learning
     IEEE.                                                                                              on Multi-Relational Data. Icml.
Laufer, C., Schwabe, D., 2017. On modeling political systems to support the trust process.         Nickel, M., et al., 2015. A review of relational machine learning for knowledge graphs.
     In: PrivOn@ ISWC..                                                                                 Proc. IEEE 104 (1), 11‚Äì33.
Le-Phuoc, D., et al., 2016. The graph of things: a step towards the live knowledge graph           Nickel, M., Rosasco, L., Poggio, T., 2016. Holographic embeddings of knowledge graphs.
     of connected things. J. Web Semant. 37, 25‚Äì35.                                                     In: Thirtieth Aaai Conference on Artificial Intelligence.
Leblay, J., Chekol, M.W., 2018. Deriving validity time in knowledge graph. In:                     Paulheim, H., 2017. Knowledge graph refinement: a survey of approaches and evaluation
     Companion Proceedings of the the Web Conference 2018.                                              methods. Semantic Web 8 (3), 489‚Äì508.
Li, R., et al., 2019. A knowledge graph framework for software-defined industrial cyber-           Pezeshkpour, P., Tian, Y., Singh, S., 2020. Revisiting Evaluation of Knowledge Base
     physical systems. In: IECON 2019-45th Annual Conference of the IEEE Industrial                     Completion Models. Automated Knowledge Base Construction.
     Electronics Society. IEEE.                                                                    Pingle, A., et al., 2019. Relext: relation extraction using deep learning approaches for
Li, Y., et al., 2020a. Domain specific knowledge graphs as a service to the public:                     cybersecurity knowledge graph improvement. In: Proceedings of the 2019 IEEE/
     powering social-impact funding in the US. In: Proceedings of the 26th ACM SIGKDD                   ACM International Conference on Advances in Social Networks Analysis and Mining.
     International Conference on Knowledge Discovery & Data Mining.                                Piplai, A., et al., 2020. Creating cybersecurity knowledge graphs from malware after
Li, L., et al., 2020b. Real-world data medical knowledge graph: construction and                        action reports. IEEE Access 8, 211691‚Äì211703.
     applications. Artif. Intell. Med. 103, 101817.                                                Ramnani, R.R., Sengupta, S., Debnath, P., 2018. Intelligent travel advisor: a goal oriented
Li, X., et al., 2020c. A knowledge graph-aided concept‚Äìknowledge approach for                           virtual agent with task modeling, planning and user personalization. In: Proceedings
     evolutionary smart product‚Äìservice system development. J. Mech. Des. 142 (10).                     of the 18th International Conference on Intelligent Virtual Agents.
Li, Z., et al., 2020d. Demonstration of fault localization in optical networks based on            Raskin, R.G., Pan, M.J., 2005. Knowledge representation in the semantic web for Earth
     knowledge graph and graph neural network. In: Optical Fiber Communication                          and environmental terminology (SWEET). Comput. Geosci. 31 (9), 1119‚Äì1125.
     Conference. Optical Society of America.                                                       Rastogi, N., Zaki, M.J., 2020. Personal Health Knowledge Graphs for Patients arXiv
Liang, C., et al., 2018. In: Investigating Active Learning for Concept Prerequisite                     preprint arXiv:2004.00071.
     Learning. AAAI.                                                                               Rotmensch, M., et al., 2017. Learning a health knowledge graph from electronic medical
Liang, X., Cao, H., Zhang, W., 2020. Knowledge extraction experiment based on tourism                   records. Sci. Rep. 7 (1), 5994.
     knowledge graph Q & A data set. In: 2020 IEEE International Conference on Power,              Rudnik, C., et al., 2019. Searching news articles using an event knowledge graph
     Intelligent Computing and Systems (ICPICS). IEEE.                                                  leveraged by wikidata. In: Companion Proceedings of the 2019 World Wide Web
Lin, Z., Yang, D., Yin, X., 2020. Patient Similarity via Joint Embeddings of Medical                    Conference.
     Knowledge Graph and Medical Entity Descriptions. IEEE Access.                                 Sadeghi, A., Lehmann, J., 2019. Linking physicians to medical research results via
Liu, H., et al., 2016. Learning concept graphs from online educational data. J. Artif.                  knowledge graph embeddings and Twitter. In: Joint European Conference on
     Intell. Res. 55, 1059‚Äì1090.                                                                        Machine Learning and Knowledge Discovery in Databases. Springer.
Liu, Y., et al., 2019a. Anticipating stock market of the renowned companies: a knowledge           Sahlins, M.D., 1960. The origin of society. Sci. Am. 203 (3), 76‚Äì88.
     graph approach. Complexity, 2019.                                                             Sahu, A., et al., 2018. Method and System for Content Processing to Query Multiple
Liu, J., Lu, Z., Du, W., 2019b. Combining enterprise knowledge graph and news                           Healthcare-Related Knowledge Graphs. Google Patents.
     sentiment analysis for stock price prediction. In: Proceedings of the 52nd Hawaii             Salehian, H., et al., 2019. Food Knowledge Graph for a Health Tracking System. Google
     International Conference on System Sciences.                                                       Patents.




                                                                                              19
B. Abu-Salih                                                                                                                  Journal of Network and Computer Applications 185 (2021) 103076

Sandberg, M.K., et al., 2020. Explaining traffic situations‚Äìarchitecture of a virtual driving             opportunities. In: Industrial Informatics (INDIN), 2015 IEEE 13th International
     instructor. In: International Conference on Intelligent Tutoring Systems. Springer.                  Conference on. IEEE.
Schindler, D., Zapilko, B., Kr√ºger, F., 2020. Investigating software usage in the social             Wongthongtham, P., Salih, B.A., 2018. Ontology-based approach for identifying the
     sciences: a knowledge graph approach. In: European Semantic Web Conference.                          credibility domain in social Big Data. J. Organ. Comput. Electron. Commer. 28 (4),
     Springer.                                                                                            354‚Äì377.
Schwabe, D., Laufer, C., Busson, A., 2019. Building Knowledge Graphs about Political                 Wongthongtham, P., et al., 2018. State-of-the-Art ontology annotation for personalised
     Agents in the Age of Misinformation arXiv preprint arXiv:1901.11408.                                 teaching and learning and prospects for smart learning recommender based on
Shen, Y., et al., 2019. KGDDS: a system for drug-drug similarity measure in therapeutic                   multiple intelligence and fuzzy ontology. Int. J. Fuzzy Syst. 20 (4), 1357‚Äì1372.
     substitution based on knowledge graph curation. J. Med. Syst. 43 (4), 92.                       Wu, W., et al., 2012. Probase: a probabilistic taxonomy for text understanding. In:
Sheng, M., et al., 2020. DSQA: a domain specific QA system for smart health based on                      Proceedings of the 2012 ACM SIGMOD International Conference on Management of
     knowledge graph. In: International Conference on Web Information Systems and                         Data.
     Applications. Springer.                                                                         Wu, J., et al., 2020. Event-centric tourism knowledge graph‚Äîa case study of hainan. In:
Sheu, H.-S., Li, S., 2020. Context-aware graph embedding for session-based news                           International Conference on Knowledge Science, Engineering and Management.
     recommendation. In: Fourteenth ACM Conference on Recommender Systems.                                Springer.
Shi, D., et al., 2020. A Learning Path Recommendation Model Based on a                               Xiao, H., et al., 2019. Embedding and predicting software security entity relationships: a
     Multidimensional Knowledge Graph Framework for E-Learning. Knowledge-Based                           knowledge graph based approach. In: International Conference on Neural
     Systems, p. 105618.                                                                                  Information Processing. Springer.
Singhal, A., 2012. Introducing the Knowledge Graph: Things, Not Strings. Google.                     Xie, R., et al., 2019. DeepLink: a code knowledge graph based deep learning approach for
Smirnova, A., CudreÃÅ-Mauroux, P., 2018. Relation extraction using distant supervision: a                  issue-commit link recovery. In: 2019 IEEE 26th International Conference on
     survey. ACM Comput. Surv. 51 (5), 1‚Äì35.                                                              Software Analysis, Evolution and Reengineering (SANER). IEEE.
Su, Y., Zhang, Y., 2020. Automatic construction of subject knowledge graph based on                  Xie, C., et al., 2020. Multi-layer Internet of things middleware based on knowledge
     educational big data. In: Proceedings of the 2020 the 3rd International Conference                   graph. IEEE Internet Things J.
     on Big Data and Education.                                                                      Xinqing, W., et al., 1999. APPLICATION OF" THE TERMINOLOGY CLASSIFICATION
Suchanek, F.M., Kasneci, G., Weikum, G., 2007. Yago: a core of semantic knowledge. In:                    CODES OF GEOLOGY AND MINERAL RESOURCES, vol. 5. ON GEOLOGICAL AND
     Proceedings of the 16th International Conference on World Wide Web.                                  MINERAL RESOURCES POINT-SOURCE INFORMATION SYSTEM.
Sun, K., et al., 2016. Visualization for knowledge graph based on education data. Int. J.            Xue, Q., Chuah, M.C., 2019. Explainable deep learning based medical diagnostic system.
     Softw. Inf. 10 (3).                                                                                  Smart Health 13, 100068.
Sun, H., et al., 2020. Medical knowledge graph to enhance fraud, waste, and abuse                    Yan, H., Yang, J., Wan, J., 2020. KnowIME: a system to construct a knowledge graph for
     detection on claim data: model development and performance evaluation. JMIR Med                      intelligent manufacturing equipment. IEEE Access 8, 41805‚Äì41813.
     Inform 8 (7), e17653.                                                                           Yang, B., et al., 2014. Embedding Entities and Relations for Learning and Inference in
Tao, X., et al., 2020a. Mining Health Knowledge Graph for Health Risk Prediction. World                   Knowledge Bases arXiv preprint arXiv:1412.6575.
     Wide Web, pp. 1‚Äì22.                                                                             Yang, A., et al., 2019a. Enhancing pre-trained language representations with rich
Tao, Y., Li, M., Hu, W., 2020b. Research on knowledge graph model for cybersecurity                       knowledge for machine reading comprehension. In: Proceedings of the 57th Annual
     logs based on ontology and classified protection. In: Journal of Physics: Conference                 Meeting of the Association for Computational Linguistics.
     Series. IOP Publishing.                                                                         Yang, Y., et al., 2019b. Multi-source heterogeneous information fusion of power assets
Tari, L., 2013. Knowledge inference. Encycl. Syst. Biol. 1074‚Äì1078.                                       based on knowledge graph. In: 2019 IEEE International Conference on Service
Taylor, K.R., et al., 2006. Bringing chemical data onto the semantic web. J. Chem. Inf.                   Operations and Logistics, and Informatics (SOLI). IEEE.
     Model. 46 (3), 939‚Äì952.                                                                         Yang, L., et al., 2020. Research on tourism question answering system based on Xi‚Äôan
Tchechmedjiev, A., et al., 2019. ClaimsKG: a knowledge graph of fact-checked claims. In:                  tourism knowledge graph. In: Journal of Physics: Conference Series. IOP Publishing.
     International Semantic Web Conference. Springer.                                                Yao, S., et al., 2020. Joint embedding learning of educational knowledge graphs. In:
Tong, R., Xue, L., Wang, H., 2016. Building and Exploring an Enterprise Knowledge                         Artificial Intelligence Supported Educational Technologies. Springer, pp. 209‚Äì224.
     Graph for Investment Analysis. GROTH P, SIMPERL E, GRAY A, et al. The Semantic                  Yu, H., et al., 2020. A domain knowledge graph construction method based on
     Web-ISWC.                                                                                            Wikipedia. J. Inf. Sci., 0165551520932510
Trouillon, T., et al., 2016. Complex embeddings for simple link prediction. In:                      Yuan, J., et al., 2020. Constructing biomedical domain-specific knowledge graph with
     International Conference on Machine Learning (ICML).                                                 minimum supervision. Knowl. Inf. Syst. 62 (1), 317‚Äì336.
Wang, J., 2020. Knowledge graph analysis of internal control field in colleges. Teh.                 Zaveri, A., et al., 2016. Quality assessment for linked data: a survey. Semantic Web 7 (1),
     Vjesn. 27 (1), 67‚Äì72.                                                                                63‚Äì93.
Wang, Y., Luo, J., 2018. An incremental reasoning algorithm for large scale knowledge                Zeng, J., Nakano, Y.I., 2020. Exploiting a large-scale knowledge graph for question
     graph. In: International Conference on Knowledge Science, Engineering and                            generation in food preference interview systems. In: Proceedings of the 25th
     Management. Springer.                                                                                International Conference on Intelligent User Interfaces Companion.
Wang, R.Y., Strong, D.M., 1996. Beyond accuracy: what data quality means to data                     Zhan, Q., Yin, H., 2018. A loan application fraud detection method based on knowledge
     consumers. J. Manag. Inf. Syst. 12 (4), 5‚Äì33.                                                        graph and neural network. In: Proceedings of the 2nd International Conference on
Wang, C., Zhu, H., 2020. Representing fine-grained Co-occurrences for behavior-based                      Innovation in Artificial Intelligence.
     fraud detection in online payment services. IEEE Trans. Dependable Secure Comput.               Zhang, N., Zhang, L., 2020. A Knowledge Graph Analysis on PE Teachers‚Äô Research
Wang, Q., et al., 2017a. Knowledge graph embedding: a survey of approaches and                            Hotspots. Design Engineering, pp. 352‚Äì366.
     applications. IEEE Trans. Knowl. Data Eng. 29 (12), 2724‚Äì2743.                                  Zhang, N., et al., 2016. Semantic framework of Internet of things for smart cities: case
Wang, X., et al., 2017b. Community preserving network embedding. In: Thirty-first AAAI                    studies. Sensors 16 (9), 1501.
     Conference on Artificial Intelligence.                                                          Zhang, Y., et al., 2018a. In: Predicting Stock Price Movement Direction with Enterprise
Wang, C., et al., 2018a. Information extraction and knowledge graph construction from                     Knowledge Graph. PACIS.
     geoscience literature. Comput. Geosci. 112, 112‚Äì120.                                            Zhang, X., et al., 2018b. Improving stock market prediction via heterogeneous
Wang, H., et al., 2018b. DKN: deep knowledge-aware network for news                                       information fusion. Knowl. Base Syst. 143, 236‚Äì247.
     recommendation. In: Proceedings of the 2018 World Wide Web Conference.                          Zhang, X., et al., 2019a. Research and analysis on the field of food additive by knowledge
Wang, R., et al., 2019a. Knowledge graph embedding via graph attenuated attention                         graph construction. In: Journal of Physics: Conference Series. IOP Publishing.
     networks. IEEE Access 8, 5212‚Äì5224.                                                             Zhang, W., et al., 2019b. The Chinese knowledge graph on domain-tourism. In: Advanced
Wang, H., et al., 2019b. Service application knowledge graph and dependency system.                       Multimedia and Ubiquitous Engineering. Springer, pp. 20‚Äì27.
     In: 2019 34th IEEE/ACM International Conference on Automated Software                           Zhang, X., et al., 2020. Spatiotemporal features based geographical knowledge graph
     Engineering Workshop (ASEW). IEEE.                                                                   construction. SCIENTIA SINICA Informationis 50 (7), 1019‚Äì1032.
Wang, Z., Zhang, X., Hu, Y., 2019c. A semantic path based approach to match subgraphs                Zhang, Y., et al., 2020a. HKGB: an Inclusive, Extensible, Intelligent, Semi-auto-
     from large financial knowledge graph. In: 2019 International Conference on                           constructed Knowledge Graph Framework for Healthcare with Clinicians‚Äô Expertise
     Mathematics, Big Data Analysis and Simulation and Modelling (MBDASM 2019).                           Incorporated. Information Processing & Management, p. 102324.
     Atlantis Press.                                                                                 Zhang, L., et al., 2020b. Construction and applications of embedded aerospace software
Wang, X., Wang, J., Han, J., 2019d. Knowledge Graph Construction for Railway                              defect knowledge graph. In: Signal and Information Processing, Networking and
     Electrical Accident Analysis. In: 2019 International Conference on Machine                           Computers. Springer, pp. 470‚Äì477.
     Learning, Big Data and Business Intelligence (MLBDBI). IEEE.                                    Zhang, Q., et al., 2020c. Construction of knowledge graph of maritime dangerous goods
Wang, F., et al., 2020a. Recent advances on graph analytics and its applications in                       based on IMDG code. J. Eng. 2020 (13), 361‚Äì365.
     healthcare. In: Proceedings of the 26th ACM SIGKDD International Conference on                  Zhao, Y., Smidts, C., 2019. A method for systematically developing the knowledge base
     Knowledge Discovery & Data Mining.                                                                   of reactor operators in nuclear power plants to support cognitive modeling of
Wang, H., Wang, T., Li, Y., 2020b. Incorporating expert-based investment opinion signals                  operator performance. Reliab. Eng. Syst. Saf. 186, 64‚Äì77.
     in stock prediction: a deep learning framework. In: Proceedings of the AAAI                     Zhao, T., et al., 2019. Towards automatic mathematical exercise solving. Data Sci. Eng. 4
     Conference on Artificial Intelligence.                                                               (3), 179‚Äì192.
Wang, J., et al., 2020c. Improving Graph-Based Label Propagation Algorithm with Group                Zheng, Y., Liu, R., Hou, J., 2017. The construction of high educational knowledge graph
     Partition for Fraud Detection. Applied Intelligence, pp. 1‚Äì10.                                       based on MOOC. In: 2017 IEEE 2nd Information Technology, Networking, Electronic
Wei, J., Liu, R., 2019. A versatile approach for constructing a domain knowledge graph                    and Automation Control Conference (ITNEC). IEEE.
     for culture. Proc. Assoc. Inf. Sci. Technol. 56 (1), 808‚Äì809.                                   Zhou, G., Chen, F., 2019. Urban congestion areas prediction by combining knowledge
Wongthongtham, P., Abu-Salih, B., 2015. Ontology and trust based data warehouse in                        graph and deep spatio-temporal convolutional neural network. In: 2019 4th
     new generation of business intelligence: state-of-the-art, challenges, and


                                                                                                20
B. Abu-Salih                                                                                                            Journal of Network and Computer Applications 185 (2021) 103076

    International Conference on Electromechanical Control Technology and                        Bilal Abu-Salih: is an Assistant Professor at the University of Jordan and an Adjunct at
    Transportation (ICECTT). IEEE.                                                              Curtin University. He holds a Ph.D. in Information Systems (with a focus on Social Big Data
Zhu, Y., et al., 2017. Intelligent Learning for Knowledge Graph towards Geological Data.        Analytics) from Curtin University since 2018. He worked with various cross-disciplinary
    Scientific Programming, 2017.                                                               funded research projects which are related to data analytics, machine learning, data
Zhu, Y., et al., 2020. Knowledge-driven drug repurposing using a comprehensive drug             mining of social media, big data analysis etc. Those projects are involved with academic
    knowledge graph. Health Inf. J. 1460458220937101.                                           research and also involved software development and industrial implementation. Bilal‚Äôs
Zou, X., 2020. A survey on application of knowledge graph. JPhCS 1487 (1), 012016.              research interests include; Knowledge Graphs, Social Big Data, Social Trust, Machine
                                                                                                Learning/Data Mining, Semantic Analytics, NLP, Information Retrieval, and the like.




                                                                                           21
                                           Enhancing Knowledge Graph Construction Using
                                                      Large Language Models
                                                   1st Milena Trajanoska                           2nd Riste Stojanov                        3rd Dimitar Trajanov
                                              Faculty of Comp. Sci. and Eng.               Faculty of Comp. Sci. and Eng.              Faculty of Comp. Sci. and Eng.
                                             Ss. Cyril and Methodius University           Ss. Cyril and Methodius University          Ss. Cyril and Methodius University
                                                     Skopje, Macedonia                             Skopje, Macedonia                          Skopje, Macedonia
                                              milena.trajanoska@finki.ukim.mk                riste.stojanov@finki.ukim.mk               dimitar.trajanov@finki.ukim.mk
                                               ORCID: 0000-0003-0105-7693                   ORCID: 0000-0003-2067-3467                  ORCID: 0000-0002-3105-6010
arXiv:2305.04676v1 [cs.CL] 8 May 2023




                                           Abstract‚ÄîThe growing trend of Large Language Models                  extracted from the texts and applied for intelligent reasoning.
                                        (LLM) development has attracted significant attention, with mod-        This fact has motivated us to use some of the state-of-the-art
                                        els for various applications emerging consistently. However, the        models in an attempt to extract information from text data on
                                        combined application of Large Language Models with semantic
                                        technologies for reasoning and inference is still a challenging task.   the Web.
                                        This paper analyzes how the current advances in foundational               Yet, creating Knowledge Graphs from raw text data is a
                                        LLM, like ChatGPT, can be compared with the specialized                 complex task that requires advanced NLP techniques such as
                                        pretrained models, like REBEL, for joint entity and relation            Named Entity Recognition [3], Relation Extraction [4], and
                                        extraction. To evaluate this approach, we conducted several             Semantic Parsing [5]. Large language models such as GPT-3
                                        experiments using sustainability-related text as our use case. We
                                        created pipelines for the automatic creation of Knowledge Graphs        [6], T5 [7], and BERT [8] have shown remarkable performance
                                        from raw texts, and our findings indicate that using advanced           in these tasks, and their use has resulted in significant improve-
                                        LLM models can improve the accuracy of the process of creating          ments in the quality and accuracy of knowledge graphs.
                                        these graphs from unstructured text. Furthermore, we explored              To evaluate our approach in connecting both fields, we chose
                                        the potential of automatic ontology creation using foundation           to analyze the specific use case of sustainability. Sustainability
                                        LLM models, which resulted in even more relevant and accurate
                                        knowledge graphs.                                                       is a topic of great importance for our future, and a lot
                                           Index Terms‚ÄîChatGPT, REBEL, LLMs, Relation-extraction,               of emphasis has been placed on identifying ways to create
                                        NLP, Sustainability                                                     more sustainable practices in organizations. Sustainability has
                                                                                                                become the norm for organizations in developed countries,
                                                               I. I NTRODUCTION                                 mainly due to the rising awareness of their consumers and
                                           The technological advancements, together with the avail-             employees. However, this situation is not reflected in devel-
                                        ability of Big Data, have led to a surge in the development of          oping and underdeveloped countries to this extent. Although
                                        Large Language Models (LLMs) [1]. This trend has paved the              the perception of sustainability has improved, progress toward
                                        way for a cascade of new models being released on a regular             sustainable development has been slower, indicating the need
                                        basis, each outperforming its predecessors. These models                for more concrete guidance [9]. Moreover, theoretical research
                                        have started a revolution in the field with their capability            has attempted to link strategic management and sustainable
                                        to process massive amounts of unstructured text data and by             development in corporations in order to encourage the inte-
                                        achieving state-of-the-art results on multiple Natural Language         gration of sustainability issues into corporate activities and
                                        Processing (NLP) tasks.                                                 strategies [10]. Even though research has set a basis for
                                           However, one of the aspects which have not yet taken over            developing standards and policies in favor of sustainability, a
                                        the spotlight is the combined application of these models with          more empirical approach is needed for policy definitions and
                                        semantic technologies to enable reasoning and inference. This           analyzing an organization‚Äôs sustainability level with respect to
                                        paper attempts to fill this gap by making a connection between          the defined policies.
                                        the Deep Learning (DL) space and the semantic space, through               In this study, the goal is to make a connection between
                                        the use of NLP for creating Knowledge Graphs [2].                       LLMs and semantic reasoning to automatically generate a
                                           Knowledge Graphs are structured representations of in-               Knowledge Graph on the topic of sustainability and populate
                                        formation that capture the relationships between entities in            it with concrete instances using news articles available on the
                                        a particular domain. They are used extensively in various               Web. For this purpose, we create multiple experiments where
                                        applications, such as search engines, recommendation systems,           we utilize popular NLP models, namely Relation Extraction
                                        and question-answering systems.                                         By End-to-end Language generation (REBEL) [11] and Chat-
                                           On a related note, there is a significant amount of raw              GPT [12]. We show that although REBEL is specifically
                                        texts available on the Web which contain valuable information.          trained for relation extraction, ChatGPT, a conversational
                                        Nevertheless, this information is unusable if it cannot be              agent using a generative model, can streamline the process
of automatically creating accurate Knowledge Graphs from             Knowledge Base. The agent consists of three steps, including
an unstructured text when provided with detailed instructions.       separate models: a supervised fine-tuning (SFT) model based
   The rest of the paper is structured as follows: Section           on GPT-3 [6], a reward model, and a reinforcement learning
II presents a brief literature overview, Section III describes       model.
the methods and experimental setup, Section IV outlines the             ChatGPT was trained using Reinforcement Learning from
results of the information extraction process, Section V states      Human Feedback (RLHF) [15], employing methods similar to
the propositions for future work, and finally section VI gives       InstructGPT with minor variations in data collection. An initial
the conclusion of the work done in this paper.                       model is trained through supervised fine-tuning, with human
                                                                     AI trainers engaging in conversations, assuming both user
                  II. L ITERATURE R EVIEW
                                                                     and AI assistant roles. To aid in formulating responses, train-
A. Algorithms                                                        ers were given access to model-generated suggestions. The
   Our study focuses on the task of information extraction from      newly created dialogue dataset was then combined with the
news and reports available on the Web. For this purpose, we          InstructGPT dataset, which was transformed into a dialogue
compare the capabilities of NLP models to generate a useful          format. In order to establish a reward model for reinforcement
Knowledge Base on the topic.                                         learning, comparison data needed to be gathered, consisting
   A Knowledge Base represents information stored in a struc-        of two or more model responses ranked by quality. This data
tured format, ready to be used for analysis or inference. Often,     was collected by taking conversations between AI trainers and
Knowledge Bases are stored in the form of a graph and are            the chatbot, randomly selecting a model-generated message,
then called Knowledge Graphs.                                        sampling multiple alternative completions, and having AI
   In order to create such a Knowledge Base, we need to              trainers rank them. The reward models enabled fine-tuning of
extract information from the raw texts in a triplet format. An       ChatGPT using Proximal Policy Optimization [16], and several
example of a triplet would be <Person, Location, City>. In           iterations of this procedure were executed.
the triplet, we have a structure consisting of the following links
Entity -> Relation -> Entity, where the first entity is referred     B. Use case: Sustainability
to as the subject, the relation is a predicate, and the second
entity represents the object. In order to achieve this structured       The Global sustainability study of 2022 has reported that
information extraction, we need to identify entities in the raw      71% out of 11,500 surveyed consumers around the world are
texts, as well as the relations connecting these entities.           making changes to the way they live and the products they
   In the past, this process was implemented by leveraging           buy in an effort to live more sustainably [17]. This shows that
multi-step pipelines, where one step included Named-entity           corporations not only need to change their operations to be
Recognition (NER) [3], and another step was Relation classi-         more sustainable for the sake of the environment but also to
fication (RC) [13]. However, these multi-step pipelines often        be able to stay competitive.
prove to have unsatisfactory performance due to the propaga-            With the vast amount of unstructured data available on
tion of errors from the steps. In order to tackle this problem,      the Web, it is crucial to develop methods that can automat-
end-to-end approaches have been implemented, referred to as          ically identify sustainability-related information from news,
Relation-Extraction (RE) [4] methods.                                reports, papers, and other forms of documents. One such study
   One of the models utilized in this study is REBEL (Relation       identifies this opportunity and attempts to create a method
Extraction By End-to-end Language generation) [11], which            for directly extracting non-financial information generated by
is an auto-regressive seq2seq model based on BART [14] that          various media to provide objective ESG information [18].
performs end-to-end relation extraction for more than 200            The authors have trained an ESG classifier and recorded a
different relation types. The model achieves 74 micro-F1 and         classification accuracy of 86.66% on 4-class on texts which
51 macro-F1 scores. It was created for the purpose of joint          they manually labeled. On a related note, researchers have
entity-relation extraction.                                          taken a step further to extract useful ESG information from
   REBEL is a generative seq2seq model which attempts to             texts. In this article [19], the authors have trained a joint entity
‚Äùtranslate‚Äù the raw text into a triple format. The REBEL model       and relation extraction model on a private dataset consisting of
outputs additional tokens, which are used during its training        ESG and CSR reports annotated internally at CreÃÅdit Agricole.
to identify a triplet. These tokens include <triplet>, which         They were able to identify entities such as coal activities and
represents the beginning of a triplet, <subj>, which represents      environmental or social issues. In [20], the authors presented
the end of the subject and the start of the predicate, and           an approach for knowledge graph generation based on ESG-
<obj>, which represents the end of the predicate and start           related news and company official documents.
of the object. The authors of the paper for REBEL provide a
parsing function for extracting the triplet from the output of                                III. M ETHODS
REBEL.
   The second approach we took was to use ChatGPT [12],                This section describes the methods used in this research,
as a conversational agent and compare the performance in the         including the data collection process and the entity-relation
task of entity-relation extraction and creation of a common          extraction algorithms used to analyze the gathered data.
A. Data Collecting Process                                            approach will not work for entities that are not present on
   In order to conduct the experimental comparison of the             DBpedia.
two approaches for entity-relation extraction, news data was             2) ChatGPT: The second approach taken in this paper uses
gathered from the Web on the topic of sustainability. For this        OpenAI‚Äôs ChatGPT [12]. We have created two experiments
purpose, the News API [21] system was used. News API is               using ChatGPT.
an HTTP REST API for searching and retrieving live articles              The first experiment prompts ChatGPT to extract relations
from all over the Web. It provides the ability to search through      from the collected news articles. After extracting the relations,
the articles posted on the Web by specifying the following            we follow the same steps as with the REBEL model in order
options: keyword or phrase, date of publication, source domain        to create a comprehensive Knowledge Base.
name, and language.                                                      The second experiment focuses on creating a prompt that
   Using News API, 94 news articles from 2023-02-15 to                would directly generate the entire Knowledge Base and write
2023-03-19 on the topic of sustainability have been collected.        an ontology describing the concepts identified in the texts.
The collected texts contained various numbers of words rang-          This approach has the goal of reducing the number of manual
ing from 50 to over 4200. With the limitation of the number           steps which need to be performed in order to obtain the final
of tokens that can be passed as input to a language model,            Knowledge Graph.
additional pre-processing steps needed to be taken to account            For both experiments, we set the value of the parameter
for the texts consisting of a large number of words.                  ‚Äôtemperature‚Äô to 0 in order to get more deterministic outputs
                                                                      since OpenAI models are non-deterministic by nature.
B. Relation-Extraction Methods                                           Experiment 1. For the first experiment, we prompt Chat-
   Relation-extraction is a fundamental task in NLP that aims         GPT to extract relations connected to sustainability. ChatGPT
to identify the semantic relationships between entities in a          was able to successfully extract entities and connect them with
sentence or document. The task is challenging because it              relations, and return the results in a triple format. After the
requires understanding the context in which the entities appear       relations had been extracted, the same post-processing step of
and the types of relationships that exist between them.               Entity Linking was implemented on the results from ChatGPT.
   In this subsection, we describe how we utilize REBEL and              Although ChatGPT was able to extract entities from the
ChatGPT for the task of relation extraction.                          articles and link them with relations, it was not successful at
   1) REBEL: Our first approach was to use REBEL in an                abstracting concepts. The entities and relations identified often
attempt to extract relations from unstructured news articles.         represented whole phrases instead of concepts.
In order for REBEL to be able to use the provided texts,                 To overcome the obstacle, we prompted ChatGPT to map
they need to be tokenized with the corresponding tokenizer            identified entities and relations to a suitable OWL ontology
function. Tokenization is the process of separating the raw text      [23]. However, ChatGPT failed to identify relevant sustainabil-
into smaller units called tokens. Tokens can refer to words,          ity concepts or define their instances. The identified classes,
characters, or sub-words. The model has a token limitation of         such as Company, Customer, MarketingEcosystem, Resource,
512 tokens, which means that the collected articles which are         CustomerExperience, Convenience, and DigitalMarketing, had
longer need to be pre-processed before sending them to the            some potential relevance to sustainability, but ChatGPT did not
model for triplets extraction.                                        identify any instances for these classes.
   To address this limitation, we tokenize the raw text and              Experiment 2. In the second experiment, we refined the
divide the tokens into 256-token batches. These batches are           prompt to ask ChatGPT to explicitly generate an OWL ontol-
processed separately by the REBEL model, and the results              ogy on sustainability, which includes concepts like organiza-
are subsequently merged to extract relations for longer texts.        tions, actions, practices, policies, and related terms. We also
Metadata is also added to the extracted relations, referencing        allowed ChatGPT to create additional classes and properties
the token batch from which the relation was derived. With             if necessary. We explicitly requested the results to be returned
this approach, some relations may not be extracted accurately         in RDF Turtle format.
because the batch of tokens might begin or end in the middle of          Providing additional information to ChatGPT resulted in the
the sentence. However, the number of cases where this happens         creation of an improved Knowledge Base. ChatGPT was able
is insignificant. Thus, we leave their handling for future work.      to define concepts such as organizations, actions, practices,
   Once the entity-relation extraction process is finished, the       and policies, as well as identify suitable relations to connect
extracted information is stored in a triplet structure. To further    them together. Moreover, it was able to create instances of the
normalize the extracted entities, we perform Entity Linking           defined classes and properties and link them together. This
[22]. Entity Linking refers to the identification and association     shows that adding more specific instructions to the prompts
of entity mentions in raw text with their corresponding entities      for ChatGPT can produce drastically different results.
in a Knowledge Base. The process of Entity Linking is not part
of the REBEL model, and it is an additional post-processing                                    IV. R ESULTS
step that is used to refine the extracted relations. In this study,      This section presents the results from the experiments de-
we utilize DBpedia as our Knowledge Base and consider two             scribed in Section III. A comparison of the created Knowledge
entities identical if they share the same DBpedia URL. This           Base from both methods is given, and the characteristics of the
generated Knowledge Bases are outlined. Table I represents
the Knowledge Bases from the REBEL model and the first
experiment with ChatGPT, respectively. The table shows the
number of entities, relations, and triplets extracted from the
raw texts on sustainability.

                          TABLE I
            K NOWLEDGE BASE STRUCTURE COMPARISON

             Algorithm    Entities   Relations   Triples
             REBEL        805        105         854
             ChatGPT      1158       677         826

   As it is evident from the table, the number of triplets
extracted by both algorithms is similar. However, the number
of entities that ChatGPT extracts are larger than those from
REBEL. Although this is true, a lot of the extracted entities
are not connected to each other via any relation, thus defeating
the purpose of creating a Knowledge Base. Moreover, the
number of unique relations is far too large for ChatGPT to             Fig. 1. Subset of the Knowledge Base generated using the REBEL model. The
be able to produce an ontology that can be used for further            Knowledge Base is displayed in a graph format where entities are represented
experimentation.                                                       as nodes and relations are represented as edges.
   The most frequent relation for the REBEL model is the
‚Äôsubclass of‚Äô relation, being part of 120 triplets. For ChatGPT,
it‚Äôs the ‚Äôhas‚Äô relation, being identified in 29 triplets. In addi-
tion, ChatGPT often fails to generate standard relations and
entities which represent abstract concepts and instead outputs
an entire phrase, such as in the example ‚Äôhas already surpassed
a goal set in 2019 to install 100,000 heat pumps in homes and
businesses‚Äô, where it identifies this phrase as a relation.
   The following subsections represent a visual display of a
subset of the generated Knowledge Bases from both algo-
rithms.
A. REBEL
    In order to be able to analyze the Knowledge Base generated
using the REBEL model more accurately, we have created a
visualization in a graph format, where each entity represents
a node in the graph, and each relation represents an edge. Fig.
IV-A displays a subset of the extracted Knowledge Base.
    It is visible from the figure that the model successfully iden-
tifies entities related to sustainability, such as ‚Äôsustainability‚Äô,   Fig. 2. Subset of the Knowledge Base generated using the first experiment
‚Äôrecycling‚Äô, ‚Äôclean technology‚Äô, ‚Äôbusiness model‚Äô, ‚Äôrepurpos-          with ChatGPT. The Knowledge Base is displayed in a graph format where
ing‚Äô, and even links corporations such as ‚ÄôSamsung‚Äô to these           entities are represented as nodes and relations are represented as edges.
entities. We can notice that multiple entities are interlinked in
a meaningful way.
                                                                          Although these phrases are related to sustainability, they
B. ChatGPT                                                             do not represent specific entities. This happens as a result
   The same visualization for the Knowledge Base generated             of the fact that ChatGPT is a conversational model trained
by the first experiment with ChatGPT is represented in this            on a task to generate responses to a provided prompt and
subsection. Fig. IV-B displays a subset of the extracted Knowl-        not specifically trained to be able to recognize entities and
edge Base.                                                             relations. On the other hand, ChatGPT is able to identify some
   We can see from the figure that ChatGPT is able to identify         concepts that REBEL does not, and additionally, it is able to
entities related to sustainability, but they are represented as        link corporations to specific sustainability-related phrases.
phrases instead of concepts. For example, ChatGPT extracts                Prompt engineering [24] is of great importance when it
‚Äôsmall high-value items in jumbo packaging‚Äô, ‚Äôsteps and waste          comes to the results generated from ChatGPT [12]. Since it
from its supply chain‚Äô, and ‚Äôsuppliers to use recycled and             is a generative model, small variations in the input sequence
recyclable materials‚Äô, as entities.                                    can create large differences in the produced output.
   Observing the full Knowledge Base generated using Chat-
GPT, most of the time, the extracted entities represent phrases
or whole sentences, which is not beneficial for creating a
Knowledge Base because it‚Äôs hard to normalize the entities
and relations and create a more general ontology consisting
of the concepts represented in the graph.
   For this reason, we conducted the second experiment with
ChatGPT, where we defined a more detailed prompt and
instructed ChatGPT to generate an ontology based on each
                                                                                  Fig. 4. Knowledge Base generated with ChatGPT for the second article. The
article it sees and additionally define instances of the generated                identified concepts are represented as yellow rectangles, and the instances are
ontology based on the information present in each article.                        represented with green rectangles.
   Figure IV-B presents the results of the refined prompt, with
the ontology and instances generated from a single article out
of the 94 collected articles.                                                     ResourceSharing>. This also allows for answering complex
                                                                                  queries in the sustainability domain.
                                                                                     While the consistency of the generated ontologies may be
                                                                                  limited, our analysis reveals that there are significant simi-
                                                                                  larities between them. Therefore, future research can explore
                                                                                  methods for unifying these ontologies across all articles, which
                                                                                  has the potential to enhance the overall definition of concepts
                                                                                  and their interrelationships in the sustainability domain.
                                                                                     It is important to mention that due to the limitations of
                                                                                  the length of the input prompt passed to ChatGPT, it was not
                                                                                  possible to prompt the model first to define an ontology based
                                                                                  on all articles on sustainability and then create instances from
                                                                                  all the other articles using the same ontology.
                                                                                  C. Quality Evaluation
                                                                                     Since the evaluation of a Knowledge Base cannot be created
                                                                                  in an automated way based on some metric, when ground truth
Fig. 3. Knowledge Base generated with ChatGPT for the first article. The          data is not available, we need to utilize qualitative principles in
identified concepts are represented as yellow rectangles, and the instances are   order to evaluate the results. Based on the practical framework
represented with green rectangles.                                                defined in the study [25], the following 18 principles identified:
                                                                                     1) Triples should be concise
   Not only does ChatGPT create an ontology using the                                2) Contextual information of entities should be captured
concepts it was instructed to use, but it also defines classes on                    3) Knowledge graph does not contain redundant triples
its own and is able to create instances of most of the classes                       4) Knowledge graph can be updated dynamically
accurately.                                                                          5) Entities should be densely connected
   As an example, it identifies the entity ‚ÄùSoluna‚Äù as an                            6) Relations among different types of entities should be
‚ÄùinstanceOf‚Äù the class ‚ÄùOrganizations‚Äù. Furthermore, it is                               included
able to identify the triplet <Soluna, utilizes, Excess Energy>,                      7) Data source should be multi-field
and <Excess Energy, instanceOf, Practices>.                                          8) Data for constructing a knowledge graph should in
   These types of triplets already start representing an initial                         different types and from different resources
knowledge base, which can answer queries on companies                                9) Synonyms should be mapped, and ambiguities should
that implement practices that use excess energy. Although                                be eliminated to ensure reconcilable expressions
the hierarchy of concepts can be better defined so that more                       10) Knowledge graph should be organized in structured
complex queries can be answered, this method represents a                                triples for easily processed by machine
solid start in building a shared Knowledge Base, using only                        11) The scalability with respect to the KG size
unstructured texts.                                                                12) The attributes of the entities should not be missed
   Using another article, the ontology and instances given                         13) Knowledge graph should be publicly available and pro-
in Fig.IV-B have been generated. Looking at this second                                  prietary
example, we can see that ChatGPT links practices, actions,                         14) Knowledge graph should be an authority
and policies to the organizations, which was not the case in                       15) Knowledge graph should be concentrated
the previous example.                                                              16) The triples should not contradict each other
   Additionally, it identifies the triplets <Starbucks, in-                        17) For domain-specific tasks, the knowledge graph should
stanceOf, Organization>, and <Starbucks, hasPractice,                                    be related to that field
 18) Knowledge graph should contain the latest resources to                      [6] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
      guarantee freshness                                                            A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., ‚ÄúLanguage mod-
                                                                                     els are few-shot learners,‚Äù Advances in neural information processing
   According to these principles, in our use case, we manually                       systems, vol. 33, pp. 1877‚Äì1901, 2020.
inspected the Knowledge Graphs generated with the proposed                       [7] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,
                                                                                     Y. Zhou, W. Li, and P. J. Liu, ‚ÄúExploring the limits of transfer
methods, and we can conclude that the second ChatGPT ap-                             learning with a unified text-to-text transformer,‚Äù The Journal of Machine
proach creates a Knowledge Graph of greater quality compared                         Learning Research, vol. 21, no. 1, pp. 5485‚Äì5551, 2020.
to the other two Knowledge Bases.                                                [8] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBert: Pre-training
                                                                                     of deep bidirectional transformers for language understanding,‚Äù arXiv
   However, it should be noted that to create these Knowledge                        preprint arXiv:1810.04805, 2018.
Bases, a few steps of refining the answers from ChatGPT                          [9] U. Nations, ‚ÄúWorld‚Äôs poorest nations left behind in reaching sustainable
are needed. Sometimes the produced output is erroneous and                           development goals, delegates stress as second committee begins general
                                                                                     debate,‚Äù 2018. https://press.un.org/en/2018/gaef3495.doc.htm.
needs to be corrected before proceeding. Thus, this calls for                   [10] R. J. Baumgartner and R. Rauter, ‚ÄúStrategic perspectives of corporate
methods for automatically identifying incorrect OWL syntax                           sustainability management to develop a sustainable organization,‚Äù Jour-
and requesting to fix the previous output.                                           nal of Cleaner Production, vol. 140, pp. 81‚Äì92, 2017.
                                                                                [11] P.-L. H. Cabot and R. Navigli, ‚ÄúRebel: Relation extraction by end-to-end
                                                                                     language generation,‚Äù in Findings of the Association for Computational
                          V. C ONCLUSION                                             Linguistics: EMNLP 2021, pp. 2370‚Äì2381, 2021.
                                                                                [12] OpenAI, ‚ÄúGpt-4 technical report,‚Äù arXiv preprint arXiv:2303.08774,
   In this paper, we presented a Natural Language Processing-                        2023.
based method for constructing a Knowledge Graph on the                          [13] D. Zeng, K. Liu, S. Lai, G. Zhou, and J. Zhao, ‚ÄúRelation classification
topic of sustainability using raw documents available on                             via convolutional deep neural network,‚Äù in Proceedings of COLING
                                                                                     2014, the 25th international conference on computational linguistics:
the Web. The study demonstrated that meaningful infor-                               technical papers, pp. 2335‚Äì2344, 2014.
mation could be extracted from unstructured data through                        [14] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,
an automated process, which can subsequently be utilized                             V. Stoyanov, and L. Zettlemoyer, ‚ÄúBART: Denoising sequence-to-
                                                                                     sequence pre-training for natural language generation, translation, and
for decision-making and process modeling. The focus on                               comprehension,‚Äù in Proceedings of the 58th Annual Meeting of the
sustainability served as a concrete use case, illustrating the                       Association for Computational Linguistics, (Online), pp. 7871‚Äì7880,
effectiveness and potential of the presented approach.                               Association for Computational Linguistics, July 2020.
                                                                                [15] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,
   Although the experiments were conducted on the use case                           C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., ‚ÄúTraining language
of sustainability, the primary emphasis is on the methodology                        models to follow instructions with human feedback,‚Äù Advances in Neural
itself, which lays the foundation for empirical analysis of                          Information Processing Systems, vol. 35, pp. 27730‚Äì27744, 2022.
                                                                                [16] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, ‚ÄúProx-
qualitative data derived from various sources. The construction                      imal policy optimization algorithms,‚Äù arXiv preprint arXiv:1707.06347,
of a Knowledge Base using the presented approach can serve                           2017.
as a first step for analyzing diverse aspects of any subject                    [17] Simon-Kucher, ‚Äú2022 global sustainability study: The growth
                                                                                     potential of environmental change.‚Äù                    https://www.simon-
matter and answering complex queries based on the gathered                           kucher.com/en/insights/2022-global-sustainability-study-growth-
information.                                                                         potential-environmental-change.
   In future research, first, we plan to adopt a more formal                    [18] J. Lee and M. Kim, ‚ÄúEsg information extraction with cross-sectoral
                                                                                     and multi-source adaptation based on domain-tuned language models,‚Äù
framework for assessing the quality of generated knowledge                           Expert Systems with Applications, p. 119726, 2023.
graphs. Such a framework will enable us to effectively evaluate                 [19] A. Ehrhardt and M. T. Nguyen, ‚ÄúAutomated esg report analysis by joint
the quality of KGs and provide a standardized means of                               entity and relation extraction,‚Äù in Machine Learning and Principles
                                                                                     and Practice of Knowledge Discovery in Databases: International
assessing their overall quality. We also want to extend the                          Workshops of ECML PKDD 2021, Virtual Event, September 13-17, 2021,
presented methodology to other domains, unifying generated                           Proceedings, Part II, pp. 325‚Äì340, Springer, 2022.
knowledge bases and employing graph-based modeling to                           [20] I. Vodenska, R. Trajanov, L. Chitkushev, and D. Trajanov, ‚ÄúChal-
                                                                                     lenges and opportunities in esg investments,‚Äù in Computer Science and
predict missing links between concepts and relationships for                         Education in Computer Science: 18th EAI International Conference,
a given domain.                                                                      CSECS 2022, On-Site and Virtual Event, June 24-27, 2022, Proceedings,
                                                                                     pp. 168‚Äì179, Springer, 2022.
                             R EFERENCES                                        [21] NewsAPI.org, ‚ÄúNewsapi.‚Äù ‚Äùhttps://newsapi.org/‚Äù.
                                                                                [22] W. Shen, J. Wang, and J. Han, ‚ÄúEntity linking with a knowledge base:
[1] T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean, ‚ÄúLarge language           Issues, techniques, and solutions,‚Äù IEEE Transactions on Knowledge and
    models in machine translation,‚Äù in Proceedings of the 2007 Joint                 Data Engineering, vol. 27, no. 2, pp. 443‚Äì460, 2014.
    Conference on Empirical Methods in Natural Language Processing and          [23] D. L. McGuinness, F. Van Harmelen, et al., ‚ÄúOwl web ontology language
    Computational Natural Language Learning, pp. 858‚Äì867, Association                overview,‚Äù W3C recommendation, vol. 10, no. 10, p. 2004, 2004.
    for Computational Linguistics, June 2007.                                   [24] E. Saravia, ‚ÄúPrompt Engineering Guide,‚Äù https://github.com/dair-
[2] X. Chen, S. Jia, and Y. Xiang, ‚ÄúA review: Knowledge reasoning                    ai/Prompt-Engineering-Guide, 12 2022.
    over knowledge graph,‚Äù Expert Systems with Applications, vol. 141,          [25] H. Chen, G. Cao, J. Chen, and J. Ding, ‚ÄúA practical framework for
    p. 112948, 2020.                                                                 evaluating the quality of knowledge graph,‚Äù in Knowledge Graph and
[3] A. Mikheev, M. Moens, and C. Grover, ‚ÄúNamed entity recognition                   Semantic Computing: Knowledge Computing and Language Under-
    without gazetteers,‚Äù in Ninth Conference of the European Chapter of              standing: 4th China Conference, CCKS 2019, Hangzhou, China, August
    the Association for Computational Linguistics, pp. 1‚Äì8, 1999.                    24‚Äì27, 2019, Revised Selected Papers 4, pp. 111‚Äì122, Springer, 2019.
[4] G. Zhou, J. Su, J. Zhang, and M. Zhang, ‚ÄúExploring various knowledge
    in relation extraction,‚Äù in Proceedings of the 43rd annual meeting of the
    association for computational linguistics (acl‚Äô05), pp. 427‚Äì434, 2005.
[5] A. Kamath and R. Das, ‚ÄúA survey on semantic parsing,‚Äù arXiv preprint
    arXiv:1812.00978, 2018.
A Framework for Adapting Pre-Trained Language Models to Knowledge
                        Graph Completion

                         Justin Lovelace‚àó                                Carolyn Penstein Ros√©
                   Computer Science Department                        Language Technologies Institute
                        Cornell University                              Carnegie Mellon University
                      jl3353@cornell.edu                                 cp3a@andrew.cmu.edu


                           Abstract                                  Recent work has utilized pre-trained language
                                                                  models to develop approaches that are more robust
        Recent work has demonstrated that entity rep-
        resentations can be extracted from pre-trained
                                                                  to the naturally occurring sparsity within knowl-
        language models to develop knowledge graph                edge graphs. These approaches utilize textual en-
        completion models that are more robust to the             tity descriptions to develop entity representations
        naturally occurring sparsity found in knowl-              that are less reliant on graph connectivity.
        edge graphs. In this work, we conduct a com-                 Such work either fine-tunes the language model
        prehensive exploration of how to best extract             directly during training to encode the entities (e.g.
        and incorporate those embeddings into knowl-
                                                                  Yao et al. (2019)) or extracts a set of entity embed-
        edge graph completion models. We explore
        the suitability of the extracted embeddings for
                                                                  dings prior to training which can then be used to
        direct use in entity ranking and introduce both           train a KGC model using standard training proce-
        unsupervised and supervised processing meth-              dures (e.g. Lovelace et al. (2021)).
        ods that can lead to improved downstream per-                While fine-tuning language models often im-
        formance. We then introduce supervised em-                proves downstream performance (Rogers et al.,
        bedding extraction methods that can extract               2020), it increases the computational overhead of
        more informative representations. We then syn-
                                                                  computing entity representations. As a result, stan-
        thesize our findings and develop a knowledge
        graph completion model that significantly out-
                                                                  dard KGC training procedures that involve evaluat-
        performs recent neural models. 1                          ing a large number of negative candidates for each
                                                                  positive instance are typically infeasible. Sampling
1       Introduction                                              only a small set of negative candidates enables
                                                                  training, but can harm performance.
Knowledge graphs (KG) are structured represen-
tations of knowledge that contain a collection of                    Approaches that extract entity embeddings prior
factual relations between entities. KGs are valu-                 to training (Lovelace et al., 2021; Wang et al.,
able resources with applications in different areas               2021a) do not introduce any overhead for com-
such as representation learning (Liu et al., 2018),               puting entity representations and are able to take
question answering (Sun et al., 2019; Shen et al.,                advantage of standard training protocols. However,
2019; Thirukovalluru et al., 2021), and entity link-              such approaches do not utilize any supervision to
ing (Thai et al., 2021).                                          adapt the pre-trained language model to KGC.
   However, the difficulty of curating knowledge                     While both lines of previous work have demon-
at scale means that existing KGs are highly in-                   strated their approaches effectiveness at retrieving
complete. This has led to the widespread study of                 sparsely connected entities, they still lag behind
knowledge graph completion (KGC) which aims to                    KGC models that do not incorporate any textual
develop automated solutions that can suggest new                  information on standard benchmark datasets.
facts to add to the KG (Yang et al., 2015; Trouil-                   In this work, we develop a framework for adapt-
lon et al., 2016; Dettmers et al., 2018). KGC is                  ing pre-trained language models to KGC that takes
typically formulated as ranking problem where an                  advantage of the strengths of both prior lines of
incomplete fact is used as a query to retrieve enti-              work. We accomplish this by decoupling the entity
ties that complete the fact.                                      representations used for computing the query rep-
        ‚àó
                                                                  resentation and the entity representations used for
     Work conducted while at Carnegie Mellon University.
    1
   https://github.com/justinlovelace/
                                                                  retrieval (see Figure 1).
LM-KG-Completion                                                     For candidate ranking, we extract and cache en-
                                                             5937
            Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5937 - 5955
                               December 7-11, 2022 ¬©2022 Association for Computational Linguistics
tity representations from a pre-trained language               that transform the textual embedding space to
model prior to training. We then introduce                     be more suitable for candidate retrieval.
lightweight unsupervised and supervised embed-               ‚Ä¢ We demonstrate that parameter-efficient fine-
ding processing techniques that improve the suit-              tuning methods can be applied scalably to ex-
ability of the space for candidate retrieval without           tract more informative query entity represen-
sacrificing the scalability necessary to use standard          tations.
KGC training procedures. The embedding process-
ing techniques introduced in this work lead to sig-      2    Related Work
nificant performance improvements across datasets
from diverse domains.                                    Yao et al. (2019) adapted a pre-trained language
   This decoupling also enables us to scalably fine-     model to KGC by fine-tuning it for triplet clas-
tune pre-trained language models to extract more         sification, i.e. predicting whether a given fact is
informative entity representations for the query.        true. However, such an approach scales poorly to
However, naively fine-tuning the language model          the widely studied ranking formulation and is not
overfits the knowledge graph and actually degrades       competitive with simpler approaches.
performance. We find that parameter-efficient fine-         Follow-up work has developed more scalable
tuning methods such as prompt-tuning mitigate this       frameworks utilizing siamese encoders to inde-
and improve downstream performance.                      pendently encode the query and candidate entities
                                                         (Wang et al., 2021b; Li et al., 2022; Daza et al.,
   We synthesize our findings and utilize the most
                                                         2021). While this is an improvement, it still cannot
effective candidate representation processing and
                                                         scale to the tens of thousands of negative candi-
entity extraction techniques with a recently pro-
                                                         dates typically considered during training. Clouatre
posed neural ranking architecture. Although we do
                                                         et al. (2021) take a different approach and adapt the
not make any modifications to the ranking architec-
                                                         MLM objective to perform candidate retrieval by
ture, our representation extraction and processing
                                                         aggregating the logits for a number of mask tokens,
techniques lead to significant improvements across
                                                         eliminating the need to directly encode negative
four diverse datasets. The findings and analysis
                                                         candidate entities. Although these approaches gen-
from this work provide useful guidelines for devel-
                                                         erally improve upon Yao et al. (2019), they still lag
oping and utilizing effective textual entity represen-
                                                         behind simpler models on standard benchmarks.
tations for KGC.
                                                            Malaviya et al. (2020); Lovelace et al. (2021);
   The rest of our paper is organized as follows. We
                                                         Wang et al. (2021a) have taken a different approach
discuss related work in Section 2, present a formal
                                                         and extracted entity embeddings from pre-trained
description of our task in Section 3, and describe
                                                         language models prior to training. This eliminates
the datasets used in this work in Section 4. We
                                                         the overhead of computing entity representations
introduce unsupervised and supervised techniques
                                                         during training, enabling the use of standard train-
to improve the suitability of entity embeddings for
                                                         ing procedures. The focus of this line of work
candidate ranking in Section 5. We then introduce
                                                         has been on developing neural ranking architec-
supervised methods to extract more informative
                                                         tures that can effectively utilize the extracted tex-
representations for the query entity in Section 6
                                                         tual embeddings. We focus on the complementary
and explore the effect of language model selection
                                                         questions of how to best extract and use entity rep-
in Section 7. Finally, we synthesize our findings in
                                                         resentations with existing neural architectures.
Section 8 and compare against recent work on our
datasets. Our contributions are as follows.              3    Task Formulation
   ‚Ä¢ We develop a novel framework for adapting           Given a set of entities E and relations R, a KG can
     pre-trained language models for KGC that            be defined as a collection of entity-relation-entity
     significantly improves performance for both         triplets K = {(ei , rj , ek )} ‚äÇ E √ó R √ó E where
     sparsely connected and widely studied bench-        ei , ek ‚àà E and rj ‚àà R. The aim of KGC is to
     mark datasets.                                      develop a model that accepts a query consisting of
   ‚Ä¢ We demonstrate that the embeddings extracted        a head entity and a relation, (ei , rj , ?), and ranks
     from pre-trained language models are subopti-       all candidate entities ek ‚àà E to resolve the query.
     mal for entity ranking and introduce unsuper-       An effective KGC model should rank correct can-
     vised and supervised processing techniques          didates more highly than incorrect candidates.
                                                     5938
                                  Figure 1: Overview of our proposed framework.


   Neural KGC models embed the head entity and            5     Candidate Retrieval
relation and compute a query vector fŒ∏ (ei , rj ) = q
where fŒ∏ (¬∑) is a neural network and ei , rj , q ‚àà Rd .   Mu and Viswanath (2018); Ethayarajh (2019); Li
Scores for each candidate, ek ‚àà E, are computed           et al. (2020) have observed that textual embedding
as the inner product between the query vector and         spaces tend to be highly anisotropic, i.e. most
the candidate entity embedding yk = qek ‚ä∫ where           vectors occupy a narrow cone within the space,
ek ‚àà Rd . We follow Lovelace et al. (2021) and use        which limits their expressiveness. Furthermore,
textual descriptors to extract the entity embeddings      approaches that improve the isotropy, i.e. the uni-
from pre-trained language models while learning           formity with respect to direction, of the embedding
relation embeddings during training.                      space lead to significant improvements on semantic
                                                          similarity benchmarks (Mu and Viswanath, 2018;
   We evaluate the KGC models with standard rank-
                                                          Li et al., 2020; Gao et al., 2021). Given that entity
ing metrics: Mean Reciprocal Rank (MRR), Hits at
                                                          ranking relies upon a similar scoring mechanism,
1 (H@1), Hits at 3 (H@3), and Hits at 10 (H@10).
                                                          the existing embedding space may be similarly sub-
We follow standard procedure and consider both
                                                          optimal for candidate retrieval.
forward and reverse relations and use the filtered
evaluation setting (Dettmers et al., 2018). We vali-
                                                          5.1     Embedding Quality Metrics
date the significance of improvements in the MRR
with the paired bootstrap significance testing (Berg-     We measure two primary aspects of the embedding
Kirkpatrick et al., 2012) and correct for multiple        space to analyze the effect of different processing
hypothesis testing with the Benjamini/Hochberg            techniques: the anisotropy of the space and the
method (Benjamini and Hochberg, 1995).                    alignment of the space with the knowledge con-
                                                          tained within the graph. We note that these aspects
                                                          correspond to the notions of uniformity and align-
4   Datasets                                              ment from work in constrastive learning (Wang and
                                                          Isola, 2020; Gao et al., 2021).
We work with KGC datasets that cover diverse
domains such as commonsense, biomedical, and              5.1.1    Effective Dimension
encyclopedic knowledge. For the commonsense               We utilize a measure of anisotropy introduced by
KG dataset, we work with the CN-82K dataset in-           Cai et al. (2021) called the œµ-effective-dimension.
troduced by (Wang et al., 2021a) which is derived         We first apply PCA to the matrix of entity em-
from ConceptNet. For the biomedical KGC dataset,          beddings. The ratio of the variance explained by
we work with the SNOMED-CT Core dataset intro-            k principal
                                                                   P components Pm‚àí1 can then be calculated
duced by Lovelace et al. (2021). For the encyclope-       as rk = k‚àí1  i=0 œÉi /  j=0 œÉj , where œÉi is the i-th
dic dataset, we utilize the widely used benchmark         largest eigenvalue of the covariance matrix of the
KGC dataset, FB15k-237 (Toutanova and Chen,               embeddings. The œµ-effective-dimension is then
2015). We additionally utilize the widely studied         d(œµ) = argmink rk ‚â• œµ. We set œµ = 0.8, which
WN18RR (Dettmers et al., 2018) dataset which              means that we measure the minimum number of
is derived from WordNet. Dataset statistics are           PCA components necessary to explain 80% of the
reported in the appendix in Table 7.                      variance in the embedding space.
                                                      5939
5.1.2 Knowledge Alignment
For some set of facts {(ei , rj , ek )}nk=1 , we
would expect {ek }nk=1 to be similar in some
way. For example, all entities that satisfy the
query (abdomen, finding_site_of, ?) are abdom-
inal conditions. The inner product scoring means
that this similarity should be encoded within the
entity embedding space to enable retrieving the set
of correct entities with a single query vector.
   To evaluate the alignment of the embedding
space and the KG, we define the similarity between
two entities as
                                                                       Figure 2: Intrinsic evaluation of embedding processing tech-
                  P                                                    niques. We note the MRR for each approach in parenthesis.
Sim(ei , ej ) =   ek ‚ààE,rl ‚ààR 1(ek , rl , ei ) √ó 1(ek , rl , ej )


where E is the set of entities, R is the set of rela-
                                                                          Normalizing flows constrain the transforma-
tions, and 1(ek , rl , ei ) evaluates to one if the fact
                                                                       tion, T , to be a diffeomorphism which al-
is contained within the KG and zero otherwise. We
                                                                       lows us to write the density of x in terms of
report the knowledge aligment as the Spearman‚Äôs
                                                                       pu (u) and the Jacobian determinant of T ‚àí1 as
rank correlation, œÅ, between our KG-induced mea-
                                                                       px (x) = pu (T ‚àí1 (x))|det(JT ‚àí1 (x))|. We can then
sure of similarity and the inner product between
                                                                       fit the flow by minimizing the negative log-
centered entity embeddings.
                                                                       likelihood of observed samples {xn }N  n=1 as
5.1.3 Lexical Alignment
                                                                           ‚àí log(px (xi )) =
As a complementary measure to knowledge align-
ment, we also measure the lexical alignment of the                         ‚àí log(pu (T ‚àí1 (xi ))) ‚àí log|det(JT ‚àí1 (xi ))|
embedding space by calculating the Spearman‚Äôs
rank correlation, œÅ, between the Jaccard Similar-                         We define T ‚àí1 (x) = Wx + b where W ‚àà
ity of the entity descriptions and the inner product                   Rd√ód and x, b ‚àà Rd . To ensure the invertibility
between centered entity embeddings.                                    of W and to simplify the computation of the Ja-
                                                                       cobian determinant, we parameterize W using its
5.2 Embedding Processing Techniques                                    LU decomposition (Kingma and Dhariwal, 2018).
5.2.1 Unsupervised Techniques                                          We select a multivariate Guassian centered on the
                                                                       origin with identity convariance for the base distri-
Normalization As a simple baseline, we normalize
                                                                       bution. Thus, the normalizing flow learns to map
each entity embedding, ei ‚àà Rd , by centering the
                                                                       the embedding space to an isotropic Gaussian.
embedding space and scaling each vector to unit
                   ‚àíc
norm as eÃÉi = ‚à•eeii‚àíc‚à•2
                        where c ‚àà Rd is the mean                       5.2.2   Supervised Techniques
of the entity embeddings.
   Normalizing Flow We learn a normalizing flow                        We explore two inexpensive supervised techniques
to transform the anisotropic embedding space to                        that learn to transform the embedding space. For
an isotropic space, similar to Li et al. (2020). We                    both techniques, we preprocess the set of entity
briefly introduce normalizing flows, but we refer                      embeddings by centering and scaling them to have
the reader to Papamakarios et al. (2021) for a com-                    unit norm prior to the transformation.
prehensive overview.                                                       MLP We consider an MLP with one hidden
   Normalizing flows can be used to transform a                        layer followed by normalization. Thus, a pro-
distribution into a known probability distribution.                    cessed entity embedding, ei , is transformed as
                                                                               M LP (ei )
Given x ‚àà Rd with an unknown true distribu-                            eÃÉi = ‚à•M LP (ei )‚à•2 .
tion x ‚àº p‚àóx (x), we can define a joint distribu-                          Residual MLP We consider an MLP that uses
tion over x following the generative process of                        a residual connection with the original embedding.
x = T (u), u ‚àº pu (u) where pu (u) is the base                         A processed entity embedding, ei , would then be
                                                                                               (ei +M LP (ei ))
probability distribution of the flow model.                            transformed as eÃÉi = ‚à•(e  i +M LP (ei ))‚à•2
                                                                                                                  .
                                                                    5940
                                 SNOMED CT Core                                CN-82K                            FB15k-237                             WN18RR
                        MRR          H@1    H@3      H@10       MRR        H@1      H@3     H@10      MRR        H@1       H@3     H@10     MRR       H@1      H@3    H@10
 Default Embeddings       .488       .383   .543      .689       .190      .127     .208     .314      .339       .259     .370    .500     .575       .503    .606    .716
 Normalization           .487        .381   .544     .692        .192      .128     .211     .317    .348‚àó‚àó‚àó     .264      .381    .514     .576       .501    .608   .726
 Normalizing Flow      .508‚àó‚àó‚àó       .401   .566     .713       .194‚àó‚àó     .129     .213     .320    .352‚àó‚àó‚àó     .265      .385    .527    .580‚àó       .509    .607   .721
 MLP                   .539‚àó‚àó‚àó‚Ä†      .431   .598     .749      .200‚àó‚àó‚àó‚Ä†    .132     .222     .339    .374‚àó‚àó‚àó‚Ä†    .282      .407    .561    .583‚àó‚àó      .510    .613   .730
 Residual MLP          .549‚àó‚àó‚àó‚Ä†      .445   .507     .752      .209‚àó‚àó‚àó‚Ä†    .138     .230     .350    .375‚àó‚àó‚àó‚Ä†    .283      .408    .564   .591‚àó‚àó‚àó‚Ä†     .518    .616   .735


Table 1: Comparison of candidate transformation techniques. The highest metrics for unsupervised and supervised techniques
are bolded. We indicate a significant improvement over the default embeddings with ‚àó, ‚àó‚àó, ‚àó ‚àó ‚àó(p < 0.05, 0.005, 5e‚àí5) and
over the normalizing flow with ‚Ä† (p < 5e‚àí5).
                            SNOMED CT Core                                CN-82K                                FB15k-237                             WN18RR
                    MRR       H@1      H@3     H@10          MRR        H@1      H@3       H@10     MRR       H@1        H@3      H@10    MRR        H@1      H@3     H@10
 CLS Token           .472     .371     .521        .671       .157      .104     .171      .259      .351     .266       .383     .525     .549      .488     .567    .675
 + Pretraining      .489‚àó     .385     .540        .695      .189‚àó      .126     .207      .314     .356‚àó     .270       .388     .530    .587‚àó      .515     .618    .732
 Mean Pooling        .503     .397     .559        .705       .184      .124     .202      .303      .352     .266       .385     .525     .577      .508     .603    .719
 + Pretraining      .509‚àó     .403     .566        .713      .195‚àó      .130     .216      .323      .352     .265       .385     .527     .580      .509     .607    .721


Table 2: Ablation of embedding extraction techniques. We indicate significant improvements from the pretraining procedure
with ‚àó(p < 5e‚àí5).


5.3 Experiments
We evaluated the different embedding processing
methods using the textual entity embeddings re-
leased by Lovelace et al. (2021)2 . We also utilize
BERT-ResNet with the default hyperparameters
from Lovelace et al. (2021) as our neural ranking
architecture, fŒ∏ (¬∑, ¬∑). We only apply the transforma-
tion, gŒ∏ (ek ) = eÃÉk where eÃÉk ‚àà Rd , to the embed-
ding matrix used for candidate ranking. Therefore,
we compute the score as yk = fŒ∏ (ei , rj )gŒ∏ (ek )‚ä∫ .
                                                                                            Figure 3: Effect Of Residual MLP on knowledge and lexical
5.4 Impact Of Embedding Space                                                               alignment.
    Transformations
We report the effect of the different transformations                                       Residual MLP lead to significantly improved per-
on downstream performance in Table 1 and display                                            formance, with the Residual MLP consistently out-
the intrinsic embedding metrics for WN18RR in                                               performing the MLP. Both transformations consis-
Figure 2. Figures for the other datasets are pre-                                           tently improve the knowledge alignment of the em-
sented in the appendix and show similar findings.                                           bedding spaces. Compared to the MLP, the Resid-
   The normalization baseline is generally ineffec-                                         ual MLP produces a more isotropic space. Given
tive, which is consistent with its limited effect                                           its strong performance, the Residual MLP seems to
on the embedding metrics. The normalizing flow                                              best balance the trade-off between the knowledge
greatly increases the effective dimensionality but                                          alignment and isotropy of the embeddings.
decreases the knowledge alignment of the space.                                                We contrast the effect of the Residual MLP on
This suggests that there may be a trade-off between                                         knowledge and lexical alignment in Figure 3. The
isotropy and alignment of the space, which is con-                                          Residual MLP strengthens the KG alignment while
sistent with observations from work in contrastive                                          reducing the lexical alignment across all datasets,
learning (Gao et al., 2021). Despite that trade-                                            demonstrating that it learns to emphasize relevant
off, optimizing solely for isotropy significantly im-                                       information while discarding spurious information.
proves performance across all datasets, confirming
that the anisotropy of the original space hurts per-                                        5.5      Embedding Extraction Ablation
formance.                                                                                   For this ablation, we used the most effective un-
   For the supervised techniques, the MLP and                                               supervised processing technique, the normalizing
   2
                                                                                            flow, for candidate ranking. We ablate the efficacy
    Lovelace et al. (2021) did not work with WN18RR, so we
developed embeddings following their procedure. We examine                                  of the following embedding extraction choices.
embedding extraction methods in detail in Section 5.5                                       [CLS] Token: We extract the embedding of the
                                                                                    5941
                                   SNOMED CT Core                     CN-82K                        FB15k-237                      WN18RR
                            MRR      H@1     H@3    H@10    MRR      H@1     H@3    H@10    MRR     H@1    H@3    H@10   MRR      H@1    H@3    H@10
 Unsupervised Extraction    .509      .403   .566   .713    .195     .130    .216   .323     .356   .270   .388   .530    .587    .515   .618   .732
 Finetuning                  .496    .386    .555   .709     .186    .124    .203   .307     .347   .260   .379   .522    .579    .509   .606   .721
 Linear Probe              .516‚Ä†‚Ä†‚Ä†   .408    .575   .722     .195    .130    .215   .324    .358‚Ä†   .272   .392   .530   .598‚Ä†‚Ä†   .524   .630   .746
 Prompt-tuning             .515‚Ä†‚Ä†‚Ä†   .410    .573   .719   .201‚Ä†‚Ä†‚Ä†   .136    .222   .333     .357   .271   .392   .528   .597‚Ä†‚Ä†   .523   .630   .744


Table 3: Comparison of query entity extraction techniques. We indicate significant improvements over the best unsupervised
approach with ‚Ä†, ‚Ä†‚Ä†, ‚Ä† ‚Ä† ‚Ä†(p < .05, 5e‚àí4, 5e‚àí5).


[CLS] token from the final layer following prior
work (Malaviya et al., 2020; Wang et al., 2021a).
Mean Pooling: We mean pool across all tokens
and layers following Lovelace et al. (2021).
MLM Pretraining: Recent work (Malaviya et al.,
2020; Wang et al., 2021a; Lovelace et al., 2021)
has pretrained the language model using the MLM
objective on the set of entity names. We ablate the
impact of this choice.
   We report the KGC metrics in Table 2. The
MLM pretraining often results in significant im-
provements in downstream performance. The opti-                                 Figure 4: Effect of supervised extraction techniques com-
mal unsupervised extraction technique varies based                              pared to the unsupervised baseline. Error bars indicate 95%
on the dataset, with mean-pooling being most effec-                             confidence intervals.
tive for the SNOMED CT Core dataset and the CN-
82K dataset while the [CLS] embedding is most                                   6.1        Experiments
effective for the other two datasets. However, we
observe that mean pooling after MLM pre-training                                To isolate the effect of the query embedding ex-
is reasonably effective across all datasets.                                    traction technique, we use the normalizing flow for
                                                                                candidate ranking with the most effective embed-
6    Query Entity Extraction                                                    dings from our prior ablation for each dataset.
                                                                                   The supervised extraction techniques introduce
We explore supervised techniques to extract more                                an additional function, hŒ∏ (ei ) = eÃÇi where eÃÇi ‚àà
informative representations from pre-trained lan-                               Rd , to extract entity representations for computing
guage models for the query entity.                                              the query fŒ∏ (eÃÇi , rj ) = qÃÇ. Therefore, the score is
   Fine-tuning: We fine-tune the language model                                 computed as yk = fŒ∏ (hŒ∏ (ei ), rj )gŒ∏ (ek )‚ä∫ .
during training and extract the entity representation
by mean pooling across the intermediate states in                               6.1.1       Impact of Embedding Extraction
each layer and aggregating across layers with a                                             Techniques
learned linear combination.                                                     We report the KGC metrics in Table 3. Fine-tuning
   Linear Probe: We freeze the language model                                   the language model during training actually de-
and apply a learned linear projection (Toshniwal                                grades performance across all datasets, although
et al., 2020) to every hidden state of the model.                               it does minimize the training loss more effectively
We then max-pool across the tokens in each layer                                than other approaches. We break down the effect
to produce a single feature vector for every layer.                             of different techniques in Figure 4 by the connec-
We aggregate these features using a learned linear                              tivity of the query entity for the WN18RR dataset.
combination across layers.                                                      We observe that the performance degradation is
   Prompt-tuning We learn continuous prompts                                    more pronounced for queries with lower connectiv-
that we prepend to the language model inputs at                                 ity although this degradation doesn‚Äôt extend to un-
every layer to prompt the frozen model (Li and                                  seen query entities. This suggests that fine-tuning
Liang, 2021). We extract entity representations by                              the language model leads to overfitting for entities
mean pooling across intermediate states in each                                 with limited information. The figures for the other
layer and aggregate across layers with a learned                                datasets show similar trends and are presented in
linear combination.                                                             the appendix.
                                                                            5942
                       SNOMED CT Core                    CN-82K                          FB15k-237                         WN18RR
                 MRR      H@1    H@3    H@10   MRR      H@1    H@3    H@10      MRR     H@1       H@3    H@10    MRR       H@1    H@3    H@10
                                               Unsupervised Embedding Extraction & Residual MLP
    BERT-base     .531    .425   .588   .736   .210     .139   .232    .352     .373    .282      .406   .559     .590     .518   .616   .735
    BERT-large   .545‚àó‚àó   .441   .601   .749   .212     .139   .234    .356     .375    .282      .410   .563    .597‚àó     .524   .624   .743
    PubMedBERT   .549‚Ä°    .444   .606   .754     ‚àí        ‚àí      ‚àí       ‚àí        ‚àí       ‚àí         ‚àí      ‚àí       ‚àí         ‚àí      ‚àí      ‚àí
                                                        Prompt-tuning & Residual MLP
    BERT-base     .530    .423   .587   .736   .214‚Ä†‚Ä†   .142   .237    .361    .376‚Ä†    .284      .410   .562     .599‚Ä†    .525   .632   .749
    BERT-large   .541‚àó‚àó   .434   .599   .749   .216‚Ä†‚Ä†   .144   .238    .361     .373    .280      .409   .561   .608‚àó‚àó‚Ä†‚Ä†   .538   .636   .751
    PubMedBERT   .550‚Ä°    .443   .611   .755     ‚àí        ‚àí      ‚àí       ‚àí       ‚àí        ‚àí         ‚àí      ‚àí        ‚àí        ‚àí      ‚àí      ‚àí


Table 4: Effect of language model selection. We indicate significant improvements from the larger language model with
‚àó, ‚àó ‚àó (p < .05, 5e‚àí5); from prompting with ‚Ä†, ‚Ä† ‚Ä† (p < 0.05, .005); and from specialization with ‚Ä°(p < 5e‚àí5).


    The parameter-efficient supervised techniques                        larger language model actually degrades perfor-
do, however, lead to significantly improved perfor-                      mance over the unsupervised extraction techniques
mance across all datasets, although there is not a                       in some cases. The effect of using supervision for
clear winner between them. These techniques miti-                        extracting the query entity is dataset-dependent and
gate the overfitting problem while enabling bene-                        is helpful for CN82K and WN18RR.
ficial adaptation to the downstream task. Figure 4                          The supervised extraction and larger language
shows that the benefits of supervision are greatest                      models do lead to lower training loss, but that im-
for sparsely connected query entities. For densely                       provement does not consistently translate to stonger
connected query entities, the impact is generally                        test performance. Thus, the mixed results likely
negligible, potentially because the graph already                        arise from overfitting which could potentially be
contains sufficient information about the entity.                        mitigated with careful regularization. Domain-
    We note that sparsely connected entities were                        specific pretraining is particularly effective, with
filtered out of the FB15k-237 KG during the cura-                        PubMedBERT consistently outperforming other
tion of the dataset, producing an artificially dense                     models.
KG (Lovelace et al., 2021). This artificial den-
sity limits the benefit of techniques which improve
performance for sparsely connected entities. There-                      8     Comparison Against Recent Work
fore, our analysis also explains the limited topline
improvements for the FB15k-237 dataset.
                                                                         We synthesize our findings to develop a KGC
7      Effect of Language Model Selection                                model and compare against recent work. We again
                                                                         simply repurpose the BERT-ResNet ranking ar-
Further performance improvements can often be                            chitecture with the default hyperparameters from
gained by scaling up the size of the language model                      Lovelace et al. (2021) to demonstrate the impact of
Devlin et al. (2019) or from using specialized,                          the decisions explored in this work.
domain-specific language models Gu et al. (2020).
In this section, we examine the effect of these two                         We report results across the two sparser datasets
aspects on downstream KGC performance.                                   in Table 5. Our embedding extraction and process-
   We conduct experiments with both unsupervised                         ing techniques outperform recent work, with the su-
and supervised query entity extraction techniques                        pervised techniques being particularly effective. In
while using our best candidate ranking approach,                         Table 5 we also compare against a selection of base-
the Residual MLP. We conduct experiments with                            lines on the FB15K-237 and WN18RR datasets.
BERT-base-uncased and BERT-large-uncased for                             We also denote whether the models utilize addi-
all three KGs. To evaluate the effect of specializa-                     tional graph information or textual information.
tion, we use PubMedBERT, which is the same size                             Our KGC model is very effective and outper-
as BERT-base, for SNOMED-CT Core.                                        forms the models that do not incorporate any ad-
   We report the results of these experiments in                         ditional information. Although this seems natural,
Table 4. When using unsupervised extraction tech-                        this was actually not the case with previous work.
niques, the larger language model consistently im-                       Therefore, our method integrates textual informa-
proves performance, but the differences can be mi-                       tion in a way that leads to competitive performance
nor. For the supervised extraction techniques, the                       even for these widely studied benchmark datasets.
                                                                   5943
                                                         SNOMED CT Core                                CN-82K                             Additional Information
                                                  MRR     H@1     H@3     H@10        MRR         H@1           H@3          H@10                          Text
 DistMult (Yang et al., 2015)                     .293     .226   .318       .426     .0280         ‚àí           .0290          .0560                        ‚úó
 ComplEx (Trouillon et al., 2016)                 .302     .224   .332       .456     .0260         ‚àí           .0270          .0500                        ‚úó
 ConvE (Dettmers et al., 2018)                    .271     .191   .303       .429     .0801         ‚àí          ..0867          .1313                        ‚úó
 BERT-ConvTransE (Malaviya et al., 2020)           ‚àí        ‚àí      ‚àí          ‚àí       .1626         ‚àí          .1795           .2751                        ‚úì
 InductivE (Wang et al., 2021a)                    ‚àí        ‚àí      ‚àí          ‚àí       .2035         ‚àí          .2265           .3386                        ‚úì
 BERT-DeepConv (Lovelace et al., 2021)            .479     .374   .532       .685       ‚àí           ‚àí            ‚àí               ‚àí                          ‚úì
 BERT-ResNet (Lovelace et al., 2021)              .492     .389   .544       .694      .190        .127         .208            .318                        ‚úì
 BERT-ResNet + Normalizing Flow                   .509     .403   .566       .713      .195       .130          .216           .323                         ‚úì
 BERT-ResNet + Prompt-tuning + Normalizing Flow   .515     .410   .573       .719      .201       .136          .222           .333                         ‚úì
 BERT-ResNet + Residual MLP                       .549     .444   .606       .754      .212       .139          .234           .356                         ‚úì
 BERT-ResNet + Prompt-tuning + Residual MLP       .550     .443   .611       .755      .216       .144          .238           .361                         ‚úì

                                                            FB15K-237                                 WN18RR                              Additional Information
                                                  MRR      H@1    H@3        H@10         MRR      H@1          H@3         H@10          Graph Structure                Text
          ‚Ä†
 RESCAL (Nickel et al., 2011)                     .357      ‚àí      ‚àí         .541         .467       ‚àí            ‚àí            .517                   ‚úó                   ‚úó
 TransE‚Ä† (Bordes et al., 2013)                    .313      ‚àí      ‚àí         .497         .228       ‚àí            ‚àí            .520                   ‚úó                   ‚úó
 DistMult‚Ä† (Yang et al., 2015)                    .343      ‚àí      ‚àí         .531         .452       ‚àí            ‚àí            .531                   ‚úó                   ‚úó
 ComplEx‚Ä† (Trouillon et al., 2016)                .348      ‚àí      ‚àí         .536         .475       ‚àí            ‚àí            .547                   ‚úó                   ‚úó
 ConvE‚Ä† (Dettmers et al., 2018)                   .339      ‚àí      ‚àí         .521         .442       ‚àí            ‚àí            .504                   ‚úó                   ‚úó
 CompGCN (Vashishth et al., 2020)                 .355     .264   .390       .535         .479      .443        .494           .546                   ‚úì                   ‚úó
 HittER (Chen et al., 2021)                       .373     .279   .409       .558         .503      .462        .516           .584                   ‚úì                   ‚úó
 KG-BERT‚Ä° (Yao et al., 2019)                      .236     .145   .258       .420         .242      .110        .280           .524                   ‚úó                   ‚úì
 BERT-TransE (Daza et al., 2021)                  .235     .150   .253       .411         .325      .144        .431           .679                   ‚úó                   ‚úì
 MLMLM (Clouatre et al., 2021)                    .259     .187   .282       .403         .502      .439        .542           .611                   ‚úó                   ‚úì
 StAR (Wang et al., 2021b)                        .296     .205   .322       .482         .401      .243        .491           .709                   ‚úó                   ‚úì
 LP-BERT (Li et al., 2022)                        .310     .223   .336       .490         .482      .343        .563           .752                   ‚úó                   ‚úì
 BERT-ResNet (Lovelace et al., 2021)              .346     .262   .379       .514         .575      .503        .606           .716                   ‚úó                   ‚úì
 BERT-ResNet + Normalizing Flow                   .356     .270   .388       .530         .587     .515         .618           .732                   ‚úó                   ‚úì
 BERT-ResNet + Prompt-tuning + Normalizing Flow   .357     .271   .392       .528         .599     .527         .630           .743                   ‚úó                   ‚úì
 BERT-ResNet + Residual MLP                       .375     .282   .410       .563         .597     .524         .624           .743                   ‚úó                   ‚úì
 BERT-ResNet + Prompt-tuning + Residual MLP       .376     .284   .410       .562         .608     .538         .636           .751                   ‚úó                   ‚úì


Table 5: Comparison against baselines and recent work. We indicate that the results are from Ruffinelli et al. (2020) with a ‚Ä† and
from the work by Daza et al. (2021) with a ‚Ä°. The baselines for SNOMED CT Core and CN82K are taken from Lovelace et al.
(2021) and Wang et al. (2021a) respectively, except for the BERT-ResNet result for CN82K which is from our implementation.
The WN18RR result for BERT-ResNet is also from our implementation. Other results are taken from the original work. Dashes
indicate that the metric was not reported by the prior work.


8.1 Complementarity of Textual Approach                                                             MRR
                                                                                                               FB15K-237
                                                                                                                H@1     H@3      H@10       MRR
                                                                                                                                                          WN18RR
                                                                                                                                                          H@1     H@3     H@10
                                                                          Transformer               .367        .272    .404      .554       .486         .446    .503    .564

To evaluate the complementarity of textual and non-                       Our Framework
                                                                            Alt. Seed
                                                                                                    .376
                                                                                                    .377
                                                                                                                .284
                                                                                                                .285
                                                                                                                        .410
                                                                                                                        .412
                                                                                                                                  .562
                                                                                                                                  .564
                                                                                                                                             .608
                                                                                                                                             .605
                                                                                                                                                          .538
                                                                                                                                                          .533
                                                                                                                                                                  .636
                                                                                                                                                                  .634
                                                                                                                                                                          .751
                                                                                                                                                                          .749

textual approaches, we train a transformer model                          Self-Ensemble            .384‚àó‚àó‚àó      .292    .420
                                                                                                                                Simple Ensemble
                                                                                                                                  .570     .613‚àó‚àó‚àó        .540    .641    .760
similarly to Chen et al. (2021). We refer the reader                      Transformer Ensemble   .388‚àó‚àó‚àó‚Ä†‚Ä°‚Ä°‚Ä°    .295    .425      .576      .609‚àó
                                                                                                                           Relation-Specific Ensemble
                                                                                                                                                          .539    .638    .755


to the appendix for full details regarding this model.                    Self-Ensemble            .391‚àó‚àó‚àó      .303    .424     .571     .616‚àó‚àó‚àó‚Ä°‚Ä°       .544    .642    .758
                                                                          Transformer Ensemble   .400‚àó‚àó‚àó‚Ä†‚Ä°‚Ä°‚Ä°    .310    .435     .582       .612‚àó‚Ä°        .543    .640    .756
We then ensemble this model with our most ef-
fective model from Table 5, computing candidate                          Table 6:        Ensembling Results.       We indicate sig-
scores as a convex combination of the two sets of                        nificant improvements over our framework with
                                                                         ‚àó, ‚àó‚àó, ‚àó ‚àó ‚àó(p < .05, 5e‚àí4, 5e‚àí5); from the transformer
scores. We tune the ensemble weight with the vali-                       ensemble with ‚Ä†(p < 5e‚àí5); and from relation-specific
dation set. We also explore using an independent                         ensembling with ‚Ä°, ‚Ä°‚Ä°, ‚Ä° ‚Ä° ‚Ä°(p < .005, 5e‚àí4, 5e‚àí5).
weight for each relation. As a baseline compari-
son, we ensemble our best configuration across two
                                                                         textual models does meaningfully improve perfor-
random seeds.
                                                                         mance over the self-ensemble. This demonstrates
   We report the results of this experiment in Ta-                       that textual approaches can complement existing
ble 6. We observe that ensembling is consistently                        methods.
effective, particularly the relation-specific ensem-
bling. On the WN18RR dataset where the tex-                              9      Conclusion
tual approach is already highly effective, ensem-
bling the different approaches does not outpeform                        We present a framework for adapting pre-trained
the self-ensemble. However, for the FB15k-237                            language models for KGC. The key insight driving
dataset where the performance of the different ap-                       the development of our framework was that decou-
proaches is closer, ensembling the textual and non-                      pling the entity representations used for computing
                                                                  5944
the query representation and the entity represen-                time to train the baseline for 6 epochs as it does
tations used for candidate retrieval enabled us to               to train the Residual MLP model for 4 epochs, the
better integrate the information from pre-trained                Residual MLP actually outperforms the baseline at
language models while maintaining the scalability                that time despite training for fewer iterations.
necessary to train performant KGC models.                           Therefore, the baseline is only more effective in
   We introduced unsupervised and supervised tech-               the earliest stage of training before being surpassed
niques to improve the suitability of entity embed-               by the Residual MLP model. For the WN18RR
dings for candidate ranking (Section 5), introduced              dataset, this breakeven point occurs within only
methods to extract entity embeddings from lan-                   29m of training. This trend holds across all datasets,
guage models (Section 6), and explored the effect                with the worst breakeven point being only 1h43m.
of language model selection (Section 7).                         Therefore the accelerated convergence offsets the
   By synthesizing the insights from our explo-                  increased per-iteration cost for all but the shortest
ration, we developed a KGC model that signifi-                   of training times.
cantly outperforms recent work while simply repur-                  Techniques such as prompt-tuning require the ap-
posing an existing ranking architecture. While in-               plication of a language model, which increases the
novations in neural ranking architecture have been               time per iteration. For the query extraction experi-
valuable, our work demonstrates the importance of                ment on the WN18RR dataset (Section 6), the base-
developing more informative entity representations.              line completes one epoch in 3m54s, while prompt-
The findings and analysis from this work provide a               tuning increases this to 8m47s. When controlling
useful framework for adapting pre-trained language               for wall clock time, we observe a similar trend
models for knowledge graph completion.                           where the baseline is more effective early in train-
                                                                 ing before being surpassed by prompt-tuning. How-
10    Limitations                                                ever, the breakeven point occurs much later (e.g.
10.1 Training Overhead                                           at 14h1m for WN18RR). Therefore, in settings
                                                                 with limited training budgets, the performance im-
We report and discuss the number of trainable pa-
                                                                 provement from prompt-tuning may not justify the
rameters and training times across our different con-
                                                                 additional training cost.
figurations in detail in the appendix 3 . We present
the main takeaways in this section.                                 We note that none of the techniques explored in
   The supervised techniques like the Residual                   our work introduce any overhead at inference time.
MLP and prompt-tuning introduce additional pa-                   After training, the improved entity representations
rameters and can increase the training time com-                 from the Residual MLP or prompt-tuning can be
pared to the BERT-ResNet baseline. However,                      computed and cached for inference, reducing the
both the Residual MLP and prompt-tuning are very                 cost of computing entity embeddings to a simple
parameter-efficient. When utilizing BERT-base, the               lookup like the original BERT-ResNet model.
Residual MLP increases the number of trainable
parameters by 3.6% and prompt-tuning increases                   10.2   Availability of Textual Descriptions
it by 1.2%. The increases are similar when uti-                  The integration of pre-trained langauge models to
lizing BERT-large (3.6% and 1.1% respectively).                  improve KG entity representations is predicated
Directly fine-tuning BERT-base, for comparison,                  upon the existence of informative textual descrip-
increases the number of trainable parameters by                  tions for the entities within the graph. Although
331.2%.                                                          this assumption holds in many scenarios, it does
   The residual MLP, while lightweight, does in-                 not hold universally. For instance, clinical data
crease the training time per iteration. For the can-             from the Electronic Health Record can naturally be
didate transformation experiment on the WN18RR                   represented as a knowledge graph for applications
dataset (Section 5), the baseline completes one                  such as question answering (Park et al., 2021).
epoch in 3m56s while the Residual MLP increases                     Entities like medications and procedures would
this to 5m44s. However, the Residual MLP also ac-                have well-defined names, but others such as those
celerates convergence, offsetting the per-iteration              representing specific admissions events or hospital
slowdown. Although it takes a similar amount of                  stays would be represented with a numerical ID
    3
      All ranking models reported in this work were trained on   and would not have natural textual representations.
a single NVIDIA GeForce GTX 1080 Ti.                             Although a hybrid approach that adaptively inte-
                                                             5945
grates textual information when available would              Empirical Methods in Natural Language Process-
likely be beneficial, the extension of our framework         ing, pages 10395‚Äì10407, Online and Punta Cana,
                                                             Dominican Republic. Association for Computational
to such settings is left for future work.
                                                             Linguistics.
11   Ethical Considerations                               Louis Clouatre, Philippe Trempe, Amal Zouaq, and
                                                            Sarath Chandar. 2021. MLMLM: Link prediction
Knowledge graphs are valuable resources utilized            with mean likelihood masked language model. In
by applications such as search engines (Sullivan,           Findings of the Association for Computational Lin-
2020) and automated voice assistants (Flint, 2021)          guistics: ACL-IJCNLP 2021, pages 4321‚Äì4331, On-
                                                            line. Association for Computational Linguistics.
to present information to users. While KGC mod-
els have the potential to improve the coverage of         Daniel Daza, Michael Cochez, and Paul Groth. 2021.
such resources, they also risk introducing inaccu-          Inductive entity representations from text via link
rate facts that could mislead users. The cost of            prediction. In Proceedings of the Web Conference
                                                            2021, WWW ‚Äô21, page 798‚Äì808, New York, NY,
such inaccuracies can vary significantly based on           USA. Association for Computing Machinery.
the information domain (e.g. film trivia vs. medical
information).                                             Tim Dettmers, Minervini Pasquale, Stenetorp Pontus,
                                                            and Sebastian Riedel. 2018. Convolutional 2d knowl-
   Therefore, such tools should not be deployed             edge graph embeddings. In Proceedings of the 32th
without careful consideration of the potential harms        AAAI Conference on Artificial Intelligence, pages
or the development of appropriate mitigation strate-        1811‚Äì1818.
gies. One way to minimize such risks is to use            Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
KGC methods to accelerate the curation of likely             Kristina Toutanova. 2019. BERT: Pre-training of
candidate facts that must undergo further verifica-          deep bidirectional transformers for language under-
tion before their inclusion in the knowledge graph.          standing. In Proceedings of the 2019 Conference of
                                                             the North American Chapter of the Association for
Acknowledgments                                             Computational Linguistics: Human Language Tech-
                                                             nologies, Volume 1 (Long and Short Papers), pages
This research was funded in part by NSF grant IIS           4171‚Äì4186, Minneapolis, Minnesota. Association for
                                                             Computational Linguistics.
1917955.
                                                          Kawin Ethayarajh. 2019. How contextual are contextu-
                                                            alized word representations? Comparing the geom-
References                                                  etry of BERT, ELMo, and GPT-2 embeddings. In
                                                            Proceedings of the 2019 Conference on Empirical
Yoav Benjamini and Yosef Hochberg. 1995. Controlling        Methods in Natural Language Processing and the
  the false discovery rate - a practical and powerful       9th International Joint Conference on Natural Lan-
  approach to multiple testing. J. Royal Statist. Soc.,     guage Processing (EMNLP-IJCNLP), pages 55‚Äì65,
  Series B, 57:289 ‚Äì 300.                                   Hong Kong, China. Association for Computational
                                                            Linguistics.
Taylor Berg-Kirkpatrick, David Burkett, and Dan Klein.
  2012. An empirical investigation of statistical sig-    Emma Flint. 2021. Alexa entities launches to general
  nificance in NLP. In Proceedings of the 2012 Joint        availability.
  Conference on Empirical Methods in Natural Lan-
  guage Processing and Computational Natural Lan-         Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.
  guage Learning, pages 995‚Äì1005, Jeju Island, Korea.       SimCSE: Simple contrastive learning of sentence em-
  Association for Computational Linguistics.                beddings. In Proceedings of the 2021 Conference
                                                            on Empirical Methods in Natural Language Process-
Antoine Bordes, Nicolas Usunier, Alberto Garcia-            ing, pages 6894‚Äì6910, Online and Punta Cana, Do-
  Duran, Jason Weston, and Oksana Yakhnenko.                minican Republic. Association for Computational
  2013. Translating embeddings for modeling multi-          Linguistics.
  relational data. In Advances in neural information
  processing systems, pages 2787‚Äì2795.                    Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto
                                                            Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng
Xingyu Cai, Jiaji Huang, Yuchen Bian, and Kenneth           Gao, and Hoifung Poon. 2020. Domain-specific lan-
  Church. 2021. Isotropy in the contextual embedding        guage model pretraining for biomedical natural lan-
  space: Clusters and manifolds. In International Con-      guage processing.
  ference on Learning Representations.
                                                          Diederik P. Kingma and Jimmy Ba. 2015. Adam: A
Sanxing Chen, Xiaodong Liu, Jianfeng Gao, Jian Jiao,        method for stochastic optimization. In 3rd Inter-
  Ruofei Zhang, and Yangfeng Ji. 2021. HittER: Hi-          national Conference on Learning Representations,
  erarchical transformers for knowledge graph embed-        ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
  dings. In Proceedings of the 2021 Conference on           Conference Track Proceedings.

                                                      5946
Durk P Kingma and Prafulla Dhariwal. 2018. Glow:           Junwoo Park, Youngwoo Cho, Haneol Lee, Jaegul Choo,
  Generative flow with invertible 1x1 convolutions. In       and E. Choi. 2021. Knowledge graph-based question
  Advances in Neural Information Processing Systems,         answering with electronic health records. In MLHC.
  volume 31. Curran Associates, Inc.
                                                           Anna Rogers, Olga Kovaleva, and Anna Rumshisky.
Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang,               2020. A primer in BERTology: What we know about
  Yiming Yang, and Lei Li. 2020. On the sentence             how BERT works. Transactions of the Association
  embeddings from pre-trained language models. In            for Computational Linguistics, 8:842‚Äì866.
  Proceedings of the 2020 Conference on Empirical
  Methods in Natural Language Processing (EMNLP),          Daniel Ruffinelli, Samuel Broscheit, and Rainer
  pages 9119‚Äì9130, Online. Association for Computa-          Gemulla. 2020. You can teach an old dog new tricks!
  tional Linguistics.                                        on training knowledge graph embeddings. In Inter-
                                                             national Conference on Learning Representations.
Da Li, Ming Yi, and Yukai He. 2022. LP-BERT: multi-
  task pre-training knowledge graph BERT for link          Tao Shen, Xiubo Geng, Tao Qin, Daya Guo, Duyu
  prediction. CoRR, abs/2201.04843.                          Tang, Nan Duan, Guodong Long, and Daxin Jiang.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:          2019. Multi-task learning for conversational ques-
  Optimizing continuous prompts for generation.              tion answering over a large-scale knowledge base. In
                                                             Proceedings of the 2019 Conference on Empirical
Zhenghao Liu, Chenyan Xiong, Maosong Sun, and                Methods in Natural Language Processing and the
  Zhiyuan Liu. 2018. Entity-duet neural ranking: Un-         9th International Joint Conference on Natural Lan-
  derstanding the role of knowledge graph semantics          guage Processing (EMNLP-IJCNLP), pages 2442‚Äì
  in neural information retrieval. In Proceedings of the     2451, Hong Kong, China. Association for Computa-
  56th Annual Meeting of the Association for Compu-          tional Linguistics.
  tational Linguistics (Volume 1: Long Papers), pages
  2395‚Äì2405, Melbourne, Australia. Association for         Danny Sullivan. 2020. A reintroduction to our knowl-
  Computational Linguistics.                                 edge graph and knowledge panels.

Ilya Loshchilov and Frank Hutter. 2019. Decoupled          Haitian Sun, Tania Bedrax-Weiss, and William Cohen.
   weight decay regularization. In International Confer-     2019. PullNet: Open domain question answering
   ence on Learning Representations.                         with iterative retrieval on knowledge bases and text.
                                                             In Proceedings of the 2019 Conference on Empirical
Justin Lovelace, Denis Newman-Griffis, Shikhar               Methods in Natural Language Processing and the
  Vashishth, Jill Fain Lehman, and Carolyn Ros√©. 2021.       9th International Joint Conference on Natural Lan-
  Robust knowledge graph completion with stacked             guage Processing (EMNLP-IJCNLP), pages 2380‚Äì
  convolutions and a student re-ranking network. In          2390, Hong Kong, China. Association for Computa-
  Proceedings of the 59th Annual Meeting of the Asso-        tional Linguistics.
  ciation for Computational Linguistics and the 11th
  International Joint Conference on Natural Language       Dung Thai, Raghuveer Thirukovalluru, Trapit Bansal,
  Processing (Volume 1: Long Papers), pages 1016‚Äì            and Andrew McCallum. 2021. Simultaneously
  1029, Online. Association for Computational Linguis-       self-attending to text and entities for knowledge-
  tics.                                                      informed text representations. In Proceedings of the
                                                             6th Workshop on Representation Learning for NLP
Chaitanya Malaviya, Chandra Bhagavatula, Antoine             (RepL4NLP-2021), pages 241‚Äì247, Online. Associa-
  Bosselut, and Yejin Choi. 2020. Commonsense                tion for Computational Linguistics.
  knowledge base completion with structural and se-
  mantic context. Proceedings of the 34th AAAI Con-        Raghuveer Thirukovalluru, Mukund Sridhar, Dung
  ference on Artificial Intelligence.                        Thai, Shruti Chanumolu, Nicholas Monath, Sankara-
Jiaqi Mu and Pramod Viswanath. 2018. All-but-the-top:        narayanan Ananthakrishnan, and Andrew McCallum.
   Simple and effective postprocessing for word repre-       2021. Knowledge informed semantic parsing for con-
   sentations. In International Conference on Learning       versational question answering. In Proceedings of
   Representations.                                          the 6th Workshop on Representation Learning for
                                                             NLP (RepL4NLP-2021), pages 231‚Äì240, Online. As-
Maximilian Nickel, Volker Tresp, and Hans-Peter              sociation for Computational Linguistics.
 Kriegel. 2011. A three-way model for collective
 learning on multi-relational data. In Proceedings of      J. Tompson, R. Goroshin, A. Jain, Y. LeCun, and C. Bre-
 the 28th International Conference on International           gler. 2015. Efficient object localization using con-
 Conference on Machine Learning, ICML‚Äô11, page                volutional networks. In 2015 IEEE Conference on
 809‚Äì816, Madison, WI, USA. Omnipress.                        Computer Vision and Pattern Recognition (CVPR),
                                                              pages 648‚Äì656.
George Papamakarios, Eric Nalisnick, Danilo Jimenez
  Rezende, Shakir Mohamed, and Balaji Lakshmi-             Shubham Toshniwal, Haoyue Shi, Bowen Shi, Lingyu
  narayanan. 2021. Normalizing flows for probabilistic       Gao, Karen Livescu, and Kevin Gimpel. 2020. A
  modeling and inference. Journal of Machine Learn-          cross-task analysis of text span representations. In
  ing Research, 22(57):1‚Äì64.                                 Proceedings of the 5th Workshop on Representation

                                                       5947
  Learning for NLP, pages 166‚Äì176, Online. Associa-
  tion for Computational Linguistics.
Kristina Toutanova and Danqi Chen. 2015. Observed
  versus latent features for knowledge base and text
  inference. In Proceedings of the 3rd Workshop on
  Continuous Vector Space Models and their Composi-
  tionality, pages 57‚Äì66, Beijing, China. Association
  for Computational Linguistics.

Th√©o Trouillon, Johannes Welbl, Sebastian Riedel, √âric
  Gaussier, and Guillaume Bouchard. 2016. Complex
  embeddings for simple link prediction. In Proceed-
  ings of the 33rd International Conference on Interna-
  tional Conference on Machine Learning - Volume 48,
  ICML‚Äô16, pages 2071‚Äì2080. JMLR.org.

Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and
  Partha Talukdar. 2020. Composition-based multi-
  relational graph convolutional networks. In Interna-
  tional Conference on Learning Representations.

Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You,
  Jure Leskovec, and C-C Jay Kuo. 2021a. Inductive
  learning on commonsense knowledge graph com-
  pletion. International Joint Conference on Neural
  Networks (IJCNN).

Bo Wang, Tao Shen, Guodong Long, Tianyi Zhou, Ying
  Wang, and Yi Chang. 2021b. Structure-augmented
  text representation learning for efficient knowledge
  graph completion. In Proceedings of the Web Confer-
  ence 2021, WWW ‚Äô21, page 1737‚Äì1748, New York,
  NY, USA. Association for Computing Machinery.
Tongzhou Wang and Phillip Isola. 2020. Understanding
  contrastive representation learning through alignment
  and uniformity on the hypersphere. In International
  Conference on Machine Learning, pages 9929‚Äì9939.
  PMLR.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
  Chaumond, Clement Delangue, Anthony Moi, Pier-
  ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-
  icz, Joe Davison, Sam Shleifer, Patrick von Platen,
  Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
  Teven Le Scao, Sylvain Gugger, Mariama Drame,
  Quentin Lhoest, and Alexander Rush. 2020. Trans-
  formers: State-of-the-art natural language processing.
  In Proceedings of the 2020 Conference on Empirical
  Methods in Natural Language Processing: System
  Demonstrations, pages 38‚Äì45, Online. Association
  for Computational Linguistics.
Bishan Yang, Scott Wen-tau Yih, Xiaodong He, Jian-
  feng Gao, and Li Deng. 2015. Embedding entities
  and relations for learning and inference in knowledge
  bases. In Proceedings of the International Confer-
  ence on Learning Representations (ICLR) 2015.
Liang Yao, Chengsheng Mao, and Yuan Luo. 2019.
  KG-BERT: BERT for knowledge graph completion.
  CoRR, abs/1909.03193.



                                                       5948
A     Dataset Information                                          counts are identical across datasets with the ex-
                                                                   ception of the relation parameters which depends
We report the details for the datasets used in this                upon the number of relations within each KG. The
work in Table 7. For SNOMED CT Core, CN82k,                        relation parameters make up a small portion of
and FB15k-237 we utilize the textual descriptions                  the overall parameters and are unaffected by the
used by Lovelace et al. (2021). For SNOMED                         methods introduced in this work, so we simply re-
CT Core and CN82k, these consist of short en-                      port parameter counts for the WN18RR dataset for
tity names. For FB15k-237, the descriptions are                    brevity.
short paragraphs that describe the entity. For the
WN18RR dataset, we utilize the entity descriptions                    The unsupervised Normalizing Flow technique
released by Yao et al. (2019), which consist of                    can be applied prior to training and thus introduces
the word and a short definition. Unless otherwise                  zero additional trainable parameters for the ranking
stated, we utilize PubmedBERT to extract embed-                    model. The supervised MLP and Residual MLP
dings for the SNOMED CT Core dataset and uti-                      techniques introduce only 3.6% additional trainable
lize the uncased version of BERT-base for the other                parameters compared to the baseline model.
three datasets.                                                       Directly fine-tuning the language model during
                                                                   training increases the number of trainable parame-
B     Evaluation Metrics
                                                                   ters by 331.2% because even the BERT-base model
We present a mathematical formulation of our eval-                 is over 3 times the size of the ranking model. The
uation metrics. We consider both forward and in-                   parameter-efficient methods, on the other hand,
verse relations for the datasets examined in this                  have a much more modest effect with the Lin-
work. For the CN82k and FB15k-237 datasets, we                     ear Probe increasing the parameters by 3.0% and
follow standard procedure and introduce an inverse                 Prompt Tuning increasing the model size by 1.2%.
fact, (el , rj‚àí1 , ei ), for every fact, (ei , rj , el ), in the
dataset. The SNOMED CT Core dataset already
contains inverse relations so manually adding in-                  C.2   Training Time
verse facts in unecessary. We let T denote the set
of all facts in the test set.                                      We compare the training times across our different
   The Mean Reciprocal Rank (MRR) is defined as                    configurations. We report details for the candi-
                          1          X               1             date processing methods explored in Section 5 in
           MRR =                                                   Table 9. The normalizing flow technique has a neg-
                         |T |                     rank(el )
                                (ei ,rj ,el )‚ààT                    ligible impact on training time because the unsu-
                                                                   pervised technique can be applied prior to training.
    The Hits at k (H@k) is defined as                              The Residual MLP does increase the time per iter-
                   1            X                                  ation as observed by the increased time needed to
      H@k =                                I[rank(el ) ‚â§ k]        complete one epoch. However, the Residual MLP
                  |T |
                         (ei ,rj ,el )‚ààT                           also accelerates convergence which largely offsets
                                                                   the aforementioned slowdown. Across all datasets,
where I[P ] is 1 if the condition P is true and is                 the Residual MLP outperforms the baseline even
0 otherwise. When computing rank(xi ), we first                    when controlling for wall clock time for all but the
filter out all positive samples other than the tar-                shortest of training times.
get entity xi . This is commonly referred to as the
filtered setting. If the correct entity is tied with                  We report the training times for the query en-
some other entity, then we compute its rank as the                 tity extraction methods explored in Section 6 in
average rank of all entities with that score.                      Table 10. The supervised methods introduce the ap-
                                                                   plication of a language model which also increases
C     Model Configuration Details                                  the time per iterations as seen by the time needed
                                                                   to complete one epoch. The effect on accelerating
C.1 Trainable Parameters                                           the convergence of the model is not as pronounced
We report parameter counts for the WN18RR                          which means that in some cases, the supervised
dataset across all the different configurations con-               query extraction techniques do meaningfully in-
sidered in this work in in Table 8. The parameter                  crease the training time compared to the baseline.
                                                               5949
                    Dataset                   # Nodes     # Rels    # Train    # Valid     # Test
                    SNOMED-CT Core             77,316      140      502,224    71,778     143,486
                    CN82K                      78,334       34       81,920    10,240      10,240
                    FB15K-237                  14,451      237      272,115    17,535      20,466
                    WN18RR                     40,943       11       86,835     3,034       3,134

                                               Table 7: Dataset statistics


    Configuration          Trainable Params   Delta (%)       cross entropy loss function. We use the Adam op-
                         BERT-base                            timizer (Kingma and Ba, 2015) with decoupled
    BERT-ResNet                 33.2M             -           weight decay regularization (Loshchilov and Hut-
     +Normalizing Flow          33.2M            0%           ter, 2019). We set the learning rate to 1e-3 and set
      +Fine-tuning             143.1M          331.2%         the weight decay coefficient to 1e-4. We reduce
      +Linear Probe             34.2M           3.0%
      +Prompt Tuning            33.6M           1.2%          the learning rate by a factor of 0.5 if the validation
     +MLP                       34.4M           3.6%          MRR has plateaued for 3 epochs. We use label
     +Residual MLP              34.4M           3.6%          smoothing with a value of 0.1, clip gradients to a
      +Prompt Tuning            34.8M           4.8%
                                                              max value of 1.
                         BERT-large
    BERT-ResNet                 58.9M             -           E.2    BERT-ResNet
     +Residual MLP              61.0M           3.6%
      +Prompt Tuning            61.6M           4.7%          We reuse the reported hyperparameters from
                                                              Lovelace et al. (2021) for the BERT-ResNet rank-
    Table 8: Parameter Counts for WN18RR Models               ing architecture which we redescribe here. We set
                                                              f = 5 where f is the hyperparameter that controls
                                                              the side length of the spatial feature map produced
D     Additional Figures                                      by the initial 1D convolution. We set N = 2 where
D.1 Effect Of Embedding Processing                            N controls the depth of the convolutional network.
    Techniques                                                Our BERT-ResNet model then consists of 3N = 6
                                                              bottleneck convolutional blocks. The dimensional-
We report the embedding metrics across all datasets
                                                              ity of the model is simply determined by the dimen-
in Figure 5.
                                                              sionality of the language model, e.g. d = 768 for
D.2 Effect Of Query Extraction Techniques                     experiments with BERT-base and PubmedBERT
                                                              and d = 1024 for experiments with BERT-large.
We report the performance of different query entity
                                                              We apply dropout with drop probability 0.2 after
extraction techniques broken down by the connec-
                                                              the embedding layer and apply 2D dropout (Tomp-
tivity of the query entity in Figure 6.
                                                              son et al., 2015) with the same probability before
E     Implementation Details                                  the convolutions. We apply dropout with probabil-
                                                              ity 0.3 after the final fully connected layer. These
We outline our implementation details below. We               hyperparameter values are simply the default val-
begin by outlining the details shared across all ex-          ues reported by Lovelace et al. (2021).
periments and then outline the details specific to
the experiments performed for each of the experi-             E.3    Candidate Retrieval
ments.                                                        We describe implementation details pertinent to
                                                              the experiments conducted in Section 5. To isolate
E.1     Training Procedure                                    the impact of the structure of the entity embedding
We train all ranking models for a maximum of                  space, we utilize a single shared bias term across all
200 epochs and terminate training if the validation           entities instead of the per-entity bias term utilized
MRR has not improved for 20 epochs. We evaluate               by Lovelace et al. (2021). Thus the entity ranking
the model with the highest validation MRR upon                is determined entirely by the query vector and the
the test set.                                                 entity embeddings. All future experiments also use
  We use a batch size of 64 with the 1vsAll train-            this shared bias term.
ing strategy (Ruffinelli et al., 2020) with the binary           For all of our embedding processing techniques,
                                                          5950
  Figure 5: Intrinsic evaluation of embedding processing techniques. We note the MRR for each approach in parenthesis.




Figure 6: Performance delta of different extraction techniques across queries of varying connectivity. Error bars indicate 95%
confidence intervals.



                                                            5951
 Configuration                           SNOMED CT Core                                              CN-82K
                                          Wall Clock Time                                        Wall Clock Time
                        Per Epoch     Best Validation MRR    Breakeven Point    Per Epoch    Best Validation MRR   Breakeven Point
 BERT-ResNet             12m31s           22h57m49s                 -             4m6s           5h33m38s                -
  +Normalizing Flow      12m38s           28h38m39s              1h2m52s          4m7s           5h21m56s             1h6m55s
  +Residual MLP           22m9s            52h5m26s              1h6m46s         7m20s           5h38m22s             1h43m9s

                                             FB15k-237                                              WN18RR
 Configuration                            Wall Clock Time                                        Wall Clock Time
                        Per Epoch     Best Validation MRR    Breakeven Point    Per Epoch    Best Validation MRR   Breakeven Point
 BERT-ResNet             11m52s            25h7m37s                 -            3m56s           11h40m37s                -
  +Normalizing Flow      11m50s            18h10m8s              35m32s          3m56s            10h10m7s             43m55s
  +Residual MLP          14m31s            15h0m48s              14m31s          5m44s             11h5m2s             28m37s

Table 9: Run time for best supervised and unsupervised processing techniques from Section 5. We report the
average wall clock time per epoch, the total time until the peak validation MRR, and the breakeven point where the
configuration begins to outperform the baseline.

  Configuration                       SNOMED CT Core                                                CN-82K
                                        Wall Clock Time                                         Wall Clock Time
                      Per Epoch     Best Validation MRR     Breakeven Point    Per Epoch    Best Validation MRR    Breakeven Point
  BERT-ResNet          12m32s           34h17m41s                 -             4m1s            5h25m20s                 -
   +Linear Probe       18m51s            42h8m20s             20h29m38s         6m25s           4h52m17s             4h52m17s
   +Prompt-tuning      26m10s           60h48m38s             41h37m57s         8m42s           11h2m26s             5h40m58s

                                           FB15k-237                                               WN18RR
  Configuration                         Wall Clock Time                                         Wall Clock Time
                      Per Epoch     Best Validation MRR     Breakeven Point    Per Epoch    Best Validation MRR    Breakeven Point
  BERT-ResNet          11m52s           15h2m11s                  -             3m54s           10h42m4s                 -
   +Linear Probe       23m19s           23h42m57s                N/A            6m3s            10h8m40s             6h36m41s
   +Prompt-tuning      32m43s           47h22m32s                N/A            8m47s           20h36m0s             14h1m5s

Table 10: Run time for query entity extraction techniques from Section 6. We report the average wall clock time
per epoch, the total time until the peak validation MRR, and the breakeven point where the configuration begins to
outperform the baseline.


we decouple the entity embeddings fed to the con-                    matrix with ones on the diagonal, U ‚àà Rd√ód is a
volutional model and the entity embeddings used                      strictly upper triangular matrix, and s ‚àà Rd is a
for candidate ranking. All of our transformations                    vector. During the training process, we fix P and
are only applied to the entity embeddings used for                   learn the parameters for L, U, and s.
candidate ranking.                                                      We train the Normalizing Flow on the set of
                                                                     entity embeddings with a batch size of 64 for a
E.3.1 Normalizing Flow                                               maximum of 500 epochs using a learning rate of
We define the normalizing flow with the transforma-                  1e-3 with the Adam optimizer (Kingma and Ba,
tion T ‚àí1 (x) = Wx + b where W ‚àà Rd√ód and                            2015). We clip gradients to a max value of 1 and
x, b ‚àà Rd4 . To ensure the invertibility of W and                    use the checkpoint that acheived the lowest train-
to simplify the computation of the Jacobian deter-                   ing loss to transform the embeddings for candidate
minant, we follow Kingma and Dhariwal (2018)                         ranking. We normalize the transformed embed-
and parameterize W using its LU decomposition.                       dings to have unit norm before use in candidate
so W = PL(U + diag(s)) where P ‚àà Rd√ód is a                           ranking so an entity embedding, ei , is transformed
                                                                                  ‚àí1 (e )
permutation matrix, L ‚àà Rd√ód is a lower triangular                   as eÃÉi = ‚à•TT‚àí1 (e  i
                                                                                             .
                                                                                       i )‚à•2

   4
     This transformation consistently outperformed more ex-          E.3.2     MLP and Residual MLP
pressive nonlinear flows (e.g. GLOW (Kingma and Dhariwal,
2018)) in our preliminary experiments. It‚Äôs possible that a          For the supervised transformations, we set the di-
more comprehensive exploration of flow architectures and
hyperparameter choices would lead to improvements over our           mensionality of the hidden layer to match the di-
design, but we leave such an exploration to future work.             mensionality of the entity embeddings. We use a
                                                                5952
ReLU nonlinearity and apply dropout with drop             the frozen model (Li and Liang, 2021). We param-
                                                                                                       ‚Ä≤
probability 0.1 after the first projection. We found      eterize the prompt embeddings, pi,j ‚àà Rd , in a
it necessary to reduce the learning rate for the MLP      low-dimensional space where d‚Ä≤ < d, and learn
to stabilize training so we set the learning rate to      an MLP with one hidden layer to project them to
1e-4 for the MLP parameters. For the residual MLP,        the dimensionality of the language model. We set
we also initialized the final linear layer to zeros so    d‚Ä≤ = 256 in this work and apply dropout with drop
that the candidate embeddings were equivalent to          probability 0.1 before the MLP and after the first
the original embeddings at the start of training. All     projection. The dimensionality of the hidden layer
other hyperparameters remained fixed.                     is set to d/2. We also apply a shared layer normal-
                                                          ization layer to the output of the MLP.
E.4   Embedding Extraction Ablation                          Therefore       the    input     to   the    ith
We describe implementation details pertinent to           layer      of     the    language      model     is
the experiments conducted in Section 5.5. We use          si = [LN(MLP(pi,0 )), . . . , LN(MLP(pi,k )), xi,0 , . . . , xi,n ]
the HuggingFace Transformers library (Wolf et al.,        where LN(MLP(pi,j )) ‚àà Rd and xi,j ‚àà Rd are
2020) to work with pretrained language models.            the transformed prompt token and tokenized entity
For this set of experiments, we utilize the normaliz-     embedding respectively for the j th position at the
ing flow technique for candidate ranking to isolate       ith layer. We use k = 3 prompt tokens across
the effect of the extraction techniques. For the          all experiments in this work. We extract the
supervised extraction experiments, we utilize the         entity representation by mean pooling across all
most effective unsupervised embeddings with the           intermediate states in each layer and aggregate
normalizing flow for candidate ranking.                   across layers with a learned linear combination.
                                                          We set the learning rate for the parameters for
E.4.1 MLM Pre-training                                    embedding extraction to 5e-5.
We fine-tune the language models using the MLM
pretraining objective over the set of textual entity      E.6     Effect of Language Model Selection
identifiers. We fine-tune the language models for 3       We describe implementation details pertinent to the
epochs with a batch size of 32 and a learning rate of     experiments conducted in Section 7. For the unsu-
3e-5. We use a linear learning rate warmup for first      pervised embedding extraction, we utilize mean-
10% of the total training steps. For SNOMED-CT            pooled embeddings from language models with
Core, CN82K, and WN18RR we set the maximum                additional MLM pretraining upon the set of entity
sequence length to 64. For FB15k-237, we set the          names. All other hyperparameters are kept constant
maximum sequence length to 256 to account for the         from earlier sections.
longer entity descriptions. All other hyperparame-
ters follow the default values from Huggingface.          E.7     Ensembling

E.5   Query Entity Extraction                             For our ensembling experiment, we train a trans-
                                                          former model that accepts a [CLS] token, the em-
E.5.1 Linear Projection                                   bedded query entity, and the embedded relation
We learn a linear projection that is applied to every     entity. This can be viewed as a simplified version
hidden state of the frozen model as hÃÉl,j = hl,j W‚ä∫ +     of the HittER model from Chen et al. (2021) that
b where hl,j ‚àà Rd , W ‚àà Rd√ód , and b ‚àà Rd . We            doesn‚Äôt utilize any additional graph context. The
then max-pool across every token in each layer            [CLS] embedding output from the final layer is
to produce a single feature vector for each layer ,       used for candidate scoring.
hÃÉl . and aggregate these features using P a learned         We tune hyperparameters by running 20 trials of
linear combination across layers eÃÉi = L   l=1 Œªl ¬∑ hÃÉl   a random search over the grid of hyperparameters
where Œªl = softmax(a)l and a ‚àà R is a learned
                                       L
                                                          defined in Table 11. All models are trained for a
vector of scalars. We set the learning rate for the       maximum of 200 epochs with the AdamW opti-
parameters for embedding extraction to 5e-5.              mizer. We linearly warm up the learning rate for
                                                          the first 4000 steps before annealing it with a cosine
E.5.2 Prompting                                           decay schedule over the rest of training. We clip all
We learn continuous prompts that we prepend to            gradient norms to 1 and apply early stopping with
the language model inputs at every layer to prompt        a patience of 50 epochs.
                                                      5953
                  Hyperparameter              Search Range                    Selected Value
                                                                           FB15k-237   WN18RR
                  Learning Rate       [3e-3, 1e-3, 5e-4, 3e-4, 1e-4]         3e-4        3e-3
                  Weight Decay      [.3, .1, .03, .01, .001, 1e-4, 1e-5]      .01         0.1
                  Output Dropout          [.1, .2, .3, .4, .5, .6, .7]         .7          .5
                  Input Dropout           [.1, .2, .3, .4, .5, .6, .7]         .6          .5
                  Label Smoothing           [.1, .2, .3, .4, .5, .6]           .2          .2
                  Number Layers                     [4,5,6]                    6           5
                  Attention Heads                      8                       8           8
                  Embedding Dim                       320                    320         320
                  Feedforward Dim                    1280                    1280        1280

                      Table 11: Hyperparameter Search Space for Transformer Model


F   Validation Results
We report the validation results corresponding to
our final results reported in Table 5 in Table 12




                                                      5954
                                                        SNOMED CT Core                   CN-82K                    FB15K-237                    WN18RR
                                                 MRR     H@1     H@3    H@10    MRR    H@1    H@3    H@10   MRR    H@1    H@3    H@10   MRR    H@1    H@3    H@10
BERT-ResNet + Normalizing Flow                   .510     .403   .568    .714   .196   .133   .216   .323   .362   .279   .393   .529   .582   .511   .610   .729
BERT-ResNet + Prompt-tuning + Normalizing Flow   .517     .411   .574    .719   .202   .137   .223   .329   .361   .278   .394   .530   .591   .521   .618   .736
BERT-ResNet + Residual MLP                       .551     .445   .608    .754   .213   .142   .235   .356   .378   .286   .414   .564   .592   .521   .621   .737
BERT-ResNet + Prompt-tuning + Residual MLP       .551     .444   .612    .757   .218   .146   .240   .363   .377   .287   .410   .564   .600   .531   .626   .742


                                  Table 12: Validation results corresponding to results reported in Table 5.




                                                                                 5955
